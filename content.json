{"meta":{"title":"DecodeZ","subtitle":"刚日读经，柔日读史","description":"刚日读经，柔日读史","author":"Pan Zhang","url":"https://decodezp.github.io"},"pages":[{"title":"ABOUT","date":"2018-11-14T14:13:51.000Z","updated":"2018-11-14T14:56:02.276Z","comments":true,"path":"about/index.html","permalink":"https://decodezp.github.io/about/index.html","excerpt":"","text":"刚日读经柔日读史昼进其技夜付诸笔"},{"title":"DOWNLOADS","date":"2018-11-14T14:14:08.000Z","updated":"2018-11-19T13:40:34.297Z","comments":true,"path":"downloads/index.html","permalink":"https://decodezp.github.io/downloads/index.html","excerpt":"","text":"E-BooksProgramming PDF 深入理解计算机系统原书第2版英文版 PDF Clean Architecture - Robert C. Martin PDF 软件架构模式 - Mark Richards History mobi 世界文明史（英文全套）威尔杜兰特 Cool Technical Slides/Papers/Articles PDF Efficiency with Algorithms, Performance with Data Structures - Chandler Carruth"}],"posts":[{"title":"云计算的发展需要向社区街道管理看齐","slug":"thoughts1-cloud-community","date":"2018-11-28T05:47:57.000Z","updated":"2018-11-28T05:53:19.517Z","comments":true,"path":"2018/11/28/thoughts1-cloud-community/","link":"","permalink":"https://decodezp.github.io/2018/11/28/thoughts1-cloud-community/","excerpt":"服务云计算本质上是一种服务。由各种不同的组件为租户提供计算、网络和存储服务。 用户对这些服务的要求除了功能之外，还有安全性、可用性、性能、成本、迁移难度、SLA等一系列要求。 与之类比，社区街道作为一个完整的功能单元，各个基层职能部门，也为社区内的居民提供各类生活服务。 如何做好基层工作，是需要费一番脑筋的。","text":"服务云计算本质上是一种服务。由各种不同的组件为租户提供计算、网络和存储服务。 用户对这些服务的要求除了功能之外，还有安全性、可用性、性能、成本、迁移难度、SLA等一系列要求。 与之类比，社区街道作为一个完整的功能单元，各个基层职能部门，也为社区内的居民提供各类生活服务。 如何做好基层工作，是需要费一番脑筋的。 服务网格下图是我在北京中关村某社区拍到的当地派出所的“网格团队”成员和工作职责。 如果你熟悉云计算，熟悉当前的领先理念，那么service mesh这个词你肯定不陌生，这是当前容器和微服务领域的最新热点，拥有Istio、Envoy等一众明星开源项目，并且有Google、AWS、Alibaba等大佬拥趸。这个词翻译过来就是服务网格。 而社区街道提出的这个“网格”的概念，明显领先于自诩为科技前沿的云计算。 如果仔细阅读一下上图中的“工作职责”，就能够轻易地将其内容与时下云计算和企业数字化转型热炒的概念对应起来： 管理网格单元：Microservice微服务 落实基信息采集：Digital Twin数字孪生 综合网格力量：Orchestration协同 加强依法自治：Decouple解耦/Distrubute分布式 排查隐患：Situational Awareness态势感知/Active Defence主动式防御 协调解决社会服务管理中存在的问题：Full Stack Management全栈管理 推进公共服务建设：Aglie敏捷/DevOps 监督管理网格力量，督促责任落实：Sidecar 及时上报网格工作数据：Telemetry遥测 完成街道交办的其他工作：Serverless无服务器 总结就是这个街道派出所就是Community-Native Microservice &amp; Service Mesh &amp; Serverless &amp; Security的典范，理念领先云计算至少5年。 好好学习为什么街道派出所的理念能领先云计算的发展？道理都是殊途同归的，很多理念（经验）的获得都是靠积攒年头。 云计算方兴未艾，但毕竟用户还不足够多，问题暴露还不足够全面，或者说，没太多管理经验。而派出所展开基层管理工作的时间至少比在坐的诸位岁数都长。同时基层群众形形色色，就像软件测试时的边界条件，绝对都能满足。 在此种“得天独厚”的条件下总结出的经验，云计算从业者除了好好消化吸收之外，也可以小小的自鸣得意一下，毕竟你仅仅用了10年就追上了街道派出所。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"},{"name":"cloud","slug":"cloud","permalink":"https://decodezp.github.io/tags/cloud/"}]},{"title":"几句话说清楚3:什么是False Sharing","slug":"quickwords3-falsesharing","date":"2018-11-27T05:12:54.000Z","updated":"2018-11-27T05:22:37.184Z","comments":true,"path":"2018/11/27/quickwords3-falsesharing/","link":"","permalink":"https://decodezp.github.io/2018/11/27/quickwords3-falsesharing/","excerpt":"不用图以为又要见到那几张网上已经用烂了的图了是不是？这次我们不用图来讲这个事。","text":"不用图以为又要见到那几张网上已经用烂了的图了是不是？这次我们不用图来讲这个事。 Cache line是64个Byte，我们经常操作(R/W)的变量是4个或者8个Byte。 于是一个Cache line里就可以放好几个变量，比如说其中有两个变量A和B。 当CPU0写入A，CPU1写入B的时候，就发生了False Sharing，就这么简单。 所谓“假共享”，其实就是你以为你俩自己操作自己的变量是共产国际按需分配互不影响，其实都是假象。 很多材料上说是因为不同的CPU核共享了相同的Cache Line，其实并不严谨。根本因素是不同的CPU核需要更新的缓存出现了地址上的重叠。 那么当其中一个核更新了它的变量A之后，CPU并不能识别出是哪4个Byte或8个Byte地址上的数据被更新，而只能认为该变量所在的整条64Byte Cache Line都应该被更新。 所有有和这64Byte重叠的Cache Line，不管在哪个CPU核上，都需要被更新，这样才能保证大家手头的数据是一致的。 于是乎，和这64Byte地址存在重叠的变量B所在的CPU1中的缓存也需要被更新，自然就影响到了性能。 如果只是读，就没有这个问题，因为不需要关心缓存一致这个事。 示例这里有一个活生生的代码的例子： https://github.com/PanZhangg/x86perf/blob/master/false_sharing_padding.c 12345678910struct counter_t &#123; uint32_t c1; #ifdef PADDING_64_BYTE uint32_t padding[15]; #elif PADDING_128_BYTE uint32_t padding[31]; #else #endif uint32_t c2;&#125;; 本来是打算用来验证在CPU预取开启的情况下到底是应该Padding 64还是128，但在Haswell和Skylake上验证，这两个长度都没有区别。 后来查找资料是在Sandy bridge上需要padding到128，但我这里没有这么老的CPU….先这样吧.. 上面的代码注意用-O0编译。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"几句话说清楚2:CPU缓存的组织形式","slug":"quickwords2-cacheassociativity","date":"2018-11-25T07:18:27.000Z","updated":"2018-11-25T07:34:15.623Z","comments":true,"path":"2018/11/25/quickwords2-cacheassociativity/","link":"","permalink":"https://decodezp.github.io/2018/11/25/quickwords2-cacheassociativity/","excerpt":"缓存缓存和其他存储形式在功能形式上没有太大区别，均是输入一个地址，还你一个数据。但作为一个缓存，要考虑如何在有限的容量下保证较高的命中率以及查找效率(相关阅读)。这个问题从本质上来说，就是如何建立缓存地址与内存地址的映射关系。","text":"缓存缓存和其他存储形式在功能形式上没有太大区别，均是输入一个地址，还你一个数据。但作为一个缓存，要考虑如何在有限的容量下保证较高的命中率以及查找效率(相关阅读)。这个问题从本质上来说，就是如何建立缓存地址与内存地址的映射关系。 组织形式缓存按照一个Cache Line的长度（主流长度为64Byte）为粒度来组织： 各种不同的映射形式就是在决定内存中某一个特定地址范围内的数据，具体可以放到哪一个Cacha Line里去。 能想出来的方式也无外乎三种： 哪个都可以放 只能放到第N个（N是内存地址的函数） 只能放到第N个至第M个（M也是内存地址的函数） 其实基本上这篇文章可以结束了，很多技术都不是什么新鲜的“创想”，只是给朴素的思想内核穿上了一层“术语”的外衣。 Direct Mapping这就是上面说的第二种方式，某一个内存地址段的数据，只能放在第N个Cache Line里 Pros:查找快，一次寻址，有就是有，没有就是没有，不啰嗦（因为只需要验证一个Cache Line中是否存在该地址） Cons:命中率低，CPU经常需要相邻地址的数据，而根据规则，同属于第N个Cache Line的数据会互相排斥，不会同时出现在缓存里 Fully Associative这就是第一种方式，随便放。 Pros:命中率高，过去和未来一段时间内需要的数据都可以被放在缓存内，同时不用担心被相邻地址上的数据踢出 Cons:查找慢，确认一个地址是否在缓存里通常需要遍历整个缓存（Miss的情况） n-Way Set Associative Cache这就是第三种方式了，颜色相同的内存地址范围和缓存Cache Line互相对应，不能越界。每一个颜色就是一个Way。 但如果单独拿出某一个颜色来看，是Fully Associative的方式。 这么做当然是为了充分发挥前两种方式的优势。既可以存在相邻内存中的数据以提高命中，同时也一定程度上减少了查找范围，提升查找效率。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"XXV710网卡Target Link Speed探秘","slug":"x710-target-link-speed","date":"2018-11-23T11:26:48.000Z","updated":"2018-11-23T11:31:44.132Z","comments":true,"path":"2018/11/23/x710-target-link-speed/","link":"","permalink":"https://decodezp.github.io/2018/11/23/x710-target-link-speed/","excerpt":"发现用lspci指令查看PCIe设备，特别是网卡设备经常会查看LnkCap及LnkSta字段，以确保网卡运行在期望的PCIe总线类型/带宽上，从而保证网卡的性能。 最近拿到一块XXV710-DA2，插上之后简单看了一下状态。LnkCap和LnkSta均显示为Speed 8GT/s，Width x8，没太大问题。这时候无意中瞥见LnkCtl2中Target Link Speed显示为2.5GT/s，引发了兴趣。","text":"发现用lspci指令查看PCIe设备，特别是网卡设备经常会查看LnkCap及LnkSta字段，以确保网卡运行在期望的PCIe总线类型/带宽上，从而保证网卡的性能。 最近拿到一块XXV710-DA2，插上之后简单看了一下状态。LnkCap和LnkSta均显示为Speed 8GT/s，Width x8，没太大问题。这时候无意中瞥见LnkCtl2中Target Link Speed显示为2.5GT/s，引发了兴趣。 1234LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not SupportedDevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF DisabledLnkCtl2: Target Link Speed: 2.5GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB Target Link Speed关于Target Link Speed是什么，查找到了Intel Skylake Processor External Design Specification(EDS)中的定义： For Downstream Ports, this field sets an upper limit on Link operational speed by restricting the values advertised by the Upstream component in its training sequences. 基本上LnkCap表示支持的速度，LnkCtl2设置你需要的速度，LnkSta显示实际Training好的速度，如果想要修改的话，都是改LnkCtl2的值。 现在的问题就是LnkSta和LnkCtl2矛盾。那么我们现在这块网卡的速度到底是多少？只能实际测试一下。 测试起个pktgen打个性能，是能直接到线速的，也就是说Target Link Speed没有实际起到限制速度的作用。 又查询了一些资料，从这里看到一个帖子：https://communities.intel.com/thread/106568 最终Intel的官方回复是，这个寄存器的值确实和实际速度没有关系。 规范也是你们写的，帖子也是你们回的，现在正话反话都让你说了，搞什么鬼。 最后查到了该寄存器的位置(D0h)，暴力修改一下： setpci -s 0000:18:00.0 d0.B=3 然后就乖乖地显示为8GT/s了，真是个毫无脾气的寄存器，你让别的遵守规范的设备如何自处。 1234LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not SupportedDevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF DisabledLnkCtl2: Target Link Speed: 8GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"}]},{"title":"程序员和工厂劳工有何不同","slug":"programmer-worker","date":"2018-11-22T12:54:07.000Z","updated":"2018-11-22T13:23:21.430Z","comments":true,"path":"2018/11/22/programmer-worker/","link":"","permalink":"https://decodezp.github.io/2018/11/22/programmer-worker/","excerpt":"如今流行的一个说法是，现在的程序员与工业时期的工厂工人并无二致。均是富集于人口密集的城市、均是超时劳动、均是遭受资本家的盘剥、均是一架大机器上的螺丝钉，在超过“劳动年龄”之后被弃如敝屣。基于这些相似点，有些人得出结论，程序员不过是这个时代的“无产阶级”，和以前的流水线工人，纺织厂女工属于同一社会分工和定位。是否当真如此，这个问题值得仔细推敲一下。","text":"如今流行的一个说法是，现在的程序员与工业时期的工厂工人并无二致。均是富集于人口密集的城市、均是超时劳动、均是遭受资本家的盘剥、均是一架大机器上的螺丝钉，在超过“劳动年龄”之后被弃如敝屣。基于这些相似点，有些人得出结论，程序员不过是这个时代的“无产阶级”，和以前的流水线工人，纺织厂女工属于同一社会分工和定位。是否当真如此，这个问题值得仔细推敲一下。 生产资料个人所处的社会阶层，取决于他能让属于他的生产资料产生的价值。传统的生产资料包括实体的机器、厂房、地皮、原材料、资本和人等等。而作为信息时代的标志，人人都可以通过网络获取一项虚拟的生产资料——信息。诚然，信息壁垒依然存在，但普通人能接触到的信息总量和质量与信息革命之前的时代相比已不可同日而语。程序员是与电子计算设备打交道的人，此类设备本质上是信息的产生、加工和分发工具。一台电脑加一条网线，程序员就可以以极其低廉的方式获得他所需要的生产资料。而拥有生产资料的人，就不能再称之为“无产阶级”。我们已经听过了太多程序员在车库创业的故事，也许这些故事仍然可以称之为“个例”，毕竟，哪个时代没有一些白手起家的人。但如果某个行业能在全社会掀起创业的热潮，那么就不能再以孤例的眼光看待。只有在该行业的生产资料极大丰富，且对再加工之后的产品有持续需求的情况下才有可能出现这类情况。是否能以足够廉价的方式获取生产资料，是程序员与工厂工人的第一个区别。 对生产资料的再分工注意这里强调的是再“分”工，而不是再加工。程序员能够开发出各种程序满足人们的需求，工人也能生产出各种生活必需品，所以在生产资料再加工这一点上，两者没有本质区别。专业细分是社会生产率提高的根本因素。每个人只负责整条产业链中的一环，愈发细致的分工与合作是现代生产活动的组织方式。程序员和工人均为某一细分领域的专家，但二者所处的分工链条深度不同。工人是分工链条的末端，他所能做的就是尽自己所能做好手头的事情。而程序员虽然仍然要听老板的，但他手下仍有电子设备作为分工的最后一环。程序员可以通过编码为这些电子设备“分工”，从而令其为程序员服务。从某种意义上说，程序员就是这些电子设备的“老板”。同时随着设备的计算能力越来越强，这些设备就能逐渐胜任更加精细的分工任务。随着分工的深入，一方面带动社会整体劳动生产率的提升，一方面更加高效地产生价值。一个大型工厂的老板最多能令数万工人为其服务，而所有能跑代码的设备都可能为程序员服务。在分工链所处的位置和对生产资料的再分工能力，是程序员与工厂工人的第二个区别。 程序员如何度过”中年危机”其实程序员是新时代的工厂工人这种论调，只不过是之前“青春饭”、“过了30岁不能再编程“等论调的新瓶装旧酒而已。但程序员面对的现实压力确实是不容忽视的问题。很多人学了很多技术，掉了很多头发，但最后仍被公司扫地出门，问题就在于做了无用的努力。解决之道其实就蕴含在前文论述的两点之内： 尽可能占有(处理)更多的生产资料——信息 为尽可能多的电子设备”分工” 实际执行的术便是一定要有自己的“产品”。这当然是一个程序，可以是公司的产品，也可以是个人作品。但需要关注两个关键点： 我的程序是否位于信息交叉的节点或能协助信息的获取、处理及分发 运行我的程序的设备是否在增长 可以看看这些久盛不衰的“产品”：操作系统、数据库、浏览器、服务器软件、办公处理、图像应用处理等等甚或编程语言本身，都是这两个关键点的很好的体现。当你拥有这样的产品时，操心的就不是公司会不会要你了，而是如何高效地指挥你自己这支被你分工的生产队，实践一些大胆的想法。最后附上我最喜欢的历史名人名言作为结尾： 臣但恐富贵来逼臣，臣无心图富贵。 ——杨素","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"几句话说清楚1:为什么CPU L1缓存容量始终很小","slug":"cachesize","date":"2018-11-20T11:45:45.000Z","updated":"2018-11-28T05:52:44.782Z","comments":true,"path":"2018/11/20/cachesize/","link":"","permalink":"https://decodezp.github.io/2018/11/20/cachesize/","excerpt":"问题CPU缓存是影响软件性能的关键因素之一。在做性能调优时，经常关注的一个指标就是缓存的命中率(hit rate)。缓存之所以不会达到100%的命中率，是因为缓存容量有限，不能将内存中的全部数据都同时放入其中。只能将当前最热，相邻最近的数据存入，同时还受多核CPU中缓存同步机制的影响。奇怪的是，CPU的制程、晶体管数量、核心数量一直都在增加，但L1缓存的容量始终维持在一个相当低的水平。为什么不加大L1缓存呢？","text":"问题CPU缓存是影响软件性能的关键因素之一。在做性能调优时，经常关注的一个指标就是缓存的命中率(hit rate)。缓存之所以不会达到100%的命中率，是因为缓存容量有限，不能将内存中的全部数据都同时放入其中。只能将当前最热，相邻最近的数据存入，同时还受多核CPU中缓存同步机制的影响。奇怪的是，CPU的制程、晶体管数量、核心数量一直都在增加，但L1缓存的容量始终维持在一个相当低的水平。为什么不加大L1缓存呢？ 缓存组织形式当然要考虑到成本和功耗，以及边界效益的问题，但这些不是本文讨论的重点。缓存存在的意义是当CPU需要某些数据时，能够以最快的速度给它。这个速度是以CPU时钟周期为计量单位的。在这一个周期内，CPU能处理的数据量并不大。作为L1缓存，首先需要做的就是把这几个周期内的数据保存好，这个确实缓存容量越大，可以做得越好。但把数据喂给CPU，还需要另外一步工作——缓存的查找。种种不同的缓存组织方式和对应的查找机制，其实是在命中率以及查找效率中寻找平衡。 直接映射(Direct Mapping)查找效率高，但命中率很低 全关联映射(Fully Associative Mapping)命中率会提高，但查找效率非常低，与缓存容量成反比 N路组相联映射(N-ways Set-Associative Mapping)折衷方案，平衡命中率和查找效率，也是缓存采用的组织方式 L1$对L1缓存来说，任务很艰巨，既要追求命中率，同时也要保证查找效率，那么解决方法就是缩小体积。既享受N-ways Set-Associative Mapping带来的命中率，同时因为每个Set的尺寸不大，仍然会有很高的查找效率。如果将缓存的容量增大，不仅仅是成本和功耗上得不偿失，也将会让缓存的查找效率降低而使缓存丧失意义。 “大曰逝，逝曰远，远曰反”，以退为进，以曲为直的道理在缓存中有了很好的体现。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"top命令使用方法补遗","slug":"topcmd","date":"2018-11-19T13:25:58.000Z","updated":"2018-11-20T12:11:01.048Z","comments":true,"path":"2018/11/19/topcmd/","link":"","permalink":"https://decodezp.github.io/2018/11/19/topcmd/","excerpt":"更改界面刷新频率 自动刷新 topd输入刷新时间（默认3秒，可调至0.5） 手动刷新空格","text":"更改界面刷新频率 自动刷新 topd输入刷新时间（默认3秒，可调至0.5） 手动刷新空格 屏幕滚动一个屏幕显示不完C使用方向键滚动 可用在使用c和V开启命令行及Forest view之后 查看线程top信息H 查看线程CPU绑定/亲和性状态F移动光标至Last Used Cpu空格q返回 与H配合使用可观察各线程是否与对应的CPU核绑定亲和性 排序M按驻留内存大小排序P按CPU使用率排序T按累计时间排序x高亮排序的列 按NUMA查看CPU使用情况2查看各NUMA节点CPU汇总使用信息3输入节点号，查看该节点各CPU使用信息 按条件过滤‘O’输入过滤条件，如:!COMMAND=top COMMAND栏中不包含top%CPU&gt;3.0 CPU占用率大于3%清除全部过滤条件 = 保存当前命令配置W下次再启动时恢复当前配置形式 其他信息man top","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"}]},{"title":"刚日读经，柔日读史","slug":"gangrirouri","date":"2018-11-18T11:27:23.000Z","updated":"2018-11-19T13:32:44.873Z","comments":true,"path":"2018/11/18/gangrirouri/","link":"","permalink":"https://decodezp.github.io/2018/11/18/gangrirouri/","excerpt":"在不知道什么时候，我们似乎被灌输了一种互补好，什么都是互补好的认知。资源要互补，团队要互补，思想要互补，连看个书也得掐着日子互补。","text":"在不知道什么时候，我们似乎被灌输了一种互补好，什么都是互补好的认知。资源要互补，团队要互补，思想要互补，连看个书也得掐着日子互补。 刚日读经，柔日读史，“刚日”就是阳数的日子，“柔日”就是阴数的日子。因为阴阳要互补，所以刚日要读致虚守弱恒常静笃的经；柔日便要读变动不居周行不殆的史。为此还有各位理论导师的笺注，比如南怀瑾： 亢阳激扬，刚也；卑幽忧昧，柔也。经主常，史主变。故刚日读经，理气养生也；柔日读史，生情造意也。有生有息，合乎天理，何乐而不为哉！ 感觉并不如我总结得那般言简意赅提要钩玄。如果说这种“互补”确实在指导我们的行为，那也无可厚非。而实际上我们日常行事，却和这种思想观念有很大出入。饮食上要以形补形，想要强要壮，自然是找来更强更壮的，绝对不会找短小“互补”的食材。婚嫁上要强强联合，至少至少也要找个“门当户对”的。至于相互互补的情节，不是出现在少儿童话故事里，就是出现在成人童话故事里。嘴里说的是阴阳互补，做的却是采阴补阳的勾当。而最重要的是，没有人觉得有问题。我们妄自接受了这些观念，很少去问这些到底是什么。只是在需要的场合，程式化地提出这一观念。什么是互补，什么是阴，什么是阳，什么是刚，什么是柔。如果我脑中只是一些不明来源，未经考究过的观念，那么什么是我自己。更诡吊的是，人与人之间最大的仇恨与惨剧，都滥觞于这种我们根本自己也没搞清楚的观念。不要说“互补”，即便是稍有不同，那便是异端邪说、是外族、是异教徒、是政治犯；那便会有党争、门户、正宗、政治清洗和宗教审判。信不知凭何而信，恨不知因何而恨。被左右的观念所左右，被迷惑的语言所迷惑，操纵感官输出的表象又被表象所操纵。无论刚日柔日，翻开经史，里面都是这样的故事。只要稍微读几页就会发现，与先前想的正好相反，教给你变化的其实是经，而教给你不变的是史。所以这句话并不是要教给你刚柔相济之道，而是提醒你认清人心之妄作，行为之颠倒，以及，追求真实的难能可贵。谨录于上，念念不忘。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"如何在偷偷搜索关键字后避免令人尴尬的广告","slug":"duckduckgo","date":"2018-11-17T13:13:36.000Z","updated":"2018-11-18T11:48:05.706Z","comments":true,"path":"2018/11/17/duckduckgo/","link":"","permalink":"https://decodezp.github.io/2018/11/17/duckduckgo/","excerpt":"转载自cloudwonders.info 当你在任意一个搜索引擎输入一个关键词之后，你就成了全网全平台追逐的流量热点。 平时大打口水战的各大平台在共享你的隐私数据方面异常团结，在B系网站搜索，在A系T系的应用APP上都会看到为你“量身定制”的推送和广告，延迟不超过一分钟。","text":"转载自cloudwonders.info 当你在任意一个搜索引擎输入一个关键词之后，你就成了全网全平台追逐的流量热点。 平时大打口水战的各大平台在共享你的隐私数据方面异常团结，在B系网站搜索，在A系T系的应用APP上都会看到为你“量身定制”的推送和广告，延迟不超过一分钟。 这一点即便是业界道德楷模G老师都未能免俗，毕竟它也要靠着广告收入维持其智能推荐算法引擎的研发投入。 最可气的是，推送些边栏广告也就算了，竟然连自己看的新闻和短视频内容也都要和搜索记录沾边，在聚会上随便刷下手机就暴露了自己到底是个什么货色。 网络对你的监视是全方位的，除了你主动输入的那些关键字，你平时的谈话、你的地理位置，你周围的环境照片都会被偷偷记录上传，用以支撑靠勤劳质朴的城镇劳动人民手动打标签的“人工”智能工程师们的高薪。 当个人隐私在巨头面前节节败退，当生而为人的尊严在利益机器面前粉碎，当你不能说的秘密被拿来公开叫卖和嘲弄，当互联网利用你心底的弱点反过来操控你之时，难道就没有一款可以放心解放双手，安全地释放自己的求知欲，满足人类最原始的好奇的搜索引擎吗？当然不是这样的鸭—— 这个创立于2008年的搜索引擎，十年来一直在巨头的夹击下惨淡经营。如果没有愈演愈烈的互联网隐私泄露事件、没棱镜门、没有小扎的听证会，恐怕Duckduckgo也不会有近来的长足发展。 Duckduckgo从创立之初秉承的理念就是不对用户的搜索做任何追踪与记录，不把用户的隐私和数据当作公司的资产，做好一个搜索引擎的本分。自2018年之初，该搜索引擎已每日接受多于两千万次的匿名搜索。 Duckduckgo的使用方式与其他搜索引擎没有区别，唯一的不同就是搜索之后在其他任何平台没有相关的广告推送。至于搜索本身的质量和水平，笔者简单做了个对比： 应当说完全可以满足日常应用，不说超越G老师，超越B老师应该是问题不大。同时不用担心在互联网大机器下无所遁形。已经有越来越多的朋友和公司将Duckduckgo设置为了默认搜索引擎。 如果说互联网早已是赢家通吃的寡头时代，用隐私交换在线服务已如缴纳“人头税“一般自然，而在这万马齐喑的时刻，Duckduckgo代表的是一豆星星点点的亮光，为所有在歌舞升平中“心怀鬼胎“的人们擎举起惊奇与愤怒的能力。可以放心大胆地搜索不可描述内容的传送门：https://www.duckduckgo.com","categories":[{"name":"wonder","slug":"wonder","permalink":"https://decodezp.github.io/categories/wonder/"}],"tags":[{"name":"resources","slug":"resources","permalink":"https://decodezp.github.io/tags/resources/"},{"name":"wonder","slug":"wonder","permalink":"https://decodezp.github.io/tags/wonder/"}]}]}