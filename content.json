{"meta":{"title":"DecodeZ","subtitle":"刚日读经，柔日读史","description":"刚日读经，柔日读史","author":"Pan Zhang","url":"https://decodezp.github.io"},"pages":[{"title":"ABOUT","date":"2018-11-14T14:13:51.000Z","updated":"2018-11-14T14:56:02.276Z","comments":true,"path":"about/index.html","permalink":"https://decodezp.github.io/about/index.html","excerpt":"","text":"刚日读经柔日读史昼进其技夜付诸笔"},{"title":"DOWNLOADS","date":"2018-11-14T14:14:08.000Z","updated":"2018-12-25T10:16:03.813Z","comments":true,"path":"downloads/index.html","permalink":"https://decodezp.github.io/downloads/index.html","excerpt":"","text":"E-BooksProgramming PDF 深入理解计算机系统原书第2版英文版 PDF Clean Architecture - Robert C. Martin PDF 软件架构模式 - Mark Richards History mobi 世界文明史（英文全套）威尔杜兰特 Cool Technical Slides/Papers/Articles PDF Efficiency with Algorithms, Performance with Data Structures - Chandler Carruth"},{"title":"NOTES","date":"2018-12-25T09:49:14.000Z","updated":"2019-05-08T14:45:25.071Z","comments":true,"path":"notes/index.html","permalink":"https://decodezp.github.io/notes/index.html","excerpt":"","text":"资治通鉴 萧方等曰：夫蛟龙潜伏，鱼虾亵之。是以汉高赦雍齿，魏武免梁鹄，安可以布衣之嫌而成万乘之隙也！今王谧为公，刁逵亡族，醻恩报怨，何其狭哉！ 包羞忍耻，无不以他日雪洗为快。能由布衣至万乘者，赏罚信明，足以垂范当世。萧方之余，身不居万乘之位而恣代万乘之政，何其陋哉。 玄后刘氏，有智鉴，谓玄曰：“刘裕龙行虎步，视瞻不凡，恐终不为人下，不如早除之。” 此节多刘宋史官曲阿之笔。 戊戌，玄入建康宫，登御坐，而床忽陷，群下失色。殷仲文曰：“将由圣德深厚，地不能载。”玄大悦 此语不妥，当作“圣德深厚，非地不能载之”。 性复贪鄙，人士有法书、好画及佳园宅，必假蒲博而取之；尤爱珠玉，未尝离手 蒲博:古代的一种博戏。亦泛指赌博 桓谦私问彭城内史刘裕曰：“楚王勋德隆重，朝廷之情，咸谓宜有揖让，卿以为何如？”裕曰：“楚王，宣武之子，勋德盖世。晋室微弱，民望久移，乘运禅代，有何不可？”谦喜曰：“卿谓之可即可耳。 枭狡诡诈，虚文矫饰，因人所欲，以从其欲。 其妻怒之曰：“君正坐此口，奈何尚尔！”始曰：“皇后不知，自古岂有不亡之国！朕则崩矣，终不改号！ 魏晋风度，苟不拘于门阀，心无所掩，神徜意徉者，虽山贼野夫，亦可不辱斯意。 刘迈往见玄，玄曰：“汝不畏死，而敢来邪？”迈曰：“射钩斩祛，并迈为三。” 射钩指的是管仲曾经为公子纠于公子小白归国途中箭射衣带钩，斩祛说的是另一个公子重耳，杀手勃辊在公子重耳逃亡途中曾斩断其衣袖。并迈为三，乃刘迈以桓玄比于齐桓晋文之谄词媚言耳。 牢之怒曰：“吾岂不知！今日取玄如反覆手耳；但平玄之后，令我奈骠骑何！”三月，乙巳朔，牢之遣敬宣诣玄请降。 牢之如不欲为三分之计，自当居正位，处义名，寻隙以观衅，使元显桓玄自相图毁，以利卞庄之便；而今尽降于玄，是自斩其势而授人以柄，再无转圜。 备德曰：“卿知调朕，朕不知调卿邪！卿所以非实，故朕亦以虚言赏卿耳。” 宜俟孟春风畅景明之时读来佐酒可也。 业，儒素长者，无他权略，威禁不行，群下擅命；尤信卜筮、巫觋，故至于败。 非斯人，亦不能推其为主。业之所败，败于欲与沮渠比权量力之时。“儒素长者”云云，盖非主因。 说纬曰：“纂贼杀兄弟，隆、超顺人心而讨之，正欲尊立明公耳。方今明公先帝之长子，当主社稷，人无异望，夫复何疑！”纬信之，乃与隆、超结盟，单马入城；超执而杀之。 此非纬昏闇轻信，固邈之所言，如纬自言，邈之所劝，如纬自劝；言而能验，事与意合，此即人之所为。 凉王纂嗜酒好猎，太常杨颖谏曰：“陛下应天受命，当以道守之。今疆宇日蹙，崎岖二岭之间，陛下不兢兢夕惕以恢弘先业，而沈湎游畋，不以国家为事，臣窃危之。”纂逊辞谢之，然犹不悛 颖言无可指摘，然必不见用，以不合纂意故也。向使颖劝以“则二王威服，外族比而咸归，克绍箕裘，可指日待也”，此纂意向往处，其言或可用之。 凝之妻谢道蕴，弈之女也，闻寇至，举措自若 谢道蕴，即谢道韫；“未若柳絮因风起”，林下风气。 会稽内史王凝之，羲之之子也，世奉天师道，不出兵，亦不设备，日于道室稽颡跪咒。 惟闻献之，不闻凝之。另，为人子者，当避父讳。羲之献之，却不讳“之”，乃奉天师道，其徒皆以“之”附名后之故。 德置守宰以抚之，禁军士无得虏掠。百姓大悦，牛酒属路。 -&nbsp;意甚怜之 珪问博士李先曰：“天下何物最善，可以益人神智？”对曰：“莫若书籍。” 书止智余意末，凋朽木死之物。若论最善者，莫若神清智爽之人。 兄子恩逃入海，愚民犹以为泰蝉蜕不死，就海中资给恩。 民诚非愚，实世多磨难，无以为继，非泰无可自托也。 丁亥，宝至索莫汗陉，去龙城四十里，城中皆喜。汗惶怖，欲自出请罪，兄弟共谏止之。 宝不疑汗，不能令汗不自疑也。汗初实不欲反，怎奈皇位至重，一旦染指，譬如养蛊，所余者唯得与死二事也。 黄门侍郎张华曰：“今天下大乱，非雄才无以宁济群生。嗣帝暗懦，不能绍隆先统。陛下若蹈匹夫之节，舍天授之业，威权一去，身首不保，况社稷其得血食乎！” 倘以“陛下雄才，德崇位尊，固宜称制，解民倒悬”请之——德三让乃许之。 甲子晦，魏王珪进军攻之。太史令晁崇曰：“不吉。昔纣以甲子亡，谓之疾日，兵家忌之。”珪曰：“纣以甲子亡，周武不以甲子兴乎？” 客尘妄作，幻翳叠生，诸事纷扰，唯心所造；凭心造境，从心所欲，一丝不挂者，可名心之主。 王光召太原公纂使讨黁。纂将还，诸将皆曰：“段业必蹑军后，宜潜师夜发。”纂曰：“业无雄才，恁城自守；若潜师夜去，适足张其气势耳。 料地不若料敌，料敌不如料势，料势不如料将，料将不如料己。 道子以其笺送恭 敌友不分，情势不明，不败何为。 不知纪极 有1：终极；限度，2、引申为穷尽的意思。 会既败魏兵，矜很滋甚；隆屡训责之，会益忿恚。会以农、隆皆尝镇龙城，属尊位重，名望素出己右，恐至龙城，权政不复在己，已知终无为嗣之望，乃谋作乱。 “疑人不用，用人不疑”，宝既疑会，可为者四，一、速图之；二、委信之，益其兵，许爵荫子，卫辄之事毋再言；余者唯败与死战耳。今宝疑而用之，且夺其兵、树二王、断其所望而谋泄，是逼会反，为政之失，莫甚于此。 宝然之。而卫大将军麟每沮其议，隆成列而罢者，前后数四 御兵以气，当一鼓作之，成列而罢之再三者，是竭己而遗敌也。隆善谋而寡决，知时而亡势，过不在麟。 既而募兵无故自惊，互相斫射。 以财而聚，因财而败，正合其宜。 司马耿稚谏曰：“乾归勇略过人，安肯望风自溃？前破王广、杨定，皆羸师以诱之。今告者视高色动，殆必有奸， 视高色动：智伯从韩魏之君伐赵，韩魏用赵臣张孟谈之计，阴谋叛智伯。张孟谈因朝智伯，遇智果于辕门之外。智果入见智伯，曰：“二主殆将有变，臣遇张孟谈，察其志矜而行高，见二君色动而变，必背君矣。”欲背而图之，当恭顺以匿其情，若露于颜色，殆必知之。 恭罢朝，叹曰：“榱栋虽新，便有黍离之叹！” 榱栋：指屋椽及栋梁。栋折榱崩，比喻当政的人倒台或死去。黍离之悲：指对国家残破，今不如昔的哀叹。《诗经&nbsp;黍离》：彼黍离离，彼稷之苗。行迈靡靡，中心摇摇。知我者，谓我心忧，不知我者，谓我何求。悠悠苍天，此何人哉。 燕主宝闻魏军将至，议于东堂。 魏军新胜，燕实应完守中山，但不可静待其弊。当密遣使于魏，说以一旦魏内有变，燕愿为应之意。则可令珪自顾不暇，而燕坐收渔利。 士大夫诣军门者，无少长，皆引入存慰，使人人尽言，少有才用，咸加擢叙。 言而用之，虚位待之，使人意己为多力，此创业之主延揽之要。 垂在平城积十日，疾转笃，乃筑燕昌城而还。夏，四月，癸未，卒于上谷之沮阳 滑虏此生，心向往之：） 燕军叛者告于魏云“垂已死，舆尸在军。” 垂实未死，且燕新胜，兵未易叛，此垂恐珪走脱，计而诱之；至于“珪欲追之，闻平城已没，乃引还阻山”云云，“阻山”当为“中山”；其料垂将死，故以收定人心为先。 宝之发中山也，燕主垂已有疾，既至五原，珪使人邀中山之路，伺其使者，尽执之，宝等数月不闻垂起居， 数月不归，音信两绝，又垂疾笃，当多发使者，求其速返，奈何闻而不问，误听伪信，乱惑人心，尸骨不还。 垂曰：“司徒意正与吾同。吾比老，叩囊底智，足以取之，终不复留此贼以累子孙也。”遂戒严。 囊，口袋。古称足智多谋的人为“智囊”。此指年虽老，智谋仍够用。 自河以南诸部悉降，获马三十馀万匹，牛羊四百馀万头，国用由是遂饶 非劫掠不足为饶用也；欲以安陈墨守而得富贵，吾知其不可也。 麟归，言于垂曰：“臣观拓跋珪举动，终为国患，不若摄之还朝，使其弟监国事。”垂不从。 此王猛言于苻坚垂终不为人下之事也，今麟奏而垂不省，正宜其分。 苌曰：“吾自结发以来，与人战，未尝如此之快，以千馀兵破三万之众，营地惟小为奇，岂以大为贵哉！” 此语前已述之，再读亦颇能为戏。 后秦主苌以秦战屡胜，谓得秦王坚之神助，亦于军中立坚像而祷之曰: 姚苌弑主篡逆，亦深自耻之。其师无正名，故虽屡胜而犹徨，苌亦行止无度，始戮尸而继求恕宥，是故心不平施，可欺于人，终不可自欺也。 后秦主苌掘秦主坚尸，鞭挞无数，剥衣倮形，荐之以棘，坎土而埋之。 有恩而见仇，是为最仇。姚苌如此自处，正当其理也。 苌曰；“苻登众盛，非旦夕可制；登迟重少决，必不能轻军深入。比两月间，吾必破贼而返，登虽至，无能为也。 苌庙算如神，非深悉三军之情者不能为，故大军之后，粮草继之，辎重未动，情报先行。 祚曰：“此乃卿之忠，固吾求也，前言戏之耳”。待之弥厚，以为中常侍。 此处应为“垂曰”,上亦有以诈为祚之误。 会七夕大宴，青抽剑而前曰：“今天下大乱，吾曹休戚同之，非贤主不可以济大事。卫公老，宜返初服以避贤路。狄道长苻登，虽王室疏属，志略雄明，请共立之，以赴大驾。诸君有不同者，即下异议！” 欲决不决之事，以正合，以奇胜，击而必断，击其节也。 魏王珪东如陵石，护佛侯部帅侯辰、乙佛部帅代题皆叛走。诸将请追之，珪曰：“侯辰等累世服役，有罪且当忍之。方今国家草创，人情未壹，愚者固宜前却，不足追也！” 如慕容农所言：当今岂可自相鱼肉，勇不堪战，志不固持，明不见机者，用之无益，不若纵之以宽，示天下延揽之心。 苌与群臣宴，酒酣，言曰：“诸卿皆与朕北面秦朝，今忽为君臣，得无耻乎！”赵迁曰：“天不耻以陛下为子，臣等何耻为臣！”苌大笑。 此实似抑实扬明贬暗褒之语，臣而能为此者，其智深而不可蠡测 坚之所以亡，由骤胜而骄故也。魏文侯问李克吴之所以亡，对曰：“数战数胜。”文侯曰：“数战数胜，国之福也，何故亡？”对曰：“数战则民疲，数胜则主骄，以骄主御疲民，未有不亡者也。”秦王坚 Cool&nbsp;光可为征引之功，此实李克之见也。 坚曰：“甚哀诸卿忠诚！然吾猛士如虎豹，利兵如霜雪，困于乌合之虏，岂非天乎？ “岂非天乎”、“殆非天乎”为此语者，前后不绝于册。坚不纳左右讽喻而执意灭晋，淝水败绩犹纵虎归山，终致“困于乌合之众”，而作天意杳远之语，知其不可为也。 后秦王苌使人谓苟辅曰：“吾方以义取天下，岂仇忠臣邪！卿但帅城中之人还长安，吾正欲得此城耳。”辅以为然，帅民五千口出城。苌围而坑之，男女无遗， 辅唯苦郡人无辜，苌之议，正中其怀，然前败苌军，杀其父兄，虽苌实欲纵之，不能平诸将也。永远不要放弃自己的筹码 燕冠军将军宜都王凤每战，奋不顾身。前后大小二百五十七战，未尝无功。垂戒之曰：“今大业甫济，汝当先自爱！”使为车骑将军德之副，以抑其锐。 锐者易折，此垂琢磨之术；然不面讽其失，托以自爱其身，此其谢而能效之语。 秦王坚遣领军将军杨定击冲，大破之，虏鲜卑万馀人而还，悉坑之。 大梦初醒，悔恨交集，往日种种，皆为幻影，事与愿违，初心难觅，生亦何欢，死亦何苦。 十一月，嘉入长安，众闻之，以为坚有福，故圣人助之，三辅堡壁及四山氐、羌归坚者四万馀人。坚置嘉及沙门道安于外殿，动静咨之。 “不待两军相当而胜负存亡之机已然存于胸中矣，岂掩于众人之言而以冥冥决事哉”，势竭智枯，乃求于神，若仅示尊崇，或可一战 范阳王德、陈留王绍、骠骑大将军农皆曰：“翟斌兄弟恃功而骄，必为国患。”垂曰：“骄则速败，焉能为患？彼有大功，当听其自毙耳。”礼遇弥重。 谋无必胜，所以胜者，因人设谋也。翟斌之流，胸无城府，目短识浅，适速其败。倘如论以苻坚之待慕容，则必无可为也。 密遣使谓泓曰：“吾笼中之人，必无还理；且燕室之罪人也，不足复顾。汝勉建大业，以吴王为相国，中山王为太宰、领大司马，汝可为大将军、领司徒，承制封拜，听吾死问，汝便即尊位。” 坚待燕族甚厚，而不得其心，盖高位厚币，小惠也；家破国灭，大恨也。欲以小惠货大恨，愚者知其不可也。 农曰：“越有智勇之名，今不南拒大军而来此，是畏王而陵我也；必不设备，可以计取之。”越立栅自固，农笑谓诸将曰：“越兵精士众，不乘其初至之锐以击我，方更立栅，吾知其无能为也。” 农众新胜，其锋甚锐，越立栅自固，欲老其师，先为不可胜，亦无可摘。然秦大势已去，人心慌乱，婴守不出，实已生怯退之心，故胜者胜在已胜，不以力战。农之论越，亦不足观。 坚曰：“卿言是也。然朕已许之，匹夫犹不食言，况万乘乎？ 坚之所重者，崇戴也，垂即远离，已无崇戴之意，坚知其不可强求，乃纵之而去，非不可食言故也。 坚曰：“但引兵少却，使之半渡，我以铁骑蹙而杀之，蔑不胜矣！”融亦以为然，遂麾兵使却 秦军百万，十倍于晋，滚石难止，兵众易乱，此用正之时，而图以奇胜，非所以因势之画也。 夏，五月，桓冲帅众十万伐秦，攻襄阳 晋既知坚深欲图己，奈何兴此无功之师，开门揖盗，自为祸阶？及融马覆以败肥水，谢安夷然而垂军独全，前后思之，此恐燕晋分秦之谋也。 冠军、京兆尹慕容垂言于坚曰：“弱并于强，小并于大，此理势自然，非难知也。以陛下神武应期，威加海外，虎旅百万，韩、白满朝，而蕞尔江南，独违王命，岂可复留之以遗子孙哉！ 卧槽，慕容垂还能表现得再明显一点吗？ 于是群臣各言利害，久之不决。坚曰：“此所谓筑室道旁，无时可成。吾当内断于心耳！” 道傍之筑：比喻无法成功的事。道傍筑室：比喻杂采各家之说。亦比喻无法成功的事。筑室道谋筑：建造；室：房屋；道谋：与过路的人商量。比喻做事自己没有主见，缺乏计划，一会儿听这个，一会儿听那个，终于一事无成。 自以有灭代之功，求开府仪同三司，不得，由是怨愤 明则有暗，亏则由满，因其不平而间之，其怨而怒之，必引之以自斗而后取之，此以小博大之法也。 勇而多力，能坐制奔牛，射洞犁耳 犁耳即犁鏡，胡三省註：「犁耳之鐵厚而堅。」 十二月，临海太守郗超卒。初，超党于桓氏，以父愔忠于王室，不令知之。及病甚，出一箱书授门生曰：“公年尊，我死之后，若以哀惋害寝食者，可呈此箱；不尔，即焚之。”既而愔果哀惋成疾，门生呈 医足痛而斫足，疗手疾则断手，郗超之谓也:D 坚报曰：“朕方混六合为一家，视夷狄为赤子。汝宜息虑，勿怀耿介。夫惟修德可以禳灾，苟能内求诸己，何惧外患乎 此苻坚之所成，亦苻坚之所毁。“内求诸己”乃方家之语，“混六合为一家”此齐物之论，坚欲“垂拱而治”，为而不恃，以至不目而见，不听而闻，虽圣贤而不能也。 王彪之曰：“前世人主幼在襁褓，母子一体，故可临朝；太后亦不能决事，要须顾问大臣。今上年出十岁，垂及冠婚，反令从嫂临朝，示人君幼弱，岂所以光扬圣德乎！ 此明显之理，安岂不知也，所意者，乃桓温所遗之独断专裁之柄也。彪之慎乎！安意若此，明君首当其冲。 坚召见，悦之，问以为治之本，对曰：“治本在得人，得人在审举，审举在核真，未有官得其人而国家不治者也。” 治本在得人，得人在心平，心平在得其所，得其所在审举..政事难治，因审举核真不力，审举所难，因审举者亦心不平也。 帝曰：“天下，倘来之运，卿何所嫌！” 倘来之物：指意外得到的或非本分应得的东西。同“傥来之物”。傥：本义:洒脱不拘,不拘于俗又如:傥然&#40;失志的样子&#41;;傥莽&#40;怅然自失&#41;表示假设,相当于“倘若”、“如果”偶然,意外地况荣宠贵盛,傥来物也,可恃以凌人乎。——欧阳修《新唐书》。又如:傥来&#40;意外得来&#41;;傥然&#40;偶然;侥幸&#41; 秦王坚不以为诛首，又从而宠秩之，是爱一人而不爱一国之人也，其失人心多矣。是以施恩于人而人莫之恩，尽诚于人而人莫之诚。卒于功名不遂，容身无所，由不得其道故也。 秦王何爱评也，其所爱者，宽博之名也。后慕容垂叛秦自立，亦深得苻坚之恩。垂评二人，非坚有另待，乃此二人有别也。 大司马温恃其材略位望，阴蓄不臣之志，尝抚枕叹曰：“男子不能流芳百世，亦当遗臭万年！ 是故不能流芳百世之语也。 坚曰：“卿不能见几而作，虚称燕美，忠不自防，返为身祸，可谓智乎？”对曰：“臣闻‘几者动之微，吉凶之先见者也。’如臣愚暗，实所不及。然为臣莫如忠，为子莫如孝，自非有一至之心者，莫能保 为臣之要，忠为上，畏为中，敬为下，最下才略。 猛能容其所短，收其所长，若驯猛虎，驭悍马，以成大功。《诗》云：“采葑采菲，无以下体。”猛之谓矣。 猛已言明：今日之事，非将军不能破勍敌。成败之机，在兹一举。猛非量大之人，实不可不容耳。若羌前实欲向攻，以慕容垂之事观之，猛必以心计除之。羌后不见于书简，卒年不详，隐而不传，何也？ 猛弗许。羌怒，还营，严鼓勒兵，将攻猛。猛问其故，羌曰：“受诏讨远贼；今有近贼，自相杀，欲先除之！”猛谓羌义而有勇，使语之曰：“将军止，吾今赦之。”成既免，羌诣猛谢。 深疑此二（三）人早有计较，因而唱和，兵老势衰，强敌当前，可砺士气。 王猛言于坚曰：“慕容垂父子，譬如龙虎，非可驯之物，若借以风云，将不可复制，不如早除之。 慕容垂仇雠尚不背之，何为反其恩主。王猛今日之势，全仗苻坚之遇，遇之稍逊，则左右环伺而起，身必无幸，岂容他人共享，定除之以为弭患。 燕之诸将争欲追之，吴王垂曰：不可。温初退惶恐，必严设警备，简精锐为后拒，击之未必得志，不如缓之。彼幸吾未至，必昼夜疾趋；俟其士众力尽气衰，然后击之，无不克矣。 慕容垂不求近利，计划规矩，然贤名远播，不知藏拙，必见疑于燕主。 胤曰：“以温今日声势，似能有为。然在吾观之，必无成功。何则？晋室衰弱，温专制其国，晋之朝臣未必皆与之同心。故温之得志，众所不愿也，必将乖阻以败其事。又，温骄而恃众，怯于应变。大众深 攻守予夺，此皆人事。故工于事者，工于人也。工于人者，善抚吏士之心。 坚遣使谕之曰：“吾待卿等，恩亦至矣，何苦而反！今止不征，卿宜罢兵，各安其位，一切如故。 既反而犹纵抚，未闻如坚者也。翦至亲，厘功臣，独夫之路也。 中军将军慕舆虔曰：“劲虽奇士，观其志度，终不为人用，今赦之，必为后患。”遂杀之。 “一个人的一生，当然要靠自我奋斗，但也要考虑历史的进程”–core 尝讨西部叛者，流矢中目；既而获射者，群臣欲脔割之，什翼犍曰：“彼各为其主斗耳，何罪！”遂释之。 此虽宽厚，却失生杀予夺之权，有赏而无罚，御下无方 时朝廷忧惧，将遣侍中止温，扬州刺史王述曰：“温欲以虚声威朝廷耳，非事实也；但从之，自无所至。” 述乃人杰，但意不重温，又能堪破其意，恐不容于温。 秦王坚命牧伯守宰各举孝悌、廉直、文学、政事，察其所举，得人者赏之，非其人者罪之。 此事推为“连坐”，利弊参半，今世弃之不用，似有深虑，当待日后验之。 今处之塞内，与民杂居，彼窥郡县虚实，必为边患，不如徙之塞外以防未然 御外族，当以离间二字为要。等序其民，许以高低之别，使上烦下，下怨上，上下相离，则可操柄握枢，垂拱而治。 士大夫至相谓曰：“安石不出，当如苍生何 宋王介甫素有重名,称为&quot;国器&quot;&nbsp;:D 俊怒曰：“兄弟之间，岂虚饰邪！”恪曰：“陛下若以臣能荷天下之任者，岂不能辅少主乎！”俊喜曰：“汝能为周公，吾复何忧！李绩清方忠亮，汝善遇之。”召吴王垂还鄴。 兄弟之间，岂可去虚饰耶？帝王之家无人伦，奈何奈何。 混谓玄胪曰：“卿刺我，幸而不伤，今我辅政，卿其惧乎？”胪曰：“胪受瓘恩，唯恨刺节下不深耳，窃无所惧！”混义之，任为心膂。 -&nbsp;混作此问，即有相恕之意，胪不过投其所好耳。若真欲相报，虽不效死，义不能为仇雠所使-&nbsp;混恕胪，示以宽悯，以安人心 绩曰：“皇太子天资岐嶷，虽八德已闻，然二阙未补，好游畋而乐丝竹，此其所以为损也。”俊顾谓曰：“伯阳之言，药石之惠也，汝宜诫之！”甚不平。 绩已施谀辞而仍得怨望，当退，私说以“进无可进，俊乃自危”之语，以欲固太子之位自固也。 会世入言事，与猛争论于坚前，世欲起击猛。坚怒，斩之。于是群臣见猛皆屏息。 猛死坚前，狐假虎威，可得善终，若死坚后，必为亲旧所噬。 王羲之与桓温笺曰：“谢万才流经通，使之处廊庙，固是后来之秀。今以之俯顺荒馀，近是违才易务矣。 此笺虽无可大用，字直千金&nbsp;:D 今根兵初至，形势方振，贼众恐惧，皆有离心，计虑未定，从而攻之，无不克者。 用势之道，疑而迫之，固而离之，锐而沮之，从容而懈之。其道一，其用无穷。 秦太后苟氏游宣明台，见东海公法之第门车马辐凑，恐终不利于秦王坚，乃与李威谋，赐法死。坚与法诀于东堂，恸哭欧血；谥曰献哀公，封其子阳为东海公，敷为清河公 -“献哀”二字，乃故秦太子苌之谥也。 臣光曰：顾命大臣，所以辅导嗣子，为之羽翼也。为之羽翼而教使剪之，能无毙乎！知其不忠。则勿任而已矣。任以大柄，又从而猜之，鲜有不召乱者也。 委以权柄，恰抚其心耳。若不豫顾命，必内自猜忌，适速其祸，此健“渐除”之意。另，多人顾命，必自相剪除，此健离间旧臣之算，必欲大权遗之子孙，不可旁落于人也。 秦太子苌之拒桓温也，为流矢所中，冬，十月，卒，谥曰献哀。 !!一代雄杰殁于无名之手，“竖子必不敢害苌”言犹在耳，故知可胜者，人也；可败者，天也。后：此处有误，不是姚苌 温与秦丞相雄等战于白鹿原，温兵不利，死者万馀人。 此时已有“白鹿原”之名，不知陈忠实在查阅此县二十余卷县志时，上面是否也载有此事？ 耆老有垂泣者，曰：“不图今日复睹官军！” 物不常有，而心恒念之。乃至囿于习心，认物为己，行颠倒之事，人之可悲可幸，皆于此处。 祚、长等匿而不宜 宜应为宣，亦可为言。-文字识别，多以贝叶斯公式判断，字形相似，以“不”字之后何字出现较多（概率较大）为判-可知自然语言中，“不宜”多于“不宣”，故此处识别为“宜” 翼曰：“将军谓平北雄武难制，终将讨之，故取马欲以自卫耳。”浩笑曰：“何至是也！” 图人之要，在阴而密之，不可见获于人，以攻无备也。备而欲图之，鲜无败者。 燕群僚共上尊号于燕王俊，俊许之。 不虚意伪辞，假言佯卑，推而当之，难得一见。 司徒刘茂、特进郎闿相谓曰：“吾君此行，必不还矣，吾等何为坐待戮辱！”皆自杀。 这个如何理解？？加入了相约自杀QQ群？？ 弟苌以马授襄，襄曰：“汝何以自免？”苌曰：“但令兄济，竖子必不敢害苌！” 此龙行虎步，瞻视不凡，自别于轻贱，而能以力济民之人。吾深佩之，慕而后效。 赵汝阴王琨以其妻妾来奔，斩于建康市，石氏遂绝。 石勒起于氓隶，筚路蓝缕，乃成后赵之盛。石虎继之，制冀、并、豫、兖、青、徐、荆之地，兵不可当。于此而绝，仅三十年矣。其兴勃亡忽，殆非天乎。 浩曰：“决大事正自难，顷日来欲使人闷。闻卿此谋，意始得了。 此其心存侥幸，怠惰拖延，不蚤自为计故也。（自知材资不如桓温，德不配位故也） 炜曰：“吾结发以来，尚不欺布衣，况人主乎！曲意苟合，性所不能。直情尽言，虽沉东海，不敢避也！ &quot;结发&quot;一词，一指结婚，另可指”束发“，“束发加冠”之意。后有姚苌语：吾自结发以来，与人战，未尝如此之快云云，当引后解&#63;:D 健怒曰：“吾岂堪为秦王邪！且晋使未返，我之官爵，非汝曹所知也。”既而密使梁安讽玄硕等上尊号，健辞让再三，然后许之。 晋室凌迟，王业偏安，戎夷不知君父，日已久矣。况逐鹿之心，非问鼎而不能已。玄硕不辨形势，加之不谙上意，恐终不能全身于乱世。 初，赵主遵之发李城也，谓武兴公闵曰：“努力！事成，以尔为太子。”既而立太子衍。 许而不予，人心构怨。由亲生恨，恨无可加。轻许重器，必为祸阶。政之所在，平抑人心。 父愔，简默冲退而啬于财，积钱至数千万，尝开库任超所取；超散施亲故，一日都尽。 处乱世，人为贵，财货为轻。得人者，退可全身保家，进可逐鹿中原。愔所以啬于财，乃贱取如珠玉之道也 或告翰称病而私飞骑乘，疑欲为变。燕王皝虽藉翰勇略，然中心终忌之，乃赐翰死 翰经略四方，独不能安内，无人臣之明，不知藏拙以利有用之身，终死乎其所，亦理之所安。 青州上言：“济南平陵城北石虎，一夕移于城东南，有狼狐千馀迹随之，迹皆成蹊。 青州善揣圣意，能谀媚其心，以其欲信而因之，虽无稽之谈亦不见疑，用心深也 陛下与胡通，孰若与晋通？胡，豺狼也，既灭晋，不得不北面事之；若与之争天下，则强弱不敌，危亡之势也，虞、虢之事，已然之戒，愿陛下熟虑之。 此言无差，然世间非无贤语，亦非无进言之阶，但少闻道勤行之士耳。 翰乃阳狂酣饮，或卧自便利，或被发歌呼，拜跪乞食。 此孙膑勾践司马宣帝之故计，真不识耶？翰真雄材。 朕闻良臣如猛虎，高步旷野而豺狼避路，信哉！ 实则明君为猛虎，良臣止假威之狐耳。 是时，庾亮犹上疏欲迁镇石城，闻邾城陷。乃止。上表陈谢，自贬三等 庾亮口颂玄老，外饰宽度，内实不及正反之道，心口不一，内外分析，故焦躁之心屡欲轻率，心为名累，吾甚怜之。 或说皝降，皝曰：“孤方取天下，何谓降也！ 为虎计，当因凌锐之势行反间，布敌酋请降之谣，托内臣通息之书，观时而伪泄，则敌自乱，可不烦而胜也。 于是尚书奏：“魏台请依唐、虞禅让故事。”虎曰：“弘愚暗，居丧无礼，不可以君万国，便当废之，何禅让也！” 生而不得，死又不能，生帝王之家，持孝子之义，无得寸步于彼世，近不虑远，前不思后故也。 光因说曰：“皇太子仁孝温恭，中山王雄暴多诈，陛下一旦不讳，臣恐社稷非太子所有也。宜渐夺中山王权，使太子早参朝政。”勒心然之，而未能从 以外臣而豫帝王家事，是以疏间亲，非力所能制，光已死此语。 俟足下军到，风发相赴，岂非遵养时晦以定大事者邪！ 处约居下，以待时变，非侃所能解也。 夏，四月，乙未，始安忠武公温峤卒，葬于豫章。 一个人一生的起落在史书中只不过是几行文字往往是机关算尽搞下去别人“成功”还没几天自己就陨落得更惨更快慢慢已经不再介意谁胜谁负，谁生谁死甚至明白这里没有好人与坏人之分当温峤毫无征兆的在史书里死了却想起当初他在王敦的酒席上在佯醉的隐忍和胆烈之中就已经编辑好了属于他的那几行文字诺亚方舟最近回复：“害人的是人性恶，这世界最可怕的魔鬼是人心。 …” 温峤欲迁都豫章，三吴之豪请都会稽，二论纷纭未决。 温峤虽未有挟天子之图，豫章乃其旧府，其意与三吴之豪同也。至于司徒导所谓安都建康，不欲离其土而出其根也。此恐亦为今上之意。 及峻平，陶侃奏敦阻军，顾望不赴国难，请槛车收付廷尉。王导以丧乱之后，宜加宽宥 宜徙北边戍卫，非有军功不得回也。 峻方劳其将士，乘醉望见胤走，曰：“孝能破贼，我更不如邪！”因舍其众，与数骑北下突陈，不得入，将回趋白木陂；马踬，侃部将彭世、李千等投之以矛，峻坠马 “若天讨有罪，则峻终灭亡；止以人事言之，未易除也。”&nbsp;–峤再闻此言，当不怒反笑矣。弓长木最近回复：“有时候服务器有问题，重试几次看看。 …” 峤等与公并受国恩，事若克济，则臣主同祚；如其不捷，当灰身以谢先帝耳。今之事势，义无旋踵，譬如骑虎，安可中下哉！ 峤止以义动，恐不为行。为峤计，当说以覆巢唇齿之利，且卑辞以示尊崇，或可为计。 峤表宝为庐江太守 令行以信，不可因胜而废。当拜以庐江太守，并断发以明军法，或可更砺其志。 五月，陶侃帅众至寻阳。议者咸谓侃欲诛庾亮以谢天下；亮甚惧，用温峤计，诣侃拜谢。 温峤擅筹人，而拙于筹国。首倡大义而授柄于侃，已自知势尽，再难为也。 峻闻之，遣司马何仍诣亮曰：“讨贼外任，远近惟命，至于内辅，实非所堪。 亮心决矣，赴诏必厄，为峻计，当托以外贼未轸，中原尤丧，北出速战，伪造战获文书，言亮通敌以求除己，可变客为主。 张竣闻赵兵为后赵所败，乃去赵官爵 骏作竣时竣亦骏，十个字来十个字 阮孚谓之曰：“卿常无闲泰，如含瓦石，不亦劳乎！”壸曰：“诸君子以道德恢弘，风流相尚，执鄙吝者，非壸而谁！ 壸性非峻刻，实厌流俗也。倘时用法家，人皆汲汲，则壸必效老庄，以不合于俗也。 老、庄浮华，非先王之法言，不益实用 非老庄无用，盖世已乱极，无可用之言，乃寄于清净无为，以遁世耳。 敦寻卒，应秘不发丧，裹尸以席，蜡涂其外，埋于厅事中，与诸葛瑶等日夜纵酒淫乐。 应非耽湎之徒，此“拖延症”之表征也。人之为“拖延”者，非事有不急，人无自制也，乃自知力所不逮，事必无成故也。 将举兵伐京师，使记室郭璞筮之，璞曰：“无成。”敦素疑璞助温峤、庾亮， 璞既知此，犹久伴虎，必有沉勇深智于其中也。吾虽不得而知其详，见字如晤，犹有感兴。 峤乃缪为勤敬，综其府事，时进密谋以附其欲。深结钱凤，为之声誉，每曰：“钱世仪精神满腹。”峤素有藻鉴之名，凤甚悦，深与峤结好。 顺附其欲，谄媚事之，不以清名为累，不虑众议枉直，其心不已，唯致其死，可谓真人君子。 琀，荡之长子，有才望，雄欲以为嗣，闻其死，不食者数日。 雄所以不听群臣之鉴而为己意者，欲助琀以军功立威，得为嗣而已。 帝脱戎衣，着朝服，顾而言曰：“欲得我处，当早言！何至害民如此！” 凡于此间而言仁者，吾知其无能为也。 -或说卓：“且伪许敦，待敦至都而讨之。”卓曰：“昔陈敏之乱，吾先从而后图之，论者谓吾惧逼而思变，心常愧之。今若复尔，何以自明！”-为君之计，莫若伪许应命，而驰袭武昌，大将军士众闻 TODO:甘使君何以前后相悖若是耶？按前不欲诈伪反复，弗为口是心非之语，而一旦从之，此必有深论，待深玩而得之。2017第一贴耶^^ 兄与我俱夷狄 夷狄亦以“夷狄”自况耶？鬼子亦自许“鬼子”耶？WTF？ 刘隗为帝谋，出心腹以镇方面。 此谋差矣。今臣强主弱，利在缓纵。尽遂王敦之意，以懈其志，外示荣宠，内遗好玩，一朝发难，“擒之止一力士之力耳”。若“出心腹以镇方面”，敦必无不觉，适速其祸耳。 灰身 灰身，粉身碎骨之意也。 光禄大夫游子远谏曰：“圣王用刑，惟诛元恶而已，不宜多杀。”争之，叩头流血。曜怒，以为助逆而囚之；尽杀徐、彭等，尸诸市十日，乃投于水。于是巴众尽反，推巴酋句渠知为主，自称大秦，改元曰 -计前后事，子远所言，必有赵主无力驭蛮之意，所以犯颜者，非独止杀省刑之说-须喻以七擒孟获之意，则蛮夷可定 今天下大乱，强者为雄。曹亦乡里，为天所相，苟可依凭，即为民主，何必与之力争，使百姓肝脑涂地！吾去此，则祸自息矣。 若退让可恃，妇仁可据，则天下大同可指日而待也。于肆强凌弱之世作恻隐之想，实乃驱民饲虎也。 翰知之，诈为段氏使者，逆于道曰：“慕容翰久为吾患，闻当击之，吾已严兵相待，宜速进也！”使者既去，翰即出城，设伏以待之。宇文氏之骑见使者，大喜驰行，不复设备，进入伏中。 翰策非尽善也，而能颇逞其计，以其尽合宇文之臆想故耳。盖计之得者，不在己而在敌。策之所重，唯造境耳。造敌之欲见之境，策之善者也。 悉独官闻之，曰：“翰素名骁果，今不入城，或能为患，当先取之，城不足忧。” 既闻之，何不示翰以不能，诱而伏之，可乎？ 三国合兵伐廆。诸将请击之，廆曰：“彼为崔毖所诱，欲邀一切之利。军势初合，其锋甚锐，不可与战，当固守以挫之。彼乌合而来，既无统壹，莫相归服，久必携贰，一则疑吾与毖诈而覆之，二则三国自 此六国约而伐秦之局也，用间无疑。为廆画策，可许宇文以边隅之地，外示结好，另布谣曰，廆与宇文谋共伐毖，俟其自乱，可以图毖。宇文不可跨地而有，是失之东隅收之桑榆也。若崔毖宇文有两败之效，则又善焉。 访在襄阳，务农训兵，阴有图敦之志，守宰有缺辄补，然后言上；敦患之，而不能制。 欲图之必秘不使闻，阴蓄异志，外示恭顺，于其意懈而图之，此肆志之道。周访不忍小忿而明其相图之志，此必为乱阶，自取祸耳。 言于曜曰：“大司马遣修等来，外表至诚，内觇大驾强弱，俟其复命，将袭乘舆。”时汉兵实疲弊，曜信之。 事推世易，势如转石，非能力抗也。此处曹君用间，实无一利，舍三族强赵以求进身于汉，吾不知其欲何为也。 选官用人，不料实德，惟在白望，不求才干，惟事请托，当官者以治事为俗吏，奉法为苛刻，尽礼为谄谀，从容为高妙，放荡为达士，骄蹇为简雅，三失也 此来之势，非荡灭不得改易也。 匹磾雅重琨，初无害琨意，将听还屯。其弟叔军谓匹磾曰：“我，胡夷耳；所以能服晋人者，畏吾众也。今我骨肉乖离，是其良图之日；若有奉琨以起，吾族尽矣。” 果有奉琨以起并讨段氏者，则末柸必以全族为先，而后能立。尚使末柸乐见匹磾之败，也可说之以卞庄刺虎之言，使琨多所疑虑。为匹磾计：1.末柸书可隐而不发，另做伪书，示琨以悖慢无晋之意。另邀琨并击末柸，可坐收两败之利。如此虽损伤士众，终不使他人为己害也。2.奉琨以原书，伪许以攻匹磾，诱而伏之，可少杀伤而并末柸之众，利尽归己。但恐琨另有谋划也。为琨计：必见疑，应遣使之末柸所，说以并分匹磾之意。计成，可另谋末柸。 矩欲夜袭之，士卒皆恇惧，矩乃遣其将郭诵祷于子产祠，使巫扬言曰：“子产有教，当遣神兵相助。”众皆踊跃争进。 世有本体，心见呈相；以符为媒，收摄人心。 无乃不可乎 高中语文课上初识此句，以为奇珍好玩，与同桌调笑无已。其时春光饱溢，书声琅琅，虽则试卷小测无尽，终能以此自娱，亦无忧也。不意今日于此重逢，如时光倒流，捧书诵读之声，春光笑靥之情，犹再现也。 猗曰：“兹事已决，吾怜卿亲旧并见族耳！”因歔欷流涕。二人大惧，叩头求哀。猗曰：“吾为卿计，卿能用之乎？相国问卿，卿但云‘有之’；若责卿不先启，卿即云‘臣诚负死罪。然仰惟主上宽仁，殿 1.&nbsp;猗之计得，乃因识人善任。知彼二人无死节之志，故能以数言为事。此其固已筹于前也2.&nbsp;盖小奸者，间于利；大奸者，间于人。 敦闻之，阳惊，亦捕如诛之。 1.非王如不能识此，盖情激于愤，心自蒙蔽2.敦本遇稜甚厚，终以不己用除之，如此可肆其志哉？可遂为帝乎？是以逞虚而失实，人心妄作也。 猗卢用法严，国人犯法者，或举部就诛，老幼相携而行，人问：“何之？”曰：“往就死。”无一人敢逃匿者。 Holy&nbsp;shit…非用法之严，乃洗脑之效也。 徽曰：“将军愚愎以取败，乃复忌前害胜，诛忠良以逞忿，犹有天地，将军其得死于枕席乎！” 徽既之志，曷不蚤自去就。择君不察，怠于行动，此自取祸耳，休怪他人。 勒曰：“吾不喜得幽州，喜得二子。”以宪为从事中郎，绰为参军。 1.宪、绰欲死晋，何能供汉将驱使？2.晋不知宪、绰而勒遇之，故能为勒属。3.固知宪、绰所大欲，非忠非利，乃逞才而已。此亦才能便捷之士所同欲也。4.因其所长而破之，因其所有而用之，此勒之所得所喜也。 石将军之比殿下，犹阴精之与太阳，是以远鉴前事，归身殿下，此乃石将军之明识所以远过于人也，殿下又何怪乎！ 子春之舌，可舔及手肘。 夫谋人而使人觉其情，难以得志矣。 此吾之累述于前也。浚左右皆苛刻小人，遗以厚赂，立时为叛，何苦委屈卑辞，寒左右之心。浚欲自立，此道路皆知，“夫谋人而使人觉其情，难以得志矣”，诚哉斯言，吾当警之。 初，范阳祖逖，少有大志，与刘琨俱为司州主簿。同寝，中夜闻鸡鸣，蹴琨觉曰：“此非恶声也！”因起舞。 祖逖年少，而与刘琨同寝，吾不忍再言也^^ 刘后闻之，密敕左右停刑，手疏上言：“今宫室已备，无烦更营，四海未壹，宜爱民力。廷尉之言，社稷之福也，陛下宜加封赏；而更诛之，四海谓陛下何如哉！夫忠臣进谏者固不顾其身也，而人主拒谏者 娶恶妻则家丧，得良妻则家兴，庶民皇胄无异也。 怀帝亦遇害 大业未成，空余悲恨。 谓我孤弱，不敢出战，意必懈惰；宜且勿出，示之以怯，凿北城为突门二十馀道，俟其来至，列守未定，出其不意，直冲末柸帐，彼必震骇，不暇为计，破之必矣。 此弱生于强，怯生于勇之谓也。吾若处此形势，必坚守勿出，设流言曰段氏将反，使闻于浚。并遣使求和于段氏，言不称浚，使王昌知之。段氏为王浚所驱使，素无怨于勒，此其所愿受也。如此则成上下相疑之势。计成，则待王、段交兵以助段，图浚并收段氏德我之惠。计失，用张宾之言不迟。 遣琨马、牛、羊各千馀匹，车百乘而还，留其将箕澹、段繁等戍晋阳 1.刘琨驱虎吞狼，自将轸灭虎口矣2.猗卢以予为取，势必兴国 琨母曰：“汝不能驾御豪杰以恢远略，而专除胜己，祸必及我。” 驾驭豪杰，以无己为先。故无己则无人可胜己，善下人者上于人也。观琨好为声色以娱己，且假以私好，授柄非人，“我执”必深。 殷常戒子孙曰：“事君当务几谏。凡人尚不可面斥其过，况万乘乎！夫几谏之功，无异犯颜，但不彰君之过，所以为优耳。” 此殷之智也，而子孙效之大不易。盖胸中实有筹策万千，而能吞言不发，面含卑让，非真人断不能为也。果能如此者，不待刘殷之教而自能行之。于此中可稍悟“知（智）”“行”合一之旨。 帝曰：“臣安敢忘之？但恨尔日不早识龙颜！ 能忍此辱，必有大节。 勒谓张宾曰：“王公位重而言卑，其图我必矣。勒乃引兵击瑞，斩之。弥大喜，谓勒实亲己，不复疑也。遣使让勒“专害公辅，有无君之心”，然犹加勒镇东大将军、督并、幽二州诸军事、领并州刺史 1.“弥与刘瑞相持甚急”?此弥智勇窘竭之时，故不明勒欲图己之意也。洎勒除其大困，如溺之得起，不查必矣。故智生于明，明生于勇，勇生于闲。2.为聪计，当表勒大功，加其荣利好玩，以弱其志，并分王弥之众以归己，潜以图勒；为勒计，当阴结晋将，俟时反汉，自固之术也。 苾自称梁、益二州牧、领湘州刺史。 自称亦可揽抚人心，盖因有此名（州牧）即可造相于人心，心因而识此已有之固相，乃因名生相，据相置心，则必以州牧待之。 猗卢以封邑去国悬远，民不相接，乃帅部落万馀家自云中入雁门，从琨求陉北之地。琨不能制，且欲倚之为援，乃徙楼烦、马邑、阴馆、繁畤、崞五县民于陉南，以其地与猗卢；由是猗卢益盛。 强弱消涨，非人力也。拓跋鲜卑得陉北之地，乃乘势也。故君子静修以待变，观势而动，因势而取，乘势而不居。 乂涕泣固请，聪久而许之，曰：“乂及群公正以祸难尚殷，贪孤年长故耳。此家国之事，孤何敢辞！俟乂年长，当以大业归之。” 聪能如此言，必非雄主。大丈夫平靖海内，扫除宗室，当自取大位居之，不然挟震主之功以事他人，其能久乎？重蹈故事而已。 何曾讥武帝偷惰，取过目前，不为远虑；知天下将乱，子孙必与其忧，何其明也！然身为僭侈，使子孙承流，卒以骄奢亡族，其明安在哉！且身为宰相，知其君之过，不以告而私语于家，非忠臣也。 魏晋之士，恨不能立时凭虚羽化，能为目下之难已属非常，岂可以百年身后子孙计劳心哉&nbsp;:D 睿命酌，引觞覆之，于此遂绝 -非能舍小利，乃明足以识大利也。大小相较，去之霄壤，故能引而绝之。 颖官属先皆逃散，惟卢志随从，至死不怠，收而殡之。 &#42;能得一卢志相随，可谓生而不枉矣。&#42;初，卢志之谋多见听于颖。后颖逸乐娇奢，不可谋大，志谋遂寝。然志见其倾败而不易其衷，可谓感于知遇之德，惟欲以死报之，亦可谓死得其所也。 毅女秀，明达有父风，众推秀领宁州事。秀奖厉战士，婴城固守。 欲得人心，必加行赏；虽赏，不如其意，此赏之为祸也赏其所意，则必图再赏，非长久之计赏之其意所必不有者，则为赏赏之赏，虽女子亦可得人死力。 若能委信君子，使各得尽怀，散蒂芥之嫌 1.人常困于外见，而非事之实也2.征而不应，求而不得，以己视之，其忿非尽诛不能平；以天下视之，则无非“芥蒂之嫌”耳。可知，人心皆有常，非心之“小大”各殊，乃眼见不同也。 勒亦被掠，卖为茌平人师懽奴，懽奇其状貌而免之。 世乱，必出英雄，虽起自氓隶而神貌奇伟，殆非天授 愿殿下抚勉士众，靖以镇之，渊请为殿下以二部摧东嬴，三部枭王浚，二竖之首，可指日而悬也。”颖悦，拜渊为北单于、参丞相军事。 刘渊此论可深玩之1.“殿下武皇帝之子，有大勋于王室，威恩远著，四海之内，孰不愿为殿下尽死力者！何难发之！”&#42;果如刘渊所陈，则睹王浚为无物也。我大太弟所以信之，因其欲信，不因事之可信&#42;可知颖智勇并竭，故不明若此也。&#42;卢志何在耶？2.“殿下一发鄴宫，示弱于人，洛阳不可得而至；虽至洛阳，威权不复在殿下也。”&#42;问计于人者，因己之无善计施也，口不宣此而心已自知&#42;故欲不用其计，仅陈以厉害可也，不必细加推敲&#42;设其计可行，为二段论之（…洛阳不可得而至，虽至洛阳，…），则冲折其节，慑服人心3.“渊请为殿下以二部摧东嬴，三部枭王浚，二竖之首，可指日而悬也。”SMART&nbsp;Objective&#42;Specific:“二竖之首”&#42;Measurable:“悬”&#42;Achievable:“摧东嬴，枭王浚”&#42;Realistic:“二部，三部”&#42;Time-bound:“指日”ORZ 丞相从事中郎王澄发孟玖奸利事，劝太弟颖诛之，颖从之。 孟玖亦为谮言所毁？WTF？王澄必知此出必擒孟玖，不若此则引颈待戮矣。此处有意含混，其中关节，不可得闻矣。 颖既杀机，意常悔之，及见拯辞，大喜，谓玖等曰：“非卿之忠，不能穷此奸。” 求心安?&gt;?求事安1.知错而证错之非错，致一错再错，无理之理也。2.孟玖可改是为非，指鹿为马，眩人主之目，塞庙堂之言，屈朝野之心，可谓中官之殊勋，内侍之翘楚也。3.欲图孟玖，止可以奸计构之 退，与雄谋袭阜军，雄曰：“为今计，当如是；而二翁不从，奈何？”离曰：“当劫之耳！” 李离此语自有一番雄才伟略。虽隔千载，读来仍觉胆气弥天。离之智足以识势，勇总以决断，处乎天地间，可以无愧矣。 冏谢曰：“非子，孤不闻过。” 冏有宽人之怀，自省之明，却无自制之力。耽于犬马，穷奢极欲，天机丧尽，此必成擒。 辛冉倾巧，曾元小竖，李叔平非将帅之材。式前为节下及杜景文论留、徙之宜，人怀桑梓，孰不愿之！但往日初至，随谷庸赁，一室五分，复值秋潦，乞须冬熟，而终不见听。绳之太过，穷鹿抵虎。流民不 Dangerous–&nbsp;David&nbsp;Garrett临此曲而温通鉴其乐千金不易也。 卢志谓颖曰：“齐王众号百万，与张泓等相持不能决；大王迳前济河，功无与贰。然今齐王欲与大王共辅朝政。志闻两雄不俱立，宜因太妃微疾，求还定省，委重齐王，以收四海之心，此计之上也。” 卢志乃浊世翩翩佳公子也。 李庠骁勇得众心，赵廞浸忌之而未言。长史蜀郡杜淑、张粲说廞曰：“将军起兵始尔，而遽遣李庠握强兵于外，非我族类，其心必异。此倒戈授人也，宜早图之。 忌其骁勇可遣其逆强敌，胜之则物尽其用，更可恃其微弱而留掩之；败之则假手于敌，更可使其兄弟激于义愤，更附于己也。何故以无妄之言诛之，盖气量狭者智计短，嗜欲深者天机浅也。 相国伦与孙秀使牙门赵奉诈传宣帝神语云：“伦宜早入西宫。” 司马懿若有知于地下，见子嗣假己之名以逞其浅劣，定不以为辱，反哑然失笑也。 言至垂涕，总不听，众遂自溃。总逃草中，模著总服格战；廞兵杀模，见其非是，更搜求得总，杀之。 赵模智勇双全、侠肝义胆，可惜爱错了人&nbsp;:D 滕数密表：“流民刚剽，蜀人软弱，主不能制客，必为乱阶，宜使还本居。若留之险地，恐秦、雍之祸更移于梁、益矣。”廞闻而恶之。 滕数为密表，廞何可得闻？但见廞之警备非常，胜滕远矣。何得不逞其志哉。 事将起，孙秀言于伦曰：“太子聪明刚猛，若还东宫，必不受制于人。明公素党于贾后，道路皆知之，今虽建大功于太子，太子谓公特逼于百姓之望，翻覆以免罪耳，虽含忍宿忿，必不能深德明公，若有瑕 孙秀此论可谓深远。一旦伦登极顶，必又为贾后故事。人人见得伦取权柄之术，则又可复为伦之故事也。此例一开，刀镬将不绝于朝堂也。 以张华、裴頠安常保位，难与行权，右军将军赵王伦执兵柄，性贪冒，可假以济事 此引狼入室之划也。吾将复见犬戎董卓于此也。 今百姓失职，犹或亡叛，犬马肥充，则有噬啮，况于夷、狄，能不为变！但顾其微弱，势力不逮耳。 1.华夷之辨，久已有之。非辨之不明，谋之不断也。盖华夷二种，有无相生，高下相顷、方生方死、方死方生。非先有华夏然后有夷狄，亦非先有夷狄然后有华夏也。无夷狄则华夏失其文章，无华夏则夷狄无以自证。故华夷羁缠，久辩未决也。2.有如上言，则二种必为消涨之势。迨其羸弱而分治之，计之上者也。欲使杂居群处以一华夷，吾知其不可也。势至则变，自然之理也。 岐盛说玮“宜因兵势，遂诛贾、郭，以正王室，安天下。”玮犹豫未决。 宜说以“即诛亮瓘，功在不赏，贾后惮之，必图以专恣，公何处自安？”之言。盖短谋者虑身不虑国，虑短利不虑长益也。 弘训少府蒯钦，骏之姑子也，数以直言犯骏，他人皆为之惧，钦曰：“杨文长虽暗，犹知人之无罪不可妄杀，不过疏我，我得疏，乃可以免；不然，与之俱族矣。 又学一招，嘻嘻&#40;&#42;^__^&#42;&#41; 初，陈群以吏部不能审核天下之士，故令郡国各置中正，州置大中正，皆取本士之人任朝廷官，德充才盛者为之，使铨次等级以为九品，有言行修著则升之，道义亏缺则降之，吏部凭之以补授百官。行之浸 1.此事有必然者也。然过不在中正，亦不在人治。2.法治亦将有乎此弊，因法亦人所制也。当今不正验乎此言哉？天下事莫外乎人事，法亦不能旁逸。3.人治之弊，亦需人医。盖人治之弊，根植于塞，乃滋于暗，其人所行为，为外人所不可得而知也，故能成其所“治”。若彰之于明，与外人消息，则其弊无复可滋也。4.彰之于明者，需以下条件：1.信息来源之多样&#40;.信息采集手段灵活方便.信息采集成本低廉.信息采集者众多&#41;2.信息传播之高效（.信息实时传播.传播成本低廉.传播源广泛|信息载体多样）3.信息反馈之集中&#40;.反馈来源众多.反馈成本低廉.反馈他人之反馈&#41;?||||||||此互联网之谓也。Note:可为善，亦可为恶也。 尚书张华，以文学才识名重一时，论者皆谓华宜为三公。中书监荀勖、侍中冯紞以伐吴之谋深疾之。会帝问华：“谁可托后事者？”华对以“明德至亲，莫如齐王。”由是忤旨，勖因而谮之。甲午，以华都 1.&#63;帝不征华，乃齐王事前后相托故也2.&#63;谮言以入，非因紞之巧舌，帝与华早有分野，此必然之事也3.&#63;按紞所言钟会之事，若求以征华，可言钟会在朝则无反，在外则有反，所制之力强弱非同也。非“上有仁暴之殊，下有愚智之异”，盖远近力殊使之然耳。可知，一事可言为万理，虽悖而同存。理之为理，乃听者以之为理也。所以者，和于听者之隐情哉。4.&#63;华以才名致谗，才位脱离，以其为事而不为人也。若止以末位小甘而自安，可也；若欲尽展才略，但非一人之事耳。P.S.“If&nbsp;you&nbsp;want&nbsp;to&nbsp;go&nbsp;fast,&nbsp;go&nbsp;alone.&nbsp;If&nbsp;you&nbsp;want&nbsp;to&nbsp;go&nbsp;far,&nbsp;go&nbsp;together.”&nbsp;An&nbsp;old&nbsp;African&nbsp;proverb 预在镇，数饷遗洛中贵要；或问其故，预曰：“吾但恐为害，不求益也。” 预之知人事，可谓能矣。可复为其家求美宅良田于洛，效王翦故事，炎但无复疑也。 濬上书自理曰：“前被诏书，令臣直造秣陵，又令受太尉充节度。臣以十五日至三山，见浑军在北岸，遣书邀臣；臣水军风发乘势，径造贼城，无缘回船过浑。臣以日中至秣陵，暮乃被浑所下当受节度之符 濬欲自理，宜陈其意如左：1.推功于众，分己功则己俞得，且令王浑无功2.表王浑不进之明理，示帝以结好睦和之相3.陈孙皓负隅困兽之情，破之不易，一，可彰己功，二，可以形势自伸4.叙失制之过，甘领责逞，明但求有功于社稷，不计身死之意按濬此疏，乖旨多矣1.数典王浑之过2.多以琐琐为辩，不以失制为意3.虽陈以社稷为重，性命为轻之意，然落笔以“明君必能明我意”为要挟，心中愤懑，溢于言表。 它日，又问吾彦，对曰：“吴主英俊，宰辅贤明。”帝笑曰：“若是，何故亡？”彦曰：“天禄永终，历数有属，故为陛下禽耳。”帝善之。 1.吾彦真吾师也2.司马炎好闻此语，此固步自封昏聩自欺之兆也 卫瓘老奴，几破汝家 1.欲图人，必不可使知之!!!!2.帝不欲废太子，故有设问以试之。瓘不知帝意明矣，而欲为废立，能不自取祸乎？3.贾南风不闻朝议而预为设备，临渴而掘井，知其无能为政矣。张泓闻“共富贵”之语，必知“无罪以当贵”矣。 夫谋之虽多，决之欲独 1.成大功者不谋于众2.多智而不足勇，不能决大事3.由1.2可知，能决大事者，必不合于众也&nbsp;:p4.上可决事，下可合众者，殆非天授以济时之用乎？ 吴主爱姬遣人至市夺民物，司市中郎将陈声素有宠于吴主，绳之以法。姬诉于吴主，吴主怒，假他事烧锯断声头，投其身于四望之下。 能得宠于吴主之人，定知事主之道，何能有此蠢行？-疏不间亲-不搦其锋-翕张之道，正反之用，欲图而必不可使其知 羊祜不附结中朝权贵，荀勖、冯紞之徒皆恶之。 良才必不合与流俗，克之可用反间。寒潭秋水最近回复：“你的手段很毒辣，一句话就点出了羊祜这种人的弱点。 …” 祜与陆抗对境，使命常通。抗遗祜酒，祜饮之不疑；抗疾，求药于祜，祜以成药与之，抗即服之。 此棋逢对手风云际会之时也，恨不能目睹耳闻。 东还乐乡，貌无矜色，谦冲如常 以抗之贞亮君子，处群小环伺之地，后必无能为也。 充乃荐恺为吏部尚书，恺侍觐转希，充因与荀勖、冯紞承间共谮之，恺由是得罪，废于家。 操纵君王之术：1.距离之远近——进己出敌2.频率之寡繁——每必谮之3.异口而同声——众口铄金 后固以为请，荀顗、荀勖、冯瓘皆称充女绝美，且有才德，帝遂从之。留充复居旧任。 1.&nbsp;能以丑为美，以猥为德，皆左右之力也，可谓之能&nbsp;:p2.&nbsp;贾南风竟因以得进为太子妃，非人算可及3.&nbsp;郭贾失和，势在必为也&nbsp;:D 丁未，以汝阴王骏为镇西大将军，都督雍、凉等州诸军事，镇关中。 1.&nbsp;诸王力多，则易为衅2.&nbsp;诸王力少，则无以御外晦3.&nbsp;有外姓之敌，续树同姓王为务，此魏之所以禅晋也4.&nbsp;苟无外敌，宜削诸王，此晋之所以乱也5.&nbsp;此无孰优孰劣之争，因于势也寒潭秋水最近回复：“唐太宗《帝范》里也有类似的议论，所遇到的具体形势不同，所采取的统治术不同，很赞同你的看法。 …” -吴人皆归罪于定，而吴主以为忠勤，赐爵列侯。-小人不明理道，所见既浅，虽使竭情尽节，犹不足任，况其奸心素笃而憎爱移易哉！”吴主不从。 此非小人不明理道，乃吴主不明理道也！-小人以曲媚事主，适其道也-苛以明主圣王之道，此其孙皓能明之理乎？罔自取祸耳。-民不罪于主而罪于定，主不罪于定而罪于非定者。此无理之理也，世所屡见。 吴主素衔其切直，且日闻何定之谮，久之，竟徙凯家于建安。 此亦可谓各死其所也。或有问曰：何如对小人？曰：以颜顺之，以礼待之，以利诱之，以令名许之，禽之止一力士之力耳。 且四臣同罪，刘友伏诛而涛等不问，避贵施贱，可谓政乎！ 政，人事也；事，人心也；心，平忿也；能平人心者，善为政者也。 晋王由是意定，丙午，立炎为世子。 1.&nbsp;鱼不可脱于渊，人不可脱于亲2.&nbsp;远近有错，亲疏有别，表疏之万言，不如比周之一语也3.&nbsp;人皆欲亲贤而远佞，贤人者，非好而致之，其自致也4.&nbsp;天下事，皆人事也，除此无他 会王复问，祥对如前，王曰：“何乃似郤正语邪！”禅惊视曰：“诚如尊命。 此刘禅之设构也。欲示无用以自全也。 夫人心豫怯则智勇并竭，智勇并竭而强使之，适所以为敌禽耳。惟钟会与人意同，今遣会伐蜀，蜀必可灭。灭蜀之后，就如卿虑，何忧其不能办邪？夫蜀已破亡，遗民震恐，不足与共图事；中国将士各自思 夫上兵伐谋，上谋攻心也！昭诚规虑深远之主也。 任贤使能，各尽其心，其本根固矣 欲收贤者之心，不为财货，不好浮名，以事任之，可也。 汉人不意魏兵卒至，不为城守调度 出其不意，攻其不守，此战之先也。由是可知，“不意”不在敌而在己；“在己”不在臆而在事；蜀汉为中侍所误，殆于秣厉，终致“不意”之敌，亦如桓灵故事。 然吴主恐布疑惧，卒如布意，废其讲业，不复使昭等入。 吴主剔心明质，能为圣主，观其进退沉虑，非俗学之士可拟，斯非博览之功耶？亦或高士皆嗜读书耶？:p 皓奸巧专恣，将败国家，请杀之！ 欲不利于人，必先以亲善为务，禽之止一力士之力耳。切切不可无权柄又令其知也。 昭累得基书，意狐疑，敕诸军已上道者，且权停住所在，须候节度。 人之心意，时有推移。能操人心之机枢，得愿意之权柄，可谓识于人；欲识人，先识己，究于人，施于法，须加多加揣摩玩味。 1.酒酣，出怨言曰&nbsp;&nbsp;&nbsp;2.布以告吴主，吴主衔之，恐其有变，数加赏赐 此亦同吾前述：1.&nbsp;欲图人，不可知也，而纟林告之2.&nbsp;欲图人，不可知也，故吴主以赏赐兵戈器具抚之3.&nbsp;图于己，不可不知也，而纟林见缚于腊会4.&nbsp;图于己，不可不知也，故吴主咨贤而谋定 妻曰：“不可。君本庶民耳，先帝相拔过重，既数作无礼，而复逆自猜嫌，逃叛求活，以此北归，何面目见中国人乎！”衡曰：“计何所出？”妻曰：“琅邪王素好善慕名，方欲自显于天下，终不以私嫌杀 李衡得如此贤妻，吾慕而羡之极也。 侍中近臣及乳母共牵攀止之，不得出 推吴主近侍，已为纟林之耳目。纟林所规划，深于吴主远矣，可无败乎？ 纪承诏以告尚。尚无远虑，以语纪母，母使人密语纟林。 非尚无远虑，实乃夫妻同体，不可隐瞒之故也。 吴孙林以吴主亲览政事，多所难问，甚惧 事有不可知者，有不可不知者，欲图人，不可知也，欲图己，不可不知也。今吴主多所难问，是欲图人可使其知也。 今与贼家对敌，当不动如山，若迁移依险，人心摇荡，于势大损。诸军并据深沟高垒，众心皆定，不可倾动，此御兵之要也且兵出逾年，人有归志，今俘馘十万，罪人斯得，自历代征伐，未有全兵独克如 按王基用兵，以势为先。势可得，亦可造。然世有得势之人，而造势之人鲜。观事之大概，可得于势，悉谙常理人心，可行于造化矣。王基之谓也。 古之用兵，全国为上，戮其元恶而已。吴兵就得亡还，适可以示中国之大度耳。 此计之非也。诛叛平乱，宜张威示刑，非表大度之时耳。使吴兵还就家室，乃知犯魏之不见罚，后吴主以家室胁之，必又来犯，无怀德之心也。不如尽坑之。 泰每以一方有事，辄以虚声扰动天下，故希简上事，驿书不过六百里。 尽己而知人，故能有此沉勇潜智 初志大其量，能合虚声而无实才。何平叔言远而情近，好辩而无诚，所谓利口覆邦国之人也。邓玄茂有为而无终，外要名利，内无关钥，贵同恶异，多言而妒前；多言多衅，妒前无亲。丰饰伪而多疑，矜 此智能之士所通病也。若能以彼为镜，自揽吾身，祛虚妄浮智，轻慢自执，或可为非常之事于今世也。 不念抚恤上下以立根基，竞于外事，虐用其民，番国之众，顿于坚城，死者万数，载祸而归，此恪获罪之日也 国败非因外敌也，皆内因致也。 昔周亚夫坚壁昌邑而吴、楚自败，事有似弱而强，不可不察也。今恪悉其锐众，足以肆暴，而坐守新城，欲以致一战耳。 虞松此论，清明练达，国士无双 威震其主，功盖一国，求不得死乎！ 若能为守雌谦冲之道，方无忧矣。司马师引责，诸葛恪推功，此皆人之所为难，若能如此，亦可谓一时瑜亮也&nbsp;:p然恪终不能为，虽人主闇弱，亦将覆于“所忌盛满”之故事也。 夏，四月，吴主殂。孙弘素与诸葛恪不平，惧为恪所治，秘不发丧，欲矫诏诛恪。 内廷外臣之故事也1.内臣之重，全赖人主之威2.君死则失权，蚤自拥立太子，以备山陵崩陷3.宜矫诏召非其党者而戮之，竟听外臣之议，身履至危之地而不自知，吾知其无能为也 全公主及侍中孙峻、中书令孙弘固争之，乃止。 1.&nbsp;亲近者施力非疏远者可及2.&nbsp;以人君之尊，父子之亲，内怀忧思而仍夺志于左右，可知2.1&nbsp;欲施力于上，必左右不离也2.2&nbsp;总肃朝纲，不可不有定见也2.3&nbsp;亲己顺意，人皆好之。权柄旁落，不可不慎于左右也 八月，戊寅，舞阳宣文侯司马懿卒。诏以其子卫将军师为抚军大将军，录尚书事。 当世强人，终为黄土，若地下有知，见其生前所屠戮，可继守其强乎？又令其见后世子嗣相斫，以致一门覆灭，前世琐琐，劳累为何人哉？ 时尚书何晏等朋附曹爽，好变改法度。太尉蒋济上疏曰：“昔大舜佐治，戒在比周；周公辅政，慎于其朋。夫为国法度，惟命世大才，乃能张其纲维以垂于后，岂中下之吏所宜改易哉！终无益于治，适足伤 欲成命世大才，岂有不为朋党者乎？唯其根深，方能成其盛，唯其枝繁，方能立其功。朋党之出，乃因利也，朋党之败，亦因利也。故因其势可坏其党，导其利可比其周，此世之难于详说之变化也，唯智者审之。 汉主数出游观，增广声乐。太子家令巴西谯周上疏谏曰：“昔王莽之败，豪杰并起以争神器，才智之士思望所归，未必以其势之广狭，惟其德之薄厚也。于时更始、公孙述等多已广大，然莫不快情恣欲，怠 此类劝谏，虽为拳拳之言，耿耿之心，然多以切责讽喻为事，居高临下，示主之黯弱；逞意卖弄，彰君之不明。终不见听，何所怪哉？臣之进鉴，宜学中官常侍之法，多为谦退为下之语，明示君洞若观火智非人所及之旨，或可得用于世。 宗室曹冏上书曰：“古之王者，必建同姓以明亲亲，必树异姓以明贤贤。亲亲之道专用，则其渐也微弱；贤贤之道偏任，则其敝也劫夺。先圣知其然也，故博求亲疏而并用之，故能保其社稷，历经长久。今 此与之为取，张弛之道也。"}],"posts":[{"title":"测来测去12：DPDK i40e X710 Flow Director Deep Dive(3)","slug":"test12-dpdk-x710-fdir-mask-3","date":"2019-05-14T11:02:43.000Z","updated":"2019-05-14T11:05:20.204Z","comments":true,"path":"2019/05/14/test12-dpdk-x710-fdir-mask-3/","link":"","permalink":"https://decodezp.github.io/2019/05/14/test12-dpdk-x710-fdir-mask-3/","excerpt":"多于两个input_set的mask先说结论，一个pctype可以设置多个input_set，但是最多仅能给两个input_set设置mask。","text":"多于两个input_set的mask先说结论，一个pctype可以设置多个input_set，但是最多仅能给两个input_set设置mask。 可以修改代码给三个或多个input_set设置mask，但仅仅前两个mask能生效。同时这应该是比较危险的行为，不要随意尝试。 提供一下代码的修改方法…..算了….验证了不能用心里也就无憾了….就不再发出来了。 这里针对710系列的fdir特性总结一下： 可以针对不同的pctype配置input_set 可以针对不同的pctype配置input_set的mask 属于针对同一种pctype的fdir规则，共享input_set和mask的配置 同一个pctype最多给两个input_set配置mask 可用的配置方式请参见前三节： 测来测去9：DPDK i40e XXV710 Flow Director Mask Configuration 测来测去10：DPDK i40e X710 Flow Director Deep Dive(1) 测来测去11：DPDK i40e X710 Flow Director Deep Dive(2)","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"},{"name":"NIC","slug":"NIC","permalink":"https://decodezp.github.io/tags/NIC/"}]},{"title":"测来测去11：DPDK i40e X710 Flow Director Deep Dive(2)","slug":"test11-dpdk-x710-fdir-mask-2","date":"2019-05-13T10:46:49.000Z","updated":"2019-05-13T10:51:29.452Z","comments":true,"path":"2019/05/13/test11-dpdk-x710-fdir-mask-2/","link":"","permalink":"https://decodezp.github.io/2019/05/13/test11-dpdk-x710-fdir-mask-2/","excerpt":"同时添加一个TCP Flow Director规则在上一篇文章的基础上，添加一个TCP相关的Fdir操作：","text":"同时添加一个TCP Flow Director规则在上一篇文章的基础上，添加一个TCP相关的Fdir操作： 12345678910111213141516struct rte_eth_fdir_filter arg_tcpport = &#123; .soft_id = 3, .input = &#123; .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_TCP, .flow = &#123; .tcp4_flow = &#123; .dst_port = 0x10, &#125;, &#125;, &#125;, .action = &#123; .rx_queue = 1, .behavior = RTE_ETH_FDIR_ACCEPT, .report_status = RTE_ETH_FDIR_REPORT_ID, &#125;,&#125;; 只填写了TCP目的端口匹配4096(0x1000)的一条匹配规则。 之后按照UDP的操作方法，配置一下先仅仅将TCP目的端口加入input_set： 12345678910111213memset(&amp;info, 0, sizeof(info));info.info_type = RTE_ETH_FDIR_FILTER_INPUT_SET_SELECT;info.info.input_set_conf.flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_TCP;info.info.input_set_conf.field[0] = RTE_ETH_INPUT_SET_L4_TCP_DST_PORT;info.info.input_set_conf.inset_size = 1;info.info.input_set_conf.op = RTE_ETH_INPUT_SET_SELECT;ret = rte_eth_dev_filter_ctrl(0, RTE_ETH_FILTER_FDIR, RTE_ETH_FILTER_SET, &amp;info); ret = rte_eth_dev_filter_ctrl(0, RTE_ETH_FILTER_FDIR, RTE_ETH_FILTER_ADD, &amp;arg_tcpport); L3fwd跑一下： ./l3fwd -c 0x1ffff -- -p 0x3 -P --config=&quot;(0,0,1),(0,1,2),(0,2,2),(1,0,3),(1,1,4),(1,2,4)&quot; 此时仅有目的端口号为4096的TCP报文可以进入Queue1。 再给input_set加入一个源端口SRC_PORT： 12345678910111213memset(&amp;info, 0, sizeof(info));info.info_type = RTE_ETH_FDIR_FILTER_INPUT_SET_SELECT;info.info.input_set_conf.flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_TCP;info.info.input_set_conf.field[0] = RTE_ETH_INPUT_SET_L4_TCP_DST_PORT;info.info.input_set_conf.field[1] = RTE_ETH_INPUT_SET_L4_TCP_SRC_PORT;info.info.input_set_conf.inset_size = 2;info.info.input_set_conf.op = RTE_ETH_INPUT_SET_SELECT;ret = rte_eth_dev_filter_ctrl(0, RTE_ETH_FILTER_FDIR, RTE_ETH_FILTER_SET, &amp;info); ret = rte_eth_dev_filter_ctrl(0, RTE_ETH_FILTER_FDIR, RTE_ETH_FILTER_ADD, &amp;arg_tcpport); 因为在arg_tcpport中没有配置具体的源端口号，所以此时只有目的端口是4096，且源端口号为默认值0的TCP报文能够进入Queue1。 当然也可以加上： 1234567891011121314151617struct rte_eth_fdir_filter arg_tcpport = &#123; .soft_id = 3, .input = &#123; .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_TCP, .flow = &#123; .tcp4_flow = &#123; .dst_port = 0x10, .src_port = 1234, //1234=&gt;0x04d2=&gt;0xd204=&gt;53764 &#125;, &#125;, &#125;, .action = &#123; .rx_queue = 1, .behavior = RTE_ETH_FDIR_ACCEPT, .report_status = RTE_ETH_FDIR_REPORT_ID, &#125;,&#125;; 注意虽然.src_port填写了1234，但匹配的TCP源端口号是53764，具体的推导步骤见注释。 同时配置UDP掩码和TCP掩码到此，可以以掩码匹配UDP报文，并且精确匹配TCP报文，那么TCP的Flow Director规则是否也可以添加掩码呢？ 先仿照UDP的方式给TCP的目的端口添加一个掩码： 1234rte_pmd_i40e_inset_get(0, 33, &amp;inset, INSET_FDIR); //tcpinset.mask[0].field_idx = 30;inset.mask[0].mask = 0x0fff;ret = rte_pmd_i40e_inset_set(0, 33, &amp;inset, INSET_FDIR); 此时源端口为53764，目的端口为4096-8191的TCP报文都可以进入Queue1。同时UDP的匹配规则不受影响。 单独给TCP的源端口加一个掩码： 1234rte_pmd_i40e_inset_get(0, 33, &amp;inset, INSET_FDIR); //tcpinset.mask[0].field_idx = 29;inset.mask[0].mask = 0x0fff;ret = rte_pmd_i40e_inset_set(0, 33, &amp;inset, INSET_FDIR); 当然按照上一篇介绍的规则，arg_tcpport也需要相应修改一下： 1234567891011121314151617struct rte_eth_fdir_filter arg_tcpport = &#123; .soft_id = 3, .input = &#123; .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_TCP, .flow = &#123; .tcp4_flow = &#123; .dst_port = 0x10, .src_port = 0x20, &#125;, &#125;, &#125;, .action = &#123; .rx_queue = 1, .behavior = RTE_ETH_FDIR_ACCEPT, .report_status = RTE_ETH_FDIR_REPORT_ID, &#125;,&#125;; 此时源端口为8192-12287，目的端口为4096的TCP报文都可以进入Queue1。且不影响UDP的匹配规则。 设置两条掩码规则给TCP的目标目的端口增加一个掩码： 123456789rte_pmd_i40e_inset_get(0, 33, &amp;inset, INSET_FDIR); //tcpinset.mask[0].field_idx = 29;inset.mask[0].mask = 0x0fff;ret = rte_pmd_i40e_inset_set(0, 33, &amp;inset, INSET_FDIR);rte_pmd_i40e_inset_get(0, 33, &amp;inset, INSET_FDIR); //tcpinset.mask[1].field_idx = 30;inset.mask[1].mask = 0x00ff;ret = rte_pmd_i40e_inset_set(0, 33, &amp;inset, INSET_FDIR); 注意，为了区别UDP的掩码(0x0FFF)，给TCP目的端口使用的是0x00FF。 此时源端口为8192-12287，且目的端口为4096-4351(0x10FF)的TCP报文均可进入Queue1。 为了验证针对UDP报文的规则不受TCP的Mask影响，发送目的端口为4352的UDP报文，仍可匹配UDP规则。证明不同pctype之间的配置不互相影响。","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"},{"name":"NIC","slug":"NIC","permalink":"https://decodezp.github.io/tags/NIC/"}]},{"title":"测来测去10：DPDK i40e X710 Flow Director Deep Dive(1)","slug":"test10-dpdk-x710-fdir-mask-1","date":"2019-05-11T06:10:03.000Z","updated":"2019-05-13T10:50:42.253Z","comments":true,"path":"2019/05/11/test10-dpdk-x710-fdir-mask-1/","link":"","permalink":"https://decodezp.github.io/2019/05/11/test10-dpdk-x710-fdir-mask-1/","excerpt":"在这篇文章介绍DPDK i40e X710网卡如何配置Flow director mask的过程中演示了一下如何给UDP流量添加dest Port Mask。首先对当时的配置再做一点细节上的补充：","text":"在这篇文章介绍DPDK i40e X710网卡如何配置Flow director mask的过程中演示了一下如何给UDP流量添加dest Port Mask。首先对当时的配置再做一点细节上的补充： 一个是Input Set的配置。这个配置决定了Flow director具体关心UDP的哪些字段。只有在Input set中的字段才有加Mask的必要。在演示的例子中： 1234567891011struct rte_eth_fdir_filter_info info; struct rte_pmd_i40e_inset inset; memset(&amp;info, 0, sizeof(info)); info.info_type = RTE_ETH_FDIR_FILTER_INPUT_SET_SELECT; //针对Nonfrag-ipv4-udp这种流量类型 info.info.input_set_conf.flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP; //添加UDP-dst-port作为一个`input set`，且仅有这一个 info.info.input_set_conf.field[0] = RTE_ETH_INPUT_SET_L4_UDP_DST_PORT; info.info.input_set_conf.inset_size = 1; info.info.input_set_conf.op = RTE_ETH_INPUT_SET_SELECT; 通过这种形式配置了Flow director仅关心一个UDP字段，也就是dest Port。其实也可以认为是给src IP/dest IP/src Port设置了通配。 另外关于配置掩码的规则在这里也说明一下，示例中给的fdir规则dst_port是0x2e06，掩码是0xF000： 12345678910111213141516struct rte_eth_fdir_filter arg_udpport = &#123; .soft_id = 1, .input = &#123; .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP, .flow = &#123; .udp4_flow = &#123; .dst_port = 0x2e06, //5678=&gt;0x162e &#125;, &#125;, &#125;, .action = &#123; .rx_queue = 2, .behavior = RTE_ETH_FDIR_ACCEPT, .report_status = RTE_ETH_FDIR_REPORT_ID, &#125;,&#125;; 这个配置可以匹配目的端口号为：1582（0x062e）；5678（0x162e）;9774（0x262e）…的端口，即前4个bit为任意数值，后12个bit为0x62e的全部端口号。 注意此时在fdir规则的配置中，.dst_port只能写0x2e06才可以生效，一是考虑大小端数字的转换，二是需要被Mask的那几位Bit必须写0。另外，对应的Mask(0xF000)中，需要被Mask的Bit位上要写1。 别问我为什么这么设定，我也不知道，我只管好不好使。 两条fdir UDP规则如果你需要配置两条UDP fdir规则，那么之前关于input set和mask的配置是同时应用于这两条UDP规则的。 比如，所有目的端口号4096（0x1000）-8191的UDP进入队列1，端口号8192（0x2000）-12287（0x2FFF）的进入队列2，可以采取如下配置方式： 123456789101112131415161718192021222324252627282930313233 struct rte_eth_fdir_filter arg_udpport1 = &#123; .soft_id = 1, .input = &#123; .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP, .flow = &#123; .udp4_flow = &#123; .dst_port = 0x10, &#125;, &#125;, &#125;, .action = &#123; .rx_queue = 1, .behavior = RTE_ETH_FDIR_ACCEPT, .report_status = RTE_ETH_FDIR_REPORT_ID, &#125;, &#125;;struct rte_eth_fdir_filter arg_udpport2 = &#123; .soft_id = 2, .input = &#123; .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP, .flow = &#123; .udp4_flow = &#123; .dst_port = 0x20, &#125;, &#125;, &#125;, .action = &#123; .rx_queue = 2, .behavior = RTE_ETH_FDIR_ACCEPT, .report_status = RTE_ETH_FDIR_REPORT_ID, &#125;, &#125;; 此时Mask需要设置为0x0FFF。然后调用示例中的相关接口就可以达到目的。","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"},{"name":"NIC","slug":"NIC","permalink":"https://decodezp.github.io/tags/NIC/"}]},{"title":"命名的力量","slug":"thoughts8-master-of-naming","date":"2019-05-08T14:38:30.000Z","updated":"2019-05-08T14:54:16.800Z","comments":true,"path":"2019/05/08/thoughts8-master-of-naming/","link":"","permalink":"https://decodezp.github.io/2019/05/08/thoughts8-master-of-naming/","excerpt":"一 To Know the Name of a Thing is to Have Power Over It如果我们知道了一件事物的名字，就有了操控它的力量。 常言道，人类最深的恐惧都来自于“未知”。那么，什么是“未知”？","text":"一 To Know the Name of a Thing is to Have Power Over It如果我们知道了一件事物的名字，就有了操控它的力量。 常言道，人类最深的恐惧都来自于“未知”。那么，什么是“未知”？ 未知并不是一片漆黑，也不是一无所知——而是没有名字。 有了名字并不代表我们就完全了解了一样事物。但奇妙的就是，我们根本不需要去了解，就可以在这个依然满是“未知”的世界里用这个名字去随心所欲地指代。自此，我们才获知事物的坐标；自此，我们才拿到操控的指令；自此，头脑中的万物才真正存在。 其实细想一下，我们当前也仅仅是对这个世界，以及我们自己，自以为了解。 二 A thing is a thing, not what is said of that thing大化流行，不拘于形 命名不仅可以让我们拥有改造事物的力量，同时也在操纵我们自己。 几乎所有的恶习，都来源于此：偏见、歧视、贪婪、愤怒、狂热、嫉妒、自以为是、自欺欺人……如果没有名字构筑的意象，事物本无意义。我们什么都看不到，什么都听不到，所能见能闻的，不过是名字在时间空谷里的涟漪和回音。 命名为我们架起桥梁，也建好牢笼；我们既接受命名的祝福，也背负命名的诅咒。 三 A men is what he speaks.至人无己，神人无功，圣人无名 我一直在试图跳出“社会人”的视角，去思考我们到底如何认知周遭的世界。直到我明白，当我只能用这套被偏见熏习浸染的语言去思考时，所有的沉思不过是徒劳无功的挣扎。“为学日益，为道日损”，那就挣扎吧，就是挣扎吧，没什么大不了的，最起码，“挣扎”只是临时给这种心情所起的名字。 曾试图知道每一样事物的名字，以为就能活得明白。却发现在知道了越来越多的名字之后，自己却成了一个只会用名字敷衍自己的人。这个是XX，那个是YY，所划所指，不过是在重复别人。到头来，发现“张冠李戴”才是一种极高明的生活态度。 从别人那里继承的名字成为一切构造的原点，包括构造我们自己。在名字罗织的网里，有人游刃有余，也有人自怨自艾，有人如数家珍，也有人忘记了自己的名字。但对我来说，我最理想的职业，就是做一个“命名师”——给所有能见能闻之物，一个最合适的名字。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"测来测去9：DPDK i40e XXV710 Flow Director Mask Configuration","slug":"test9-x710-fdir-mask","date":"2019-05-06T11:59:29.000Z","updated":"2019-05-06T12:15:36.067Z","comments":true,"path":"2019/05/06/test9-x710-fdir-mask/","link":"","permalink":"https://decodezp.github.io/2019/05/06/test9-x710-fdir-mask/","excerpt":"Flow Director最常见的Flow Director使用方式就是将匹配某个五元组的报文送到一个特定的队列里去。但精确匹配有时候并不能满足全部需求，需要给一些特定的字段加Mask。","text":"Flow Director最常见的Flow Director使用方式就是将匹配某个五元组的报文送到一个特定的队列里去。但精确匹配有时候并不能满足全部需求，需要给一些特定的字段加Mask。 配置方式 修改dpdk-18.05.1/example/l3fwd/main.c 目的是给UDP的DST Port添加一个0XF000的掩码。 首先用i40e提供的私有接口加持一下： 1#include &lt;rte_pmd_i40e.h&gt; 这里面都是偷偷夹带的私货，可以关注一下。 然后加一个”中规中矩“的FDIR规则： 123456789101112131415161718192021222324252627282930313233343536static struct rte_eth_conf port_conf = &#123; .rxmode = &#123; .mq_mode = ETH_MQ_RX_RSS, .max_rx_pkt_len = ETHER_MAX_LEN, .split_hdr_size = 0, .ignore_offload_bitfield = 1, .offloads = (DEV_RX_OFFLOAD_CRC_STRIP | DEV_RX_OFFLOAD_CHECKSUM), &#125;, .rx_adv_conf = &#123; .rss_conf = &#123; .rss_key = NULL, .rss_hf = ETH_RSS_IP, &#125;, &#125;, .txmode = &#123; .mq_mode = ETH_MQ_TX_NONE, &#125;, .fdir_conf = &#123; //jma fdir .mode = RTE_FDIR_MODE_PERFECT, .pballoc = RTE_FDIR_PBALLOC_64K, .status = RTE_FDIR_REPORT_STATUS, .drop_queue = 127, .mask = &#123; .vlan_tci_mask = 0, .ipv4_mask = &#123; .src_ip = 0xffffffff, .dst_ip = 0xffffffff, &#125;, .src_port_mask = 0xffff, //ori .dst_port_mask = 0xffff, .dst_port_mask = 0xff00, &#125;, &#125;,&#125;; 不过其实mask不起作用，这里主要做一下错误示范。然后在main函数里加一下配置代码： 1234567891011121314151617181920212223242526struct rte_eth_fdir_filter_info info;struct rte_pmd_i40e_inset inset;memset(&amp;info, 0, sizeof(info));info.info_type = RTE_ETH_FDIR_FILTER_INPUT_SET_SELECT;info.info.input_set_conf.flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP;info.info.input_set_conf.field[0] = RTE_ETH_INPUT_SET_L4_UDP_DST_PORT;info.info.input_set_conf.inset_size = 1;info.info.input_set_conf.op = RTE_ETH_INPUT_SET_SELECT;struct rte_eth_fdir_filter arg_udpport = &#123; .soft_id = 1, .input = &#123; .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP, .flow = &#123; .udp4_flow = &#123; .dst_port = 0x2e06, //5678=&gt;0x162e &#125;, &#125;, &#125;, .action = &#123; .rx_queue = 2, .behavior = RTE_ETH_FDIR_ACCEPT, .report_status = RTE_ETH_FDIR_REPORT_ID, &#125;,&#125;; 这里定义了一个Flow Director规则：”目的端口为5678的UDP报文进入队列2”。 那么如何加掩码呢？ 在启动转发程序(rte_eal_mp_remote_launch())之前加上： 12345678ret = rte_eth_dev_filter_ctrl(0, RTE_ETH_FILTER_FDIR,RTE_ETH_FILTER_SET,&amp;info);ret = rte_eth_dev_filter_ctrl(0, RTE_ETH_FILTER_FDIR,RTE_ETH_FILTER_ADD, &amp;arg_udpport);rte_pmd_i40e_inset_get(0, 31,&amp;inset, INSET_FDIR); //udpinset.mask[0].field_idx = 30;inset.mask[0].mask = 0xf000;ret = rte_pmd_i40e_inset_set(0, 31,&amp;inset, INSET_FDIR); 这里面需要关注几个数值，一个是rte_pmd_i40e_inset_get/set参数里的31。这个是pctype的编号。可以查看x710 datasheet的Table 7-5。31号对应的是NonF IPv4, UDP，正好是我们需要的。 另外一个是inset.mask[0].field_idx给出的30。这个30出自datasheet中的Table 7-12。其中提到29:32这两个word在UDP协议下代表的是First 8 bytes of the UDP header。在UDP header中，前两个Byte是SRC port，对应29；第三第四个Byte是DST port，对应30。这就是30的来历。 至此就完成了最初的目的。 Future WorkX710在这方面的配置方法总体来说还是非常隐晦的。在未来还有很多可以验证的工作，比如是否可以针对不同的pctype设置不同的mask，比如mask是否仅限于两个字段等等。","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"},{"name":"NIC","slug":"NIC","permalink":"https://decodezp.github.io/tags/NIC/"}]},{"title":"终端断开任务不中断","slug":"terminal-nohup-screen","date":"2019-04-27T03:37:12.000Z","updated":"2019-04-27T03:38:47.925Z","comments":true,"path":"2019/04/27/terminal-nohup-screen/","link":"","permalink":"https://decodezp.github.io/2019/04/27/terminal-nohup-screen/","excerpt":"其实是很常见的需求，但之前一直用nohup command &amp;这种方式。不过有些时候没有充分估计到某些工作的不靠谱性，以为很快能搞定的事，就没用nohup直接执行，当你快要下班了它还遥遥无期。这个时候也可以先ctrl + z从前台挂起，然后bg让它跑到后台去执行，最后再来一个disown -a，这样就可以放心关了终端早点回家了。下次再用其他终端连接上来之后你的工作仍会在持续执行，但是这时候是不能用fg这样的命令让它再回到前台执行的，jobs也不会显示它。 如果你想持续看到后台进程的输出，以前的办法就是在运行之前就将它重定向到一个文件，后续回来查看文件即可。但如果进程已经开始执行了，再去重定向就稍微费点劲。网上有些用gdb调的方法，我试了试不是太成功，本来打算继续看看，结果发现还是老老实实用screen靠谱一点…","text":"其实是很常见的需求，但之前一直用nohup command &amp;这种方式。不过有些时候没有充分估计到某些工作的不靠谱性，以为很快能搞定的事，就没用nohup直接执行，当你快要下班了它还遥遥无期。这个时候也可以先ctrl + z从前台挂起，然后bg让它跑到后台去执行，最后再来一个disown -a，这样就可以放心关了终端早点回家了。下次再用其他终端连接上来之后你的工作仍会在持续执行，但是这时候是不能用fg这样的命令让它再回到前台执行的，jobs也不会显示它。 如果你想持续看到后台进程的输出，以前的办法就是在运行之前就将它重定向到一个文件，后续回来查看文件即可。但如果进程已经开始执行了，再去重定向就稍微费点劲。网上有些用gdb调的方法，我试了试不是太成功，本来打算继续看看，结果发现还是老老实实用screen靠谱一点… 其实screen这个命令应该不是什么新鲜玩意了，也有很多人在使用。不过对我来说还是一个挺有新意的发现。我的一般套路： 新建一个screen并命名为ftp： screen -S ftp 此时会直接进入新的bash，这里搞一些耗时的操作，例如scp等等。 从ftp退回： 用快捷键ctrl+a d 这个时候其实就可以关闭当前终端了。 新打开一个终端 查看现有screen列表： screen -ls 看看上传得怎么样了： screen -r ftp 不但scp的工作没有中断，还可以看到scp当前所有输出，和之前的终端没有关闭一样。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"}]},{"title":"测来测去8：公有云实例性能实际波动情况","slug":"test8-cloud-vm-performance","date":"2019-04-22T04:49:27.000Z","updated":"2019-04-22T04:52:22.963Z","comments":true,"path":"2019/04/22/test8-cloud-vm-performance/","link":"","permalink":"https://decodezp.github.io/2019/04/22/test8-cloud-vm-performance/","excerpt":"公有云作为一种资源打包整合再售卖的商业模式，不可避免地存在多租户共享资源的情况。除了安全问题之外，更多的是需要辨别这种共享对用户各自的性能存在多大的影响。这种影响不仅仅表现在性能的下降，而更多的是表现为性能的不一致：在高峰时段和空闲时段，性能出现较大的波动。","text":"公有云作为一种资源打包整合再售卖的商业模式，不可避免地存在多租户共享资源的情况。除了安全问题之外，更多的是需要辨别这种共享对用户各自的性能存在多大的影响。这种影响不仅仅表现在性能的下降，而更多的是表现为性能的不一致：在高峰时段和空闲时段，性能出现较大的波动。 这里在某公有云平台购买一台4vCPU/8GB的实例作为DUT，在不同时间执行： phoronix-test-suite benchmark xsbench 进行CPU处理的性能测试，除此之外该虚拟机上没有任何其他workload，也没有任何其他配置更改，全部采用默认配置。 以下是不同时段的一组测试数据(lookup/s)： time result 11:00 923024 14:00 783030 16:00 841485 17:00 840289 18:00 838885 可以看出，11：00性能最高，14：00性能最低，16：00-18：00性能稍有波动，最好与最低性能相差15%+。 针对以上情况的几种可能解释： 虚拟机新创建时(14:00)根据公有云后台调度算法创建到了一台空闲的“物理机”上，以提高物理资源的整体利用率。后续随着新虚拟机的加入导致性能下降。 虚拟机新创建时没有特别选择“空闲”物理机，此时物理机中已存在其他虚拟机。但受其他虚拟机各时段业务压力不同影响（14:00为业务压力较大的时间段，16:00-18:00业务压力相对平稳），表现出性能的波动。 其他虚拟机压力没有较大波动，但受账号等级、任务优先级等商务或其他因素影响，导致在hypervisor层中为各虚拟机进程分配不同的优先级以及CPU硬件绑定策略，进而影响虚拟机的性能表现。 以上原因综合影响。 总之，在公有云上部署应用，如果并没有选购那些资源独占型的产品，就需要充分评估性能波动带来的业务影响。同时，在此一方面做好与云供应商的SLA的制订工作。","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"performance","slug":"performance","permalink":"https://decodezp.github.io/tags/performance/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"}]},{"title":"Quickwords27 Skylake Microarchitecture(10)","slug":"quickwords27-skylake-pipeline-10","date":"2019-04-20T05:36:19.000Z","updated":"2019-04-20T05:39:11.955Z","comments":true,"path":"2019/04/20/quickwords27-skylake-pipeline-10/","link":"","permalink":"https://decodezp.github.io/2019/04/20/quickwords27-skylake-pipeline-10/","excerpt":"Load and Store instructionsIn previous chapters we discussed how does ROB and RS as well as RAT work. You may notice that we did not include load and store instruction in the demonstrated examples. This is partly due to simplification reason and partly because of the specialized mechanisms we will introduce in this article.","text":"Load and Store instructionsIn previous chapters we discussed how does ROB and RS as well as RAT work. You may notice that we did not include load and store instruction in the demonstrated examples. This is partly due to simplification reason and partly because of the specialized mechanisms we will introduce in this article. Although we categorize load and store instructions as special from other classes of instructions, all instructions and the design of the pipeline share unified purpose: increase the instruction level parellarmise by eliminating dependencies. By what I am saying: Eliminate control dependencies by leveraging branch prediction Eliminate false dependencies by leveraging register renaming Note that register renaming is primarily aimed for registers, not memory. Is there also dependency existing for memory operations? If yes, what can we do about it? These are the questions we are trying to address. Load and Store Are Different From Read And WriteLoad and store are terms used for memory instructions whereas read and write are used for actions directly operated on memory. Most of the time, these terms are interchangeable. However, in our scope, we must differentiate those in order to avoid misunderstanding in following discussion: Stores are instructions and they follow the same procedure described before. Only after the store instruction is committed, memory written happens. Loads are also instructions, but memory read action may happen before or after load instruction is committed. That’s mainly because load is able to leverage results of previous stores which store to the same address of the load instruction. Therefore, loads perform in execute stage. Registers and MemoryRegisters and memory share same type of dependences. False dependencies can be eliminated during Out-of-order execution. However, there’s one important difference, the address of memory operation known only at runtime, makes memory operation much more difficult to tell if there’s a dependency. For example: 12345Load r3 = 0[R6]Add r7 = r3 + r9Store r4-&gt;0[r7]Sub r1 = r1 - r2Load r8 = 0[r1] Here, in the third instruction you store value in r4 to memory location represented by r7, and then you load value in memory location [r1] to r8. We assume there is a cache hit. If r7 is not equals to r1, there’s no problem. Problem arises if r7 equals r1, as the store/third instruction has not been committed, the value in cache/read by the last instruction is not the latest/correct. In other word, this is a RAW true dependency. Our trusted friend, compiler, can not help under this circumstance neither. This is the root cause of memory aliasing, when two pointers refer to the same memory location, true dependency happens. Although you can give compiler hint to omit memory aliasing, it is up to the unreliable programmer to take care of their spaghetti logic. As before, we set an example to make the explanation easier to understand…in next chapter.","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"tar命令速查手册","slug":"tar-cheat-sheet","date":"2019-04-19T19:15:05.000Z","updated":"2019-04-19T19:17:32.280Z","comments":true,"path":"2019/04/20/tar-cheat-sheet/","link":"","permalink":"https://decodezp.github.io/2019/04/20/tar-cheat-sheet/","excerpt":"总是会忘记这个命令后面的各种参数对应的压缩格式，每次都要上网重新搜索。可能也是对这种“查一查就能知道”的信息天生缺乏敏感性，但每次都搜索显得实在不太professional，所以…那就在一个地方查吧 ^^","text":"总是会忘记这个命令后面的各种参数对应的压缩格式，每次都要上网重新搜索。可能也是对这种“查一查就能知道”的信息天生缺乏敏感性，但每次都搜索显得实在不太professional，所以…那就在一个地方查吧 ^^ .tar 解压缩： tar zxvf FileName.tar 压缩： tar czvf FileName.tar path/to/file .tar.bz2 解压缩： tar jxvf FileName.tar.bz2 压缩： tar jcvf FileName.tar.bz2 path/to/file .tar.bz 解压缩： tar jxvf FileName.tar.bz .tar.gz &amp; .tgz 解压缩： tar zxvf FileName.tar.gz 压缩： tar zcvf FileName.tar.gz path/to/file .tar.Z 解压缩： tar Zxvf FileName.tar.Z 压缩： tar Zcvf FileName.tar.Z path/to/file","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"}]},{"title":"如果你到鲁汶来，一定要喝Stella","slug":"thoughts7-leuven-stella","date":"2019-04-19T06:56:20.000Z","updated":"2019-05-08T14:54:19.622Z","comments":true,"path":"2019/04/19/thoughts7-leuven-stella/","link":"","permalink":"https://decodezp.github.io/2019/04/19/thoughts7-leuven-stella/","excerpt":"自打那次正式的告别之后，很久都没有再梦见过鲁汶。那几年大部分的时光，都仿佛跌入了时间的黑洞，如今能找到的，只有下面这篇旧文中的只言片语。刚想要深入挖掘一下脑海中的记忆，却又畏葸不前——毕竟清扫记忆这事，如扫落叶，旋扫旋生。","text":"自打那次正式的告别之后，很久都没有再梦见过鲁汶。那几年大部分的时光，都仿佛跌入了时间的黑洞，如今能找到的，只有下面这篇旧文中的只言片语。刚想要深入挖掘一下脑海中的记忆，却又畏葸不前——毕竟清扫记忆这事，如扫落叶，旋扫旋生。 人生第一次喝到不管不顾，是在2012年1月31日的晚上。那时已是我在鲁汶的最后一年。第二天早上是学校统一安排的论文中期答辩，于是我便知道在今晚，我一定会和K出现在鲁汶一处无所事事的场所。中期答辩这种半娱乐性质的学术活动，对我们来说就像是一场临时起意的火锅，断不能未雨绸缪，更不能胸有成竹：人员、食材、厨具，场所，一定要临渴掘井，倚马援笔，才能在朵颐的餍足之后额外获得一种怪诞的速度感。经验给我们的启示是，只要英语说得足够快，肢体足够挥洒，眼神足够信誓旦旦，就可以弥补学术上的浅尝辄止。于是这天晚上，在Tiensestraat一家新开不久的披萨店，我们坐到了一起。那晚鲁汶没有在准备PPT的学生，可能都在这家披萨店里。 鲁汶虽小，见面却也需要缘份。作为不是一个系，懒得算计课时费督促自己去上课，中午也很少去吃ALMA的两个人，我和K很少见面。两个人单独活动的次数，其实也屈指可数。双方都在维持一个避免尴尬的微妙距离。这里的每一个人，都会邀请别人到自己的单人Studio／apartment里作客，都会参加由四川人民搞起的各类火锅，但也都会有一些不示人的东西，装在角落那个随着他们漂洋过海的行李箱里。在鲁汶呆了三年，很多事物渐渐地丧失了新鲜感，就连圈子里的八卦，来来回回也总是那些。不再计算欧元的汇率，也不再为法语键盘诡谲的键位苦恼，只有周围的这些人，总能让你感到新的发现。我想，很少和另外一个人联系，也许只是因为并不想在对方身上发现这种“新意”——如果镜子某天被发现了一个裂璺，难免令人恐慌。 披萨店开在Tiense街，是一个很明智的决断。Tiense街并不是鲁汶的主街，但作为我们到这里之后第一条踏足的街道，它成了我们一切路径规划的起点。这一条街两边的店面，几乎可以满足一个学生的所有需求。沿着这条街，大大小小的街道像血管般交汇铺陈。在这些血管里游走，就像沉入到鲁汶的血液里，被心脏的节律送去每一个总要到达的地方。有些时候是迫不得已地找寻某处地址，有些时候只是自己或他人的兴之所至。哪里是超市，哪里是教堂，哪里新开了一家冰激凌店，就这样不自觉地摸清了每一根血管的秘密。也正是在去哪都轻车熟路之后，才清楚地明白了自己外乡人的身份。却又一边保持着外乡人的执拗，一边从Tiensestraat 154开始，把自己紧紧地编织进一张杂乱又熟稔的网里。 我跟K说，今天街上的人真少，披萨也很一般。K说，何不去喝杯酒。这是一个很难拒绝的提议。就像很难拒绝在去鲁汶的火车上看到车站旁百威英博的巨大厂房。那上面的Stella Logo初起时引人注目，后来反而会视而不见。毕竟，谁也不会为花萼上开出了一朵花而感到惊奇。比利时数百种啤酒，我只尝过一些最常见的种类。Stella算不上最好喝的，更算不上名气最大的，但在鲁汶，这却是最自然的选项。毕竟两个男人去分吃冰淇淋和华夫饼，还是太需要勇气了。天早就黑了，中心图书馆前的广场上，只有那只甲虫反射着孙燕姿的绿光。鲁汶的纬度据说超过哈尔滨，冬天昼短夜长得像是一杯被人遗忘在角落里的KASTEEL，蕾丝般单薄的泡沫随时会被黑色的酒浆吞没。但这里并不像哈尔滨那般寒冷，北大西洋的暖流从不远的地方流过，海洋和陆地两种不同比热容的东西造就了这里特别的风，像刚刚把开水与冰水混合在一起，在没有达到相互妥协的温度之前，纠结得泾渭分明。 这种纠结，快要毕业的人感受得最深。那个时候，周围的同学已经开始谋划自己的未来了，至少每个人都是这样以为。献身学术的要继续读博，爱动手解决问题的对工业界早已跃跃欲试，挂科太多的也决心在明年毕业。是走是留，可能每个人都在心里盘算了许久。 我那个时候没什么特别的打算，除了不想继续读博之外，觉得去哪里都好，或者说是，也不清楚要去哪里。如果工作的话 ，希望能找到一个设计嵌入式系统的公司，搞一搞R&amp;D。站在此时此刻的时间纵深上，那个时候的打算都如一场喃喃的梦呓。至少对我来说，现在的生活几乎和那时设想的没有一点关系，但也许现在才是一杯混合好的凉白开的样子。 但是当我们坐在著名的Professor酒吧里时，自然是不会点一杯凉白开的。以Stella开场，以明早的答辩下酒，两个人似乎都有今晚要发生些什么的预感。桌子上的圆烛越燃越亮，在酒吧街卖花的阿裔大叔凑上来问我们要不要买一支玫瑰，我们三个都笑了。话说得越来越多，酒也喝得越来越快。奇怪的是我现在已经完全想不起来那时说过些什么，只记得啤酒没有了味道，鸡尾酒像一杯果汁，而伏特加因为酒精浓度太高，喝到嘴里不会有任何被水份湿润的感觉。酒精像是一整团粘连的黏液，到达喉咙之后，在胸腔里炸开。 我和K曾经在同一家中餐馆打工，那还是我们刚到这个国家的时候。不过我们并不是同时在那里，而是一先一后。在靠近法国边境的地方，有一个叫做富豪大酒楼的夫妻店，这也许是我第一次明白了浮夸的含义。老板和老板娘都是浙江青田人，只是老板是二代移民。我去的时候，老板娘已经生了三个儿子，K去了之后，又有了第四个。那个大酒楼是一个纯正的多语言环境，无论是谁的儿子，和老板要说荷兰语，老板和老板娘说青田方言，老板和我说英语，老板娘和我说普通话。传说上帝破坏巴别塔的方法，就是让人说不同的语言。但我想，失败的原因并不是因为无法靠语言交流，而是往昔的环境被打破之后，在新的环境里找不到可以锚定的礁石。个人无法定位，集体也就无法协作。过往经验的全然失效，会生出一种存在与否的焦虑。在这座六个人的巴别塔里，我突然有了这种焦虑。以前并不明白，以为对任何一个问题，都要细加推敲，从长计议，但有些时候，只有迷失时的横冲直撞，才能找到可以靠岸的水港。就像这次在Professor酒吧中所发生的一样。我不记得我们谈话的内容，我甚至怀疑我们有没有说话，我们肯定也不懂古奥的阿拉伯语，但我分明知道我们做了一场酣畅淋漓的交流，也都读懂了那支玫瑰的含义。一杯接一杯，酒保已经放弃投递提醒的眼色，自然也不会有人再考虑明早的答辩，甚至不会去考虑明天。也许酒才是真正意义上的世界语，那么Stella就是鲁汶的方言。 直到现在，关于鲁汶的记忆已经被严重压缩，甚至在反复加工的过程中失真走样。许多当初习以为常的细节已经如Tiensestraat 154般烟消云散，但我依然记得我们如何在Professor酒吧门口告别——虽然还没有毕业，却像是明天就要各奔东西——揽了揽对方的肩头，并镇定地说着要回去再看一下明天答辩的内容。由此可知，语言的作用并不在交流，而是撒谎。我几乎是一路小跑着跑回了Campus Irena，但还是没来得及在进宿舍之前保持直立行走。手脚并用的从0层爬到了2层，艰难地够到钥匙孔，推开门的瞬间，就给地毯附丽了一幅写意画作。数年以后的同学会，我看到喝多了的J在杭州街头呕吐，泼洒的秽物溅到了我的双脚，竟然有一种熟悉的温热。在鲁汶最后的那段时间里，一度很喜欢Campus Irena的楼顶。夜晚无聊的时候，就会从顶楼的梯子上爬上来，随身带一个高脚杯，和一盒全脂牛奶。周围没有比它更高的建筑，“可以看到整块没有分割的天空”。在这之前，当国内已经是入眠的午夜，我会选择出去闲逛，那些傍晚时的漫步，很多时候都以不知所云，迷途知返收场。楼顶的平台很大，可作闲庭信步，但每当抬起头面对扑面而来的夜空时，就再也不敢迈动一步，失足青年，在那时已逐渐有了暧昧的含义。鲁汶很小，但有些时候却空旷得不知身在何处。只有在离开许久之后，才能在一万两千公里之外看清自己曾经的身影。即便是到了现在，我也无法总结这段时光给我留下了什么，直到2014年的6月，在北京三里屯，我见到了酒吧屋檐下挂出的Stella的酒招。断裂的时光和距离，才在那时重合。第二天，我准时出现在论文答辩的门前，淡定的就像早已胜券在握。我看到K穿着正装，打着领带，从旋转楼梯那边缓缓走来，甚至还丧心病狂地戴着一顶一丝不苟的礼帽。擦肩而过的时候，他问我，昨晚回去吐了吗？ 没有，你吐了？ 没有。 我们点头致意，心里都默默给对方打了一个8分。下次我们再见，似乎就到了那一年的十月。我虽然没想清楚毕业之后要去哪，但我那个时候就知道，在不远的将来，我们会出现在世界的各个地方。不可免俗的，还是会让一份工作成为我们安身立命的栖身之所。那个时候我们将不能只凭脑力就记住手机通讯录里每一个人的面孔，我们会交换很多名片，会发很多邮件，会参加很多次团建或者林林总总的商务宴请，但却很少再有新的朋友。这很好，可以让我们将感情投入到真正值得的人身上。2012年的1月似乎是我两个时代的分水岭，可惜的是，我那时无知无觉。2012年1月1日的早上，鲁汶oude market广场上满是昨夜跨年时人群遗落的疯狂痕迹。被风推着滚动的杂物以极度亢奋之后的萎靡姿态占领了广场。彼时天空下着小雨，一次性塑料杯中没喝完的啤酒渗透了石头广场的每一个罅隙，整个小城似乎还在宿醉中没有醒来。广场周围的酒吧里还有人停留在2011年的最后一天，随着音乐扭动小脑失效的身体。只是激荡肾上腺的嘈杂音乐一出酒吧的门口就成了强弩之末，唤不醒广场上任何一块酣饮了啤酒的石子。我穿过空气里幽浮起的酒精的气息，想要在如此举世皆醉的清晨看一看2012年第一天的鲁汶，不成想一个醉依在酒吧门口的年轻学生朝我走过来，用无法捋直的舌头对我说，如果你到鲁汶来，一定要喝Stella。 作者：张攀链接：https://www.jianshu.com/p/3d065950e73a来源：简书简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"夜色温柔","slug":"thoughts6-tender-is-the-night","date":"2019-04-16T16:06:41.000Z","updated":"2019-04-19T07:00:49.522Z","comments":true,"path":"2019/04/17/thoughts6-tender-is-the-night/","link":"","permalink":"https://decodezp.github.io/2019/04/17/thoughts6-tender-is-the-night/","excerpt":"好像总是不能沉浸在当下。看着书想着邮件，吃着饭想着项目，看着电影想着停车费，在外面喝酒想着一会回家撸猫。","text":"好像总是不能沉浸在当下。看着书想着邮件，吃着饭想着项目，看着电影想着停车费，在外面喝酒想着一会回家撸猫。 也不是没有专注的时候，但这些时候总像一个美梦，做不多时就会下意识地提醒自己，我是不是在做梦？方醉复醒，梦了无痕。 今天也是如此。春意浓浓，月色溶溶，酒吧里光影横斜。我端详着酒杯里的泡沫，心思却又不知神游何处。辜负的不止是此时此刻，还有未来那个，终会后悔现在没有更投入一些的自己。 玩不是玩，工作不是工作，被背景噪音消音，让零碎片段化整为零。不去接收那些廉价的信息，仿佛就是现代最大的罪愆。第一次，我决定好好坐下来，用舌头去听清泡沫在破裂时的轻响；用鼻尖去看清夜风里繁衍的生机；用无缘无故接了一单大活的膀胱，说出心口直通的快乐。 不愿从众，不想被操控，不接受罗织的罪名。人皆被洪流裹挟，减熵需要额外的输入。而这些输入并不需要你下决心与这个时代分道扬镳，感受被自己遗忘的感官，就是今夜教给我的温柔。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"商业供稿3：2019云计算安全5大趋势","slug":"commerical3-2019-cloud-security-trends","date":"2019-04-15T12:18:29.000Z","updated":"2019-04-15T12:23:59.865Z","comments":true,"path":"2019/04/15/commerical3-2019-cloud-security-trends/","link":"","permalink":"https://decodezp.github.io/2019/04/15/commerical3-2019-cloud-security-trends/","excerpt":"原载于云杉网络 www.yunshan.net 微信公众号 安全将成为云计算最大的挑战","text":"原载于云杉网络 www.yunshan.net 微信公众号 安全将成为云计算最大的挑战 云计算从诞生之初的“实验性”技术到为IT行业广泛接受，成为新一代社会数字基础设施的核心技术，经历了不同的发展阶段。在“上云”已从一个可选项变成必选项之后，用户对云计算安全的担心将经受现实的真正考验。 云计算的发展历程自始至终都充满挑战：从灵活性、稳定性、性能、成本等技术挑战到用户教育等市场挑战，云计算已在这些方面取得长足进步，并通过应对这些挑战变得更加成熟。而用户也将在解决了迁移、高可用和成本控制等多种难题之后，逐渐采取以“安全”为第一出发点的上云和演进策略。这不仅要求云服务厂商具备相应的安全技术和产品支撑，也需要用户转变观念和部门文化，适应云计算环境带来的技能变化。根据调查，安全仍是用户最大的疑虑，并将随着云计算市场规模的持续增长成为云计算面临的最大挑战。 容器和Serverless的普及将催生新的安全攻防形态容器是一种新的虚拟化形态，因其轻量、高效的特点正受到热烈追捧。但同传统的虚拟机不同，多个容器或不同租户间的容器都共享同一个系统内核，而不是像虚拟机一样各自拥有独立的内核。这为恶意攻击者提供了更大的攻击面。一项调查表明，60%的组织机构在2018年都遭遇过容器安全事件。 2019年，容器和Serverless的发展必将持续，同时基于这两项技术的DevOps等技术最佳实践方式也将进一步获得普及。针对容器技术特点的安全攻击和防范方法将会各自提升到一个新的阶段。当前的云计算用户对针对容器的攻击方式和防范方法仍缺少意识和规范的制度，此前在Docker Hub中发现的几十个恶意Docker镜像至今仍存在于某些用户的生产环境中，未加以任何审核和监控。但随着容器和Serverless的普及和进一步应用，此过程中必将有更多的用户意识到“容器安全”在整个基础设施体系中的重要位置，并成为整个云计算生态的重要一环。进而催生出DevSecOps等新技术最佳实践。 云安全事件将波及社会基础服务设施在云计算发展之初，一度打出的口号是成为“IT行业的水和电”。云计算也确实在践行这一目标，并取得了IT基础设施的中心地位。有意思的是，和当初设想的略有不同，传统的社会基础设施，比如云计算的目标“水和电”，也已经开始和云计算互相融合。传统行业和社会基础服务设施也已开始数字化转型和网络化改造。《世界城市报告》指出，未来20年全球发展中国家的城市，每年都会新增近7500万人口，满足这些人口的需求，自然就需要对现有的社会服务基础设施进行改造。 金融支付、智慧交通、智慧城市、智慧油田、智慧电网、智慧农业等等都是新兴的基于云计算的社会基础服务设施改造工程。这些改造在享受云计算带来的种种便捷，提升社会整体效率的同时，也将传统社会服务基础设施和数字基础设施相互耦合，物理世界与数字世界的边界将进一步模糊。此时数字基础设施所遭受的安全风险将不仅仅局限于数字世界内部，而将进一步传导至日常社会生活的方方面面。针对此类风险的安全监管和防护规范必将成为相关工作的重点。 云计算服务商将加强与安全生态的合作云计算把涉及IT基础设施的方方面面都高度集成并统一开放给用户，计算、存储、网络、应用都划归于统一的资源池，成为一套完整的体系。并且各个不同云计算服务商之间也将涉及混合云业务和多云互联等业务。云计算安全防护的考虑，也必须针对每一个可能涉及的环节。Gartner也有报告指出，云计算服务商将最终向着“安全服务提供商”转变。 计算、存储、网络每一项都是一个专门的安全研究领域，单凭任何一家企业或组织都不可能构建一个涵盖全部细节的安全体系。云计算服务商现在多是采取与用户”责任分担”的安全策略，但并不能从根本上解决安全问题。好消息是，传统的安全公司也在向虚拟化和云原生转型，提供多种适合云计算环境的安全防护产品，并在某一特定领域有多年的沉淀和积累。云计算服务商、用户、安全生态合作伙伴将在这种合作模式中各取所需，一同打造完整的云计算安全体系。 使用云内流量可视化构筑微分段安全策略微分段（Microsegmentation）是当前确保云内安全的一种有效的实践方式。通过隔离不同属性的工作负载并单独加以防护，使网络具备细粒度防护的能力，同时安全规则可以随着工作负载在云内的迁移而迁移。确保不因云环境的灵活性特点而产生额外的安全策略维护负担。 针对工作负载的可视化，比如应用流量，性能，访问拓扑关系等信息，可以让用户快速构建适宜的微分段策略，并实现安全策略的自动化下发和处理。通过云内流量可视化的手段，对虚拟机和容器基于应用、审计合规需求、数据敏感性等特征分组并划分为不同的工作负载，将会极大减轻规则维护开销，并提供适应于云环境特点的细粒度的防护能力。这将是未来确保云内网络安全的主流方式。","categories":[{"name":"commerical","slug":"commerical","permalink":"https://decodezp.github.io/categories/commerical/"}],"tags":[{"name":"commerical","slug":"commerical","permalink":"https://decodezp.github.io/tags/commerical/"}]},{"title":"Quickwords 26 Linux Perf Under The Hood","slug":"quickwords26-linux-perf-under-the-hood","date":"2019-04-12T16:22:44.000Z","updated":"2019-04-12T16:40:57.653Z","comments":true,"path":"2019/04/13/quickwords26-linux-perf-under-the-hood/","link":"","permalink":"https://decodezp.github.io/2019/04/13/quickwords26-linux-perf-under-the-hood/","excerpt":"Too many perf usage articles exist on the Internet yet few talks about its source code, mechanism and architecture under the hood. For anyone who’s not satisfied with a black box, this article tries to address this. Hardware Background KnowledgeYou probably know that perf retrieves CPU hardware PMU counter value at some regular sampling frequency to make everything happen. The path through the hardware value is called MSR(Model-Specific Register) operations. Note that MSR is a general designation for various kinds of registers and PMU is just a small portion of it. To be more specific, we are mainly talking about the Performance Event Select Registers and the Performance Monitoring Counters(PMC) which make up the PMU together. By interacting with the Performance Event Select Register at the software side, value of performance events is streaming out via PMC.","text":"Too many perf usage articles exist on the Internet yet few talks about its source code, mechanism and architecture under the hood. For anyone who’s not satisfied with a black box, this article tries to address this. Hardware Background KnowledgeYou probably know that perf retrieves CPU hardware PMU counter value at some regular sampling frequency to make everything happen. The path through the hardware value is called MSR(Model-Specific Register) operations. Note that MSR is a general designation for various kinds of registers and PMU is just a small portion of it. To be more specific, we are mainly talking about the Performance Event Select Registers and the Performance Monitoring Counters(PMC) which make up the PMU together. By interacting with the Performance Event Select Register at the software side, value of performance events is streaming out via PMC. The Performance Event Select Register has quite a lot of control flags to let you specify which and how a performance event you’d like to monitor. This article does not try to cover this topic, one can refer to the Intel Software Developer Manual for detail. The PMC value can be proactively counted as well as reactively sampled. In this article we narrow our scope to the proactive manner only as we would like to concentrate more on the “big picture”. How perf WorksIn order to understand how perf works we need to answer the following questions: How to read PMC How does perf obtain PMC value via file operation These are basically the core functionalities of perf and every its fancy feature is based on this. How To Read PMUMSR is relatively difficult to interact when compare to stuffs like rdtsc. You need a whole software schema to build up the APIs even though they share similar names(rdpmc). Regarding the underlying implementation, one can find in the struct pmu data struct(/include/linux/perf_event.h) which consists of a branch of operation function pointers. Implementations pointed by these pointers are the real workers for PMU tasks. In case of x86, the implementations are located in file /arch/x86/events/intel/core.c. Address of worker functions are assigned to corresponding function pointers in struct x86_pmu(/anch/x86/events/core.c). Set x86_pmu_read which reads the PMU of a particular kind of event as an example, this function finally invokes x86_perf_event_update()(/arch/x86/events/core.c) to obtain PMC value via rdpmcl which involves with the ultimate assembly instruction, in a compare and swap manner. How Does perf Obtain PMC Value via File OperationA complete perf_event consists of the value of PMC, the critical part, and a handful of linked list, status and statistics elements. The definition is struct perf_event in /include/linux/perf_event.h. perf_event exposes as a file descriptor to the user space applications(stat, top, record etc). These applications interact with perf_event, as well as PMU, by invoking normal file operations on corresponding file descriptors. It appears that application just calls read on a file operations, actually, the read action has already been replaced by actions of static const struct file_operations perf_fops in /kernel/events/core.c. The real read function invoked is perf_read. This function will finally call pmu-&gt;read to stream out the PMC value. The initialization process of perf_event and file descriptor is sys_perf_event_open in /kernel/events/core.c. The new file descriptor will be returned when success. In real application, buildtin-stat.c for instance, __run_perf_stat consequently calls process_interval(), read_counters(), read_counter(), perf_evsel__read_counter(), perf_evsel__read_one(), perf_evsel__read(), and readn(). Multiple file descriptors/counters can be polled as same as the normal poll() operation from application’s perspective. The only difference is invoking fd’s customized poll() function.","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"perf","slug":"perf","permalink":"https://decodezp.github.io/tags/perf/"}]},{"title":"几句话说清楚25：Skylake微架构(Microarchitecture)剖析(9)","slug":"quickwords25-skylake-pipeline-9","date":"2019-04-07T17:20:24.000Z","updated":"2019-04-07T17:25:47.250Z","comments":true,"path":"2019/04/08/quickwords25-skylake-pipeline-9/","link":"","permalink":"https://decodezp.github.io/2019/04/08/quickwords25-skylake-pipeline-9/","excerpt":"接上期。 第六个cycle之后看一下第六个cycle时会发生什么。","text":"接上期。 第六个cycle之后看一下第六个cycle时会发生什么。 仍然分为两个阶段。第一个阶段cycle 6’里，第六条ADD指令指令可以进入ROB以及RS。 在RS中，D-tag填写该指令所在的ROB条目ROB6，两个操作数通过读取RAT获得，R4和R2对应的分别是ROB5和ROB1。 RAT中R1所对应的最新值修改为ROB6。 在第二个阶段，注意到此时第二条指令也在cycle 6执行完毕，因此它将执行的结果(8)写入到其所在的ROB条目ROB2，并在同时将执行的结果广播给RS中的指令。 此时RS中的MUL指令正在等待ROB2的值，此时将其对应的Value1中写入计算的结果(8)。 在第七个周期，注意到第五条指令也该执行完成，其所执行所得到的结果(-1)，也需要写回到ROB5并广播给RS中的指令。但此时没有等待该值的指令。所以对其他状态暂时没有影响。 但如果此时有新的指令需要R4，ROB5此时的值可以直接传递给该指令。 在第7个指令之后，CPU进入一个尴尬的时期。没有新的指令执行完毕，RS中的指令也没有Ready的，观察一下时刻表，下一个时刻有新的指令执行完毕是cycle 12的事。 在cycle 12中第一条DIV指令执行完毕，结果写入ROB1，广播结果给RS中的指令，正好两个都需要ROB1，并且拿到这个结果之后都进入Ready状态，可以在下一个cycle执行。 更新一下第四条和第六条指令的时刻表，执行都是在第13个cycle，完成将分别在第16和14个cycle。 此时还发生了一件事，就是ROB中的第一条指令的DONE标志位标成了Y。ROB之前我们介绍是一个先入先出的FIFO结构，只有第一条指令完成之后，才能按顺序开始commit。 所以在cycle 13，第一条指令历史性的commit了。Commit的意思就是把结果写入到ARF，因此R2在ARF中改为了4。同时删除该ROB条目，为后续的指令腾出资源。当然RAT中也不再需要rename到ROB1，最新的值已经在ARF中。 在cycle 14中，ROB中的当前在队列头部的指令，也就是第二条指令也可以commit了，按之前的操作，R1的值也改成了最新的值(8)。 同时，第六条指令也执行完毕，计算的结果写入ROB6。当然这条指令还不能commit，因为commit需要按指令顺序。 第15个cycle，除了commit第三条指令之外没什么好做的。和以前的操作类似。 第16个指令，第4条指令执行完毕，结果写入ROB4，同时它也是当前ROB中在队列头部的指令，可以在下一个cycle commit。 那就commit呗。 剩下的第18,19 cycle想必你也知道该干什么了：把最后的两条指令commit掉。 OK，当指令时刻表都完成之后，这6条指令正式执行完毕。 关于这几个组件全部目的都在于通过一个示例解释RAT, ROB和RS这三个组件的组成、特性和功能。在熟悉了这个例子的基础上可以再去寻找那些传统的“教科书”去印证理解那些大段大段的文字描述。 这个例子其实还缺少一些类似分支转跳，尤其是分支预测失败之后如何操作的说明。但足矣描述清楚CPU的乱序执行和顺序commit到底是怎么回事。 关于CPU微架构，前端和后端的内容基本上介绍的差不多了，后面会开始最后一个部分，也就是内存操作相关的组件的介绍。兴许会再添加一个后端执行的示例也说不定，看心情。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"几句话说清楚24：Skylake微架构(Microarchitecture)剖析(8)","slug":"quickwords24-skylake-pipeline-8","date":"2019-04-06T04:58:15.000Z","updated":"2019-04-06T04:59:55.285Z","comments":true,"path":"2019/04/06/quickwords24-skylake-pipeline-8/","link":"","permalink":"https://decodezp.github.io/2019/04/06/quickwords24-skylake-pipeline-8/","excerpt":"一个示例介绍Reorder Buffer(ROB)和Register Alias Table(RAT)和Reservation Station(RS)理解乱序执行（Out-of-Order）的核心其实就是把ROB，RAT和RS这三个组件搞透。","text":"一个示例介绍Reorder Buffer(ROB)和Register Alias Table(RAT)和Reservation Station(RS)理解乱序执行（Out-of-Order）的核心其实就是把ROB，RAT和RS这三个组件搞透。 如果要单独讲，很容易成为一大锅概念和专有名词的杂烩。所以这次把这几个紧密相关的组件放到一起，先用例子说明，仅描述自然行为，同时也避免出现太多概念。 上图是在一个起始时刻CYCLE 0时CPU后端各组件的状态。它即将执行Instructions表格里的6条指令。不同种类指令所需要消耗的执行时间如Cycle Consumption所示。 ARF是Architectural Register File，里面保存有当前时刻architectural register中的值；RAT就是前面介绍过的Register Alias Table，主要用作对architectural register的Rename。 Reservation Station(RS)根据所连接的执行不同类型指令的Port而分成两类，一类保存ADD/SUB相关的指令，一类保存MUL/DIV相关的指令。里面的指令在两个Value都Ready的时候将发送到执行单元执行。 Re Order Buffer旁边的表格是这6条指令从Issue到Execute, Write最后再到Commit这几个状态的cycle时刻表。 OK，那么下面进入第一个cycle。 第一条指令DIV R2, R3, R4按照先进先出的原则首先进入ROB1。 在ROB中，Dst填该指令的目的architectural register，也就是R2；Value是该指令执行完计算出来的结果，显然现在还不得而知，表示是否执行完的Done标志位也是N的状态。 同时针对DIV指令的RS中也有空闲资源，因此该指令也会在同一cycle进入RS。目的tagD-tag填写指令对应的ROB条目(ROB1)；Tag1和Tag2通过查阅RAT中R3和R4的状态，如果有Rename的情况，则填写对应的ROB条目，如果没有，则直接读取ARF中的值，作为Value填入。 因此，D-tag是ROB1，Tag1和Tag2因为R3和R4没有Rename所以不填，直接读取ARF中的值，20和5，放入Value1和Value2中。 之后，在RAT中，R2被Rename成了ROB1，即表示后续指令欲读取R2的值的话，都应该去读取ROB1中value的值。 此时该DIV指令所需要的操作数都已经Ready，那么就可以在下一个cycle时从RS中发射到执行单元去执行。 下面进入第二个cycle。 在第二个cycle中，第一条DIV指令开始执行，根据DIV的执行周期，那么我们知道它将在第2 + 10 = 12个cycle中执行完成。同时ROB中还有空闲，我们可以issue第二条MUL指令。 在RS中，上一条DIV指令已经清出，也有空闲资源，所以MUL指令也可以进入到RS中。另外几个选项也如DIV指令的判断方式，因此D-tag为ROB2，两个value为4和2。此时MUL指令也已经Ready，可以在下一个cycle开始执行。 同时RAT中将R1rename到ROB2。因为后续最新的R1的值将等于ROB2中的value。 在第三个cycle中，MUL指令开始执行，根据MUL的执行周期，它将在第3 + 3 = 6个cycle中执行完成。因ROB中 还有空闲，此时可以issue第三条ADD指令。 RS里面，ADD指令需要放到存放ADD/SUB指令的RS中，除此之外，各字段的填写方式与之前的指令没有区别。R7和R8也可以直接从ARF中获取数值，因此该ADD指令也已经Ready，可以在下一个cycle开始执行。 之后，RAT中将R3rename到ROB3。 那么在第四个cycle中，第四条MUL指令可以进入ROB和RS之中。在RS中，D-tag填入该指令对应的ROB条目，即ROB4。而它的第一个操作数R1通过RAT读取（参见cycle 3中的RAT情况。），rename到了ROB2，因此tag1需要填ROB2。Tag2同理，填ROB1。 之后，RAT中的R1需要rename到ROB4，以保持最新的状态。 RS中，因为该条指令两个操作数的value还没有Ready，不能在下一个cycle开始执行，因此还暂存在RS之中。 在第五个cycle中，拆成两个阶段来看。第一个阶段，也即cycle 5`，第五条SUB指令进入ROB和RS，各字段的填写方式与之前相同。 在cycle 5的第二个阶段中，注意到指令时刻表中，第三条在指令将在cycle 5完成执行，并进入Write阶段。 于是此时第三条指令在ROB中对应的ROB3的Value中将填入该指令执行的结果，也就是3，同时设置标志位DONE为Y。 在执行完成之后，在同一个cycle中，CPU还将进行一个操作，就是将该结果广播给RS中现存的指令，如果有等待ROB3执行结果的指令，将接收该结果并更新状态。 在当前RS(Adder)中，SUB指令正在等待ROB3的结果（参见cycle5`），于是其不再等待Tag1，并在Value1中填入结果3。此时该SUB指令也已经Ready，并将在下一个cycle中执行，根据其执行开销，将在第6 + 1 = 7cycle时执行完成。 后面的下期再继续。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"几句话说清楚23：Skylake微架构(Microarchitecture)剖析(7)","slug":"quickwords23-skylake-pipeline-7","date":"2019-04-03T14:01:30.000Z","updated":"2019-04-06T05:08:20.991Z","comments":true,"path":"2019/04/03/quickwords23-skylake-pipeline-7/","link":"","permalink":"https://decodezp.github.io/2019/04/03/quickwords23-skylake-pipeline-7/","excerpt":"接前Register Rename这次得用Markdown画表格了，想来想去用markdown这么久还是第一次。","text":"接前Register Rename这次得用Markdown画表格了，想来想去用markdown这么久还是第一次。 如前所述，physical register的数量远多于architectural register的数量。其实architectural register仅仅是一个“代号”，并不是真正存放数据的位置。用这种方式，可以消除WAW和WAR这两种数据依赖进而增加程序整体的并行性。 那么到底怎么操作呢？其实本质上也就是建立一个“映射表”，一个从“代号”到存储位置的映射表。 E.g. 现有5个architectural register寄存器：r1, r2, r3, r4, r5；9个physical register寄存器：p1, p2, …, p9。 指令： 123Add r1, r2, r3 ;r1 = r2 + r3Sub r2, r1, r2 ;r2 = r1 - r2Add r1, r4, r5 ;r1 = r4 + r5 最开始是一个简单的映射关系： r1 r2 r3 r4 r5 p1 p2 p3 p4 p5 在这张表里面还有一个FreeList，用来保存还没有被占用的physical register。 p6 p7 p8 p9 OK，首先考虑不使用Register Rename的情景。第二条指令是必须等待第一条指令执行完成之后才能执行，因为r1有RAW型依赖。这个其实Register Rename也没有办法。但是第三条指令也不能在第二条指令之前执行，因为写入r1可能会影响第二条指令的结果（r2）。 为了增加指令的并行性，让第三条指令能与第一条指令并行，同时消除WAW和WAR型依赖，看一下Register Rename是怎么做的。 第一条指令就用原始对应的寄存器，此时还没有Register Rename。对应的“映射表”Rename Table如下： r1 p1 r2 p2 r3 p3 r4 p4 r5 p5 第二条指令中，r2针对第一条指令有WAR型依赖，可以将写入r2的结果放在另外一个寄存器里。从FreeList中选取下一个空闲的physical register，即p6。 所以这条指令实际上就变成了Sub r6, r1, r2; r6 = r1 - r2。 Rename Table如下： r1 p1 r2 p6 r3 p3 r4 p4 r5 p5 即告之后续指令r2最终的结果保存在p6里面。 第三条指令，r1针对第一条指令有WAW型依赖，可以将写入r1的结果放到另外一个寄存器里。从FreeList中选取下一个空闲的physical register，即p7。 所以这条指令实际上就变成了Add p7, p4, p5 ; p7 = p4 + p5 Rename Table如下： r1 p7 r2 p6 r3 p3 r4 p4 r5 p5 即告之r1最终的结果保存在p7里面。 所有指令对architectural register的读取都先通过Rename Table获得确切地址。 回到最初提到的问题，因为第一条指令和第三条指令实际写入的寄存器（分别是p1和p7）并不冲突，且第二条指令仅在p1中读取数据，因此这两条指令可以并行执行。 现代CPU的Rename Table一般是在ROB里的RAT(Rename Alias Table)。同时physical register也会被ROB entry取代。 其实现在对Register Rename的理解更多的是建立一个概念，在整个微架构中，这一步不是一个孤立的组件，所有组件之间都需要紧密配合。 后续会对后端的执行进行示例介绍。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"雨中冒险2 Risk Of Rain 2","slug":"games-risk-of-rain-2","date":"2019-04-03T13:38:40.000Z","updated":"2019-04-06T05:09:38.542Z","comments":true,"path":"2019/04/03/games-risk-of-rain-2/","link":"","permalink":"https://decodezp.github.io/2019/04/03/games-risk-of-rain-2/","excerpt":"《雨中冒险》是我买的第一款Steam游戏。 6年前，刚刚毕业，手边只有一台上学时陪伴着我的笔记本电脑，我知道它只能带得动这种简陋的像素风游戏。","text":"《雨中冒险》是我买的第一款Steam游戏。 6年前，刚刚毕业，手边只有一台上学时陪伴着我的笔记本电脑，我知道它只能带得动这种简陋的像素风游戏。 好在这游戏可玩性很好，在2013年这个难过的年份里带给我很多慰藉。那时的我刚刚处于毕业后的迷茫期，各种失望，看不清也不想看什么所谓的未来。每天晚上下班在合租的房子里玩一会这个游戏，就是一天里最快乐的一段时间。 《雨中冒险》当时也小火了一阵。我会在网上看看别人的视频和评价，有一次无意中看到了游戏开发者发的一篇博客。我大概记着他在博客里说这款游戏最初只是一个学生项目，谢谢大家的支持，他没有想到可以走这么远。 传统的一些套话。我真正记住的是他后面说的： 我想看看还能走多远。 后来，我自己买了房子，摆了一台可以碾压市面上所有游戏的台式机，可以在Steam上不再关注什么打折促销信息，什么火买什么。简单地说，就是实现了“Steam自由”。 但很多最初期待颇高的游戏大作，我都是进入游戏看看，就再也没打开过。 唯一例外的是，我总会想起《雨中冒险》，虽然我距离上一次打开它已经有了三四年的时间。 人们会相信一些东西，往往只是因为那是人们心里想要相信的东西；人们也会记住一些东西，却并不是因为记忆力有多么好，而只是因为那是心里想要记住的。对我来说，我还一直记得《雨中冒险》，只是因为想要明确那个当初说“想看看还能走多远”的人，到底走了多远。 虽然我和这游戏的作者素不相识，但我那时仿佛单方面和他立了一个约定。 所以当我得知《雨中冒险》出了续作之后，一点也不吃惊；当我得知《雨中冒险2》是3D画面的时候，一点也不吃惊；当我购买了游戏结束了一盘战斗的时候，我觉得这游戏就应该是这个样子，我仿佛看到了我过去6年的足迹。 给五星，没有什么好说的。","categories":[{"name":"game","slug":"game","permalink":"https://decodezp.github.io/categories/game/"}],"tags":[{"name":"game","slug":"game","permalink":"https://decodezp.github.io/tags/game/"},{"name":"life","slug":"life","permalink":"https://decodezp.github.io/tags/life/"}]},{"title":"几句话说清楚22：什么是AF_XDP Socket","slug":"quickwords22-af-xdp","date":"2019-03-26T14:24:25.000Z","updated":"2019-03-26T14:36:30.222Z","comments":true,"path":"2019/03/26/quickwords22-af-xdp/","link":"","permalink":"https://decodezp.github.io/2019/03/26/quickwords22-af-xdp/","excerpt":"AF_XDP默认读者已经了解XDP(eXpress Data Path)的概念。","text":"AF_XDP默认读者已经了解XDP(eXpress Data Path)的概念。 基于Kernel提供的BPF能力，XDP可以提供高性能的数据面处理能力。 所谓AF_XDP，和AF_INET一样，也是address family的一种，用于规定socket通讯的类型。相当于socket底层通讯方式的不同实现（多态）。一般的，AF_INET可以用于IPv4类型地址的通讯，在实际通讯中应用自己的那套具体实现（TCP/IP协议栈等），AF_XDP就是一套基于XDP的通讯的实现。 还有支持IPX的AF_IPX，支持蓝牙的AF_BLUETOOTH等等Address Family。 Main Idea XDP程序在Kernel提供的网卡驱动中直接取得网卡收到的数据帧，然后直接送到用户态应用程序。应用程序利用AF_XDP类型的socket接收数据。 用虚拟化领域的完全虚拟化和半虚拟化概念类比，如果DPDK是”完全Kernel bypass”，那么AF_XDP就是“半Kernel bypass”。 XDP程序会把数据帧送到一个在用户态可以读写的队列Memory Buffer中，叫做UMEM。用户态应用在UMEM中完成数据帧的读取和写入。当然了，整个过程都是零拷贝（Zero Copy）的。 AF_XDP Socket和它的小伙伴们 AF_XDPSocket的创建过程可以使用在网络编程中常见的socket()系统调用，就是参数需要特别配置一下。在创建之后，每个socket都各自分配了一个RX ring和TX ring。这两个ring保存的都是descriptor，里面有指向UMEM中真正保存帧的地址。 UMEM也有两个队列，一个叫FILL ring，一个叫COMPLETION ring。其实就和传统网络IO过程中给DMA填写的接收和发送环形队列很类似。在RX过程中，用户应用程序在FILL ring中填入接收数据包的地址，XDP程序会将接收到的数据包放入该地址中，并在socket的RX ring中填入对应的descriptor。 但COMPLETION ring中保存的并非用户应用程序“将要”发送的帧的地址，而是已经完成发送的帧的地址。这些帧可以用来被再次发送或者接收。“将要”发送的帧的地址是在socket的TX ring中，同样由用户应用填入。 RX/TX ring和FILL/COMPLETION ring之间是多对一（n:1）的关系。也就是说可以有多个socket和它们的RX/TX ring共享一个UMEN和它的FILL/COMPLETION ring。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"}]},{"title":"后凉龙骧将军吕邈教你如何一本正经胡说八道","slug":"history3-lvmiao","date":"2019-03-24T13:26:32.000Z","updated":"2019-03-24T13:49:11.502Z","comments":true,"path":"2019/03/24/history3-lvmiao/","link":"","permalink":"https://decodezp.github.io/2019/03/24/history3-lvmiao/","excerpt":"胡说八道容易，看起来一本正经也不难，但那都是从你自己的眼光出发。 让别人看起来同样一本正经就非常有挑战了，即便你真的是在一本正经。","text":"胡说八道容易，看起来一本正经也不难，但那都是从你自己的眼光出发。 让别人看起来同样一本正经就非常有挑战了，即便你真的是在一本正经。 历史上很多著名的说服案例，其实都有一个“成功核心”。因此，那些有名的谋臣说客不用上沃顿商学院的谈判课也能够纵横捭阖。 和秦仪良平比起来，后凉龙骧将军吕邈只是一个小角色，但他也有属于自己的高光时刻。这个时刻就是那一次他胡说八道的时候。 吕邈也算是后凉的皇亲贵胄，虽然这个政权只有17年的历史，但这并不妨碍在这里上演那些百年王朝的保留节目——夺嫡。 后凉太祖吕光，是所有人的爸爸。但参与夺嫡的不仅有自己的儿子，还有自己的侄子。这场宫廷戏有三位主角：庶长子吕纂，侄子吕超，以及吕光嫡出的吕纬。而我们的主人公吕邈，是吕超的弟弟。 其实还有一位太子吕绍，在吕光崩后很快就被吕纂逼死。 吕纂继位不到一年，本来朝内就众心不安，几个兄弟又各自为政，本应多加优抚，延揽人心，却又不知道哪根筋搭错，对吕超开起了“不听话就把你杀掉”的玩笑。吕超自然当了真，也不得不当真。在一起喝了场大酒之后趁机将吕纂贯胸刺死。 吕超虽说杀了吕纂，但还不能自己继承大统，因为按继承人的顺位，前面还有吕光的嫡子吕纬。 当时就有人劝吕纬： 超为逆乱，公以介弟之亲，仗大义而讨之。姜纪、焦辨在南城，杨桓、田诚在东苑，皆吾党也，何患不济！ 倘若能兴“义师”击超，或许真能一战。但吕纬自然知道，成王败寇，这一仗如果不能保证取胜，那么自己只会万劫不复。面对“举事已成，据武库，拥精兵”的吕超，吕纬心里还是打鼓的。 这种时候，谁都需要有一个人能信任。而之所以信任他，并不是“这个人”多么值得信任，而是“这个人”能告诉你，你自己是多么值得信任。 这就是那些纵横家赖以肆其志的关键，但在具体的操作手法上还有讲究。 于是我们的主人公登场。吕超的弟弟吕邈当时“有宠于绍”，进言曰： 纂贼杀兄弟，隆、超顺人心而讨之，正欲尊立明公耳。方今明公先帝之长子，当主社稷，人无异望，夫复何疑！ 在我们这些“外人”看来，这根本就是吕超派来的卧底在跳反：用这些华而不实的理由麻痹吕邈，给吕超以可乘之机。 吕超杀了吕纂，是为了给吕绍你清除障碍，现在大家都等着你去当老板，吕超根本就没想和你抢——这不是胡说八道是什么？ 吕绍绝非昏聩之人，又在吕家历练多年，既知道宫廷斗争的六亲不认，也知道吕邈和吕超的关系。他说的话，能信吗？ 纬信之，乃与隆、超结盟，单马入城；超执而杀之。 他彻头彻尾地信了，于是彻头彻尾地输了。 吕邈这段话为什么能在吕纬这里取得“一本正经”的效果，主要有以下几个原因： 吕纬愿意相信。当时的形势，吕纬如果不兴师任由吕超发展，那么自己肯定是下一个被除掉；如果兴师讨伐，心里却没底，甚至他可能已经肯定自己在军事上不是吕超的对手。两者都是死，但他同时也认定一点，就是自己在“伦理”上占有嫡出的优势，这是他唯一的“卖点”。所以他愿意相信吕邈说的，这是第一个原因。 吕邈说出了吕纬对现实的设定。“先帝长子，当主社稷”，这应该是吕纬无数次对自己说过的话。人在世上，只受一件事的驱动，那就是让自己的想法与现实实际保持一致。但这件事有一个特点，如果是自己考虑，会对“现实究竟是不是我想的这样”保持怀疑，但如果由别人说（特别是自己从来没有向别人提起过），那么就很容易轻信。因为这份“认同”是现实能向我们罗织的最温柔的陷阱。这是第二个原因。 吕邈描绘了一幅图景。这是这套一本正经胡说八道心法的具体招式。“正欲尊立明公耳”，让人仿佛看到了吕超将王位拱手让人，北面称臣的样子，吕邈可能还给自己添了些黄袍加身、山呼万岁的戏份。在前两点的前提下，如果再能将具体的景象描绘出来，激发出对方的瑰丽想象，那么你的胡说八道就成了发自肺腑的金玉良言。 庄子《大宗师》开篇有云： 知天之所为，知人之所为者，至矣。 老天究竟是什么意思，我摸不明白，但人都在想什么，庶几可以窥测。特记于书侧： 此非纬昏闇轻信，固邈之所言，如纬自言，邈之所劝，如纬自劝；言而能验，事与意合，此即人之所为。","categories":[{"name":"history","slug":"history","permalink":"https://decodezp.github.io/categories/history/"}],"tags":[{"name":"history","slug":"history","permalink":"https://decodezp.github.io/tags/history/"}]},{"title":"商业供稿2：网络可视化如何抵御数字化转型风险","slug":"commerical2-visibility-digital-transform","date":"2019-03-23T00:41:19.000Z","updated":"2019-03-23T00:46:23.346Z","comments":true,"path":"2019/03/23/commerical2-visibility-digital-transform/","link":"","permalink":"https://decodezp.github.io/2019/03/23/commerical2-visibility-digital-transform/","excerpt":"原载于云杉网络 www.yunshan.net 微信公众号 当前，“数字化转型”已成为企业或组织绕不过去的一个话题。诚然，并非所有(云杉网络的)客户都会直接声称“我们正在数字化转型”或者“我们正在做一个数字化转型的项目”，但对IT基础设施进行敏捷性改造，提升业务灵活性和效率，已是各行各业的一致追求。","text":"原载于云杉网络 www.yunshan.net 微信公众号 当前，“数字化转型”已成为企业或组织绕不过去的一个话题。诚然，并非所有(云杉网络的)客户都会直接声称“我们正在数字化转型”或者“我们正在做一个数字化转型的项目”，但对IT基础设施进行敏捷性改造，提升业务灵活性和效率，已是各行各业的一致追求。 数字化转型不是一蹴而就，对希望能“快速转型”的企业CIO和IT Leader来说，除了关注转型的战略制定和执行之外，还需要特别注意转型过程的风险。这些风险不仅会延长数字化转型的周期，还会降低IT基础设施的整体可用性。有没有可以显著降低转型风险的手段呢？近期一份研究机构推出的数字化转型关键观点报告表明：可视化是解决转型风险的关键(ASSET VISIBILITY IS KEY TO MITIGATING RISK)。 分析报告中提到了CIO与IT Leader在数字化转型中最为顾虑的几个问题： 关注最多的三个问题都与可视化直接相关。 IT基础设施中的盲点：在虚拟化已成为必选配置之后，容器、微服务、混合云、多云、云+边缘等最新趋势也将进一步加剧IT基础设施的复杂度，盲点也自然随之而生。“心里没底“是很多客户在面对复杂度呈指数级增长的IT基础设施时的共同心态。与其在半夜三更爬起来处理紧急网络故障，不如未雨绸缪，建立一套可以消除盲点的监控体系。各类监控工具自然是早已有之，但能适应IT基础设施最新发展的现代监控体系必须能“整合“进基础设施本身之中，换句话说，监控工具也应具有虚拟化或云原生的基因。所有支撑数字化转型的IT基础设施所具备的特点，也应同样适用于监控方案。唯有如此，监控才能伴随基础设施一同发展，并深入到日益复杂的基础设施的方方面面，才能看到传统监控工具看不到的“盲点”。在认识到基础设施复杂性的同时，也应意识到不同组件间的普遍关联性。如果仍将基础设施“分门别类”并分别加以监控，将只会在不同的部门之间树立一个个独立的“烟筒”，既令监控方案与基础设施方凿圆枘，无法发挥已有监控工具的能力，也无法通过统一的数据分析纳管消除盲点。 扩展监控的能力：IT基础设施在变得日益复杂的同时带来了一个简单粗暴的问题：如此大规模的数据采集和处理监控工具能不能扛得住？曾有报道提到Google每周启动40亿个容器，Uber的监控系统每秒钟采集5亿条指标。这些事件产生的是海量的需要处理的数据。即便很多企业或组织达不到这种互联网巨头的体量，但物理机、虚拟机、容器和网络规模的大幅度增长也是数字化转型过程中必然可以预见的事情。当量变产生质变，之前的工具和手段是否仍然行之有效，或者说，当前的监控方案为IT基础设施的增长预留了多大的成长空间，自然成为CIO和IT Leader关心的事情。相应的，现代监控系统也应具备这种伸缩能力以及深度优化的数据处理性能，才能持续为数字化转型保驾护航。这不仅要求该方案具有极高的技术含量，同时也需要深厚的产品哲学和数据理念。 成熟的IT运维流程：数字化转型享有的一大优势就是能以敏捷的方式应对业务和客户的需求，从而对市场做出快速反应。这一方面需要IT基础设施提供生产资料保证，另一方面，生产资料能创造多大的生产力，仍然取决于它握在谁的手里。传统的IT运维团队往往以各种形式划分为独立的小团队，团队之间会一般性地存在信息壁垒。这些壁垒导致运维流程只能不断迁就人为的限制，造成效率方面的损失，已不能适应数字化转型之后的IT基础设施的发展。为了应对数字化转型带来的挑战，CIO和IT Leader需要考虑为DevOps团队打造更加成熟的流程。一支训练有素的DevOps团队将是提高企业生产力的最核心要素。高效的团队一定有成熟的流程保证，但流程的制定是建立在信息透明，全局可控的基础之上。不同职能的个人可以在一个统一的可视化监控平台中交换信息，形成合力，逐步完善运维、扩容和安全流程。这也应是监控体系在数字化转型中提供的能力。 当企业或组织的CIO和IT Leader在评估IT基础设施中的监控方案时，需要着意上述提到的数字化转型过程中的风险以及它们的应对方法。","categories":[{"name":"commerical","slug":"commerical","permalink":"https://decodezp.github.io/categories/commerical/"}],"tags":[{"name":"commerical","slug":"commerical","permalink":"https://decodezp.github.io/tags/commerical/"}]},{"title":"生小猫啦","slug":"hello-kitty","date":"2019-03-20T12:33:55.000Z","updated":"2019-03-20T12:35:07.521Z","comments":true,"path":"2019/03/20/hello-kitty/","link":"","permalink":"https://decodezp.github.io/2019/03/20/hello-kitty/","excerpt":"去年夏天的时候家里从地铁站门口迎来了两位新成员，蓝猫derder和他的媳妇葡萄。 我其实本意并不想养宠物的，毕竟从小到大除了养过两只乌龟之外，从来也没和动物有过什么亲密接触。养猫基本上都是张老师的主意，她从小就是养鸡小能手，还养过狗啊鱼啊刺猬啊这些，所以一直想在家里恢复一下她的童年记忆。","text":"去年夏天的时候家里从地铁站门口迎来了两位新成员，蓝猫derder和他的媳妇葡萄。 我其实本意并不想养宠物的，毕竟从小到大除了养过两只乌龟之外，从来也没和动物有过什么亲密接触。养猫基本上都是张老师的主意，她从小就是养鸡小能手，还养过狗啊鱼啊刺猬啊这些，所以一直想在家里恢复一下她的童年记忆。 对此我嘴上说太麻烦，但其实心里多少也有一些期待。所以当某一天张老师告诉我地铁站门口在卖猫的时候，我也就直接答应了下来。 后来张老师跟我说，她一眼相中derder的原因就是因为他那张大脸，在一群猫中显得卓尔不群： 刚到家里的时候两只猫并没有这么放浪形骸，躲在前主人送的猫厕所里不敢出来。我们也完全是新晋猫奴，还曾担心过他们会不会因为思念过往得上抑郁症。后来证明完全是多余的，derder完全就是一只毫无气节奴颜媚骨的弄臣，几天的时间就把我们讨好得心甘情愿给他和他媳妇铲屎。 而和derder相比，葡萄就显得太过孤僻了。不敢和我们靠近，经常自己躲在一个小角落里向外观望，一旦家里有什么风吹草动就瑟缩在一个自认为安全的角落里。虽然颜值很高，但还是能看出心里总是有戒备，总是一副生气的表情，所以在家里完全失宠，作为derder的一个“附庸”存在，成为了“愤怒的葡萄”。 自从有了猫，我感觉家里的快递就没停过。猫粮、猫砂、猫罐头、猫薄荷、亮毛膏就一股脑地往家里运，还有猫抓板、猫别墅、饮水器、逗猫棒、摄像头、各种小玩具、小衣服等等不一而足。一直没仔细算过养两只猫一个月得有多少成本，但我觉得这个市场规模可能比我从事的云计算规模还大。 Derder很快就和我们混熟了，我觉得最重要的一点原因就是他从来不惮于表达他对我们的喜爱。晚上在门口迎接，跟着你到处跑，你坐下的时候就爬到你身上，不停地蹭你，拱你，用小肉垫拍拍你，喉咙里还经常呼噜呼噜的，让你觉得不用手撸他就是一种毫无人性的犯罪。我们也很吃这套，张老师每天都会把derder抱在怀里治愈自己。 这期间我换了份工作，张老师也取得了一些进步，所以有时候我们会把derder看成是家里的一个吉祥物，能够为我们带来好运气。我当初在derder来家里不久就把我的微信头像换成了他，当时很大一部分是出于讨好张老师的原因，后来我却是真的想用这个头像了。另外，为了祝贺我跳槽成功，张老师也送了我一个特别的礼物，叫做Der CUP。 张老师养猫的决策发挥了很大的积极作用，当然，在这个过程里我觉得我也做了两条关键的决策。第一是没有一上来就给derder绝育，而是等到葡萄怀孕之后。虽然不绝育有发情期的各种问题，但能体验到新生命降临的幸福感，这绝对是我的功劳。第二是没让张老师把葡萄送人，葡萄当时一直是一只孤僻胆小的小母猫，跟谁也不亲近，骨瘦如柴，还经常”保持愤怒“。但我还是不想放弃她，相信她最终能融入到我们家，因为我们家就有这种包容的气质。 后来证明我是对的，葡萄慢慢对我们放下了戒备，也慢慢有了些许的互动，甚至体重也上升了。我觉得虽然是我坚持没有放弃葡萄，但葡萄能产生这种转变应该主要归功于张老师。她天生就有这种母性的光辉和气质，能融化一切冰冷。 作为一个从前从未养过宠物的人，我从derder他们身上得到的最大的惊喜就是”陪伴“。以前我在电脑上搞个什么东西的时候，从来都是一个人，在我的意识里，其实就没有“有人陪着你”的概念。但是当derder开始在我弄这些东西的时候趴在我旁边，虽然他可能仅仅是想让我挠他，但这让我开始意识到生活中很多事情可以不必一个人完成。这对我来说，是很大的突破了。 转眼就到了圣诞节，derder和葡萄也在相互打闹和撕咬中成为了我们家里自然而然的一部分。每天早晨铲屎、吸地、铺猫砂、添水加粮都成了平日寻常，晚上也会在下班回到家的时候看到derder在门口贱贱的样子。张老师喜欢让两只猫当模特摆拍，然后修图发朋友圈。也不知道她是炫耀她的猫还是炫耀她对家的匠心。我非常希望看到她发这些照片，因为这让我感觉自己真的是一个“成功人士”。 刚进入2019年，葡萄就发情了，有那么几天会在家里叫一整夜。和张老师不同，我对葡萄非常宽容，因为我睡着了什么也听不见。葡萄就是那个时候怀孕的，怀孕之后的葡萄完全褪去了之前的“愤怒”和戒备，让我愈发觉得自己之前的决策简直英明神武。 随着葡萄的腰身越来越粗，我们也意识到葡萄要生了。既然我说了要为葡萄接生，我还是在网上搜了搜相关资料的。不过都太复杂了，所以我没怎么仔细看。我还是比较相信动物的本能和生存能力，真要出了问题，与其说是考验我的姿势水平，不如说是考验我的心理素质。这个我可以确保没有问题。另外有可能她生的时候我不在家或者是晚上在睡觉，所以看了也没用，日子就这么得过且过了。 直到前天下午我回到家，听到了不一样的叫声。我当时就意识到是葡萄生了。到阳台一看，除了有些血迹之外，葡萄看起来没有什么困难，4只新出生的小猫浑身湿哒哒的，有3只像derder一样的蓝猫，和一只像葡萄的蓝白。简单清理了一下现场，戴着手套把一只跑到产房外面嗷嗷待哺的小derder放回了准备好的产房里。上手一拿之下，才吃惊于小猫的重量，比看起来重多了。 我赶紧通知了张老师，和她分享了这份欣喜。我也感觉自己再次走了狗屎运，没有遇到难产这一类的特殊事件，葡萄自己就在我们没在家的时候把事都办了。另外我觉得最淡定的是derder，他好像什么事也没有发生一样。 到这里这篇文章就该结束了。没有什么总结，就是流水账一样的记述。每年过的节，要记得日子越来越多，让人习惯了过一段时间就总结点什么，其实没这个必要，上班开的会还不够多吗？也没有什么对未来的展望啊，规划啊这类内容，文章可以是流水账，但不能是PPT。 最后，这篇文章，献给张老师。 2019/3/20","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"OVS-DPDK 82599 VF初始化失败诊断方法一例","slug":"82599-vf-err-debug","date":"2019-03-19T12:55:24.000Z","updated":"2019-03-19T15:51:46.783Z","comments":true,"path":"2019/03/19/82599-vf-err-debug/","link":"","permalink":"https://decodezp.github.io/2019/03/19/82599-vf-err-debug/","excerpt":"问题在82599上创建了两个VF之后，各自绑定到vfio，启动DPDK时出现错误： 123PMD: eth_ixgbevf_dev_init(): VF Initialization Failure: -15EAL: Error - exiting with code: 1 Cause: Requested device 0000:01:10.0 cannot be used","text":"问题在82599上创建了两个VF之后，各自绑定到vfio，启动DPDK时出现错误： 123PMD: eth_ixgbevf_dev_init(): VF Initialization Failure: -15EAL: Error - exiting with code: 1 Cause: Requested device 0000:01:10.0 cannot be used 诊断其实第一眼也看不出个什么来，但报错信息提供了两个线索： 错误是eth_ixgbevf_dev_init报的 错误代码是-15 剩下后面的看起来也直接提供了error code和错误的root cause，其实什么也没说。 所以从eth_ixgbevf_dev_init入手吧。 先找到这个方法在哪： grep -r “eth_ixgbevf_dev_init” ./ 123456./ixgbe_ethdev.c:static int eth_ixgbevf_dev_init(struct rte_eth_dev *eth_dev);./ixgbe_ethdev.c:eth_ixgbevf_dev_init(struct rte_eth_dev *eth_dev)./ixgbe_ethdev.c: sizeof(struct ixgbe_adapter), eth_ixgbevf_dev_init);./ixgbe_ethdev.c: * is mapped to VFIO vector 0 in eth_ixgbevf_dev_init( )../ixgbe_ethdev.c: * If previous VFIO interrupt mapping setting in eth_ixgbevf_dev_init( )./ixgbe_ethdev.c: ret = eth_ixgbevf_dev_init(dev); 是在ixgbe_ethdev.c这个文件里没跑了。 打开看一下，是在： 123456789if ((diag != IXGBE_SUCCESS) &amp;&amp; (diag != IXGBE_ERR_INVALID_MAC_ADDR)) &#123; PMD_INIT_LOG(ERR, \"VF Initialization Failure: %d\", diag); /* * This error code will be propagated to the app by * rte_eth_dev_reset, so use a public error code rather than * the internal-only IXGBE_ERR_RESET_FAILED */ return -EAGAIN;&#125; 这个位置，但实际上打印的是一个变量diag的值。在上面diag的赋值方法是： diag = hw-&gt;mac.ops.reset_hw(hw) 这个看起来就是个抽象层封装了一堆ops函数指针的形式。要马上找到具体调用的是哪个实现还不是太容易的事情。但看到上面定义的IXGBE_ERR_INVALID_MAC_ADDR的宏就应该能猜到相关的error信息应该都在一起。 通过Ctags转跳IXGBE_ERR_INVALID_MAC_ADDR的定义，果然找到了我们要找的-15是什么错误： #define IXGBE_ERR_RESET_FAILED -15 OK，下面只要看一下这个错误在什么地方返回： 12345678910[root@Server-N3 ixgbe]# grep -r \"IXGBE_ERR_RESET_FAILED\" ././base/ixgbe_82598.c: status = IXGBE_ERR_RESET_FAILED;./base/ixgbe_vf.c: return IXGBE_ERR_RESET_FAILED;./base/ixgbe_x540.c: status = IXGBE_ERR_RESET_FAILED;./base/ixgbe_82599.c: status = IXGBE_ERR_RESET_FAILED;./base/ixgbe_82599.c: ret_val = IXGBE_ERR_RESET_FAILED;./base/ixgbe_phy.c: status = IXGBE_ERR_RESET_FAILED;./base/ixgbe_type.h:#define IXGBE_ERR_RESET_FAILED -15./base/ixgbe_x550.c: status = IXGBE_ERR_RESET_FAILED;./ixgbe_ethdev.c: * the internal-only IXGBE_ERR_RESET_FAILED 对我们的VF初始化场景来说，肯定就是在./base/ixgbe_vf.c这个文件里返回的前述的错误。打开看一下返回这个错误的逻辑是什么： 12345678/* we cannot reset while the RSTI / RSTD bits are asserted */ while (!mbx-&gt;ops.check_for_rst(hw, 0) &amp;&amp; timeout) &#123; timeout--; usec_delay(5); &#125; if (!timeout) return IXGBE_ERR_RESET_FAILED; 基本就是在一定时间段内检测一个寄存器有没有被设置正确，如果没有就返回这个错误。 好在代码注释中提到了检测的是RSTI/RSTD这两个标志位。 那就查查这两个标志位是什么意思呗，打开82599祖传的datasheet： 在PDF里搜索一下就能看到，这个标志位其实就是表示PF的reset过程有没有完成。 那么reset如果完成了..应该PF至少会UP起来吧…检查了一下果然PF没有UP，UP之后问题解决。 主要是主要并不是想说这个具体的问题应该怎么解决，而是如何在不死扣细节的情况下快速找到线索，快速解决问题。从最直接的表象入手，熟稔一套猜测的直觉，保持对复杂问题的简单看法。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"dpdk","slug":"dpdk","permalink":"https://decodezp.github.io/tags/dpdk/"}]},{"title":"几句话说清楚21：Skylake微架构(Microarchitecture)剖析(6)","slug":"quickwords21-skylake-pipeline-6","date":"2019-03-10T03:44:34.000Z","updated":"2019-03-10T03:48:45.973Z","comments":true,"path":"2019/03/10/quickwords21-skylake-pipeline-6/","link":"","permalink":"https://decodezp.github.io/2019/03/10/quickwords21-skylake-pipeline-6/","excerpt":"OOO Once More这里对OOO(Out-Of-Order)乱序执行再简单讲两句。深入乱序执行的难点不在于“不按指令顺序执行”，而是如何做到“按指令顺序退出”。 这里面的关键是，所有执行过的指令都先被“缓存”起来，并不把执行之后的结果真正写到寄存器或者内存里。从用户角度看，这个指令其实并没有被“执行”，因为它没有引起任何数据方面的变化。等到它可以确定是需要被执行的指令，并且它前面的指令都已经把结果写入(commit)之后，它再去Commit。这样从用户角度看来，程序就是按照指令顺序执行了。","text":"OOO Once More这里对OOO(Out-Of-Order)乱序执行再简单讲两句。深入乱序执行的难点不在于“不按指令顺序执行”，而是如何做到“按指令顺序退出”。 这里面的关键是，所有执行过的指令都先被“缓存”起来，并不把执行之后的结果真正写到寄存器或者内存里。从用户角度看，这个指令其实并没有被“执行”，因为它没有引起任何数据方面的变化。等到它可以确定是需要被执行的指令，并且它前面的指令都已经把结果写入(commit)之后，它再去Commit。这样从用户角度看来，程序就是按照指令顺序执行了。 在很多文档里，Commit和Retire是两个可以互换(interchangable)的词。 说实话，研究这块东西，最烦的就是同一个概念有N个名字。 再来总结一下OOO的Big Picture: 左边Fetch&amp;Decode是之前讲的前端（Front-End）相关的内容。此时指令还是有序的。 Decode成微指令（uop）之后，这些微指令进入一个指令池（Instruction Pool），这里面能够被执行的指令，就直接被执行。“能够被执行”是指满足以下两个条件： 已有指令需要的数据 执行单元有空闲 当指令被执行之后 通知所有对该指令有依赖的指令（们），它们所需要的数据已经准备好。 注意这里说的是“执行”，不是上面说的“Retire”或“Commit” 为实现这一功能，CPU中还必须要对微指令的操作数（数据）有Bookkeeping的能力 Commit指令 只有当前指令的前序（指令顺序）指令都Commit之后，才能Commit当前指令 Commit也可以并行进行，前提是满足上面一条的条件，同时并行Commit的指令间没有依赖 False Dependency乱序执行的一大前置条件就是指令数据间没有相互依赖。下面就着重分析一下依赖。 用下面的指令过程作一个示例： 简单分析一下： Read After Write(RAW)型依赖(2)指令需要读取r1的值，而r1的值需要(1)指令执行之后给出。所以(2)指令对(1)指令有RAW依赖。RAW依赖也被称作true dependency或者flow dependency。 Write After Read(WAR)型依赖(3)指令需要更新r8的值，但在此之前(2)指令需要读取r8的值参与计算。所以(3)指令对(2)指令有WAR依赖。WAR依赖也被称作anti-dependencies。 Write After Write(WAW)型依赖(4)指令需要在(2)指令写入r3之后再写入r3。所以(4)指令对(2)指令有WAW依赖。WAW依赖也可以被叫做output dependencies 按照以上的分析，这几条指令几乎没有可以并行执行的余地。不过，我想你也已经看出了一些“转机”：针对WAR和WAW，是可以被Register Rename这种方法破解的。这两种依赖都被称为false dependency。 Register Rename当需要写入r1的指令在读取r1的指令之后，写入的r1的新值可以首先保存在另外一个寄存器r1’里。读取r1的指令仍然读取原r1寄存器中的值，这样WAR指令就可以并行执行。当所有需要读取r1原值的指令都执行完毕，r1就可以用新值代替。 Register Rename其实就是利用CPU提供的大量的物理寄存器，为寄存器制作“分身”或者，Alias，提供能够增加程序并行性的便利。 上面的例子里，r1是architectural register，r1’是内部的physical register。Rigster Rename就是在制作这两种寄存器间的映射关系。当然，这一切对用户来说都是透明的。 其他内容留待后面介绍。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"在控制台水平滚动","slug":"terminal-horizontal-scrolling","date":"2019-03-07T13:05:17.000Z","updated":"2019-03-07T13:06:42.596Z","comments":true,"path":"2019/03/07/terminal-horizontal-scrolling/","link":"","permalink":"https://decodezp.github.io/2019/03/07/terminal-horizontal-scrolling/","excerpt":"在CLI下操作，很多时候会因为屏幕尺寸的原因导致格式化输出的字符变成一副惨不忍睹的样子。比如你在有很多CPU核的环境下打印cat /proc/interrupts的时候。 当然你可能有很多方式能够处理这种情形，比如使用awk或者重定向到某个文件再打开。","text":"在CLI下操作，很多时候会因为屏幕尺寸的原因导致格式化输出的字符变成一副惨不忍睹的样子。比如你在有很多CPU核的环境下打印cat /proc/interrupts的时候。 当然你可能有很多方式能够处理这种情形，比如使用awk或者重定向到某个文件再打开。 但要始终相信Linux总有更好的办法，不可能在如此常见的场景中留下没有人看管的尾巴。 经过一番尝试和搜索，终于发现一个最简单的方法： cat /proc/interrupts | less -S 使用Arrow键水平移动就可以了。 信念帮助了我们！","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"linux","slug":"linux","permalink":"https://decodezp.github.io/tags/linux/"}]},{"title":"商业供稿1：消除虚拟化环境网络盲点","slug":"commerical1-eliminate-vnet-blind-spot","date":"2019-03-05T13:23:21.000Z","updated":"2019-03-23T00:45:36.061Z","comments":true,"path":"2019/03/05/commerical1-eliminate-vnet-blind-spot/","link":"","permalink":"https://decodezp.github.io/2019/03/05/commerical1-eliminate-vnet-blind-spot/","excerpt":"原载于云杉网络 www.yunshan.net 微信公众号 网络盲点是引起虚拟化环境中业务中断、服务质量下降以及遭受安全威胁的最主要原因。当公司或组织缺乏网络可见性，无法完全掌握其虚拟化环境中业务的网络运行情况时，将必然面临频繁的业务中断、客户投诉以及恶意攻击带来的损失。据Gartner预测，到2019年，实现适当的网络可见性和控制工具的60%的企业将减少三分之一的安全故障。 随着业务规模的扩大，公司和组织对网络可见性的投入亦将会持续增加。但除了购买增强网络可见性的产品和服务之外，还应针对虚拟化环境中的业务特点，从以下几个导致网络盲点的原因出发，构建完善的网络监控和安全体系。","text":"原载于云杉网络 www.yunshan.net 微信公众号 网络盲点是引起虚拟化环境中业务中断、服务质量下降以及遭受安全威胁的最主要原因。当公司或组织缺乏网络可见性，无法完全掌握其虚拟化环境中业务的网络运行情况时，将必然面临频繁的业务中断、客户投诉以及恶意攻击带来的损失。据Gartner预测，到2019年，实现适当的网络可见性和控制工具的60%的企业将减少三分之一的安全故障。 随着业务规模的扩大，公司和组织对网络可见性的投入亦将会持续增加。但除了购买增强网络可见性的产品和服务之外，还应针对虚拟化环境中的业务特点，从以下几个导致网络盲点的原因出发，构建完善的网络监控和安全体系。 缺乏虚拟网络监控手段Gartner报告声称80%的虚拟化数据中心流量将是虚拟机或容器之间的东西向流量。这些流量可能永远不会到达ToR交换机，而仅仅发生在服务器内部。随着东西向流量规模的进一步增长，以及未来微服务和Serverless架构的盛行，对虚拟环境网络及流量的监控将成为决定业务健康的重头戏。据某金融行业资深专家反馈，当前大部分公司或组织仍依靠传统的从ToR交换机上获取镜像流量的采集方式或是采用功能薄弱，性能不完善的虚拟网络监控工具，将使自身在虚拟网络和云时代中身处盲人摸象的尴尬境地。 采集丢包传统的流量采集方法多使用“采样”的方式采集大规模网络流量，这些信息一般会通过NetFlow/IPFIX等协议形式生成汇总信息。在采样的过程中将会不可避免地产生失真。这种失真虽然是一种折衷和妥协的产物，但却使得精细化的网络管理不再可行。在传统网络时代，采样的方式仍可以产生一定作用，但在虚拟网络时代，业务流量具有短连接多、并发与突发流量密集、转发路径复杂、虚拟机/容器E2E端点变化频繁等特点，使得原始的采样方法在构建真正能转化成生产力的网络全景视图方面显得力不从心，甚至因采样这种方式的天然缺点，可能会对网络运维人员产生误导。很多一线的网络运维人员反映，现有的工具无法满足他们在虚拟网络和云时代运维决策的制定需求。除此之外，在应对激增的东西向流量时，只有经过精心调校的采集软件可以在不影响服务器生产业务效率的条件下全量采集流量。除此之外的产品都将会因为过载而产生丢包，使得产品能力无法得到充分发挥。随着10G/25G/100G网卡在数据中心的普及，性能将成为一项关键指标。 虚拟机/容器变动虚拟化环境的特点就是可以针对不同的应用场景，从计算、存储和网络资源中灵活抽象出虚拟机/容器示例。当抽象的规模达到一定程度之后，将会逐渐失去对资源的掌控。在某金融企业1000台服务器规模的数据中心中，因回收不及时而闲置的虚拟机有将近100台的规模。另外，因一再删除添加的防火墙/安全组规则而产生的安全漏洞，以及在复杂的抽象层中丢失或延迟到达的网络流量，都将成为制约资源集约化利用，提供业务安全保障的网络盲点。 工具集关联在大规模企业和组织中，都存在多种网络工具共存的情形。将不同的工具可以提供不同的互补的能力，但往往需要事先配置不同的工具使能方式。如有些工具需要网元提供NetFlow信息，有些需要配置ERSPAN，有些需要In-band串联等等。这种后台工具各自不一的使能方式在增加网络复杂度的同时，也进一步提升了工具的使用成本。据分析机构报告显示，企业将持续增加IT预算，并达到5%以上的年增长率，IT工具会持续增多。因工具获取信息“源”各不相同，无法对各自的分析结果进行有效综合，也就无法形成工具间的优势互补，进而导致本应可以实现的能力没有实现，损害企业投资。若能从单一信息源处获取网络信息，将产生1+1&gt;2的规模优势。 工具操作复杂新的工具本身会很复杂，而让使用人员完全掌握新工具的特点，摸清它的“脾气”会是更复杂的事情。如何能最大效率地利用工具，为企业或组织带来最大的投资回报率并非是一件显然的事情。虚拟化环境以及云上环境本身正在变得越来越复杂，而针对它的工具也有同样的趋势。Gartner的报告显示，每增加25%的工具功能，将会提升100%的工具复杂度。而工具本身的复杂将从“工具盲点”最终传导为网络盲点。清晰、简明、强大的工具本身就是从最终用户的层面消除网络盲点的一种手段。 网络中的盲点将最终成为业务问题。其所波及的并不仅仅是网络组件，而是所有身处这一网络之中的虚拟化以及物理组件。消除网络盲点的方式就是提高网络，特别是虚拟网络的可见性。","categories":[{"name":"commerical","slug":"commerical","permalink":"https://decodezp.github.io/categories/commerical/"}],"tags":[{"name":"commerical","slug":"commerical","permalink":"https://decodezp.github.io/tags/commerical/"}]},{"title":"几句话说清楚20：eBPF的机制","slug":"quickwords20-ebpf-intro","date":"2019-03-01T13:56:23.000Z","updated":"2019-03-01T14:10:14.433Z","comments":true,"path":"2019/03/01/quickwords20-ebpf-intro/","link":"","permalink":"https://decodezp.github.io/2019/03/01/quickwords20-ebpf-intro/","excerpt":"怎么出来的eBPF用Linux Kernel Module来做一个类比说明eBPF诞生的目的。","text":"怎么出来的eBPF用Linux Kernel Module来做一个类比说明eBPF诞生的目的。 Kernel Module的主要目的就是让用户可以通过这种机制，实现对内核的“赋能”，动态添加一些内核本身不支持的功能，比如硬件的驱动能力，新的文件系统或是系统调用。当然也可以融合到现有的内核处理流程中，比如在netfilter的某个hook点中添加包处理方法等。 Kernel Module的优点： 动态添加/删除，无需重新编译内核 减小内核体积 缺点： 一旦出现BUG可能导致内核直接崩溃 增加内核攻击面，影响内核安全 eBPF要做的事情也非常类似，但它想要克服Kernel Module的缺点，即确保执行的代码绝对安全。 eBPF的使用方式为了达到这一目的，eBPF在内核中实现了一个虚拟机执行用户的指令。与Kernel Module直接在真实的物理硬件上执行用户的指令不同，eBPF提供给用户一个虚拟的RISC处理器，以及一组相关的指令。用户可以直接用这组指令编写程序。同时，程序在下发到该虚拟机之前也会经过eBPF的检查，比如会不会进入无限循环，会不会访问不合法的内存地址等等。只有在通过检查之后才可以进入执行的环节。 同时eBPF生态链中也有将高级语言转换成虚拟处理器指令的工具，这个主要靠LLVM提供。 eBPF的架构 对eBPF来说，和Kernle Module一样，也是通过特定的Hook点监听内核中的特定事件，进而执行用户定义的处理。这些Hook点包括： 静态tracepoint 动态内核态探针(Dynamic Kernel probes) 动态用户态探针(Dynamic User Probes) 其他hook点 针对主要是监控、跟踪使用的eBPF应用来说，主要通过这种方式取得内核运行时的一些参数和统计信息。例如，系统调用的参数值、返回值，通过eBPF map将得到的信息送给用户态程序，进而在用户态完成后处理流程。 另外一类应用则直接在一些内核处理流程中加入自己的处理逻辑，例如XDP，就是在网卡驱动和内核协议栈之间插入了eBPF扩展的网包过滤、转发功能。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"}]},{"title":"几句话说清楚19：描述性能优化成果的正确姿势","slug":"quickwords19-desc-perf-improvement","date":"2019-02-24T07:06:30.000Z","updated":"2019-02-24T07:09:28.413Z","comments":true,"path":"2019/02/24/quickwords19-desc-perf-improvement/","link":"","permalink":"https://decodezp.github.io/2019/02/24/quickwords19-desc-perf-improvement/","excerpt":"从10秒到1秒周末了说点不硬的技术。","text":"从10秒到1秒周末了说点不硬的技术。 自从摩尔定律不那么好使了之后，人们才真正开始关注软件性能。各类开源或者商业产品也经常以性能提升XXX作为卖点宣传。如果在搜索引擎以“性能提升[9, 8, 7, 6]0%”为关键字搜索一下，能看到连篇累牍的精确匹配的信息。但这些信息本身却并不“精确”，甚至都不正确。 经常能看到的一个错误与下面这个简化的例子相似： 一辆汽车以前行驶100米需要10秒钟，新型号推出后，仅需要1秒钟。 你会看到很多产品信息将这种提升描述为“性能提升90%”。 我猜测90%的计算方式是： (10 - 1) / 10 = 90% 但实际上这完全错误。 性能的表达所有的性能都可以表达为： 性能 = 工作量 / 单位时间 其实就是单位时间内能完成的工作量。 在上面的例子中，工作量是移动距离（m），单位时间（s），性能其实就是m/s，也就是“速度”。 我们有很多常用的指标已经直接是这种形式，例如QPS、PPS、BPS等。 性能优化的表达方式那前后两次的速度是多少呢？分别是10m/s和100m/s。那性能提升就是100m/s / 10m/s = 10x。 所以上面的例子中，你可以说： 性能（速度）10倍提升 快了10倍/1000% 但不能说： 性能提升90% 快了90% 一定要用到90%的话，那就是： 移动耗时减少90% 如果真正按性能提升90%来计算，那么速度之前是10m/s，之后是10 * ( 1 + 90% ) = 19m/s，也就是1.9倍。 这个问题在英语世界里也很常见。例如经常会看到一些Get something done 90% faster的宣传，其实都应该改成Get something done 10 times faster。当然也有故意利用这部分认知漏洞，让人误以为性能提升了10倍的。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"}]},{"title":"几句话说清楚18：PCIE带宽单位GT/s到Gbps转换方法","slug":"quickwords18-pcie-gtps-gbps","date":"2019-02-22T13:41:22.000Z","updated":"2019-02-22T13:48:53.561Z","comments":true,"path":"2019/02/22/quickwords18-pcie-gtps-gbps/","link":"","permalink":"https://decodezp.github.io/2019/02/22/quickwords18-pcie-gtps-gbps/","excerpt":"PCIE的表达方式PCIE使用GT/s这个单位表达自己的带宽，这并不是为了标新立异，而是为了更好（直接）地表达PCIE的工作方式。","text":"PCIE的表达方式PCIE使用GT/s这个单位表达自己的带宽，这并不是为了标新立异，而是为了更好（直接）地表达PCIE的工作方式。 原始的数据在采用PCIE总线传输的时候，需要重新编码。因为PCIE是一种串行总线所以总线时钟要嵌入在串行的数据里。为了保证数据接收方能够正确地还原出时钟，需要提供足够多的信号电位变化（Level Transitions），电位的高低其实代表的就是传输的比特（0或者1）。所以对PCIE来说，它的传输效率并非在于传输了多少有效的数据，而是电位变化的频率。 GT/s其实就是GigaTransfers per second。而重新编码的电位变化频率也会高于原始数据的比特变化频率，从而导致PCIE传输对带宽有一些因为编码产生的Overhead。 一次电位变化从数据角度说就相当于传输了一个Bit。所以在下面的计算里GT/s可以等同于Gbps，不过这是编码后的数据。 PCIE Gen2/Gen3的区别按上面介绍的原理，为了提高传输速率，一是提高最大可用电位变化频率，而是提高编码效率。 变化频率 Gen2最大支持5GT/s Gen3最大支持8GT/s 编码效率 Gen2编码8Bit原始数据需要10Bit的数据量 Gen3编码128Bit原始数据需要130Bit的数据量 GT/s到Gbps的转换 Gen2 Gen2最大支持5GT/s/lane。相当于5Gbps的编码后的数据，乘以编码效率5Gbps * (8/10) = 4Gbps = 500MBps未编码的原始数据。 Gen3 Gen3最大支持8GT/s/lane。按上述算法： 8Gbps * (128/130) = 7876Gbps = 984.6MBps 如果是PCIE Gen3 x8那就是984.6MBps x 8 速查表格","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"}]},{"title":"几句话说清楚17：用Makefile.am和configure.ac构建一个专业的Hello World","slug":"quickwords17-makefileam-configureac","date":"2019-02-21T12:46:35.000Z","updated":"2019-02-22T13:48:55.394Z","comments":true,"path":"2019/02/21/quickwords17-makefileam-configureac/","link":"","permalink":"https://decodezp.github.io/2019/02/21/quickwords17-makefileam-configureac/","excerpt":"首先感谢GUN的良好教程，这里主要是做一点点加工。 GNU Autotool现在写开源项目，如果只提供一个Makefile可能会令别人怀疑你项目的专业程度:D虽然其实并没有什么关系，但看着别的项目目录下面的configure, configure.ac, Makefile.in, Makefile.am, aclocal.m4等文件还是会觉得有必要也用这些东西“装点”一下。","text":"首先感谢GUN的良好教程，这里主要是做一点点加工。 GNU Autotool现在写开源项目，如果只提供一个Makefile可能会令别人怀疑你项目的专业程度:D虽然其实并没有什么关系，但看着别的项目目录下面的configure, configure.ac, Makefile.in, Makefile.am, aclocal.m4等文件还是会觉得有必要也用这些东西“装点”一下。 这些文件其实都是由GNU Autotools生成的。Autotools的功能当然不止是装点一下，但我们不在这里深究这个问题，下面通过一个最简单的Hello World示例来解释一下Autotools的使用方法。 构建必要的文件src/main.c在项目根目录下新建一个src文件夹，放Hello World的main.c 12345678910#include &lt;config.h&gt;#include &lt;stdio.h&gt;intmain (void)&#123; puts (\"Hello World!\"); puts (\"This is \" PACKAGE_STRING \".\"); return 0;&#125; 特别注意一下与”传统”Hello World不同的是include了一个config.h，所以才会有PACKAGE_STRING这一变量。 不直接在根目录创建main.c是因为后续Autotools会自动创建一些额外的作为一个”专业”项目所需要的文件夹，例如man/和data/等等。 README这个直接放根目录就行了： 12This is a demonstration package for GNU Automake.Type 'info Automake' to read the Automake manual. 根目录下的Makefile.am这个这么写： 12SUBDIRS = srcdist_doc_DATA = README src目录下的Makefile.am是的，确实需要写两个Makefile.am： 12bin_PROGRAMS = hellohello_SOURCES = main.c configure.ac下面就可以写最后的configure.ac文件了，这个放在根目录下： 123456789AC_INIT([amhello], [1.0], [bug-automake@gnu.org])AM_INIT_AUTOMAKE([-Wall -Werror foreign])AC_PROG_CCAC_CONFIG_HEADERS([config.h])AC_CONFIG_FILES([ Makefile src/Makefile])AC_OUTPUT AC_INIT等等Autotools预定义的宏，看一下括号里的东西大概就能明白是什么意思了吧：D当然，除了这几个之外还有很多其他功能强大的操作，可以自行查找相关信息。 实例化构建系统运行autoreconf命令： 12345autoreconf --installconfigure.ac: installing './install-sh'configure.ac: installing './missing'configure.ac: installing './compile'src/Makefile.am: installing './depcomp' 这个时候你就可以看到你的目录下面多出了configrure, config.h.in, Makefile.in以及src/Makefile.in这几个文件。但autoreconf的目的不仅仅是创建这几个文件，而是为了在你的系统里创建GNU Build System。 编译安装下面你就可以用平时你在开源项目里用到的操作手法编译生成安装了： 12345678910111213141516171819202122./configurechecking for a BSD-compatible install... /usr/bin/install -cchecking whether build environment is sane... yeschecking for gawk... nochecking for mawk... mawkchecking whether make sets $(MAKE)... yeschecking for gcc... gccchecking for C compiler default output file name... a.outchecking whether the C compiler works... yeschecking whether we are cross compiling... nochecking for suffix of executables...checking for suffix of object files... ochecking whether we are using the GNU C compiler... yeschecking whether gcc accepts -g... yeschecking for gcc option to accept ISO C89... none neededchecking for style of include used by make... GNUchecking dependency style of gcc... gcc3configure: creating ./config.statusconfig.status: creating Makefileconfig.status: creating src/Makefileconfig.status: creating config.hconfig.status: executing depfiles commands 用了configure之后就可以看到Makefile和src/Makefile以及config.h了。下面直接make就好。 12345make…src/helloHello World!This is amhello 1.0.","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"program","slug":"program","permalink":"https://decodezp.github.io/tags/program/"}]},{"title":"几句话说清楚16：如何构建零干扰CPU Benchmark环境","slug":"quickwords16-noisy-free-benchmark-env","date":"2019-02-20T13:07:28.000Z","updated":"2019-02-20T13:09:10.002Z","comments":true,"path":"2019/02/20/quickwords16-noisy-free-benchmark-env/","link":"","permalink":"https://decodezp.github.io/2019/02/20/quickwords16-noisy-free-benchmark-env/","excerpt":"CPU性能测试对环境的要求即便是硬件配置完全一样，操作系统相同，工作负载也相同的硬件平台，性能测试的结果也可能会因为各项配置的不同出现较大出入。","text":"CPU性能测试对环境的要求即便是硬件配置完全一样，操作系统相同，工作负载也相同的硬件平台，性能测试的结果也可能会因为各项配置的不同出现较大出入。 除了硬件的Hyper Thread/Turbo等特性之外，OS对进程的调度、中断等等也可能会产生影响。当然如果你要测试的工作负载还要和网络、存储交互的话，那么就还需要把他们放在一起综合考虑。 这里的讨论只限于Linux系统。 几种手段识别系统架构先看一下系统NUMA的情况，以及与要测试的工作负载相关的硬件资源分布情况。选用合理的测试配置（e.g. CPU核与网卡在同一个NUMA节点上）。 配置scaling_governor将scaling_governor配成performance是一个比较常用的手段。 echo performance &gt; /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor 可以仅配置参与测试的CPU核(cpu*)，也可以全部配置。另有cpupower工具可以协助完成，相关资料可以自行man cpupower。 关闭Hyper ThreadIntel的CPU如果打开Hyper Thread，同一个CPU核中有很多流水线资源是两个Thread共享的。详情可以参见Skylake微架构剖析系列文章。如果能操作BIOS，最好就是直接关闭Hyper Thread。如果不方便操作BIOS或者只想关闭与测试有关的CPU核的Hyper Thread也可以用： 查看该CPU核的siblings列表： /sys/devices/system/cpu/cpuN/topology/thread_siblings_list 看到另外那个CPU X之后： echo 0 &gt; /sys/devices/system/cpu/cpuX/online 关闭Turbo并不是说Turbo不好，其实Trubo能比较显著地提高性能，但我们这里追求的是一个”纯净”的测试环境，需要尽量排除Trubo在频率升降过程中产生的误差干扰。 echo 1 &gt; /sys/devices/system/cpu/intel_pstate/no_turbo 屏蔽内核干扰内核有些时候也会对测试结果产生干扰，比如用户/内核线程到参与测试的CPU核，或者给CPU分配网卡等设备的中断等等。这些都有相应的内核参数可以配置，在这里推荐一个简单点的工具： cpuset:https://github.com/lpechacek/cpuset 那么预留出参与测试的CPU核就比较简单了： cset shield -c N1,N2 -k on N1,N2就是CPU的编号。 查看和分配中断的方法可以参考这篇 执行要测试的负载可以用taskset也可以继续使用cset e.g. cset shield --exec -- perf stat -r 10 &lt;cmd&gt; 关闭ASLRASLR(Address Space Layout Randomization)是一种安全机制，但可能会引入性能下降。我本人没有太深入研究具体原因，但可以参考一些现有的资料e.g.On the Effectiveness of Address-Space Randomization。 Implementations of WX on CPUs whose memory-management units lack a per-page execute bit, for example, current x86 chips, incur a significant performance penalty. 关闭的方法： echo 0 &gt; /proc/sys/kernel/randomize_va_space","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"测来测去7：筛法求素数Loop Unrolling性能优化实例","slug":"test7-prime-opt","date":"2019-02-19T11:57:18.000Z","updated":"2019-02-19T11:58:59.312Z","comments":true,"path":"2019/02/19/test7-prime-opt/","link":"","permalink":"https://decodezp.github.io/2019/02/19/test7-prime-opt/","excerpt":"筛法求素数最近拿到一段筛法求素数的代码，希望能够在不改变原有算法的基础上提高性能。","text":"筛法求素数最近拿到一段筛法求素数的代码，希望能够在不改变原有算法的基础上提高性能。 关于筛法求素数的算法，网络上有很多介绍。算法之间的效率存在差异，但我们的重点不在这里，而是如何在不改动现有算法的前提下提升性能。 关于不同筛法算法可以参见这里，这段程序里使用的是埃拉托斯特尼筛法。 核心代码段： 12345678910111213count = 0; for (i=2; i &lt;= 8192; i++) &#123; flags[i] = 1;&#125;for (i=2; i &lt;= 8192; i++) &#123; if (flags[i]) &#123; /* remove all multiples of prime: i */ for (k=i+i; k &lt;= 8192; k+=i) &#123; flags[k] = 0; &#125; count++; &#125;&#125; 完整代码在： wget https://raw.githubusercontent.com/llvm-mirror/test-suite/master/SingleSource/Benchmarks/Shootout/sieve.c 其实是LLVM编译器的性能测试代码。 测试环境12345CPU: Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHzHyper-thread:OFFPower-governor: PerformanceGCC: 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC)GCC option: -O3 诊断先运行一下原有代码看看时间： 1234567gcc sieve.c -O3 -o sievetime -p ./sieveCount: 1028real 3.34user 3.34sys 0.00 简单想象一下代码流程： 处理的数据是8K Byte(char flags[])，相对于32K的L1缓存不算什么数据量，所以数据缓存似乎问题不大 生成的二进制文件也不大，指令缓存也没太大压力 前端这边处理的主要是带分支的循环，内层循环就算还好吧…但外层循环中有个if分支判断 涉及到这个判断，因为素数的出现/分布没太大规律，所以对CPU来说，这个分支判断结果相当于是随机的，有可能会影响前端流水线的性能 然后用我们之前介绍的Top-down方法和toplev工具看看实际测试的情况： ./toplev.py -v --no-desc -l1 /root/perfcontest/sieve 123456789Using level 1.# 3.4-full on Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHzperf stat -x\\; --no-merge -e '&#123;cpu/event=0xc2,umask=0x2/,cpu/event=0xe,umask=0x1/,cpu/event=0xd,umask=0x3,cmask=1/,cpu/event=0x9c,umask=0x1/,cycles&#125;' /root/perfcontest/sieveCount: 1028FE Frontend_Bound: 38.45 +- 0.00 % Slots &lt;==BAD Bad_Speculation: 16.45 +- 0.00 % Slots BE Backend_Bound: 8.92 +- 0.00 % Slots belowRET Retiring: 36.19 +- 0.00 % Slots below MUX: 100.00 +- 0.00 % 基本上可以看到是前端Bound了，同时分支预测里出现了比较多的Bad_Speculation。 优化OK，先用个简单的方法处理一下分支： 结合业务的话，素数越到后面分布是越稀松的，所以外层循环中的那个判断应该大部分时间是false。所以，先套个likely/unlikely。 123456#define likely(x) __builtin_expect((x),1)#define unlikely(x) __builtin_expect((x),0)... if (unlikely(flags[i])) &#123;... 编译之后看一下时间： 12345time -p ./sieveCount: 1028real 3.08user 3.08sys 0.00 有些许提升，不过不太明显。如果此时再用toplev测试一下，可以发现分支预测的改善并不可观。 那么如何改善分支预测呢？最好的办法就是不要有分支；或者，如果完全没有不可能的话，就让分支出现规律性；如果这样也不行的话，就减少分支；如果减少也不可能的话，就搞大乱序并发。 对于我们这个算法来说，判断每个数字的标志位并做后续的置位是算法的要求。提升规律性的话，也没有什么特别好的办法（至少我没想出来）， 那就只能用最后一种办法了… 把循环展开，提升流水线并行性。 展开16级还不算那么激进吧…同时内层循环也可以适当展开… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111for (i=2; i &lt;= 8191; i = i + 16) &#123; if (unlikely(flags[i])) &#123; for (k=i+i; k &lt;= 4096; k+=(7 * i)) &#123; flags[k] = 0; flags[k + i] = 0; flags[k + (2 * i)] = 0; flags[k + (3 * i)] = 0; flags[k + (4 * i)] = 0; flags[k + (5 * i)] = 0; flags[k + (6 * i)] = 0; &#125; count0++; &#125; if (unlikely(flags[i + 1])) &#123; for (k=i+i + 2; k &lt;= 8191; k+=(i + 1)) &#123; flags[k] = 0; &#125; count1++; &#125; if (unlikely(flags[i + 2])) &#123; for (k=i+i + 4; k &lt;= 8191; k+=(i + 2)) &#123; flags[k] = 0; &#125; count2++; &#125; if (unlikely(flags[i + 3])) &#123; for (k=i+i + 6; k &lt;= 8191; k+=(i + 3)) &#123; flags[k] = 0; &#125; count3++; &#125; if (unlikely(flags[i + 4])) &#123; for (k=i+i+8; k &lt;= 8191; k+=(i + 4)) &#123; flags[k] = 0; &#125; count4++; &#125; if (unlikely(flags[i + 5])) &#123; for (k=i+i + 10; k &lt;= 8191; k+=(i + 5)) &#123; flags[k] = 0; &#125; count5++; &#125; if (unlikely(flags[i + 6])) &#123; for (k=i+i + 12; k &lt;= 8191; k+=(i + 6)) &#123; flags[k] = 0; &#125; count6++; &#125; if (unlikely(flags[i + 7])) &#123; for (k=i+i + 14; k &lt;= 8191; k+=(i + 7)) &#123; flags[k] = 0; &#125; count7++; &#125; if (unlikely(flags[i + 8])) &#123; for (k=i+i+16; k &lt;= 8191; k+=(i + 8)) &#123; flags[k] = 0; &#125; count8++; &#125; if (unlikely(flags[i + 9])) &#123; for (k=i+i + 18; k &lt;= 8191; k+=(i + 9)) &#123; flags[k] = 0; &#125; count9++; &#125; if (unlikely(flags[i + 10])) &#123; for (k=i+i + 20; k &lt;= 8191; k+=(i + 10)) &#123; flags[k] = 0; &#125; count10++; &#125; if (unlikely(flags[i + 11])) &#123; for (k=i+i + 22; k &lt;= 8191; k+=(i + 11)) &#123; flags[k] = 0; &#125; count11++; &#125; if (unlikely(flags[i + 12])) &#123; for (k=i+i+24; k &lt;= 8191; k+=(i + 12)) &#123; flags[k] = 0; &#125; count12++; &#125; if (unlikely(flags[i + 13])) &#123; for (k=i+i + 26; k &lt;= 8191; k+=(i + 13)) &#123; flags[k] = 0; &#125; count13++; &#125; if (unlikely(flags[i + 14])) &#123; for (k=i+i + 28; k &lt;= 8191; k+=(i + 14)) &#123; flags[k] = 0; &#125; count14++; &#125; if (unlikely(flags[i + 15])) &#123; for (k=i+i + 30; k &lt;= 8191; k+=(i + 15)) &#123; flags[k] = 0; &#125; count15++; &#125;&#125; &#125; printf(\"Count: %d\\n\", count0 + count1 + count2 + \\ count3 + count4 + count5 + \\ count6 + count7 + count8 + \\ count9 + count10 + count11 + \\ count12 + count13 + count14 + \\ count15); 先直接刷一下时间： 12345time -p ./sieveCount: 1028real 1.56user 1.56sys 0.00 提升了120% 再用toplev看一下： 12345678910./toplev.py -v --no-desc -l1 /root/perfcontest/sieveUsing level 1.# 3.4-full on Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHzperf stat -x\\; --no-merge -e '&#123;cpu/event=0xc2,umask=0x2/,cpu/event=0xe,umask=0x1/,cpu/event=0xd,umask=0x3,cmask=1/,cpu/event=0x9c,umask=0x1/,cycles&#125;' /root/perfcontest/opt1Count: 1028FE Frontend_Bound: 11.60 +- 0.00 % Slots belowBAD Bad_Speculation: 3.30 +- 0.00 % Slots belowBE Backend_Bound: 8.43 +- 0.00 % Slots belowRET Retiring: 76.68 +- 0.00 % Slots &lt;== MUX: 100.00 +- 0.00 % 瓶颈已经不在分支预测上了。 用perf stat看一下： 123456789101112131415[root@server-P1 perfcontest]# perf stat ./sieveCount: 1028 Performance counter stats for './opt1': 2334.081187 task-clock (msec) # 1.000 CPUs utilized 7 context-switches # 0.003 K/sec 0 cpu-migrations # 0.000 K/sec 141 page-faults # 0.060 K/sec 5,355,895,762 cycles # 2.295 GHz 19,038,809,322 instructions # 3.55 insn per cycle 4,209,500,410 branches # 1803.494 M/sec 10,114,763 branch-misses # 0.24% of all branches 2.334590616 seconds time elapsed branch-misses占比很小，同时IPC也在3.55，已经接近理论最大值(4)。 后续仅仅调了一个小时，应该还有继续优化的空间，比如利用PGO和SIMD指令。这个留在后续尝试。","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"},{"name":"performance","slug":"performance","permalink":"https://decodezp.github.io/tags/performance/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"}]},{"title":"《居家男人》","slug":"thoughts5-family-man","date":"2019-02-15T11:02:39.000Z","updated":"2019-02-15T11:24:35.920Z","comments":true,"path":"2019/02/15/thoughts5-family-man/","link":"","permalink":"https://decodezp.github.io/2019/02/15/thoughts5-family-man/","excerpt":"大约在2010年左右的时候，我会经常在PPS这种视频流软件上面看尼古拉斯凯奇的电影。他早期的一些作品还是令人印象深刻。相较于那些有名的动作片，《居家男人》应该只是一部家庭剧小品，但却成了我这些年重复播放最多的他的片子。","text":"大约在2010年左右的时候，我会经常在PPS这种视频流软件上面看尼古拉斯凯奇的电影。他早期的一些作品还是令人印象深刻。相较于那些有名的动作片，《居家男人》应该只是一部家庭剧小品，但却成了我这些年重复播放最多的他的片子。 故事很普通，两个原本相爱的大学生在毕业时各奔前程，十几年后，一个成了家住曼哈顿上东区的金融巨子，一个是某律所的女合伙人，事业上都很成功，却都没有组建家庭。在圣诞这天，凯奇有了一次体验家庭生活的机会——如果毕业时他没有登上去往伦敦的飞机在巴克莱实习，而是选择与女主厮守，那么十几年后他们的家庭生活将会是什么样子。 当然有纽约一般中产的琐碎和烦恼，以及一儿一女等种种家庭生活的幸福。电影还是在宣扬“家庭幸福比世俗成功更重要”的主题，让人们认清什么是真正珍贵的东西。我对这种类似“说教”的信息并不反感，但这绝不至于让我把这部片子反复观看，甚至我个人认为，这应该是比《真爱至上》更好的圣诞电影。 之所以能这样认为，纯粹是因为观看这部影片时的私人体验。这种体验并不在于电影的镜头、布景、台词这些评判一部电影的“指标”，而仅仅在于片中场景的似曾相识，以及晏殊赋予”似曾相识“的另外一重意境——无可奈何。 面对生活中的各种取舍的时候，我们似乎有一个默认的“优先级”。这里面，个人的发展似乎是不言自明的第一位。因为逻辑是非常清晰的：你爱我，那么你会希望我好，你支持我追求我的发展，自然就是对我好。至于是否会为此失去其他，那倒不重要了。一旦有一方亮出这张牌，其他所有的理由都要退避三舍。这张牌往往还有一些别的登场方式，比如”这是为了我们共同的未来”、“这是我的梦想”等等。 影片的设定也是如此。凯奇为了追求自己的金融”梦”义无反顾地与女主在机场分道扬镳。登机前他向女主也基本上讲了一遍上面的逻辑，最后他说： 在伦敦的一年并不会改变什么。 正是这句话让我有了一种无可奈何的情状。一是因为世事难料，一是因为你无法指责别人的健忘。而更重要的是，即便你做了万全的计划，即便你为此舍弃了你自认为需要舍弃的东西，但最终真正能实现计划的人，却并没有多少。这和你的能力，你的决心以及外界的环境都没有关系。 因为一定要舍弃什么重要的东西才能实现的计划，要么是舍弃的东西并不那么重要，要么是这个计划并不值得实现。舍弃不重要的东西，不需要用这么”宏大“的计划作为说辞；而一旦没有了真正重要的东西，也很难“身残志坚”地应对挑战。这很像你打算爬上珠峰，却要先砍断一条腿一样。身处其中的人往往很难看清这一点，但拉开一段时间的距离，很快就能看清楚。 而所谓”为了我好”的逻辑，只不过是没有根据的臆想。往往在做这种幻梦的时候，我们还不够成熟，却喝了太多夹杂了催熟添加剂的鸡汤。归根到底，是没有真正地认识生活——生活的途径，永远不止一条。 不过还好，我虽然也有自己的安排，但似乎没有这种权衡和取舍，反而得到了所有想要的。理智给出的方案在很多时候确实是最优解，但首先要确保的是理智处在最优的状态。我从来不做难做的选择题，我宁愿在这种问题上交白卷，因为我知道“割舍”这个词其实就是“自戕”的另外一种写法，而你永远不会知道这张卷子后面哪里能找到一个加分题。 影片中凯奇得偿所愿，自己住在全球最贵的豪华公寓内俯瞰芸芸众生。我很喜欢当夜幕降临，他穿着条内裤独自躺在床上的片段，此时他的卧室因为刻意的灯光调整显得狭小而逼仄，我也曾经以同样的dress code，同样的姿势，躺在这样的房间里。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"几句话说清楚15：Top-Down性能分析方法资料及Toplev使用","slug":"quickwords15-toplev","date":"2019-02-14T11:40:58.000Z","updated":"2019-02-14T11:42:33.035Z","comments":true,"path":"2019/02/14/quickwords15-toplev/","link":"","permalink":"https://decodezp.github.io/2019/02/14/quickwords15-toplev/","excerpt":"Top-down Microarchitecture Analysis Method(TMAM)资料之前介绍过TMAM的具体内容，在这里对网络上相关的信息和资料做一个汇总： Tuning Applications Using a Top-down Microarchitecture Analysis Method","text":"Top-down Microarchitecture Analysis Method(TMAM)资料之前介绍过TMAM的具体内容，在这里对网络上相关的信息和资料做一个汇总： Tuning Applications Using a Top-down Microarchitecture Analysis Method Top-down Microarchitecture Analysis through Linux perf and toplev tools A Top-Down method for performance analysis and counters architecture Performance_Analysis_in_a_Nutshell Top Down Analysis Never lost with Xeon® perf. counters How TMA* Addresses Challenges in Modern Servers and Enhancements Coming in IceLake 当然还有一些其他的相关信息，不过上面几个都可以覆盖（其实已经有点过量了）。 Toplev使用toplev是一个基于perf和TMAM方法的应用性能分析工具。从之前的介绍文章 中可以了解到TMAM本质上是对CPU Performance Counter的整理和加工。取得Performance Counter的读数需要perf来协助，对读数的计算进而明确是Frondend bound还是Backend bound等等。 在最终计算之前，你大概需要做三件事： 明确CPU型号，因为不同的CPU，对应的PMU也不一样 读取TMAM需要的perf event读数 按TMAM规定的算法计算，具体算法在这个Excel表格里 这三步可以自动化地由程序来做。本质上toplev就是在做这件事。 toplev的Github地址：https://github.com/andikleen/pmu-tools 另外补充一下，TMAM作为一种Top-down方法，它一定是分级的。通过上一级的结果下钻，最终定位性能瓶颈。那么toplev在执行的时候，也一定是包含这个“等级”概念的。 下面是toplev使用方法的资料： toplev manual pmu-tools, part II: toplev 基本上都是由toplev的开发者自己写的，可以作为一个Quick Start Guide。 toplev仅针对系统瓶颈是CPU的场景，除此之外仍需要使用其他方法，如pcm tool。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"几句话说清楚14：Skylake微架构(Microarchitecture)剖析(5)","slug":"quickwords14-skylake-pipeline-5","date":"2019-02-03T07:42:55.000Z","updated":"2019-02-03T07:44:13.811Z","comments":true,"path":"2019/02/03/quickwords14-skylake-pipeline-5/","link":"","permalink":"https://decodezp.github.io/2019/02/03/quickwords14-skylake-pipeline-5/","excerpt":"Instruction Decode Queue(IDQ)IDQ也叫Allocation Queue(AQ)，也有时候会写成是Decode Queue。解码完成的uops在进入后端之前需要先在IDQ中做一下缓冲。作为一个”缓冲队列”，主要作用是将前端解码可能引入的流水线”气泡(bubbles)“消化掉，为后端提供稳定的uops供应(目标是6uop/cycle)。","text":"Instruction Decode Queue(IDQ)IDQ也叫Allocation Queue(AQ)，也有时候会写成是Decode Queue。解码完成的uops在进入后端之前需要先在IDQ中做一下缓冲。作为一个”缓冲队列”，主要作用是将前端解码可能引入的流水线”气泡(bubbles)“消化掉，为后端提供稳定的uops供应(目标是6uop/cycle)。 Skylake的IDQ最大可以存放64个uops/thread，比Broadwell的28个多一倍还多。这些uop在IDQ中除了排一下队之外，还会被Loop Stream Detector(LSD)扫描一遍，用来发现这些uop是不是来自于一个循环。 Loop Stream Detector(LSD)如果在IDQ中能被发现存在循环体uop，那么在下一次循环的时候，就不需要去重新解码这些循环体生成的uop，而是直接由LSD提供uops。这便可以省去指令fetch、解码、读uop cache、分支预测等所有之前的步骤，并且能进一步减少缓存占用。当然，当LSD起作用的时候，整个前端都是处于Disabled的状态。 Skylake的LSD需要在IDQ的长度（64uop）内发现循环，所以，循环体还是尽量紧凑一点吧:D 后端（Backend） 还是首先介绍一下这个部分是否有别的名字。在有些文档里后端又直接被称为Execution Engine。后端的主要任务当然就是执行前端解码出来的这些uop。但后端和前端的设计都在围绕着“如何提高指令的并行性”来设计和优化。 在Skylake架构中，IDQ以最大6uop/cycle的速度将uop送入Re-order Buffer，后端的处理在Re-order Buffer中正式开始。 Out-of-order(OOO)Execution/Engine先讲一下OOO（乱序）以便对后端的执行有一个整体的把握。 我们的程序虽然是按顺序编写的指令，但CPU并不（一定）会按相同的方式执行。为了提升整体效率，CPU采用的是乱序执行的方式。从一个“窗口”范围内选取可以执行的指令执行，并且这些操作对用户透明，在程序编写者的角度看来仍是在按他编写的指令顺序执行。 从根本上来讲，OOO是用”数据流（Data flow）”的角度来看待程序，而非程序员的“指令流”视角。 指令的目的就是以一种特定的方式操纵存在于内存/缓存中的数据，引起数据的变化，其实这就是我们通常所说的“写程序”。只不过这是人类习惯的逻辑方式，在机器看来并不一定高效。 在上图例子中，需要执行左上角的六个计算指令。In-order execution是假设完全按照程序顺序执行这六个指令的耗时。下面的`In-order(superscalar3)是合并了一些可以并行执行的指令的耗时。 因为指令(2)中的r1要依赖指令(1)的结果，所以指令(2)只能等(1)执行结束再执行。而本来可以并行执行的(3)(4)也因为要保证In-order顺序而只能一同放在(1)之后执行。 但从左下角的Data flow的角度来看，其实我们并不需要按照指令顺序运行程序：指令(2)完全可以放在后面执行，并重新安排并行计算顺序。这样就又节省了执行所需的时间。 OOO选择可执行指令的依据是： 不依赖未执行指令操纵的数据 有可用的执行资源 为了尽可能让进入后端的指令满足这两个条件，OOO采用了一系列的组件和技术。在后面的章节中将会进行介绍。 上图是一个OOO的概念示意图。前端输出给后端的都是顺序指令流，后端在一个窗口范围中选择可以执行的指令进行乱序执行。这里面没有强调的是，最终指令退出(retire)的顺序仍是按照程序的顺序。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"程序员学英语的几点实用经验","slug":"how-to-learn-english","date":"2019-01-31T12:47:03.000Z","updated":"2019-01-31T12:49:20.096Z","comments":true,"path":"2019/01/31/how-to-learn-english/","link":"","permalink":"https://decodezp.github.io/2019/01/31/how-to-learn-english/","excerpt":"学习英语当然要靠不断的练习，但同样的练习时间往往效果却大相径庭。以下是我结合自己的经历总结的一些经验和方法，希望能帮助大家提高学习英语的效率。 Rubbish in, rubbish out把自己想象成一个处理英文的黑盒，输入就是听读，输出就是说写。和人工智能训练模型需要优质的标签数据一样，学习英语也需要优质的输入才能达到良好的学习效果。 在程序员的领域，最直接的优质的英文材料就是经典的英文原版技术书籍。编写这些书籍的大师不但是技术领域的巨擘，同时也是操纵语言的大师，他们的书籍往往最是简洁明快，逻辑清晰。","text":"学习英语当然要靠不断的练习，但同样的练习时间往往效果却大相径庭。以下是我结合自己的经历总结的一些经验和方法，希望能帮助大家提高学习英语的效率。 Rubbish in, rubbish out把自己想象成一个处理英文的黑盒，输入就是听读，输出就是说写。和人工智能训练模型需要优质的标签数据一样，学习英语也需要优质的输入才能达到良好的学习效果。 在程序员的领域，最直接的优质的英文材料就是经典的英文原版技术书籍。编写这些书籍的大师不但是技术领域的巨擘，同时也是操纵语言的大师，他们的书籍往往最是简洁明快，逻辑清晰。 复写但如果你是刚开始决定提高自己的英文水平，看这些书籍其实很容易产生挫败感。我的建议是，找自己这个领域最著名的开源项目，一般这种项目都会有很好的文档(教程)支持。这个项目的教程就是你英文的入门材料。 但不是说能看着教程，自己找了台电脑跟着操作了一遍就算学会了。在有了实际操作经验之后，你其实已经知道这一节教程内容是要告诉你什么了，这个时候把教程的窗口最小化，打开你最喜欢的文字编辑器，将刚刚教程的内容复写一遍。 就是要有那种“明明知道要表达什么，但就是忘了刚才教程里是怎么写的了”的焦灼感。 这种时候先用自己的“初中英语”硬把坑填上。等这一节都复写完成之后，把教程的窗口重新最大化，再看一遍，看看刚刚自己胡说八道的地方教程都是怎么写的，默默记下来，然后重新把窗口最小化，修改刚刚自己复写的内容。 别指望看了第二遍就能全部记住，重复这个过程，直到完全一致。注意单复数，be动词时态，以及a/an/the定冠词的用法。 慢慢你就会发现英语的表达，尤其是在技术领域，就那么几个套路。 利用Google在练习了一段时间的复写之后，在工作中遇到开发或技术上的问题，不要用百D或是中文搜索，而是在Google上用英文搜索(bing也不行，只建议用Google)。 搜索栏里填什么关键词随便你，但最开始很可能找不到你要搜索的问题的答案。 尝试不断更换关键词，多往后翻几页，直到找到那个你认为你最需要的页面。这个时候不要Ctrl+C/V把页面里的代码一复制再来个git commit就完了，重新回到Google，重新调整你的关键词，用最短，最少的关键字让这个页面出现在搜索结果的第一页第一行。 能让自己的表达逐渐精确，就是语言能力的提升。 建立全面的信息关联两个人面对面说话，所传达的全部信息，纯粹语言的内容只能占30%。剩下的信息是由肢体语言、表情、语调语速传递的。 为什么很多人学了半天仍然觉得语言实际应用能力提高不大，就是因为只冲着那30%去的，实际能传达出要传达的20%就算不错了。 关键就是在于，没有将一句话放到实际中去关联场景，而大脑关联学习或关联记忆的效率是最高的。 在教程和搜索上小有成就了之后，你需要学习真正的语言。将语言划分为“听说读写”四项没有错，但如果你练习听力就只塞一个耳机那是效率很低的学习方法。 打开一个经典的技术视频，或者你感兴趣的TED演讲，不要关注演讲者说的你是不是都能听懂，而是关注演讲本身，关注他的肢体语言、关注观众的反馈、关注他如何使用他的PPT，关注他是如何表达，语言本身只是这一切的副产品。你的大脑会自己将这些都分门别类罗缕纪存。 之后自己尽最大的努力将要点复述(用嘴说)一遍，回想当时的场景，回想演讲者的动作和表情，回想他的语调和语速，回想当时的摄像机的角度和PPT的内容。然后把你能想到整场演讲的逻辑和每一环节的中心思想写下来。返回视频，和复写一样，对照修改，直到自己满意。 输出的时候放空大脑最后一点想说的是，无论是说还是写，很多人遇到的问题是，英文输出的过程多了”翻译”这个步骤。先想中文的意思，再将这个意思翻译成英文，再转换为文字或者口语。而对听和读，也是要翻译一遍，大脑再去处理中文的意思。 这是很没效率的事情，就像Linux收发包要对数据报文做多次拷贝一样，很有可能成为你整个系统的瓶颈。这里放空大脑的意思和”零拷贝”技术十分类似，就是不要有任何翻译的过程。在练习的时候，不要用中文去想你要表达什么，不要让大脑中出现任何中文的”声音”，不要给你对面的哥们做同声传译。最开始可能不容易做到，但要不断强调这个意识。","categories":[],"tags":[]},{"title":"几句话说清楚13：什么是Top-Down性能分析方法","slug":"quickwords13-tma","date":"2019-01-27T13:17:45.000Z","updated":"2019-01-27T13:29:03.211Z","comments":true,"path":"2019/01/27/quickwords13-tma/","link":"","permalink":"https://decodezp.github.io/2019/01/27/quickwords13-tma/","excerpt":"目的前几篇连续介绍了一些Skylake微架构的内容（还没有结束，还会继续填坑），主要目的并不是要对读者开启名词或者概念的Flood攻击，而是为了方便读者以后可以“有理有据”地进行软件的性能优化。","text":"目的前几篇连续介绍了一些Skylake微架构的内容（还没有结束，还会继续填坑），主要目的并不是要对读者开启名词或者概念的Flood攻击，而是为了方便读者以后可以“有理有据”地进行软件的性能优化。 但不能否认的是，CPU微架构的学习还是有比较陡峭的曲线的。是不是一定要非常精通微架构之后，才能进行软件的性能优化呢？从我自己的经验来说，并非如此。 性能优化虽然是一门专业的技术，但它和其他所有技术一样，也有自己的整体思想和方法论。首先对其方法论有一个大概的认识之后，再去精研细节，在我看来是一个比较有效率的学习方法。 《三国志》诸葛亮传中曾载： 亮在荆州，以建安初与颍川石广元、徐元直、汝南孟公威等俱游学。三人务于精熟，而亮独观其大略。 先贤轨物范世在前，古今一辙，今日正当观其荦荦大端者。 Top-down Microarchitecture Analysis(TMA)Top-down可以翻译成“自顶向下”，经常做一些有可有无的PPT架构设计的同学应该对这类词汇比较熟悉。当然也有一些“分析方法”喜欢用这个词。 TMA就是一套基于CPU微架构的“自顶向下”分析的方法。我对这个词的理解倒和具体的方位无关，而是紧紧抓住目标的一种思维方式。 这里就不得不提一下我的初中物理老师，她教给我们的一种解题方法似乎就可以概括为“自顶向下”，简单在这里介绍一下，希望这一类比能在后面叙述时帮助理解。 比如有一道很复杂的题目，题干很长，但最终的问题就是求密度。那么前面的东西可以先忽略，仅仅针对“密度”来说，那么就需要知道质量和体积。假设体积是已知的，那么问题“转化”为如何知道质量。质量等于匀速运动时的滑动摩擦力除以滑动摩擦系数。在题干中找出这些条件，或继续进行类似的推导。虽然最终在列公式时需要“反向”求得最终的密度，但思考方式是先从密度开始的。 基本上就是这个道理。同如何“求得密度”类似，TMA解决的问题就是如何“求得瓶颈”。 那么为了求得瓶颈，其实就是首先看CPU流水线总体上有多少时间没有真正在处理计算任务（aka流水线利用率）。继而，观察没有处理计算任务，是因为各方面没有协调好导致流水线空转(Stalled)还是虽然没有空转(Non-stalled)但却没有进行实际的计算（e.g.分支预测失败aka指令没有最终retired）。 然后针对空转，看看是前端的原因还是后端的原因。然后再具体看是前/后端哪一个具体项目导致的空转，进而定位系统瓶颈。当然最终还是依赖PMU counter提供的基础数据。 Pipeline slotsPipeline slots是一个经常出现的概念。它是流水线利用率的一种抽象表达，并没有实际的硬件或软件对应于这一概念。这里尝试解释一下：想象一条组装汽车的流水线，一开始时，很多汽车外壳被“挂”在了一个钩子上面，这个钩子其实就可以类比为一个Pipeline slots，只不过这个slot里装的是一条指令，uop，确切地说。 这些汽车壳子在以一个均匀的速度往前走，进而在不同的流水线阶段完成不同的工作，最后组装成一台完整的汽车。向前走的速度可以类比为CPU的Clock cycle，最终下线出厂就是指令retired。只不过有可能这些slot有些挂上了汽车外壳，有些还是空的（指令没取到），有些挂的，是没有用的废品壳子（分支预测失败）。 在上图中，Uop allocate其实就是说Uop有没有挂到Pipeline slot中的意思。 分析指标（Metric）OK，有了总体的方法之后，下面的工作就是如何再量化一下了。比如如何确定流水线的利用率，如何确定是前端Stall还是后端Stall，判断的依据和计算方法，设定的阈值等等。这些不是本文的重点，但在后续介绍完Skylake微架构后详细介绍。心急的同学可以先下载Intel总结好的Excel表格。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"测来测去6：Linux网络性能调优方法（补遗）","slug":"test6-linux-network-performance-optimization-2","date":"2019-01-24T10:35:31.000Z","updated":"2019-01-24T10:36:53.721Z","comments":true,"path":"2019/01/24/test6-linux-network-performance-optimization-2/","link":"","permalink":"https://decodezp.github.io/2019/01/24/test6-linux-network-performance-optimization-2/","excerpt":"没提到的上一篇内容中介绍了一些Linux网络协议栈的调优方法，但遗漏了一些可以发挥重要作用的方法，在这一篇中补充一下。","text":"没提到的上一篇内容中介绍了一些Linux网络协议栈的调优方法，但遗漏了一些可以发挥重要作用的方法，在这一篇中补充一下。 net_rx_action budget这个参数可以决定NAPI可以占用多少CPU的处理能力，可以调到900 sysctl -w net.core.netdev_budget=900 netdev_max_backlogsysctl -w net.core.netdev_max_backlog=65535 dev_weightsysctl -w net.core.dev_weight=1024这个参数在实际测试中影响也比较大 ip_early_demuxsysctl -w net.ipv4.ip_early_demux=0这个参数根据实际测试结果调整。改为0或1。 关于RPS在前面提到需要关闭RPS功能，但在实际测试中发现设定相应的CPU Mask还是能对性能有比较大的提升，具体原因在进一步挖掘的过程中，当前需要实际测试找出最适合的配置方法。","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"},{"name":"performance","slug":"performance","permalink":"https://decodezp.github.io/tags/performance/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"}]},{"title":"测来测去5：Linux网络性能调优方法","slug":"test5-linux-network-performance-optimization","date":"2019-01-22T13:06:06.000Z","updated":"2019-01-22T13:21:27.637Z","comments":true,"path":"2019/01/22/test5-linux-network-performance-optimization/","link":"","permalink":"https://decodezp.github.io/2019/01/22/test5-linux-network-performance-optimization/","excerpt":"换换口味老搞DPDK的人有一个毛病就是怎么也看不上内核网络，又是中断又是拷贝的，实在没有一脚地板油CPU直接100%炸街来得爽快。另外作为一个软件性能优化的“硬核”玩家，是很看不上内核这种改改参数，调调设置的玩法的。不过…既然自己主动跳了个大坑，该调内核性能的时候还是要调的…所以今天就换换口味，看看在Linux下通过配置调优网络性能怎么搞。","text":"换换口味老搞DPDK的人有一个毛病就是怎么也看不上内核网络，又是中断又是拷贝的，实在没有一脚地板油CPU直接100%炸街来得爽快。另外作为一个软件性能优化的“硬核”玩家，是很看不上内核这种改改参数，调调设置的玩法的。不过…既然自己主动跳了个大坑，该调内核性能的时候还是要调的…所以今天就换换口味，看看在Linux下通过配置调优网络性能怎么搞。 了解你的设备性能调优只有一个任务，就是充分发挥现有资源的能力。因此，了解自己的设备，就成了一切的前提。 硬件软件的细节难以遍数，若从细处着手…傻子才从细处着手吧。在网络方面，需要从全局上搞清楚这样几个问题： 网卡什么型号 网卡有几个口 每个口有几个队列 有什么硬件offloading的功能 CPU什么型号 CPU有几个核心 CPU有什么能调高主频的方法 CPU有什么指令集 有没有NUMA 其他至于内存、存储的可以先放一边。搞清楚系统配置之后需要准备几样工具。 几样工具 htop和top相比确实更直观一些，没有的话用top凑活一下也行。难就难在有些自己裁剪的Linux系统（比如OpenWRT）里虽然有top，但和我们用的不是一个top…. ethtool非常非常非常值得深度挖掘的工具，最近一个星期最后悔的事就是自己编译OpenWRT时没有勾上它。导致配代理配了个一六八开才把OpenWRT盒子挂上外网用opkg装上。 sysctl主要用来修改内核参数。 perf其实在这里用处不大，但一个系统里没装perf就会感觉少点什么。 常规工具cat、echo、ifconfig等基础自带的工具。 搞一搞测试拓扑及相关拓扑如下： 其中Gateway Moon就是需要调优性能的OpenWRT盒子。Gateway Moon和Gateway Sun之间建立了IPsec加密隧道。进行Client Alice和Client Bob之间的路由转发。 在两个Client上分别运行iperf3 server和client，来进行带宽（也即IPSec隧道的转发性能）测试。 目前除了Gateway Moon之外所有服务器都是用的高端服务器，所以瓶颈肯定在这片可怜的阿童木小盒子上。 IPsec相关的详细配置可以参考这里。 如果只是单纯测试转发速率完全不用这么复杂，两个盒子直连就可以。我这里只是最近需要搞IPsec隧道。 打开网卡多队列先看看你的网卡支持多少个队列： ethtool -l eth3 这里面RX和TX等于0是说仅仅能用作接收或发送的队列个数为0，而下方combined是指既可以作为发送队列也可以作为接收队列的个数，一般看这个数字就知道可以有多少个接收队列和多少个发送队列了。 而other是指用作link interrupt或SR-IOV协调的队列，在我们这个场景下并没有什么卵用。 打开多队列： ethtool -L eth3 combined 2 这样你就有了两个接收队列，以及两个发送队列。 这个时候看一下cat /proc/interrupts应该能看到eth3-rx-0/1的中断号。 打开能打开的网卡Offloading首先看一下你都有哪些offloading能力： ethtool -k eth3 带[fixed]标识的就别多想了。如果有想打开的offloading能力，比如RX checksum： ethtool -K eth3 rx on 全部能力和操作方法参考man ethtool。 网卡队列深度看一下最大支持深度和现在的配置情况： ethtool -g eth3 将接收队列深度改为4096 ethtool -G eth3 rx 4096 RSS队列配置开了多队列最好配置一下RSS，先看一下RSS现在的配置： ethtool -x eth3 能看到RSS indirection table和RSS hash key以及RSS hash function。 具体RSS是什么就不在这里讲解了，如果想比较均匀地让报文散列到前两个RX队列上： ethtool -X eth3 equal 2 再看一下RSS indirection table，也许会有不一样的地方，当然也许没有 :D 如果想让某条RX队列收取更多的报文，可以配置报文的权重： ethtool -X eth3 weight 6 2 这样RX queue 0的权重是6，会比RX queue 1收取更多的报文(一般情况下)。在需要更细粒度优化的情况下可以使用。 RSS Hash配置这里可以决定针对不同的流量（IPv4-tcp, IPv4-udp, IPv6-tcp, Ethernet…)采用报文的哪些字段进行RSS Hash。 有没有体验过UDP流量换了端口号还是始终进入同一条队列的恐惧？ 那是因为： 1234root@OpenWrt:~# ethtool -n eth0 rx-flow-hash udp4UDP over IPV4 flows use these fields for computing Hash flow key:IP SAIP DA 针对UDP流量只用Src IP和dst IP做哈希…如果这两个字段没变化那么就只能进入同一条队列… 想添加上src和dst port一同作为RSS的字段： ethtool -N eth3 rx-flow-hash udp4 sdfn 查看一下man ethtool可以明白sdfn的意义： 123456789m Hash on the Layer 2 destination address of the rx packet.v Hash on the VLAN tag of the rx packet.t Hash on the Layer 3 protocol field of the rx packet.s Hash on the IP source address of the rx packet.d Hash on the IP destination address of the rx packet.f Hash on bytes 0 and 1 of the Layer 4 header of the rx packet.n Hash on bytes 2 and 3 of the Layer 4 header of the rx packet.r Discard all packets of this flow type. When this option is set, all other options are ignored. 另外注意如果你搭建的是IPsec隧道，即便你加解密之前/后可能是UDP/TCP流量，但经过加密之后都是esp4类型的流量。 N-tuple filters配置这个需要考虑自己的实际应用场景，比如在一个web服务器中将处理http流量的进程绑定在CPU1，同时将RX queue-1的中断都放在CPU1，这时如果将所有dst port是80的http流量都导入Rx queue-1将会在进程切换和缓存命中方面提供好处。 首先查看一下网卡是不是支持： 123ethtool -k eth3...ntuple-filters: off 打开： ethtool -K eth3 ntuple on 配一条过滤规则： ethtool -U eth3 flow-type tcp4 dst-port 80 action 1 具体流量的命中情况可以通过 ethtool -S eth3 中的fdir_match和fdir_miss查看。 中断分布内核收包的一大瓶颈就是中断处理。一个常见的技巧就是让这些中断由所有CPU核共同分担。最优的配置就是一个NUMA节点中有多少个CPU核，该节点上的网卡就有多少个收包队列。当然我这里用的这个盒子是不敢奢望什么NUMA了…. 先看一下都挂了哪些中断：cat /proc/interrupts 然后把某个收包队列对应的中断号绑定到对应的CPU核上： echo mask &gt; /proc/irq/$IRQ/smp_affinity 其中mask就是允许发送中断的CPU的bit位。mask=1就是CPU0, mask=2就是CPU1, mask=3就是CPU0和1. 在自己手动设置中断分布之前，先检查一下系统里是不是已经在运行irqbalance守护进程。如果有先把它关掉。 贴一个网上应用比较广泛的脚本： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# setting up irq affinity according to /proc/interrupts# 2008-11-25 Robert Olsson# 2009-02-19 updated by Jesse Brandeburg## &gt; Dave Miller:# (To get consistent naming in /proc/interrups)# I would suggest that people use something like:# char buf[IFNAMSIZ+6];## sprintf(buf, \"%s-%s-%d\",# netdev-&gt;name,# (RX_INTERRUPT ? \"rx\" : \"tx\"),# queue-&gt;index);## Assuming a device with two RX and TX queues.# This script will assign:## eth0-rx-0 CPU0# eth0-rx-1 CPU1# eth0-tx-0 CPU0# eth0-tx-1 CPU1#set_affinity()&#123; MASK=$((1&lt;&lt;$VEC)) printf \"%s mask=%X for /proc/irq/%d/smp_affinity\\n\" $DEV $MASK $IRQ printf \"%X\" $MASK &gt; /proc/irq/$IRQ/smp_affinity echo $DEV mask=$MASK for /proc/irq/$IRQ/smp_affinity echo $MASK &gt; /proc/irq/$IRQ/smp_affinity&#125; if [ \"$1\" = \"\" ] ; then echo \"Description:\" echo \" This script attempts to bind each queue of a multi-queue NIC\" echo \" to the same numbered core, ie tx0|rx0 --&gt; cpu0, tx1|rx1 --&gt; cpu1\" echo \"usage:\" echo \" $0 eth0 [eth1 eth2 eth3]\"fi ## Set up the desired devices.# for DEV in $*do for DIR in rx tx do MAX=`grep $DEV-$DIR /proc/interrupts | wc -l` if [ \"$MAX\" == \"0\" ] ; then MAX=`egrep -i \"$DEV:.*$DIR\" /proc/interrupts | wc -l` fi if [ \"$MAX\" == \"0\" ] ; then echo no vectors found on $DEV exit 1 fi for VEC in `seq 0 1 $MAX` do IRQ=`cat /proc/interrupts | grep -i $DEV-$DIR-$VEC\"$\" \\ | cut -d: -f1 | sed \"s/ //g\"` if [ -n \"$IRQ\" ]; then set_affinity else IRQ=`cat /proc/interrupts | egrep -i $DEV:v$VEC-$DIR\"$\" \\ | cut -d: -f1 | sed \"s/ //g\"` if [ -n \"$IRQ\" ]; then set_affinity fi fi done donedone 内核网络相关参数这一部分没太多好说的，下面给一个/etc/sysctl.conf的配置内容，可以参考，若是觉得有些数字还不够激进，可以自己再改大一点，最后别忘了用sysctl -p生效。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061### GENERAL NETWORK SECURITY OPTIONS ### # Number of times SYNACKs for passive TCP connection.net.ipv4.tcp_synack_retries = 2 # Allowed local port rangenet.ipv4.ip_local_port_range = 2000 65535 # Protect Against TCP Time-Waitnet.ipv4.tcp_rfc1337 = 1 # Control Syncookiesnet.ipv4.tcp_syncookies = 1 # Decrease the time default value for tcp_fin_timeout connectionnet.ipv4.tcp_fin_timeout = 15 # Decrease the time default value for connections to keep alivenet.ipv4.tcp_keepalive_time = 300net.ipv4.tcp_keepalive_probes = 5net.ipv4.tcp_keepalive_intvl = 15 ### TUNING NETWORK PERFORMANCE ### # Default Socket Receive Buffernet.core.rmem_default = 31457280 # Maximum Socket Receive Buffernet.core.rmem_max = 67108864 # Default Socket Send Buffernet.core.wmem_default = 31457280 # Maximum Socket Send Buffernet.core.wmem_max = 33554432 # Increase number of incoming connectionsnet.core.somaxconn = 65535 # Increase number of incoming connections backlognet.core.netdev_max_backlog = 65536 # Increase the maximum amount of option memory buffersnet.core.optmem_max = 25165824 # Increase the maximum total buffer-space allocatable# This is measured in units of pages (4096 bytes)net.ipv4.tcp_mem = 786432 1048576 26777216net.ipv4.udp_mem = 192576 256768 385152# Increase the read-buffer space allocatablenet.ipv4.tcp_rmem = 8192 87380 33554432net.ipv4.udp_rmem_min = 131072 # Increase the write-buffer-space allocatablenet.ipv4.tcp_wmem = 8192 65536 33554432net.ipv4.udp_wmem_min = 131072 # Increase the tcp-time-wait buckets pool size to prevent simple DOS attacksnet.ipv4.tcp_max_tw_buckets = 1440000net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_tw_reuse = 1 Interrupt Coalescing在大流量情况下需要考虑对NIC发送的中断进行一些“批量处理”，合并一些中断请求，从而减少CPU的压力。 看一下当前网卡的Interrupt Coalescing的配置情况： 123456789101112131415161718192021222324252627[root@server-P1 ~]# ethtool -c eno3Coalesce parameters for eno3:Adaptive RX: off TX: offstats-block-usecs: 0sample-interval: 0pkt-rate-low: 0pkt-rate-high: 0rx-usecs: 1rx-frames: 0rx-usecs-irq: 0rx-frames-irq: 0tx-usecs: 0tx-frames: 0tx-usecs-irq: 0tx-frames-irq: 0rx-usecs-low: 0rx-frame-low: 0tx-usecs-low: 0tx-frame-low: 0rx-usecs-high: 0rx-frame-high: 0tx-usecs-high: 0tx-frame-high: 0 改动这些配置需要网卡硬件和驱动的支持。如果可以改动的话，比较简单的就是改成自适应模式： ethtool -C eth3 adaptive-rx on 自适应模式就是自动在网络压力小或者大的时候调整参数，从而达到最小延迟/最大吞吐。 其他的参数的含义如下： rx-usecs：从收到报文到发送中断delay的usec rx-frames：发送中断前最大收取的报文数量 rx-usecs-irq：再次发送中断的delay的usec等等… Receive Packet Steering(RPS)RPS是一种软件实现的RSS。在多队列网卡系统上，这个东西是非常多余的…所以前面的中断和RSS都配置得没问题得话，一定要记得关闭RPS： echo 0 &gt; /sys/class/net/&lt;dev&gt;/queues/rx-&lt;n&gt;/rps_cpus 关于RPS具体的说明，以及为什么它是多余的，可以参看这里。","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"},{"name":"performance","slug":"performance","permalink":"https://decodezp.github.io/tags/performance/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"}]},{"title":"几句话说清楚12：Skylake微架构(Microarchitecture)剖析(4)","slug":"quickwords12-skylake-pipeline-4","date":"2019-01-20T05:37:25.000Z","updated":"2019-01-27T13:29:05.176Z","comments":true,"path":"2019/01/20/quickwords12-skylake-pipeline-4/","link":"","permalink":"https://decodezp.github.io/2019/01/20/quickwords12-skylake-pipeline-4/","excerpt":"MSROM MSROM(Micro-code sequencer ROM)就是在上一篇连载中提到的专门处理输出大于4个uop的那块类似缓存的ROM。很多文档里面也直接将其称为MS，具体叫什么多需要结合上下文语境，知道是一回事就好了。 我个人其实推荐读者在编写自己的文档时能注意这些名称上的“一致性”，同编写程序时给变量或函数命名时的一致性一样，这些看似没什么“技术含量”的工作，却能够极大地提高信息传达的效率，也就是提高文档或代码的可读性和可维护性。","text":"MSROM MSROM(Micro-code sequencer ROM)就是在上一篇连载中提到的专门处理输出大于4个uop的那块类似缓存的ROM。很多文档里面也直接将其称为MS，具体叫什么多需要结合上下文语境，知道是一回事就好了。 我个人其实推荐读者在编写自己的文档时能注意这些名称上的“一致性”，同编写程序时给变量或函数命名时的一致性一样，这些看似没什么“技术含量”的工作，却能够极大地提高信息传达的效率，也就是提高文档或代码的可读性和可维护性。 在Instruction Decoder收到一个输出要大于4个uop的指令之后，它就会将请求转发给MSROM。MSROM虽然是专门解码/查询大于4个uop的指令的组件，但它最大的传输效率是4uop/cycle。同时在它工作的时候，所有的Instruction Decoder都要处于Disable的状态。因此虽然它的工作不太需要“动脑子”，但却仍要尽量避免。 Stack EngineStack Engine是专门处理栈操作指令的专用组件。类似PUSH、POP、CALL、RET这样的指令都算栈操作指令。Stack Engine不算什么新鲜的黑科技，自从Pentium M时代起就已经出现在Intel的CPU中。它的主要目的是避免栈操作指令对后端资源的占用，从而为其他计算任务提供出更多的资源。为此，Stack Engine提供栈操作指令专用的加法器和其他所需的逻辑完成这一任务。 Stack Engine在Instruction Decoder之后，监控所有流出的uop，并且从中提取出栈操作指令，进而直接执行，从而减轻栈操作指令对后端资源的占用。 这也可能是为什么有些时候inline的函数性能还不如不inline的原因吧:D（不负责任猜测） Decoded Stream Buffer(DSB) 别名像DSB这种组件，首先要说明的就是它也叫uop cache或decoded icache。 作用无论是用Instruction Decoder还是用MSROM，终究还是要做一次“解码”的操作。但同所有Cache加速的原理一样，如果能把解码之后的结果(uop)存下来，下次再出现的时候直接使用，那么就可以显著提高解码速度，DSB就是这个目的。 参数DSB的组织形式是32个set，每个set有8条cache line，每条cache line最多保存6个uop。 每次cache hit可以传输最大6个uop/cycle，这6个uop最大可以对应到64 byte的前端fetch window size，并且完全不需要任何Instruction decoder参与，也没有繁琐的解码过程。在实际应用中，DSB的cache hit rate在80%或以上。 与icache的关系CPU的icache一般存储的是最原始的从内存里读进来的程序的汇编指令(marco instruction)。而DSB或者uop cache虽然也是存instruction的cache，但如前所述，它存的是已经解码好的uop，所以这玩意有时候又被称为“decoded icache”。当然了，这些uop都是CPU的icache中的指令解码之后得到的。 与MSROM的关系输出大于4个uop的指令依然只能由MSROM解码。DSB保存的也是那些小于等于4个uop指令的uop。 MITE Path和DSB Path这两个概念主要用于区分最终需要执行的uop是通过什么方式来的。在上一节Decoded Stream Buffer之前的所有内容，都算是MITE Path。MITE是(Micro-instruction Translation Engine)的缩写，同时它在有些文档里也被称作legacy decode pipeline或legacy path。这条线路上过来的uop都是从marco instruction一步一步解码来的。 DSB path就是直接从DSB那条道上过来的uop。当CPU需要在MITE Path、DSB Path以及MSROM之间切换(switch)以便取得所需的uop时，需要花费一定的CPU cycle完成这一工作。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"有时做梦","slug":"thoughts4-dream","date":"2019-01-19T06:08:32.000Z","updated":"2019-04-16T16:08:16.477Z","comments":true,"path":"2019/01/19/thoughts4-dream/","link":"","permalink":"https://decodezp.github.io/2019/01/19/thoughts4-dream/","excerpt":"活得年头多起来之后，很难再明确地忆起某件事发生在哪一年。时间变得不再激烈，但往事却在交织纠缠，许多不可能的事还以为理所当然，而那些早已发生的事实却总需要确认再三。","text":"活得年头多起来之后，很难再明确地忆起某件事发生在哪一年。时间变得不再激烈，但往事却在交织纠缠，许多不可能的事还以为理所当然，而那些早已发生的事实却总需要确认再三。 这些事往往都发生在梦里。纵使过了做梦的年纪，也依然会有美梦，有噩梦，有能轻易按照弗洛伊德按图索骥的梦，还有一些不知所云得让人拍案叫绝的梦。但与年少时的最大区别，是有越来越多明知是梦的梦。在这些梦里，有不曾实现的愿望，有毋须弥补的过错，有仇恨背后的和解，有始终羞于开口的依赖，还有离开了却又回来的人，他们在梦里，有一场亲切的重逢。 人们总是倾向于相信自己愿意相信的事，而不是真真正正的现实。所以这种梦做多了并不好，容易把梦境与现实混淆。同时，越多这样的梦，下次就会越早意识到自己是在做梦。 可能每个人始终在梦中反复出现的都是那几件同样的事。 当意识到自己是在做梦之后，以前会一下就惊醒，现在反而会摆摆手继续做下去，甚至闭着眼都能看到自己蜷缩在枕头里自嘲的笑容。既然又梦到这里，就这样吧。 更多时候，就只是“昼有所思，夜有所梦”，或者说，是那些起床之后蹲在马桶上能想起来搜索一下的梦。所有这些梦，在“周公解梦”里都能找出来好几个解释，有些能相互印证，有些凶吉完全相反。但不管怎样，看来大家除了明知是梦的梦之外，梦到过的东西都一样。在给解梦类网站带来几个点击之后，这些梦都在早高峰的时候统统被忘掉。 做梦同Sex一样，也是一项夜晚（或早晨:D）的福利。我想我应该不会听从那些“每天只睡4小时”的成功学鸡汤而把这样的大礼买椟还珠。每个白天，从马桶上站起来之后就是战斗状态。要并线、要抢道、要甩锅、要争功、要倾轧、要离间、要摆脱已经发生的事，却又总要等待还没发生的事…最后的结果就是，梦可以明知是梦，而生活却不知是否一定要是这样的生活。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"在OpenWRT中添加perf工具","slug":"openwrt-perf","date":"2019-01-15T14:08:39.000Z","updated":"2019-01-15T14:16:05.292Z","comments":true,"path":"2019/01/15/openwrt-perf/","link":"","permalink":"https://decodezp.github.io/2019/01/15/openwrt-perf/","excerpt":"OpenWRT性能调优的必要如果仅仅是家庭网关，确实没太大必要，毕竟网络的瓶颈主要在运营商的出口那。OpenWRT之所以开始关注极致的性能，是由于OpenWRT的应用场景出现了变化。从SD-WAN和边缘计算概念，到混合云与智能网关，都催生出了在边缘接入侧uCPE或其他类似的小盒子中部署基于OpenWRT系统的必要。不同于满足家庭接入的需求，这些小盒子往往对应一间Office或公司分支的网络需求。增长的网络带宽和对安全性、QoS等能力的要求都对OpenWRT的性能提出了更高的要求。","text":"OpenWRT性能调优的必要如果仅仅是家庭网关，确实没太大必要，毕竟网络的瓶颈主要在运营商的出口那。OpenWRT之所以开始关注极致的性能，是由于OpenWRT的应用场景出现了变化。从SD-WAN和边缘计算概念，到混合云与智能网关，都催生出了在边缘接入侧uCPE或其他类似的小盒子中部署基于OpenWRT系统的必要。不同于满足家庭接入的需求，这些小盒子往往对应一间Office或公司分支的网络需求。增长的网络带宽和对安全性、QoS等能力的要求都对OpenWRT的性能提出了更高的要求。 没有perf按照官网的教程，在make menuconfig之后就可以选择要一起编译到系统里的工具了。首先查找一下perf在哪： 1/perf 显示在Development这个分类下面： OK，在Development这个分类下面自然是找不到的，不然也没必要写这篇博客了。 搞一搞那么怎么把它搞出来呢？ 首先进入Global build settings选项卡，然后找到Kernel build options，然后选上Compile the kernel with performance events and counters和Compile the kernel with profiling enabled，如下图： 再回到Development这里就可以看到perf了： 天下的知识分两类，一类是从这里学会了，在别处也能用的；一类是在一个地方学会了就只能在一个地方用的。本文中介绍的内容其实属于后者。但诡吊的是，掌握第二类知识往往更加费时费力。所以记录这一类的内容，主要出于节省他人时间的目的。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"openwrt","slug":"openwrt","permalink":"https://decodezp.github.io/tags/openwrt/"}]},{"title":"王朝兴亡周期律的本因","slug":"thoughts3-zhouqilv","date":"2019-01-13T15:50:04.000Z","updated":"2019-01-13T15:59:19.841Z","comments":true,"path":"2019/01/13/thoughts3-zhouqilv/","link":"","permalink":"https://decodezp.github.io/2019/01/13/thoughts3-zhouqilv/","excerpt":"王朝兴亡周期律 六位参政员将要回重庆时，毛泽东问黄炎培有什么感想，黄炎培坦率地说：“我生六十多年，耳闻的不说，所亲眼看到的，真所谓‘其兴也勃焉’，‘其亡也忽焉’，一人，一家，一团体，一地方，乃至一国，不少单位都没有跳出这周期率的支配力。大凡初时聚精会神，没有一事不用心，没有一人不卖力，也许那时艰难困苦，只有从万死中觅取一生。既而环境渐渐好转了，精神也就渐渐放下了。有的因为历史长久，自然地惰性发作，由少数演变为多数，到风气养成，虽有大力，无法扭转，并且无法补救。也有为了区域一步步扩大，它的扩大，有的出于自然发展，有的为功业欲所驱使，强求发展，到干部人才渐见竭蹶、艰于应付的时候，环境倒越加复杂起来了，控制力不免趋于薄弱了。一部历史‘政怠宦成’的也有，‘人亡政息’的也有，‘求荣取辱’的也有。总之没有能跳出这周期率。中共诸君从过去到现在，我略略了解的了。就是希望找出一条新路，来跳出这周期率的支配。”","text":"王朝兴亡周期律 六位参政员将要回重庆时，毛泽东问黄炎培有什么感想，黄炎培坦率地说：“我生六十多年，耳闻的不说，所亲眼看到的，真所谓‘其兴也勃焉’，‘其亡也忽焉’，一人，一家，一团体，一地方，乃至一国，不少单位都没有跳出这周期率的支配力。大凡初时聚精会神，没有一事不用心，没有一人不卖力，也许那时艰难困苦，只有从万死中觅取一生。既而环境渐渐好转了，精神也就渐渐放下了。有的因为历史长久，自然地惰性发作，由少数演变为多数，到风气养成，虽有大力，无法扭转，并且无法补救。也有为了区域一步步扩大，它的扩大，有的出于自然发展，有的为功业欲所驱使，强求发展，到干部人才渐见竭蹶、艰于应付的时候，环境倒越加复杂起来了，控制力不免趋于薄弱了。一部历史‘政怠宦成’的也有，‘人亡政息’的也有，‘求荣取辱’的也有。总之没有能跳出这周期率。中共诸君从过去到现在，我略略了解的了。就是希望找出一条新路，来跳出这周期率的支配。” 不仅仅中国有此周期规律，任何国家，任何民族，任何团体，乃至任何个人，都有此周期规律。 这其实不是什么新鲜概念，我们的语言体系里早就有各种玄之又玄的词汇可以给出模棱两可的总结：物极必反、物壮则老，以及所有和消、息、盈、冲，相关的词汇。但既然人们早已总结出这样的规律，为何在事到临头之时，却都无法避免被裹挟而去的命运？这一“兴亡律”当真是万世不易的铁律吗？ 人与物质世界的根本矛盾人是自然的造物，却也在永不停歇地与自然斗争。这种斗争从最初的生存之争，到现如今的索取与利用，再到以后可能的自然律改造，看似人在逐步认知物质世界，并取得了和谐共处的权利甚至一定程度的相对优势，但人与物质世界的根本矛盾仍然存在，并依旧支配着人类的所有活动。 人对物质的认知人类所认知的物质世界，从某种意义上讲，全部都是人类自己的臆造。 但这并非等同于物质不存在，或者是“缸中之脑”这种科幻玩笑。物质真实存在，人类也可以因为与物质的相互作用产生出对物质的认知，但这种认知仅仅是对真实物质世界的狭隘偏见。 这种偏见的产生由两方面原因造成： 人类感官的局限 人类描述语言的局限 感官的局限很好理解，如同可见光光谱仅仅占据电磁波谱很细小的一部分一样，即便我们可以自己发明现代仪器帮助我们一定程度地突破人类肉体的感官局限，但只要最终的信号仍需要由人类的肉体来接收，那么感官的局限就无法完全突破。 同样，人类的语言也无法描述真实的物质世界，因为无论是哪种自然语言，符号（形式）语言或者由人类技术衍生出的智能人造物的语言，都不可能描述出从来没见过的东西。 已有的认知在我们自己的体系里是自洽的，虽然这体系仅仅是真实的一个狭小的侧面，但也足够用了——这反倒成为我们应该感谢自身局限的理由。人类虽然一直在努力排除这种局限，我也相信我们在这条路上会继续打开局面，但同样的，随着认知越来越多，会越来越发觉我们的认知是如此之少。 人类活动的根本目的那么“认知”这件事本身是为了什么？我们大可以如同岩石那样安然接受周遭的一切，毕竟了解万万万万分之一和全然不了解，似乎也没什么差别。但人不会接受这样的安排。也许是出自动物的本能，也许是造物者的旨意，我们在这里不探究原因，只讨论这给我们带来什么。 我们所做的一切活动，都是为了能让真实世界与我们认知的世界一致。 这是我们内心中最原始也是最底层的驱动力。无论是群聚生产、巫术卜筮、屯田开荒、君权天授、两相攻伐、望气观星、揭竿而起、六艺俱佳、推导公式、狂敲代码，都是为了这一件事——即便我们并没有生活在“三体运动”的混乱之中，我们也一定要用那些最聪明的头脑来研究混乱的轨迹。 因为这种“一致”，为我们带来最基本的两点对物质世界的诉求： 可控 可预期 我可以接受我的农田远离河流，但我不能接受我开渠引水之后粮产依旧；我可以接受今年因为干旱导致赤地千里，但我不能接受风调雨顺时仍然欠收。这对任何拥有智能的生物都至关重要。 为了让感知的物质世界与认知的物质世界保持一致，人类必须一直处于与物质世界交互的状态。这种交互中的活动，要么是对物质世界进行改造，使其至少感知起来，与认知的情况一致；要么是调整自身对物质世界的认知（一般是进一步加深认知），继而达到更高层次的一致。 这便是所有人类活动的根本原因和内在驱动力，或者也可以说，即便你现在悲观厌世只想了此残生，你也同其他所有人一样，一直走在理想的路上。 人类不能停止的心理摆动是否达成一致之后，人类就不再继续活动了呢？ 这种静态的一致永远不可能达到。我想也不必用科学上的不断进步来举例说明。造成没有静态一致的原因，正是因为追求静态一致的原因：我们自身的认知有限。 因为认知有限，所以我们要追求一致，在追求一致的过程中，又总会有超出现有认知的发现，因此又要继续追求一致。如此，既可以类比于西西弗斯的意象，又可以从逻辑上解释叔本华对人生犹如钟摆的描述。 王朝兴亡周期律的本因王朝的兴亡，只不过是人类“追求一致”的一个产物。只不过它看起来宏大又神秘，所以被拿出来单说。 如开篇中黄炎培的引言中所述：大凡“聚精会神，用心卖力”，多是因为心中有一理想世界，却与现今的世界大不相同。因此人人可知，欲求得“一致”，非尽心竭力不可。而一旦达成目标，又会激发人心思寻新的“一致”——对这“理想世界”更多的可控与可预期的“理想”，这便是黄炎培所言之“惰性发作”，其实和科学探索并无本质区别。至于后续“环境愈加复杂”，乃是因为人人各有探索，因此也各有理想，人人都寻求各自的一致，而再无统一的一致。 如此社会又回到了需要建立一个“理想世界”的状态。所谓“理想世界”，就是指与大多数人的认知相一致的世界。而此时人的认知，因为前面所述不断发展的原因，已与建立上一个“理想世界”时大不相同，上一个“理想世界”自然也就“人亡政息”了。 从某一个王朝角度出发，这似乎是一个由盛而衰的过程，但从宏观上讲，这其实是一个再正常不过的自然发展的过程。所谓“盛极则衰”，背后的原因也是因为不同的人（多是不同阶级）所要求的“一致”出现了分裂和不可弥合的矛盾。 因此，跳出“周期律”的方式也非常简单，就是平衡这些人对“一致”的诉求。可以简单称之为“平衡各方利益，表达不同阶层人民诉求”，但这需要王朝实现自我革新，这并不是一个仅仅需要决心就能完成的事情。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"几句话说清楚11：Skylake微架构(Microarchitecture)剖析(3)","slug":"quickwords11-skylake-pipeline-3","date":"2019-01-12T04:50:46.000Z","updated":"2019-01-12T04:52:25.295Z","comments":true,"path":"2019/01/12/quickwords11-skylake-pipeline-3/","link":"","permalink":"https://decodezp.github.io/2019/01/12/quickwords11-skylake-pipeline-3/","excerpt":"解码 在拿到了经过“预解码”的macro-ops之后，开始正式进入解码过程。marco-ops进入Instruction Decode组件解码，最终的输出为定长的micro-ops。 Insturction Decode组件也有入口带宽限制，每个Cycle最多取3个unfused指令+2个fused指令，或者5个unfused指令（这里指macro ops）。所以说fused多了也不好，一个cycle最多取两个。同时如果开了Hyper Thread，则两个Thread按Cycle交替使用Instruction Decode。","text":"解码 在拿到了经过“预解码”的macro-ops之后，开始正式进入解码过程。marco-ops进入Instruction Decode组件解码，最终的输出为定长的micro-ops。 Insturction Decode组件也有入口带宽限制，每个Cycle最多取3个unfused指令+2个fused指令，或者5个unfused指令（这里指macro ops）。所以说fused多了也不好，一个cycle最多取两个。同时如果开了Hyper Thread，则两个Thread按Cycle交替使用Instruction Decode。 在Instruction Decode组件里面的就是各个具体的Decoder。Decoder类型可以分类两类，一类是Simple Decoder，一类是Complex Decoder，感觉这句是在说废话。 顾名思义，Simple Decoder处理的是解码之后的输出为1个fused-uop的指令；Complex Decoder处理的是解码之后的输出为1个至4个fused-uop的指令。 Fused-uop注意这里说的是fused-uop，不是fused-marco。在这里所有输出的uop都是做过fused处理的，目的是减少后续资源的占用。 但这里有一个比较容易混淆的概念，就是fused-uop并非专指那些两个uop合并之后生成的“合并uop”，而是指所有经过了uop fusion处理的uop：有些指令可能两个uop变一个，但也有一些是一个还是一个，即便如此，输出的那一个也叫fused-uop。 为了进一步澄清这个概念，我们稍微需要涉及一点后端的概念。在前端这里，生成fused-uop的部分还属于CPU流水线中的uops fused domain，而在后端需要将指令发射到执行单元去的时候，是不能执行fused uop的，所以fused uop还需要再分解为unfused uop才可以执行，这一部分就属于CPU流水线中的uops unfused domain。 有了这些概念之后，我们可以看一下Instruction Tables.pdf这份文档。 在P244中有对skylake指令的说明，上面有对一些概念的解释，下面是一张表格： 在这张表格里是最常见的mov命令的说明。但因为操作数(operands)的不同在真正执行的时候也会有细节上的差别。第一行中的mov的两个操作数一个是register，另外一个是一个立即数。在uops fused domain和uops unfused domain两栏中的计数都是1。 这种指令也算在uops fused domain经过了fusion处理。只不过其实前后没什么区别。 但如果我们看一下所有在uops unfused domain里计数为2的mov指令，它们在uops fused domain中的计数都是1。这种mov指令就是真正做过2条uop合并的mov指令。 这份表格还有很多有趣的内容，推荐有时间的时候随手翻翻。 Skylake有4个Simple Decoder和1个Complex Decoder。但从表里我们可以看到uops fused domain计数为1，也就是可以被Simple Decoder处理的指令在所有指令中所占的比例似乎并没有达到4/5那么高。 这里需要说明的是，输出大于4个uop的指令，既不由Simple Decoder处理，也不由Complex Decoder处理，而是直接去查Microcode Sequencer(MS)，这是一块类似于缓存的ROM。 Complex Decoder的数量始终为1的原因是Complex Decoder解码出来的uop都很难在执行时进行并行化处理，同时Complex Decoder每多解码一个uop，就要有一个Simple Decoder处于不能工作的状态。 对CPU来说，它最希望的就是它要做的工作，它需要的数据，它要执行的指令，都已经在一块缓存里准备就绪了。这是CPU上班摸鱼的主要方法，但摸出了风格，摸出了水平。下一部分介绍一下在指令解码方面的缓存内容。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"几句话说清楚10：Skylake微架构(Microarchitecture)剖析(2)","slug":"quickwords10-skylake-pipeline-2","date":"2019-01-10T09:42:40.000Z","updated":"2019-03-05T13:29:31.982Z","comments":true,"path":"2019/01/10/quickwords10-skylake-pipeline-2/","link":"","permalink":"https://decodezp.github.io/2019/01/10/quickwords10-skylake-pipeline-2/","excerpt":"前端处理器在前端这一部分的时候还是顺序(in-order)处理的，主要是也确实没什么乱序的空间。虽然说是顺序，但前端因为贴近业务，所以受人写的代码的影响也比较大。如果仅仅只是“取指令-&gt;解码”，恐怕需要写程序的人是个非常聪明的程序员。前端很多组件的工作其实都是在填程序员的坑，这也是我比较心疼前端的地方。","text":"前端处理器在前端这一部分的时候还是顺序(in-order)处理的，主要是也确实没什么乱序的空间。虽然说是顺序，但前端因为贴近业务，所以受人写的代码的影响也比较大。如果仅仅只是“取指令-&gt;解码”，恐怕需要写程序的人是个非常聪明的程序员。前端很多组件的工作其实都是在填程序员的坑，这也是我比较心疼前端的地方。 Fetch 前端的任务，首先是从内存中取得指令。同读取数据类似，CPU通过查询页表获得指令所在的内存地址，同时把指令塞到CPU的L1指令缓存里。 具体要把哪个地址上的指令数据送到L1I$里，这是分支预测器(Branch predictor)的工作。作为CPU的核心技术，Intel并没有透露太多信息，我们这里也只好一笔带过。不过它的细节也许很复杂，但它的脾气很好掌握：和我们很多人不喜欢自己的工作一样，它的工作就是处理分支，但它最不喜欢分支。 在Skylake架构里，L1I$大小为32KB，组织形式为8-way set associative(关于CPU缓存组织形式的讲解可以参照这篇)，每个Cycle可以取16Byte长度(fetch window)的指令。如果你开了Hyper-thread，那么同一个物理核上的两个逻辑核均分这个fetch window，每个Cycle各占用一次。 所以没事别开Hyper-thread，不过我这么说没有任何技术依据，单纯是帮Intel多卖几个核。 在L1I$里的指令还都是变长的x86 macro-ops，也就是我们看到的那些编译之后的汇编指令。如果熟悉这些指令的话，就会知道这些指令的长度（就是那些二进制数字）都不一样，同时一条指令有时可以由好几个操作组成。 这种指令对CPU的执行单元来说是很不友好的，同时如果想要通过乱序执行提高指令的并行度，减小指令的粒度也是必须的步骤。因此需要把这些marco-ops“解码”为“micro-ops”。 当然具体的解码工作还在后面。从L1I$中取得指令数据后，首先要进入“预解码”阶段，在这里需要识别出在一个fetch window中取得的这16个Byte的数据里面有多少个指令。除此之外，还需要对一些特殊指令，比如分支转跳打上一些标记。 但因为指令变长的原因，16个Byte往往并不对应固定的指令数，还有可能最后一个指令有一半在这16Byte里，另一边还在后面。另外就是pre-decode在一个Cycle最多识别出6个指令，或者这16Byte的数据都解析完。如果你这16个Byte里包含有7个指令，那么第一个Cycle识别出前6个之后，还需要第二个Cycle识别最后一个，然后才能再读取后面16Byte。 那么pre-decode的效率就变成了3.5 instruction / cycle，比最理想的情况6 instruction / cycle降低了41%，现实就是这么残酷。 经过pre-decode之后，才真正从16Byte的二进制数据中识别出了指令，这些指令下一步要被塞到一个队列里(Instruction Queue)看看有没有什么能被优化的地方。一个最常见的优化方式就是macro-op fusion，就是把两个相邻的，且能被一个指令表示的指令，用那一个指令替换掉。比如： 12cmp eax, [mem]jne loop 直接换成1cmpjne eax, [mem], loop 当然既然决定这么替换，新指令对流水线的开销肯定小于被替换的两个指令之和。如此可以减轻一部分后端执行单元的工作负荷和资源开销。 OK, 在取得了指令数据，识别出了数据中的指令，并对指令做了一些优化合并之后，就该开始正儿八经地解码了，这部分在后面的文章中介绍。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"几句话说清楚9：Skylake微架构(Microarchitecture)剖析(1)","slug":"quickwords9-skylake-pipeline-1","date":"2019-01-07T15:52:11.000Z","updated":"2019-01-07T15:55:42.417Z","comments":true,"path":"2019/01/07/quickwords9-skylake-pipeline-1/","link":"","permalink":"https://decodezp.github.io/2019/01/07/quickwords9-skylake-pipeline-1/","excerpt":"楔子了解CPU的微架构是基于其开发“硬核”软件的必需步骤。由于一些历史遗留问题，现存的技术资料往往存在一些概念混淆、重复命名甚至自相矛盾之处。本文一来梳理Skylake微架构(主要是流水线)的组成和特性，二来试图厘清一些含混的概念用以帮助后来者。 另外在介绍完微架构之后，会继续结合Perf中的Performance Event来对照说明互为印证。","text":"楔子了解CPU的微架构是基于其开发“硬核”软件的必需步骤。由于一些历史遗留问题，现存的技术资料往往存在一些概念混淆、重复命名甚至自相矛盾之处。本文一来梳理Skylake微架构(主要是流水线)的组成和特性，二来试图厘清一些含混的概念用以帮助后来者。 另外在介绍完微架构之后，会继续结合Perf中的Performance Event来对照说明互为印证。 需要强调的是，本文的重点是Skylake的流水线(pipeline)架构，core间的连接和架构方式不作重点说明。 Skylake简介Skylake是由Intel以色列研发中心于2015年发布的14nm CPU架构。作为Broadwell的继任者，Skylake在原有架构的基础上，对一些关键特性和组件做出了相当幅度的优化： 上图简单列举了一些量化指标，现在不求甚解就好。 在指令集方面，引入了AVX-512、CLFLUSHOPT、CLWB等新的指令集，不过本文不打算介绍这些东西，写到这里只是觉得如果只用上一段话结束这一小节有些太突兀了。 流水线总览 引用上面这张图是为了举一个反例，说明一下本文要解决的问题。这张图可以被当做是一张流水线的架构抽象，我可以指着每一个组件讲讲它们都是干嘛的，但这里的问题就是某一个相同的组件在不同的文档、资料、甚至语境下可能有两个甚至更多个名字。 比如蓝色方块最下面的Allocation Queue，它就还有一个名字叫做Instruction Decode Queue，同时它还有可能被叫做IDQ或AQ。而关于Decoded Instruction Queue、Micro Instruction Sequencer、Re-order buffer、Scheduler、Reservation Station等概念的辨析也是…需要下一番功夫。 本文将以全网最清晰的方式讲清楚这些概念。 从high-level的层面来讲，Skylake的流水线架构与Broadwell和Haswell没有太大出入。还是可以分为两个阶段： 前端(Front-End)上图中蓝色部分就代表流水线的前端。它的主要作用就是获取指令、解码(Decode)指令。 为了最大限度的发挥CPU的能力，前端就需要尽可能高效率地把程序指令输送给后端。这里就面临两个挑战： 如何更快更准确地取得要执行的指令 如何将取得的指令更快地解码为微指令(micro-ops/uops) 有了更多的微指令输送给后端（执行单元），后端的工作量才能饱和。而前端的所有组件和机制，都是围绕这两个挑战进行的。 后端(Back-End)上图中红色的部分就代表流水线的后端。一般来讲绿色的部分是存储子系统，虽然与后端交互，但严格讲不算在后端里面。 后端的主要任务就是执行前端送过来的指令。和前端类似，后端除了“来料加工”之外，也有它自己需要面对的挑战： 如何提高指令的并行程度 如何充分利用已有的CPU能力 如果将CPU比作一家餐厅，跑在上面的应用就是来餐厅就餐的食客。前端类似餐厅的服务生，需要接受客人的下单，同时将订单送到后厨。而后厨就类似后端，负责做出客人需要的菜品。 但如何能让上菜速度更快？前端是否可以在客人排位时就让其提前下单？后厨是否能够提前准备好本店热门的特色菜，或者一并煮好一大锅面条，根据需要浇上不同的浇头？ CPU说是高科技，其实干得也就是这些事情。 在下一篇文章中将详细介绍一下前端。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"汉光文帝教你如何提出领导无法拒绝的方案","slug":"history2-liuyuan","date":"2019-01-05T06:24:48.000Z","updated":"2019-01-05T06:40:23.713Z","comments":true,"path":"2019/01/05/history2-liuyuan/","link":"","permalink":"https://decodezp.github.io/2019/01/05/history2-liuyuan/","excerpt":"在成为领导之前只有开国皇帝的孙子生下来就是皇帝，开国皇帝往往都给别人打过工。 别人给老板打工，不高兴了可以换个老板，而开国皇帝给老板打工，不想干了还必须得干掉老板。","text":"在成为领导之前只有开国皇帝的孙子生下来就是皇帝，开国皇帝往往都给别人打过工。 别人给老板打工，不高兴了可以换个老板，而开国皇帝给老板打工，不想干了还必须得干掉老板。 这次要说的就是汉赵的开国之君汉光文帝刘渊。当然在成为开国之君之前，刘渊也曾有过一位叫司马颖的老板。 司马颖是司马家“八王之乱”中的一乱。在还没有乱起来的时候，匈奴贵族出身的刘渊就被送到晋朝作质子(人质)。 说到做人质，这是一个投资收益比两极分化严重的工作。史书上出现过的人质，要么潜龙入海回归故国做了一番大事，要么就是成为第一个祭旗的祭品。 同样的问题也摆在了刘渊面前。在司马颖还没登上历史舞台的时候，司马家内部就有声音要除掉刘渊，以防其“非我族类其心必异”。虽然由于贵人的保荐逃过一劫，但刘渊一定不喜欢自己的命运捏在别人手上的滋味。 等到司马家的兄弟们相斫之时，刘渊和他的匈奴族人终于等来了机会——趁中原板荡，他要回到匈奴。 但司马颖不会不明白这么基本的道理。他一方面要利用刘渊领兵打仗的能力襄助自己，一方面也更不可能纵虎归山。 刘渊需要提出一个能让司马颖心甘情愿让他回到匈奴族人那里去的方案。 还是要考虑历史的进程如果司马颖一手平定了内乱成为了晋朝的中兴之主，那肯定也就没刘渊什么事了。 但司马颖此时正在遭受外部敌人的猛烈攻击。刘渊自然会利用这一时机，提出回部请匈奴部众救援的提议。 但司马颖必然还是会担心，所以他首先提出一个方案： 颖曰：“五部之众，果可发否？就能发之，鲜卑、乌桓，未易当也。吾欲奉乘舆还洛阳以避其锋，徐传檄天下，以逆顺制之，君意何如？”——《资治通鉴》 基本思想就是，你的方案我没太大把握(对你没什么信心)，即便可行，也不见得打得过敌人。我先带着皇帝回洛阳躲避一下锋芒，然后再挟天子慢慢想办法。 这个时候，切忌就领导的方案展开细节上的辩论。比如说一些什么“我一定能动员我的族人过来帮你”、“鲜卑乌桓，一帮乌合之众而已”，“皇帝早就不能号令天下了”等等。 那应该说什么？看一下刘渊怎么说的： 渊曰：“殿下武皇帝之子，有大勋于王室，威恩远著，四海之内，孰不愿为殿下尽死力者！何难发之！王浚竖子，东嬴疏属，岂能与殿下争衡邪！殿下一发鄴宫，示弱于人，洛阳不可得而至；虽至洛阳，威权不复在殿下也。愿殿下抚勉士众，靖以镇之，渊请为殿下以二部摧东嬴，三部枭王浚，二竖之首，可指日而悬也。”——《资治通鉴》 这段话可以分为三个部分： 为什么这么做可行刘渊在陈述这一句的时候，并没有以“我”为主语。他没有说“我”在我的族人里多么有威信，“我”有哪些神奇的手段可以确保可行等等。而是将“你”，也就是领导作为了最主要的原因。 此时即便你说的是最没有逻辑的理由，在领导那里也是有逻辑的。因为领导首先是个人，而不是一架逻辑的机器。 当你将领导认为最能体现出他的特点和价值的东西拿出来说服他，如果你还说服不了他，那只能证明他已经神经错乱了，比八王之乱还要乱。 证明可行要用“正”，证明为什么要这么做要用“奇”，也就是从反面来论述。 为什么要这么做从反面来论述，就是假设你不这么做，会有什么危害。 会有什么危害呢？必须是失去其最看重的东西。 虽至洛阳，威权不复在殿下也。 也许能逃得性命，也许手里还能有“皇帝”这样一枚棋子，但在现在的世道，谁拳头大谁就是权威。你自己就是这么上来的，当然明白权威的价值。如果别人一吓唬就逃跑了，那别人就是新的权威。 你没有了权威，其他的一切还有什么意义？你要不这么做，还闹啥闹？ 具体怎么做关于这一部分，刘渊只用了最短的篇幅，却把所有需要说明的要素都覆盖了： 渊请为殿下以二部摧东嬴，三部枭王浚，二竖之首，可指日而悬也。 作为一个办公室里的白领，你一定听别人说过“要用SMART法则给领导提方案”。 那么我们就套用一下SMART法则的框架分析一下刘渊的这句话： 1234567SMART法则*Specific:“二竖之首”*Measurable:“悬”*Achievable:“以二部摧东嬴，三部枭王浚”*Relevant: “渊请为殿下”*Time-bound:“指日” 这TM简直是古典与现代的完美结合。 司马颖在听后终于放下了他对刘渊的芥蒂。不是因为他真的不再怀疑刘渊，而是刘渊的提议毫无破绽。 而刘渊也终于凭借这个提议回到了他的北方，在接下来的历史里开创了属于自己的时代。","categories":[{"name":"history","slug":"history","permalink":"https://decodezp.github.io/categories/history/"}],"tags":[{"name":"history","slug":"history","permalink":"https://decodezp.github.io/tags/history/"}]},{"title":"测来测去4：82599在DPDK下使用fdir","slug":"test4-82599-fdir","date":"2019-01-04T05:09:54.000Z","updated":"2019-01-04T05:12:04.380Z","comments":true,"path":"2019/01/04/test4-82599-fdir/","link":"","permalink":"https://decodezp.github.io/2019/01/04/test4-82599-fdir/","excerpt":"文档过期近期有客户反馈82599的fdir(flow director)功能在DPDK环境下不生效，本想丢一个DPDK官网上的82599 fdir测试资料过去，但幸好我仔细看了一下测试流程，发现这个官方文档里使用的testpmd命令已经过期了(时间戳：Jan 3rd, 2019)….所以…我自己写一个吧。","text":"文档过期近期有客户反馈82599的fdir(flow director)功能在DPDK环境下不生效，本想丢一个DPDK官网上的82599 fdir测试资料过去，但幸好我仔细看了一下测试流程，发现这个官方文档里使用的testpmd命令已经过期了(时间戳：Jan 3rd, 2019)….所以…我自己写一个吧。 Setup1234DPDK Version: 17.11NIC: 82599DUT: test-pmdTraffic Generator: scapy 其中DUT与Traffic Generator 10G接口直连。 Test Cases首先测试对ipv4-tcp报文的支持perfect mode1234567./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=perfect --nb-ports=1set verbose 1set fwd rxonlyflow_director_filter 0 mode IP add flow ipv4-tcp src 172.16.182.82 20 dst 2.2.2.3 80 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1start 在Traffic Generator侧构造一个匹配的报文并发送： 12p1=Ether(src=get_if_hwaddr(\"ens785f0\"))/IP(src=\"172.16.182.82\", dst=\"2.2.2.3\")/TCP(sport=20, dport=80)sendp(p1, iface=\"ens785f0\") 应该可以看到testpmd将该报文收到了Queue 1。 signature mode1./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=signature --nb-ports=1 除在上面的命令行中--pkt-filter-mode=signature之外与前一个测试例完全一致。 对ipv4-udp的测试也基本类似，不再赘述。 测试对ipv6-tcp报文的支持Signature mode 82599 DPDK ixgbe驱动不支持IPv6报文flow director的perfect mode，所以只能用signature mode。 1234567./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=signature --nb-ports=1set verbose 1set fwd rxonlyflow_director_filter 0 mode IP add flow ipv6-tcp src fcbd:dc01:1:222:0:0:0:3 8000 dst fcbd:dc01:1:222:0:0:0:12 1029 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1start 在Traffic Generator侧构造一个匹配的报文并发送： 12p1=Ether(src=get_if_hwaddr(\"ens785f0\"))/IPv6(src=\"fcbd:dc01:1:222:0:0:0:3\",dst=\"fcbd:dc01:1:222:0:0:0:12\")/TCP(sport=8000,dport=1029)sendp(p1, iface=\"ens785f0\") 应该可以看到testpmd将该报文收到了Queue 1。 ipv6-udp报文的支持也基本类似。 添加Mask问题主要在对Mask的支持上，首先用ipv4-tcp举个栗子： 如果想mask掉(通配)全部的src ip123456./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=signature --nb-ports=1set verbose 1set fwd rxonlyport stop 0flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFF dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFFport start 0 这个配mask的命令长得令人发指，同时必须要先stop port 0。通配的方式就是src_mask后写0.0.0.0。这时如果你希望所有源端口号是20，目的IP是2.2.2.3，目的端口号是80的报文都进入Queue 1，那么flow director的命令必须写成：12flow_director_filter 0 mode IP add flow ipv4-tcp src 0.0.0.0 20 dst 2.2.2.3 80 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1start 一般人的理解，设置了通配mask之后，src IP写成什么都无所谓了，但这里必须要写成0.0.0.0，不然匹配不到。 Traffic Generator侧构造任意src IP的且满足其他匹配条件的报文，并发送：1234567p1=Ether(src=get_if_hwaddr(\"ens785f0\"))/IP(src=\"172.16.182.82\", dst=\"2.2.2.3\")/TCP(sport=20, dport=80)p2=Ether(src=get_if_hwaddr(\"ens785f0\"))/IP(src=\"172.16.182.8\", dst=\"2.2.2.3\")/TCP(sport=20, dport=80)p3=Ether(src=get_if_hwaddr(\"ens785f0\"))/IP(src=\"172.16.18.82\", dst=\"2.2.2.3\")/TCP(sport=20, dport=80)sendp(p1, iface=\"ens785f0\")sendp(p2, iface=\"ens785f0\")sendp(p3, iface=\"ens785f0\") 可以在testpmd中看到三个报文均进入了Queue 1。 如果想mask掉(通配)全部的src ip与scr port与上一个类似，设置mask和fdir规则的命令分别为： 123flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0x0 dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFFflow_director_filter 0 mode IP add flow ipv4-tcp src 0.0.0.0 0 dst 2.2.2.3 80 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1 与之前一样，fdir规则中，src后面必须写0.0.0.0 0才能达到预期效果。 此时仅由目的IP和目的端口号决定报文的去向。 1234567p1=Ether(src=get_if_hwaddr(\"ens785f0\"))/IP(src=\"172.16.182.82\", dst=\"2.2.2.3\")/TCP(sport=19, dport=80)p2=Ether(src=get_if_hwaddr(\"ens785f0\"))/IP(src=\"172.16.182.8\", dst=\"2.2.2.3\")/TCP(sport=2, dport=80)p3=Ether(src=get_if_hwaddr(\"ens785f0\"))/IP(src=\"172.16.18.82\", dst=\"2.2.2.3\")/TCP(sport=21, dport=80)sendp(p1, iface=\"ens785f0\")sendp(p2, iface=\"ens785f0\")sendp(p3, iface=\"ens785f0\") 可以在testpmd中看到三个报文均进入了Queue 1。 IPv6的情况如果想mask掉IPv6报文的src ip 123port stop 0flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 0:0:0:0:0:0:0:0 0x0 dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFFport start 0 同理，fdir规则中： 1flow_director_filter 0 mode IP add flow ipv6-tcp src 0:0:0:0:0:0:0:0 0 dst fcbd:dc01:1:222:0:0:0:12 1029 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1 ipv6-tcp src后必须写0:0:0:0:0:0:0:0 0以配合mask的设置。 关键就是如果mask中某字段中某bit为0，那么fdir规则中该字段对应的bit位也必须为0，82599网卡才能按预期的方式工作。 再举一个栗子，如果想将dst port的mask设置为0x00F0，对应的mask和fdir规则为：123flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 0:0:0:0:0:0:0:0 0x0 dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0x00F0flow_director_filter 0 mode IP add flow ipv6-tcp src 0:0:0:0:0:0:0:0 0 dst fcbd:dc01:1:222:0:0:0:12 240 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 2 此时再发送目的端口号为240或241…的IPv6报文都可以匹配该fdir规则。","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"dpdk","slug":"dpdk","permalink":"https://decodezp.github.io/tags/dpdk/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"}]},{"title":"唯识与C语言指针","slug":"thoughts2-weishi-c-pointer","date":"2018-12-30T17:06:05.000Z","updated":"2018-12-30T17:26:02.327Z","comments":true,"path":"2018/12/31/thoughts2-weishi-c-pointer/","link":"","permalink":"https://decodezp.github.io/2018/12/31/thoughts2-weishi-c-pointer/","excerpt":"旧文虽无殊胜处却最解少年意，重发于此，乃自喜其披坚执锐行而无返之气。 作者按丙申孟春，始得熊君十力之微言宏旨，于《新唯识论》中得窥心外无物，体用不二，翕辟成变之理。数年兵、道、史、释之学，终为一脉贯通，于世间纷杂，万相罗织，始有定见。乃身蹈统摄之道，心得自在清凉，不免情动于衷，喜不自胜。 熊君为阐唯识之旨，于书中多举譬喻。举“海水与众沤”喻，“绳索与大麻”喻种种；更尝作图形，以穷其本旨，表其胜义，苦口婆心，令人动容，非沐手开卷不能彰其功，焚香斋戒不能铭其德。吾观乎此学，虽能以物物强为譬喻，然万物浩汤，皆为大化，果有以大化喻大化之理乎？终须另觅一人造之物，探幽寻明，见微知著，庶几可得于大化矣。今请试以指针喻之。 下面开始正常说话。","text":"旧文虽无殊胜处却最解少年意，重发于此，乃自喜其披坚执锐行而无返之气。 作者按丙申孟春，始得熊君十力之微言宏旨，于《新唯识论》中得窥心外无物，体用不二，翕辟成变之理。数年兵、道、史、释之学，终为一脉贯通，于世间纷杂，万相罗织，始有定见。乃身蹈统摄之道，心得自在清凉，不免情动于衷，喜不自胜。 熊君为阐唯识之旨，于书中多举譬喻。举“海水与众沤”喻，“绳索与大麻”喻种种；更尝作图形，以穷其本旨，表其胜义，苦口婆心，令人动容，非沐手开卷不能彰其功，焚香斋戒不能铭其德。吾观乎此学，虽能以物物强为譬喻，然万物浩汤，皆为大化，果有以大化喻大化之理乎？终须另觅一人造之物，探幽寻明，见微知著，庶几可得于大化矣。今请试以指针喻之。 下面开始正常说话。 这是要干什么？没有人会对“世界到底是什么？”这个问题不感兴趣。科学、哲学、艺术，宗教都在以种种的方式诠释这个问题的答案。作为人生不可逃避的问题之一，每个人或多或少，也都会有自己或明朗或隐约的勾画。 但是在这个问题上，一直存在诸多的争论。且不说唯心唯物之争，在以确定性立身的科学领域，在人们得窥量子的堂奥之后，也观察到了诸如“二相性”、“测不准”，“非定域”等等的现象，虽然有各个理论都在尝试自圆其说，但不可否认的一点是，随着人类的进步，世界不是变得越来越简单，而是变得越来越复杂了。 而这恰恰是符合逻辑的。外物确为实有，却不曾脱离心而存在。人类的进步，自然伴随心智的成长，自然就会见到以前“视而不见”的东西。并非有新物凭空而生，而是原物之一“相”得显于成长了的心智。这一新“相”又成为心智继续成长的养料，从而使人认识到更多。这一过程永无休止，方生方死，方死方生。这不是简单的唯物或唯心，而是要结合两者各自的主张。 唯识论就是在做这一尝试。为表明物与心的关系，亦即如何认识世界的问题，熊君在其论述中做了种种譬喻。惜哉熊君，英才天纵，所举例证却仅限于瓶、罐、桌，绳之间，虽可强为譬喻，但恐有志于学者，不能于此中得其全旨。 计算机是人类创造的一个世界，人通过编程语言与这个世界发生相互作用。正可成为我们用以阐明世界本旨的绝佳实例。简单类比，计算机里的三极管，是真实存在的“物”，三极管的开关，是其呈现出的“相”，而对这些开关如何认识，就是我们的“心”。唯识精深，非我所能穷究，仅在此以C语言另作一譬喻，以望有启于同侪，足慰心愿。 如何从C语言中领悟心外无物在Linux上编写的C语言是相对底层的语言，原因有很多，但可以直接操作允许范围内的系统内存一定是原因之一。内存的操作除了分配、释放和更改之外，还需要更加频繁地标记和指向，这便引入了指针的概念。一个指针也只是一个普通的变量，只是它的值是一个内存的地址，如此便“指向”了该内存。这些基础的知识，无需再赘言。本文所强调的，是指针、内存、程序之间的种种变换。 有如下基础代码： 123456789101112131415161718192021222324252627/*object struct*/struct object&#123; element_type element; ...&#125;;/*void pointer*/void*ptr=NULL;struct object obj;obj.element=element_value1;/*point to obj, cast to type struct object*/(struct object*)ptr=&amp;obj;/*modify obj's member value through pointer*/*ptr.element=element_value2; Line1-6 声明object结构体 Line 8 定义了一个指针，类型为void*,并指向NULL Line 9 定义了objecti结构体对象obji，系统为其分配一片内存 Line 10 为iobj中的elementi成员赋值为element_value1 Line 12 将对象iobji所在的内存首地址存入iptri指针中，并将指针类型转换为struct object * Line 14 解析ptri指针，更改ielement对应内存的内容，并赋值为ielement_value2 定义对象obj，系统在栈内存上划出了一片内存空间，其长度为obj的长度。但在完成这一步之后，这一部分内存并没有因此产生任何变化。内存里的每一个比特，并没有带上任何“这是obj的内存”的标记。从内存本身来看与没有obj时没有分别。内存作为载体，是一切变动的肇始，不增不减，不净不垢，是真实存在的。 物是实有的到这里，分配给obj的这片内存是有实体存在，却是没有任何“相”可言的。 在Line10中，我们为elementi赋值，相应的，会引起内存的变化。变化的内存的位置，程序可于struct objecti的定义中得知（计算element_type的offest，）。在赋值之后，这片内存有了第一个“相”，我们可以将这个“相”笼统称为“element的值为element_value1”的obj，就如同我们称呼一个“蓝色带横条纹的“皮球一样。这个值，可以为任何一个允许的值，于是obj就可以显现出任何一个对应的“相”。 相是变动不居的接下来是对指针的的操作。指针是什么？前面虽然已有技术上的说明，但还没有点出本文想阐明的主旨。指针可以让程序连接到相应的数据内存上，如果将程序本身比作自身的意识，内存比作实有的物质世界，那么指针就是我们用以认识世界的感官，是“眼耳鼻舌身意”，它将决定我们接触（看、听、嗅，触摸等等）到哪个实有的物质（指向内存），以及意识中对物质的“相”如何认识（依何种struct定义去解析内存）。 真正的关键，是指针类型的转换。只有将指针的类型转换为struct object *i，后续的代码才有意义。类型转换并没有改变指针本身，它所在的内存地址，它的长度，它的作用域等等并没有任何变化，但程序（意识）却懂得了，它所接触到的那片内存（实体），是一个struct object的区域（相），并且可以以此认识和改造obj此时显现出来的“相”。这便是常说的“相由心生”之意。 人通过感官与物质的相发生作用就像我们的眼睛、口鼻，手足（指针本身）始终没有什么变化，但我们却可以将某一物质识为瓶瓶罐罐，桌子麻绳，皆是因为我们的意识通过感官注意于其上（Line12），并依照指针的类型给出了对此“相”解释。依照对“相”的理解，我们可以作用于物质，令起变为另外一种“相”(Line14)。 如果我们不能通过感官去注意(动宾用法，下同)此物，或对此物视而不见（即不能有相关的struct去解释此物，”视而不见”不等同于”看不到”），那么虽然该物是真实存在的，但其“相”在我们的心里是不存在的。此柏拉图洞穴壁影所喻之意，亦为王阳明“与花同归于寂，同起于明”之意。就像虽然内存中的数据是一直都有的，但如果我们没有指针类型的转换，甚至没有struct object的定义，那对程序（意识）来说，任何obj的“相”都是不存在的。唯其二者（指针与struct）皆备于心（意识），才可得obj之“相”。此所谓“心外无物”之意。 如何从C语言中领悟翕辟成变一个某一类型的指针，只要该类型(struct)存在于程序（意识）中，就可以内存（实有的物质）作出相应的解析（物质的相）。通过对“相”的认识（struct中成员的定义），就可以使意识与物质发生作用，但所能改变的，及其改变后的形态，却始终不出“相”的范畴。若上述明了，可稍悟叔本华“意志与表象”之旨。 但我们需注意的是，指针的类型可以变为任意类型。如从ivoid*变为istruct object*i，其指向的内存并没有变化，内存本身也没有变化，但程序（意识）对这片内存的解释发生了变化。同一物质，转换成了另外的相，这便是熊君所述，物质转为心上之相的翕的势用。 如指针从struct object*类型转为void*i类型，则对程序而言，该处内存所显现出的相尽皆消失，只是一片混沌虚静，原有的“相”复返归于大化，此熊君所述，心上之相转为物质的辟的势用。翕辟两者结合，便是老子所谓“无为而无不为”之意。 从中亦说明一个道理，同一个物质，可计现万相。即同一片内存，可以接受任何类型的指针，其所显现的“相”，亦因指针类型的不同而可显为一组群相。而某一时刻我们所见得的一种”相“，只是此实在之物的“诈现”之相。“相”终是变动不居的，此即《心经》所述“一切有为法，皆如梦幻泡影，如电亦如露”之意。 于万相中取其一相有如下基本代码： 12345678910111213141516171819202122232425262728293031struct object1&#123;intobject1_num;&#125;;struct object2&#123;intobject2_num;&#125;;void*ptr=NULL;struct object1 obj;(struct object1*)ptr=&amp;obj;/*assign random_value to the first sizeof(int) bytes*/*ptr.object1_num=random_value;/*cast pointer type to struct object* and do the same thing*/*(struct object2*)ptr.object2_num=randome_value;/*cast pointer type to int* and do the same thing*/*(int*)ptr=random_value;/*cast pointer type to char* and do the same thing*/int i=sizeof(int);while(--i)&#123;*(char*)(ptr+i)=random_value&amp;(0xFF000000&gt;&gt;(i*8));&#125; 以上的代码，从Line12开始，都是在对同一块内存进行相同的赋值操作。不同的指针类型，使程序对同一块内存的解释也不尽相同。struct可以从iobject1至object2乃至于无穷，所有的struct皆可为&amp;obj处内存所诈现的任一之相。这也解释了，为什么同一事物，有人识得，却有人不识，或两人皆识得，却有不同的态度和看法。 人的一生，始终都在填充自己的头文件库。有了新的阅历，即是添加了新的struct；对事物有了新的认识，即是在原有的struct中添加了新的成员变量。意识将这些从感官搜集来的struct再重新注意于感官（指针类型转换）之上，便得出了我们所见的世界。 如果我们所见到的事物，只是真实本体诈现的一相，我们是否有可能穷尽事物所有的相？答案是不能。因为我们的感官无法无限拓展。虽然我们如今有了红外探测仪，X光机等等设备辅助我们的眼睛，声呐、雷达等设备辅助我们的耳朵，但即便是集合所有的外来辅助，甚至是未来所有的外来辅助，所能见到的也只是物质本体的一部分“相”。如一个红色的气球，在可见光范围内，红色是其一相，在红外线范围内，又呈另外一相，既有物质波的相，也有引力波的相，未来还会有新的相。这个过程，便是人对物质的逐步深入认识，即寻找出本体所呈现出的更多的相。但这永远不会止步，就如同struct的定义没有限制一样。所能得知的，就是在指针类型的转换中，在一翕一辟中，在对struct不断地添加调整修改中，形成了我们现在所身处的此在世界。就如同指针不能指向地址长度之外的内存一样，有些相，是我们永远也看不见的。但这些看不见的东西，离我们并不遥远，它是与我们能见到的“相”同时存在的，都是实有的物质本身。如同引力波是物质都具有的一个“相”，但在之前我们都不曾有所体认一样。我们始终在认识“相”的路上，而成就了一切“相”却又不是“相”的，是实有的物质。此即老子所谓“万物恃之以生而不辞，功成不名有，衣养万物而不为主”之谓。 再论人生之意义如果我们无法完全识却世界之本体万相，那我们岂非是活在自欺欺人之中。此言大谬。须知当指针指向一片内存的时候，程序便已可接触内存的每一位比特。易言之，当感官接收到某一实体显现的“相”时，意识已经注意到了实体本身。套用不同的struct会让同一片内存显为不同的“相”，但并不妨碍程序在此“相”中对内存的操作和功用。人生的意义，须在这里求得。 每一段程序，都有其特别的作用，即便是运行在同一台机器上，运行在同一片内存上（不同时刻），也都有其所特有的对内存的理解和操作。为完成程序自身的任务，体现其意义与价值，每段程序都要对内存有其自身的理解与互动。我们见不到实体全部的“相”，并不是对我们的一种限制，恰恰是对我们的一种褒奖。让我们可以于万相纷杂中取其一，并专注于此，完善自己的心智，完成自己的任务。 而人生的意义，不在于求得对实体的全部理解，因为那可能是别人的人生，是一种向外的追寻；真正的意义在于求得自身的圆满，而这一切都需要向内去寻求。写好自己的头文件，磨练自己的API，若能将自己这段“程序”补充完整，让它完成自己要去做的任务，吾不知复有何求矣。 2016.4.22","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"吃牛排的技术","slug":"steak","date":"2018-12-28T09:35:26.000Z","updated":"2018-12-28T09:39:19.317Z","comments":true,"path":"2018/12/28/steak/","link":"","permalink":"https://decodezp.github.io/2018/12/28/steak/","excerpt":"虽然不知道背后是什么原理，但烤出好吃的牛排一定是一门重要的技术。 因为重要的技术，门槛一般都很高。它的高不仅体现在如何掌握这门技术，还体现在如何使用这门技术。","text":"虽然不知道背后是什么原理，但烤出好吃的牛排一定是一门重要的技术。 因为重要的技术，门槛一般都很高。它的高不仅体现在如何掌握这门技术，还体现在如何使用这门技术。 作为一个普通的食客，一个“烤牛排”这门技术的用户，你首先得学会实例化牛的各个部位。必须要准确给出Rib Eye、T-Bone、Filet的名字，大小写敏感，但也许其实你根本不知道这具体是牛身上的哪个部分。 然后要学会在不同场景下调用一分熟、五分熟、九分熟和rare、medium、well-done这种多态接口，以及不要设置“十分熟”这种非法参数。 对于高级用户自然还会有cru、à point、bien cuit来丰富抽象接口的实现；同时还会用一杯Pinot Noir或者Sauvignon Blac作为必不可少的语法糖点缀。 但当品尝了食客、厨师、还有牛都付出了如此努力才端上来的珍馐之后，你很难在第二天回味起它是什么味道——仿佛残留在唇齿间的始终是当时在餐桌上没说的心思。 见过一个人吃火锅，但我始终没见过一个人吃牛排。似乎“技术”可以用来掩盖目的，越是高深的技术，掩盖得越不动声色，掩盖得越托物言志。 我也从来不自己一个人来这家店。周五的中午，没有太多项目和进度报表，没有轻描淡写的握手和佶屈聱牙的名片，更没有迷离的夜色温柔；我所仰仗的“技术”，不过是打开APP找一找团购的套餐，然后在咬上一口汁液四溢时捂住嘴，和对面的人说上一句含混不清的： “新年快乐” emmmm..","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"测来测去3：抽象层直接调用实例方法性能提高百分之20","slug":"test3-indirectcall","date":"2018-12-27T12:40:30.000Z","updated":"2018-12-27T12:49:18.335Z","comments":true,"path":"2018/12/27/test3-indirectcall/","link":"","permalink":"https://decodezp.github.io/2018/12/27/test3-indirectcall/","excerpt":"首先吐槽一下hexo标题不能以%结尾 -_-|| 抽象层经常，我们会在相对比较成熟的软件中见到这样一类结构体：","text":"首先吐槽一下hexo标题不能以%结尾 -_-|| 抽象层经常，我们会在相对比较成熟的软件中见到这样一类结构体： 123456typedef void (*func)(void);struct abstraction_layer &#123; func f; …&#125;; 内部的成员变量，多以函数指针为主。 这种结构体主要作用是实现一个”抽象层”，用来解耦上层的业务需求和具体的实现。在操作系统、设备驱动等各种场合有很广泛的应用。 采用这种抽象形式，虽然增加了程序的灵活性和拓展性(其实就是OOP中多态的实现方式)，但最大的问题就是当真正需要调用某一实例的方法时，只能通过抽象层的函数指针间接调用(indirect call)，而这种调用是伤害性能的。 有没有在性能上更好的方式呢？ 测试对象我们构造这样一个抽象层和一组具体的实现： 抽象层struct op需要实现六个操作接口： 1234567891011121314151617181920#define FUNC_RETURN_TYPE void#define FUNC_PARAMETER void#define OPS \\ _(open) \\ _(close) \\ _(write) \\ _(read) \\ _(add) \\ _(delete)#define _(op) typedef FUNC_RETURN_TYPE (*op)(FUNC_PARAMETER);OPS // typdef void (*open)(void) and so on...#undef _#define _(op) op op##_fp;struct op &#123; OPS // open open_fp; and so on...&#125;;#undef _ 而具体实现这些结构体的实例我们用不同的“颜色”表示： 12345678910111213141516171819#define LIST \\ _(red) \\ _(blue)\\ _(yellow)\\ _(black)\\ _(white)#define FUNC_BODY &#123;int i=0; i++;&#125;#define _(color) FUNC_RETURN_TYPE open_##color(FUNC_PARAMETER) FUNC_BODY \\ FUNC_RETURN_TYPE close_##color(FUNC_PARAMETER) FUNC_BODY \\ FUNC_RETURN_TYPE write_##color(FUNC_PARAMETER) FUNC_BODY \\ FUNC_RETURN_TYPE read_##color(FUNC_PARAMETER) FUNC_BODY \\ FUNC_RETURN_TYPE add_##color(FUNC_PARAMETER) FUNC_BODY \\ FUNC_RETURN_TYPE delete_##color(FUNC_PARAMETER) FUNC_BODYLIST // void open_red(void) &#123;int i=0; i++&#125; and so on...#undef _ 然后我们分别把这几个“颜色”的具体实现与抽象层挂钩： 12345678910111213141516171819202122#define OP_TYPE_NUM 5enum types &#123; red, blue, yellow, black, white&#125;;struct op ops[OP_TYPE_NUM];#define _(color) ops[color].open_fp = &amp;open_##color; \\ ops[color].close_fp = &amp;close_##color; \\ ops[color].write_fp = &amp;write_##color; \\ ops[color].read_fp = &amp;read_##color; \\ ops[color].add_fp = &amp;add_##color; \\ ops[color].delete_fp = &amp;delete_##color;LIST // ops[red].open_fp = &amp;open_red; and so no...#undef _ 准备好了被测对象之后，下面就是对比测试了。 直接调用对每种实例中的方法，有两种调用方式： 间接调用： 以调用每个实例的open接口为例： 1ops[idx].open_fp(); 这种是最常见的调用方式。因为需要先获取指针，再根据指针去调用，所以称为间接调用。 直接调用： 仍是以调用实例的open接口为例： 123456switch(idx) &#123; #define _(color) case color: open_##color(); break; LIST // case red: open_red(); break; and so on... #undef _ default: open_red(); break;&#125; 用一个switch结构先判断该欲调用的方法属于哪个实例，然后直接调用该方法。 看起来直接调用的方式不如间接调用“优雅”，但直接调用是否能带来性能提升呢？ 性能对比12345678910CPU： Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHzOS：3.10.0-514.21.1.el7.x86_64GCC：4.8.5====RANDOM IDX -O0call_ops() : 7936.000 cycles per input word (best) 8279.895 cycles per input word (avg)call_ops_directly() : 6287.000 cycles per input word (best) 6858.248 cycles per input word (avg)====FIX IDX -O0call_ops() : 7862.000 cycles per input word (best) 8035.686 cycles per input word (avg)call_ops_directly() : 6713.000 cycles per input word (best) 7234.337 cycles per input word (avg) 在两种不同的调用方式下（一种是随机选取实例调用，一种是固定调用一个实例），直接调用的方式都比间接调用快(消耗的cycle数少)，在随机调用模式下有接近20%((8279-6858)/8279)的性能提升。 完整代码已传到Github：https://github.com/PanZhangg/x86perf/blob/master/indirectcall.c 至于为什么会出现这个结果，会在后续的系列文章中探究。","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"performance","slug":"performance","permalink":"https://decodezp.github.io/tags/performance/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"}]},{"title":"几句话说清楚8：Intel 700系列网卡内部结构概览","slug":"quickwords8-700-nic-arch","date":"2018-12-25T09:17:39.000Z","updated":"2018-12-27T12:39:54.302Z","comments":true,"path":"2018/12/25/quickwords8-700-nic-arch/","link":"","permalink":"https://decodezp.github.io/2018/12/25/quickwords8-700-nic-arch/","excerpt":"一不小心这个系列写到了第8期，原本打算写些别的东西，不过看到8这个数字就想到了Intel将要推出的800系列网卡…的小弟——命途多舛的700系列网卡。从目前市场(主要是云计算、互联网公司和数据中心)的情况看，700系列有逐渐推广的趋势，那么这一期就介绍一下700系列网卡的基本技术架构和特点吧。","text":"一不小心这个系列写到了第8期，原本打算写些别的东西，不过看到8这个数字就想到了Intel将要推出的800系列网卡…的小弟——命途多舛的700系列网卡。从目前市场(主要是云计算、互联网公司和数据中心)的情况看，700系列有逐渐推广的趋势，那么这一期就介绍一下700系列网卡的基本技术架构和特点吧。 Intel 700系列网卡的内部架构在处理完物理层的事情之后，数据包会进入网卡内部的处理流水线。 对于网络中的事情，所有参与者基本上就在做一个事情：分类-&gt;转发。大到核心路由器，小到iptables都是一样。只不过有些按IP地址的前缀分类，有些按报文的协议类型分类，有些按某些header字段分类罢了。 所以对Intel 700系列网卡来说，在物理层接收到帧之后，首先要做的就是”解析“一下，这个帧到底属于哪一类。 因此Parser解析器就是流水线的第一环。它会根据帧本身的特点，以及自己的识别解析能力，给每个包都打上一个标签(PTYPE和PCTYPE)。 而根据这些标签，会抽取帧中相应的字段(一般是标签所代表的协议中比较关键的字段)存入Field Vector，以备后用。 后面的Switch主要就是用Field Vector中的数据，包括DMAC VLAN ID等等，来决定该帧是应该进入PF还是VF。 流分类(RSS和fdir)在确定了进入哪一个PF或VF之后，就可以对帧进行RSS或者fdir的操作，来决定根据预设的配置，这个帧最终进入哪个队列，进而被哪些上层进程所消费。 Field Vector中的数据在这个时候就会被拿过来做Hash或者过滤，来计算出最终的结果。 而上面提到的PCTYPE，其为”Packet Classifier Type”的缩写。其实是每一种PCTYPE对应后面一套预设的处理过滤规则(Classifier)。比如IPV4 TCP和IPV6 TPC就分别是两种PCTYPE，那么对于这两种报文的处理就可以分别设定规则。e.g. IPV4 TCP的报文进入Queue2, IPV6 TCP的报文进入Queue3。 700系列网卡所谓的“灵活性”和“可编程性”也主要基于此。 最大支持64种PCTYPE，但网卡默认支持的只有…呃..几种。但可以通过DDP动态添加。可以参考前一篇关于DDP的说明文章。 收包流程再简单总结一下700系列网卡的收包流程。 二层帧到达之后，首先进入Parser解析器。解析器根据协议类型，给二层帧打上PTYPE和PCTYPE的“标签”。 同时，根据这些标签，提取标签规定的字段，存入到Field Vector中。Field Vector相当于该二层帧的一个meta data，一直跟随到从某一端口或队列发送出去。 然后在Switch阶段，网卡会根据该二层帧Field Vector中的某些字段判断该帧进入哪个PF或VF。 在进入PF和VF之后，会根据帧各自的PCTYPE，从Field Vector取数据(其实也就是各协议的关键字段e.g. 目的IP地址，VNI等等)参与计算或过滤规则匹配。最后按照规则转发或丢弃。 严格来说，是先经过fdir，再去RSS。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"}]},{"title":"几句话说清楚7：DPDK不同CPU平台交叉编译指令不支持的问题","slug":"quickwords7-dpdk-cross-compile","date":"2018-12-24T13:06:12.000Z","updated":"2018-12-24T13:11:48.307Z","comments":true,"path":"2018/12/24/quickwords7-dpdk-cross-compile/","link":"","permalink":"https://decodezp.github.io/2018/12/24/quickwords7-dpdk-cross-compile/","excerpt":"现象在比较高级的CPU平台(比如skylake)编译DPDK，会在编译的目标文件中加入一些高级指令集中的指令，比如AVX512。 如果运行最终可执行文件的机器的CPU架构(比如broadwell)不支持编译机器中的指令，则会在执行时报类似这种错误：","text":"现象在比较高级的CPU平台(比如skylake)编译DPDK，会在编译的目标文件中加入一些高级指令集中的指令，比如AVX512。 如果运行最终可执行文件的机器的CPU架构(比如broadwell)不支持编译机器中的指令，则会在执行时报类似这种错误： 1174146:Dec 21 10:56:30 n10-023-013 kernel: [57619.700220] traps: obj-name[861199] trap invalid opcode ip:501c31 sp:7fff9782d090 error:0 其实就是在0x501c31(ip是instruction pointer)这个位置上的指令不支持(invalid)。 原因那么如何查看具体是哪条指令呢? 用objdump -D obj-name查看一下目标文件的汇编代码，找到该位置上的指令。 我这里的例子中，这个指令是vmovdqa64，简单搜索一下可以知道这是个AVX512f的指令。 其他详细内容可以查看Intel SDM(Software Development Manual)下载链接 而这个指令在skylake上支持，broadwell上不支持。 可以通过在两个机器上执行cat /proc/cpuinfo | grep flags查看支持的指令集。或者执行gcc -march=native -Q --help=target查看。 方法在编译机器(skylake)DPDK的/mk/machine/native/rte.vars.mk中，设置MACHINE_CFLAGS= -march=native为-march=broadwell就可以了。 当然还有一些详细的交叉编译方法，可以参考这篇文章。 另外还有一点要提醒的是，如果你是在编译某些基于DPDK的应用，比如DPVS，要一并修改应用中的编译配置，例如DPVS就是在./src/dpdk.mk中，需要修改CFLAGS += -march=broadwell。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"dpdk","slug":"dpdk","permalink":"https://decodezp.github.io/tags/dpdk/"}]},{"title":"5分钟经典英文技术演讲2：软件设计真正的精髓-Scott Meyer","slug":"eng-talk2-things-matter","date":"2018-12-21T13:07:58.000Z","updated":"2018-12-21T13:20:43.840Z","comments":true,"path":"2018/12/21/eng-talk2-things-matter/","link":"","permalink":"https://decodezp.github.io/2018/12/21/eng-talk2-things-matter/","excerpt":"一个人的能力上限很大程度上取决于他获取信息的能力。 而能力增长的速度与获取信息的_质量_正相关。 不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。 最新内容将发布于DecodeZ: https://decodezp.github.io 往期回顾：如何快速掌握新技术 DConf2017：软件设计真正的精髓原视频 PPT/Slides下载 演讲者：Scott Meyer 上一张演讲者的照片，硬撸过C++的应该都很熟悉他: 摘要：成功的软件产品都有其共性。在Scott Meyer看来，这些共性由几个要素组成。在你的作品中考虑这些要素，将帮助你掌握软件设计真正的精髓。","text":"一个人的能力上限很大程度上取决于他获取信息的能力。 而能力增长的速度与获取信息的_质量_正相关。 不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。 最新内容将发布于DecodeZ: https://decodezp.github.io 往期回顾：如何快速掌握新技术 DConf2017：软件设计真正的精髓原视频 PPT/Slides下载 演讲者：Scott Meyer 上一张演讲者的照片，硬撸过C++的应该都很熟悉他: 摘要：成功的软件产品都有其共性。在Scott Meyer看来，这些共性由几个要素组成。在你的作品中考虑这些要素，将帮助你掌握软件设计真正的精髓。 效率/速度(Efficiency/Speed)效率高(所需要执行的指令数少)的软件在大多数情况下等于速度快性能高的软件。 在硬件性能普遍过剩的2C和移动市场，对软件效率的追求也可以带来更广泛的平台配适性和更好的功耗表现。 而在每增加100毫秒延时，年收入就掉几个百分点的电商、在线广告和高频交易领域，对服务器软件效率的追求没有止境。 追求软件的高性能肯定没错，但大家一定都熟悉一句话： “过早优化是万恶之源”(Pre-mature optimization is the root of all evil)。 很多人将这句话作为“先不忙优化，最后再说”的理由。但有多少人知道这句话的出处和上下文? 这句话出自Donald Knuth的一篇叫做”Structured Programming with go to Statements”的论文。而这句话的前面一句话和它连起来是： 如果你不能确定在哪里可以优化，就先不要优化。过早优化是万恶之源。 而在这篇总长度41页的论文的同一页，Donald写道： 可以简单获得(easily obtained)的性能提升，并非无足轻重。 当软件已届完成时再考虑性能优化，将是艰难甚至不可能的任务，例如单线程程序改为多线程，有锁替换为无锁结构等等。 所谓”过早优化“(我还是更喜欢将其直译为”不成熟的优化“)，并不是指“从软件的设计阶段就考虑性能”，而是指你还并不知道哪里能优化就一通乱搞的时候。 而能看出系统性能的瓶颈，可以给出“成熟的优化”方案，是需要长期的学习和实践积累的。 Side Note: 对软件性能优化，特别是结合CPU内存等硬件特性感兴趣的读者可以自行搜索一下笔者在青涩时期挖了还没填上的大坑: x86高性能编程笺注 可移植性(Portability)可移植性的出发点，是市场和客户。 Scott举出了一个他供职过的公司的例子：有自己的硬件平台、编译器、和操作系统。他们的产品跑在自己高度定制化的平台上，各方面的优化已臻完美，一切都很美好。 相形之下，那些跑在“拼凑”出来的平台上的竞品，就像一个拙劣的玩笑。 这一切都随着“通用硬件”性价比突飞猛进而结束，竞品提出的策略是：提供该公司80%的产品性能，但只需要20%的价格。 而这样的故事，在Scott二十余年的从业经历中重复发生着。 当你真的认真在考虑一个严肃的软件产品时，请通过可移植性给予它更多的市场适应能力，而不至于因为产品之外的因素影响产品本身的生命周期。 同时可移植性也可以帮助你在推出了一款成功的产品并在当前平台下达到市场饱和之后，开拓出更多的市场增长空间。有增长才有后续的融资嘛 :) 而做好产品的可移植性设计，其难度不亚于上一节提到的性能优化。有太多硬件的和软件的细节需要考虑，不但要做好不同平台之间的抽象，还要考虑如何充分利用不同平台的独有特性。 而这一切都将是你不断学习的内容。 修补性(Toolability)字典中出给的翻译是“修补性”，但我觉得这是一个不贴切的翻译。Toolability在这里的意思是，当你创造出某种产品的时候，需要考虑能够简单地让别人围绕它开发出工具(Tool-able)。 我个人的理解就是，预留出构建生态的能力。 如果把编程语言看作是一种产品，那么某种语言的重构工具就是它整个生态中重要的一环。 重构工具的一项基本功能，就是在一个项目工程中替换某一个函数的名字。在Java中我们有Intellij，有Eclipse，在对C++来说，我们还没有一个特别好使的重构工具。 因为在C++中，一个简单的f(x)可能是： 一个函数 一个函数指针 一个重载操作符 一个模板 一个宏 等等等等 这样的复杂度，让实现C++的重构工具变得几乎不可能。Comments: 现在确实出现了一些C++的重构工具，但相比于其他语言，晚了十余年。 但我们想强调的并不是C++如何重构，而是当没有这些工具，没有产品生态的时候，你的产品能发挥出多大作用，完全受限于使用者本身的能力。而如果他人能够迅速构建出一套工具，将会帮助你提升产品能力的下限。 简单来说就是，只靠产品一个人打天下不行，需要有组件团队的能力。同时当别人想加入你的团队时，最好不要有太多障碍。 一致性(Consistency)一致性是用户体验提升的核心，这里的用户既包括产品最终的消费者，同时也包括开发者。 所谓用户体验，是能够轻易的与以往的经验做类比。保持一致并不是处女座强迫症作祟，而是在软件设计领域有重要意义——带来有效的抽象和类比。一致性本质上是在为我们的大脑创造一种”模式“，既然是模式，就需要有保持一致的东西。 看一个iOS10上的例子： 删除按钮的图标都是一致的，但位置和颜色并没有保持一致。 试想，如果一系列相关的函数调用，它的相同类型的参数位置都不一样，如下面这个C语言的例子： 即便是编写了数十年C程序的程序员，每次也都需要查表才能确定自己把参数放对了位置。 又如Java中求得某个数据类型的长度的方法： 123array.lengthstring.length()List.size() 这种体验需要开发者针对每种不同的数据类型分别记忆不同的方法，而不能构建一个一致性的抽象。 现在当然有智能化的IDE可以帮助我们摆放好参数或者使用正确的方法，但我们想探究的正是，为什么IDE会加入这个功能——因为不一致的参数位置和方法名实在太恼人了。 而用户体验的核心，并非是扁平化设计，而是追求一致：产品本身性能一致，稳定性一致；用起来的时候，能把我以前的经验带到这里来，并且我一看就知道，这个产品如何操作。 接口(Interfaces)设计接口，既要考虑如何容易用对，同时也考虑如何很难用得不对。 而上一节提到的一致性，就是一个很好的指导原则。 毕竟会调用你接口的人，都是聪明人，都是有软件经验的人，同时他们也希望你实现的接口能够帮助他们自己，所以也愿意去读一点文档。 如果即便如此他们还是不能正确使用你的接口，那一定是你自己的问题。 而真正优秀的接口，是调用者凭借你提供的一致性，凭直觉就能使用的接口——“我也不知道为什么，但这个接口就是工作了”。 而一个设计不靠谱接口的开发人员的典型口头禅就是：他们会搞明白的。 这可能正是你的产品变得混乱不堪的开始。 以上就是Scott Meyer想要在本次演讲中传达给我们的内容。","categories":[{"name":"ENG_talk","slug":"ENG-talk","permalink":"https://decodezp.github.io/categories/ENG-talk/"}],"tags":[{"name":"English","slug":"English","permalink":"https://decodezp.github.io/tags/English/"},{"name":"Presentation","slug":"Presentation","permalink":"https://decodezp.github.io/tags/Presentation/"}]},{"title":"几句话说清楚6：什么是DDP(Dynamic Device Personalization)","slug":"quickwords6-ddp","date":"2018-12-18T12:25:40.000Z","updated":"2018-12-18T12:28:33.598Z","comments":true,"path":"2018/12/18/quickwords6-ddp/","link":"","permalink":"https://decodezp.github.io/2018/12/18/quickwords6-ddp/","excerpt":"要解决的问题通过网卡的多队列和RSS将网包根据一些关键字段散列(hash)到不同的队列已成为一种主流的在x86平台开发信通以及云计算领域产品的方式。 在整体产品架构规划中，不同的网卡队列(Rx/Tx Queues)往往对应/绑定着不同的CPU核(Worker)，以利用资源隔离的方式提高性能。 传统的RSS，往往是依据header的五元组来做散列。通常，网卡可以识别出的报文类型包括ipv4-tcp|ipv4-udp|ipv4-other|ipv6-tcp|l2-payload等等，然后根据能识别出的类型进行关键字段的提取。 但现在如此简单的识别能力已经不能满足业务的需求。在复杂的协议和隧道通讯场景下，往往还需要识别隧道内层header甚至私有字段才能实现业务能力的最优化。","text":"要解决的问题通过网卡的多队列和RSS将网包根据一些关键字段散列(hash)到不同的队列已成为一种主流的在x86平台开发信通以及云计算领域产品的方式。 在整体产品架构规划中，不同的网卡队列(Rx/Tx Queues)往往对应/绑定着不同的CPU核(Worker)，以利用资源隔离的方式提高性能。 传统的RSS，往往是依据header的五元组来做散列。通常，网卡可以识别出的报文类型包括ipv4-tcp|ipv4-udp|ipv4-other|ipv6-tcp|l2-payload等等，然后根据能识别出的类型进行关键字段的提取。 但现在如此简单的识别能力已经不能满足业务的需求。在复杂的协议和隧道通讯场景下，往往还需要识别隧道内层header甚至私有字段才能实现业务能力的最优化。 所以对RSS/Fdir来说，首先需要能“识别”出特定的协议报文，才能找到关键的字段进行散列操作。 在网卡出厂的时候，是可以预置一些协议类型的，但还是最好能有自定义的动态调整的能力。 DDP(Dynamic Device Personalization)名字起得很“大”，不过就是上面说的定制化的技能——动态地赋予网卡识别新协议的能力。 具有这种能力之后，就可以把任意协议的网包按用户意愿提取出关键字段(Key)，然后散列到网卡各个Rx队列里。比如VxLAN协议中的内层DIP等等。 下图是一个赋予网卡GTP-U协议(好吧，我并不知道这是什么…)识别能力，并可以依据TEID字段的值进行RSS计算的示例： 现在已经能被识别出的包括L2TPv3\\QUIC\\PPPOE\\SRv6\\RoE\\MQTT-SNoUDP等等，还有一些大客户做了自己私有协议的定制。 总得来说就是，可以把这部分classification的活儿offload到硬件上，减轻后续CPU处理/分发时的压力，同时均衡一下负载，提升整体性能。 DDP的需求： Intel 700系列网卡以上 固件版本6.01以上 一个由Intel官方出品的特定协议识别的binary package file(需要到官网下载) DPDK提供的配置接口 具体在DPDK上怎么搞后续会有文章说明。 Q&amp;A Q:如何自己制作binary package file?A:目前不支持自己制作，只能由Intel提供。 Q:一张网卡最多支持载入多少个binary package file(profile)?A:最多支持16个，但不推荐这么做，推荐同时只载入一个。 Q:载入之前需要首先关闭网卡设备吗？A:不需要，支持运行时直接载入，但会引起一些丢包","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"}]},{"title":"谁不是在像CPU一样活着","slug":"cpulized-life","date":"2018-12-16T10:06:40.000Z","updated":"2018-12-16T10:12:04.758Z","comments":true,"path":"2018/12/16/cpulized-life/","link":"","permalink":"https://decodezp.github.io/2018/12/16/cpulized-life/","excerpt":"上一次兴奋到浑身发热，还是把赛扬300A超频到450兆赫的时候。身体如摩尔定律般长高，觉得距离1GHz只差一罐液氮，心里装着只有一心一意才能装下的事情。 记得那时看到一篇报道，英特尔说“到2011年的时候，我们都能用上10GHz的电脑”。十几岁的你笑这家美国公司野心不大，现在你说出这件事，只是想给大家讲个笑话。","text":"上一次兴奋到浑身发热，还是把赛扬300A超频到450兆赫的时候。身体如摩尔定律般长高，觉得距离1GHz只差一罐液氮，心里装着只有一心一意才能装下的事情。 记得那时看到一篇报道，英特尔说“到2011年的时候，我们都能用上10GHz的电脑”。十几岁的你笑这家美国公司野心不大，现在你说出这件事，只是想给大家讲个笑话。 2018年，没等来10GHz的电脑，也再也没有一心一意的机会。学会了MMX、SSE、AVX，TSX和AEX等十八般武艺，领导说你是“业务中坚”，其实你知道你只是个挣扎着适应环境的执行人员。 好在熟稔让你变得老练，打点好前端后端的各种关系，再低的IPC也可以不动声色。毫无指摘地把锅甩给温吞的硬盘，你想你可能明白了什么是sophisticated，就是心里只寻思自己那点14nm的柴米。 但越是老练越让你厌恶风险，你给自己加了iCache、dCache、iTLB、dTLB，IOTLB等各种保险，但每次分支预测失败还是要彻底打乱你的流水线。即便凭借经验已能做到99%的正确，却能又让你掉入Spectre的窠臼。 真是怕什么来什么，左右为难的时候，自己的窘样又让心里有一点点好笑，能用一罐液氮解决的事情，偏要搞这么复杂。 突然有些怀念那个为450兆赫兴奋的自己，当时你只想完成这一件事。但此刻你心里不再只住着你自己，每个人都同时在跑好几个角色，你号称你是3GHz还能hyperthread，其实你知道你早已没了章法，所有的事情都不过是水来土掩的乱序执行。 但好在还有一块L3缓存，和你那些sophisticated的L1缓存相比，这里虽然慢，慢得就像曾经的赛扬300A，但却有一心一意的完整。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"几句话说清楚5：影响服务器内存性能的硬件知识","slug":"quickwords5-server-memory","date":"2018-12-13T14:20:51.000Z","updated":"2018-12-13T14:38:25.712Z","comments":true,"path":"2018/12/13/quickwords5-server-memory/","link":"","permalink":"https://decodezp.github.io/2018/12/13/quickwords5-server-memory/","excerpt":"发挥内存条理财的最大收益率内存条作为年度最佳理财产品除了能躺着赚钱之外，使用得好还可以一条当两条用。 在计算机系统中，内存的价值就体现在快速提供数据给CPU处理。当CPU需要的数据没有在缓存里时，CPU内部的Memory Controller就需要去内存中读取内容。","text":"发挥内存条理财的最大收益率内存条作为年度最佳理财产品除了能躺着赚钱之外，使用得好还可以一条当两条用。 在计算机系统中，内存的价值就体现在快速提供数据给CPU处理。当CPU需要的数据没有在缓存里时，CPU内部的Memory Controller就需要去内存中读取内容。 而Memory Controller为了尽快完成CPU交代的任务，用了多通道的方式增大内存存取带宽。 多通道这个概念很好理解，和多条车道是一个意思。比如CPU需要1MB大小的数据，单通道的话数据就只能在一条通道上老老实实排队；双通道就可以并行两个512KB的读取；四通道就是并行四个256KB的读取。 我知道你要问什么，这1MB大小的数据已经被Memory Controller通过一种叫做Interleave(交织)的技术“打散”在了两个通道或者四个通道对应的物理内存上。Interleave由硬件实现，细节不在这里深究，我们想说明的是发挥这些硬件组件的最大能力需要外界条件配合。 内存在硬件方面的性能优化，就围绕这个主题。 内存相关概念现在主流Intel E5 CPU的配置是一颗CPU上两个Memory Controller，每个Controller有两个通道，每个通道对应主板上三个内存插槽(DIMM)。 Interleave首先发生在通道层面，进而发生在通道的DIMM层面（使用的DIMM越多，交织得越充分） 同时每根内存条还有一个Rank的概念。这个概念可以理解为更进一步的Interleave，多Rank的内存条可以再进行一次Interleave。 充分平衡满足最优的内存配置就是四个字：充分平衡。 -充分：并不是要你插满所有插槽，而是充分利用每个Memory Controller和每条通道-平衡：每个Memory Controller和通道上的内存配置(Size, Rank和频率)都相同。 在实际应用中，首先绘制一个内存拓扑，如下图： 如何检查是否充分？看一下每个Memory Controller中的每个通道是否都有内存条如何检查是否平衡？将拓扑图从中垂线对折一次，检查图像是否能重合；再从水平中位线对折一次，检查是否能重合。如果两次回答都是yes，就平衡了。 实例1 实例2 实例3 实例4 软件检查工具为了不让每次内存检测都需要打开机箱…有一个开源工具可以通过读取dmidecode的信息自动化做检验：DPDKick","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"performance","slug":"performance","permalink":"https://decodezp.github.io/tags/performance/"},{"name":"memory","slug":"memory","permalink":"https://decodezp.github.io/tags/memory/"}]},{"title":"5分钟经典英文技术演讲1：如何快速掌握新技术 - Kathy Sierra","slug":"eng-talk1-fast-learn","date":"2018-12-12T14:51:14.000Z","updated":"2018-12-12T15:09:49.362Z","comments":true,"path":"2018/12/12/eng-talk1-fast-learn/","link":"","permalink":"https://decodezp.github.io/2018/12/12/eng-talk1-fast-learn/","excerpt":"一个人的能力上限很大程度上取决于他获取信息的能力。 而能力增长的速度与获取信息的质量正相关。 不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。 最新内容将发布于DecodeZ: decodezp.github.io Fluent: 如何快速掌握新技术原视频演讲者: Kathy Sierra 摘要：无论是谁，以有限的精力来面对层出不穷的新技术挑战都是不够的。你需要学会一套方法论来帮助你快速习得新的技能。而快速学习的秘诀却还不止这些…","text":"一个人的能力上限很大程度上取决于他获取信息的能力。 而能力增长的速度与获取信息的质量正相关。 不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。 最新内容将发布于DecodeZ: decodezp.github.io Fluent: 如何快速掌握新技术原视频演讲者: Kathy Sierra 摘要：无论是谁，以有限的精力来面对层出不穷的新技术挑战都是不够的。你需要学会一套方法论来帮助你快速习得新的技能。而快速学习的秘诀却还不止这些… 每个程序员都面临的挑战为了成为一名“合格”的程序员，你认为你需要掌握哪些技术？ 这将是一个长长长长长的名单，更可怕的是，每个人列出的内容都将各不相同。 所以这么提问并没有太大意义，更好的问题是： 我如何快速掌握新的技术？ 认知资源我们习得新的技能，需要依赖我们自己的认知资源（Cognitive resources）。 但作为一个正常的“人类”，我们的认知资源易耗且稀缺。 到底有多容易消耗？Kathy提到了一个大学里的实验：实验人员要求一半实验参与者记忆一个两位的数字，而另外一半参与者记忆一个七位的数字。 等确保每个人都记住了自己的数字之后，实验人员随即宣布实验结束，并邀请所有参与者去取用一些零食——蛋糕，或水果。 而实验结果也能猜到，仅仅是5位数字的差别，就让记忆七位数的实验者选取蛋糕的比例比记忆两位数的参与者高出一半。 你是否有想认真掌握一门新技能，但一拿起各类技术书籍、文档，很快就放弃的经历？你又是否在做一些让别人“选择蛋糕”的事情？比如让别人阅读你自己编写的项目文档。 当你想要快速掌握一项技能的时候，你需要学会管理自己的认知资源。 学习方法将你现在的技能分为三类： A还没有掌握，但需要掌握的 B经过一定努力可以掌握的 C已经掌握的 我们的目标其实是如何将AB的技能快速移动到C。在这个过程中我们会遇到两类典型问题： 没有进步 耗时太久 没有进步第一类问题的根本原因在于你的认知资源不足以支撑技能的学习需求。我们不能要求自己有无限的认知资源，在资源极度有限的情况下，仍有两种解决策略： 第一种，将更多的需要掌握的技能放在A，将精力集中于少量的B类技能。但在日常工作中，需要掌握哪些技能，解决哪些问题，都不是自己可以安排的。对此，我们还有第二种策略。 第二种策略，就是将B中的技能分解为更小的粒度。这种策略，在有限的认知资源的情况下效果等同于一个需要处理多任务并发的CPU，上面运行的程序都采用了更加细粒度的锁机制，带来了程序性能的提升。 那么如何界定分解之后的技能足够“细”？Kathy给出了一个她的评判标准： 从完全不会到十分熟练，最多经过3次练习，每次45-90分钟。 能满足上面的标准就可以认为分解到了合理的粒度。 耗时太久程序员不但要学习很多技能，还需要快速学习。所以从A开始，我们最好能够绕过B直接到C。 怎么可能从完全不懂，到突然就明白了？ Kathy给出了一个“极端”的例子：学习给分辨雏鸡的性别。 从视觉上，这是一件不可能的事，但日本却有一些非常擅长分别雏鸡性别的人。 人们希望这些“性别分辨大师”能够将他们的方法教授给别人，但这些人并不能讲出什么明确的“规则”。 这就是这件真正神奇的地方，我们的大脑能够在潜意识中处理一些信息，但却讲不出来为什么。 所以学习雏鸡性别分辨的人最开始只是随机判断雏鸡的性别，而这些“专家”则告诉他们结果是不是正确。 一段时间以后，这些学习分辨性别的人正确率越来越高，最终达到了专家的水平。 这些学习的人并没有记忆任何具体的“规则”，却能够不断提升自己的技能水平。这里产生核心影响的是：高质量的例子。 这非常类似机器学习的过程，模型的质量取决于训练这些模型的数据的质量。 关键的缺失——高质量的例子当要学习某样特殊技术的时候，你是找官方的、正式的、长而无味的文档，还是去找一个精悍的例子？ 当你能找到一个精确的示例来演示如何使用这样技术的时候，你几乎可以“瞬间”掌握这项技术。 你需要这些示例来让大脑自动地，潜意识地识别其中的模式。但现在的问题是，所有技术里又臭又长的文档很多，但短小精悍的示例很少。 所以是否可以利用社区的力量，将这些文档转换成一系列高质量的示例库呢？ 以上就是在本次演讲中，Kathy想要传达给我们的内容。 引申《庄子》中有这样一个故事： 桓公读书于堂上，轮扁斫轮于堂下，释椎凿而上，问桓公曰：“敢问：“公之所读者，何言邪？”公曰：“圣人之言也。”曰：“圣人在乎？”公曰：“已死矣。”曰：“然则君之所读者，古人之糟粕已夫！”桓公曰：“寡人读书，轮人安得议乎！有说则可，无说则死！”轮扁曰：“臣也以臣之事观之。斫轮，徐则甘而不固，疾则苦而不入，不徐不疾，得之于手而应于心，口不能言，有数存焉于其间。臣不能以喻臣之子，臣之子亦不能受之于臣，是以行年七十而老斫轮。古之人与其不可传也死矣，然则君之所读者，古人之糟粕已夫。“ 真正的精髓，都在手上，而不在文档里。","categories":[{"name":"ENG_talk","slug":"ENG-talk","permalink":"https://decodezp.github.io/categories/ENG-talk/"}],"tags":[{"name":"English","slug":"English","permalink":"https://decodezp.github.io/tags/English/"},{"name":"Presentation","slug":"Presentation","permalink":"https://decodezp.github.io/tags/Presentation/"}]},{"title":"几句话说清楚4：什么是Pointer Aliasing","slug":"quickwords4-pointer-aliasing","date":"2018-12-11T11:33:46.000Z","updated":"2018-12-11T11:45:43.584Z","comments":true,"path":"2018/12/11/quickwords4-pointer-aliasing/","link":"","permalink":"https://decodezp.github.io/2018/12/11/quickwords4-pointer-aliasing/","excerpt":"指向同一地址的两个相同类型的指针aliasing本身是一个信号处理方面的概念。是指在信号采样过程中，不同的信号不再能相互区分的现象。 如下图所示的波纹现象，相对于拍摄的采样频率（横纵像素分辨率），墙砖缝隙变化的频率要大于采样频率。或者换句话说，多条墙砖缝隙需要挤在一个像素里面。","text":"指向同一地址的两个相同类型的指针aliasing本身是一个信号处理方面的概念。是指在信号采样过程中，不同的信号不再能相互区分的现象。 如下图所示的波纹现象，相对于拍摄的采样频率（横纵像素分辨率），墙砖缝隙变化的频率要大于采样频率。或者换句话说，多条墙砖缝隙需要挤在一个像素里面。 同样的现象也会出现在程序员穿着“高密度”的格子衬衫接受电视采访时。 墙砖缝隙出现aliasing后无法再行区分，从字面意义来说，Pointer Aliasing就是不同的指针也无法区分。 指针无法区分，只有一种情况，就是指针的类型和指向的地址都是相同的，这就是Pointer Aliasing。 为什么会有性能影响12345void foo(int *array, int *size, int *value) &#123; for(int i=0; i &lt; *size; ++i) &#123; array[i] = 2 * *value; &#125;&#125; 如果让我们自己“优化”一下这段代码，我们可能会首先将value指向的值存入一个临时变量里，然后将临时变量在循环中直接赋值给array。 我们假设个array的初始状态：[0, 1, 2, 3, 4] 如果value指向的值等于3，那么按我们优化的方式，array最终的状态是：[6, 6, 6, 6, 6] 但这里存在一个问题，如果value指向array[3]，那么array最终的状态就是：[6, 6, 6, 12, 24] value和array[3]就是指向相同地址类型相同的指针。 编译器为了得到最终正确的结果，就不得不取消我们之前提到的”优化”方式。 预防方法使用__restrict关键字： 12345void foo(int * __restrict array, int *__restrict size, int *__restrict value) &#123; for(int i=0; i &lt; *size; ++i) &#123; array[i] = 2 * *value; &#125;&#125; 当然，前提是自己可以确定代码逻辑中不会引入aliasing。 怎么使用首先明确一点，不是加上了__restrict性能就会提升。 Pointer aliasing对性能根本的伤害不是需要每次重新去某个地址取值，而是因为引入了潜在的数据依赖关系，从而关闭了很多编译器优化代码的能力。 上面两段代码，在-O0优化时生成的汇编代码(gcc 4.8.5)完全相同。不同的地方在于，第一段代码在-O2和-O3时生成的汇编代码仍然相同；而第二段做了__restrict处理的代码则会在-O3时加入大量循环展开等优化方式。 在线查看汇编代码：链接 所以__restrict需要在打开较高等级的编译器优化的情况下使用才会有效果。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"},{"name":"performance","slug":"performance","permalink":"https://decodezp.github.io/tags/performance/"}]},{"title":"产品观察1：华为FabricInsight产品简要分析","slug":"product1-huawei-fabricinsight","date":"2018-12-07T22:26:24.000Z","updated":"2018-12-07T22:38:54.500Z","comments":true,"path":"2018/12/08/product1-huawei-fabricinsight/","link":"","permalink":"https://decodezp.github.io/2018/12/08/product1-huawei-fabricinsight/","excerpt":"123最近机缘巧合之下接触到了华为FabricInsight这款产品，简要谈谈看法。只针对2018年8月份左右发布的版本。另外注意，在Google搜索相关资料的时候，记得要把Fabric Insight这两个单词合并在一起搜索，中间不要加空格，别问我怎么知道的。","text":"123最近机缘巧合之下接触到了华为FabricInsight这款产品，简要谈谈看法。只针对2018年8月份左右发布的版本。另外注意，在Google搜索相关资料的时候，记得要把Fabric Insight这两个单词合并在一起搜索，中间不要加空格，别问我怎么知道的。 概述信息采集SNMP在使用FabricInsight之前需要配置华为设备的SNMP协议，主要作用为获取设备的MIB信息，并进行其他管理操作。 LLDP使能各设备的LLDP功能，以便FabricInsight据此（以及通过SNMP上送的MIB信息）绘制硬件连接拓扑图。 NetConf使能各设备的NetConf配置，以便FabricInsight能通过NetConf协议配置各设备的ERSPAN功能。 ERSPAN配置ERSPAN功能，destination IP配置为FabricInsight collector的地址。底层实现为：通过GRE隧道的方式将远程设备的流量路由/镜像至分析节点，以实现对流量可视化分析。ERSPAN可配置筛选特定的流量，并非全量镜像。从华为对交换机的配置： [~Device] observe-port 1 ​ destination-ip 10.10.10.20 ​ source-ip 10.1.1.1 [*Device] traffic-mirroring vxlan tag-format none tcp-flag fin syn rst observe-port 1 inbound [*Device] traffic-mirroring tcp-flag fin syn rst observe-port 1 inbound [*Device] commit 通过ERSPAN镜像给FabricInsight的流量包括带有FIN/SYN/RST等TCP flag的网包。对应其产品中对TCP事件的可视化能力。注*：据此可以看出FabricInsight没有全量流量镜像&amp;分析能力注*：命令中的vxlan可能是将流量通过vxlan封装，做三层转发，而非镜像全部vxlan流量 Telemetry华为的Telemetry指设备主动、以固定周期上报的一些设备信息，包括CPU\\MEM\\QUEUE等信息。 手动录入主要为用户业务信息，每一个业务的定义为一组IP和某一固定端口号的集合，需要用户手工录入。 功能分类Underlay拓扑可视化依据LLDP生成及SNMP上报的信息，可生成Underlay设备间的拓扑信息。流量事件统计依据ERSPAN镜像的含有SYN\\FIN\\RST等flag的TCP网包，可统计一条流（五元组）中的事件发生次数、时间及类型。并可据此进行简单的SYN重传、建立连接RTT、建连成功率分析。但缺少对网流完整过程（e.g.流量传输数据总量、pps、整体平均时延等）的统计和分析。 设备信息统计根据Telemetry信息给出CPU\\MEM等设备运行状态统计信息，以及对各网络端口IN/OUT总量、drop、error数量等的统计信息。 应用流量分类过滤其应用功能，本质为手动设置IP+端口号过滤规则，通过过滤的流量即为一个应用。应用间的流量状态展现，即为在流量事件统计数据库中分别为起止两端的流量配置两个应用的过滤规则，筛选出的流量即可作为应用间的流量状态展示。 FabricInsight特点强绑定性只能用于华为的硬件设备。并且后期会形成双向绑定，如若依赖FabricInsight，扩容时只能继续采购华为设备。 基于流量事件对于流的分析仅涉及五元组和TCP流量事件。可依据SYN、FIN、RST等TCP流量事件完成TCP SYN重传、RST等事件的侦测，并作为报警依据。 无流量全量分析当前观察，仅有TCP流量的事件信息，对UDP、ICMP、ARP等网络流量无采集分析能力。仅针对TCP流量，亦无流量全量分析能力，无法获取诸如流量总字节数、总包数、pps、平均时延、最大时延等信息。 Overlay能力暂无当前FabricInsight宣称的可分析虚拟网络是指，手工指定某一虚拟网元（Virtual NE）IP地址，手工指定其角色（e.g. FW\\LB\\Router）其与外界通讯的流量可以以与Underlay网络相同的方式采集。未发现针对虚拟网络VM间的采集分析能力。从其官方手册中针对ERSPAN的配置来看，可能或未来会具有一定的VXLAN隧道解封装及关联对应能力。但即便如此，在大规模网络流量的情况下，对全部VXLAN流量分析亦将为设备带来压力。另外，主机内的虚拟网络流量，FabricInsight以现在的形式是绝对无法取得的。 FabricInsight未来演进趋势推测In-band TelemetryFabricInsight的数据采集能力全部来自于设备提供的能力。在设备/芯片领域的发展趋势是提供更加精细化的In-band Telemetry遥测能力。从Cisco/Barefoot等厂商近期对P4芯片的动态来看，华为跟风也是早晚的事。In-band Telemetry可以提供诸如per packet的全生命周期、匹配的具体转发规则、更加精细的时间戳等能力。但如若采用新的芯片组提供In-band Telemetry，则会仅支持新款产品。除此之外，也将不仅仅将流量分析的范畴局限于TCP流量。 虚拟网络虚拟网络是行业演进的趋势，但需要考虑华为对FabricInsight这款产品本身的定位。如果添加虚拟网络能力，则其品牌名称、目标人群都将会有较大调整。但华为整体上缺乏虚拟网络可视化的产品和能力，因此推断会先对接华为自己的云平台FusionCloud，计算节点绑定探针。但先期仍会仅采用TCP流量事件的分析模式，不会全量采集和分析。 AIopsAI的概念在当前版本的FabricInsight中已有所体现，但当前仅是一些标准差方差的统计计算。演进的方式将是对网络中断和延迟的诊断以及自调优的赋能。但这种分析首先要求用户能够输入一定的专家经验作为数据训练的标记，同时对分析节点的部署要求较高（支持大数据分布式计算和存储）。 安全防御这是当前看起来最有实际效能的功能。其本身具有的TCP事件分析能力完全可以用来完成DDoS攻击的侦测和防御。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"product","slug":"tech/product","permalink":"https://decodezp.github.io/categories/tech/product/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"product","slug":"product","permalink":"https://decodezp.github.io/tags/product/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"}]},{"title":"可以预测交通路况的 APP","slug":"life-traffic-prediction","date":"2018-12-06T06:41:18.000Z","updated":"2018-12-06T06:45:25.440Z","comments":true,"path":"2018/12/06/life-traffic-prediction/","link":"","permalink":"https://decodezp.github.io/2018/12/06/life-traffic-prediction/","excerpt":"能不能有这样一款应用","text":"能不能有这样一款应用 或者地图 APP 实现这样一个功能 能通过历史路况大数据分析 告诉我今天晚上几点出发上路 东北四环不堵 把什么机器学习人工智能数字孪生 能加的都给它加上 感觉又是一个割 VC 韭菜的杀手应用 只要有人搭出来这个框架 我愿意帮忙实现所有的业务代码 因为只需要一句 return &quot;您期望的时间不存在&quot; 2018.12.6","categories":[{"name":"life","slug":"life","permalink":"https://decodezp.github.io/categories/life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://decodezp.github.io/tags/life/"}]},{"title":"测来测去2：CPU缓存读入策略","slug":"test2-cache-line-alignment","date":"2018-12-06T06:18:31.000Z","updated":"2018-12-06T06:29:21.926Z","comments":true,"path":"2018/12/06/test2-cache-line-alignment/","link":"","permalink":"https://decodezp.github.io/2018/12/06/test2-cache-line-alignment/","excerpt":"到底哪些数据写入了CPU缓存我们知道CPU会在要读写某个数据时，先将数据写入缓存。 我们也知道这个操作一般以Cache Line为操作粒度，并且Cache Line的长度一般为64Byte。","text":"到底哪些数据写入了CPU缓存我们知道CPU会在要读写某个数据时，先将数据写入缓存。 我们也知道这个操作一般以Cache Line为操作粒度，并且Cache Line的长度一般为64Byte。 那么这个Cache Line包含的数据到底是哪64Byte呢？ 如果要读写的数据的地址正好以64Byte对齐，那么肯定是这个数据和它之后的（64 - sizeof(数据)）Byte存在于这个缓存行里。 但是如果要读写的这个数据地址不以64Byte对齐，而是在两个64Byte对齐的地址中间的某个位置，CPU写入Cache Line里的数据还是它和它之后的64Byte吗？CPU会“向前”对64取整作为Cache Line中的数据吗？ 用False Sharing证明根据之前介绍False Sharing的原理链接，通过判断是否发生False Sharing可以判断某两个数据是否存在于同一条Cache Line里。 构造如下结构体： 123456struct counter_t &#123; uint32_t front_padding[15]; uint32_t c1; /* 64 bytes */ uint32_t c2;&#125;; 其中c1和c2是分别被两个CPU core写入的变量。 在构造counter_t的实例时，利用GCC attribute确保其起始地址与64Byte对齐： struct counter_t counter __attribute__((aligned(64))); 在两个CPU核分别开始操作c1和c2之前利用clflush指令清除所有相关缓存： 12345inline voidclflush(volatile void *p)&#123; asm volatile (\"clflush (%0)\" :: \"r\"(p));&#125; 如果发生了False Sharing，则说明这两个变量在一个Cache Line里，则证明CPU是取欲读写变量及其之后64Byte数据写入缓存如果没有发生False Sharing，则说明这两个变量不在一个Cache Line里，则证明CPU是取欲读写变量向前64取整地址上的数据写入缓存 结果结果当然是没有发生False Sharing。 不然还搞什么n-way set associative :) 代码：https://github.com/PanZhangg/x86perf/blob/master/cache_line_alignment.c","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"}]},{"title":"魏孝文帝教你提proposal","slug":"history-tuobahong","date":"2018-12-05T07:09:12.000Z","updated":"2018-12-05T07:14:40.277Z","comments":true,"path":"2018/12/05/history-tuobahong/","link":"","permalink":"https://decodezp.github.io/2018/12/05/history-tuobahong/","excerpt":"艰难的Proposal每个人都有独自一人面对全世界的时候，即便你是魏孝文帝拓跋宏。 北魏太和十七年，承平日久的北魏都城里正在酝酿一件大事——迁都。","text":"艰难的Proposal每个人都有独自一人面对全世界的时候，即便你是魏孝文帝拓跋宏。 北魏太和十七年，承平日久的北魏都城里正在酝酿一件大事——迁都。 自天兴元年拓跋圭定都平城起，北魏在此地经营了九十余年。此时的平城，早已是北魏王公贵族富商巨贾的乐土。 而拓跋宏却不想在这呆了，对这位一心思慕华夏风仪的少数民族首领来说，城狭地偏的平城终究不是久居之地。 迁都，迁往洛阳，只有住在这座每块城砖上都写满了厚重的城邑的中心，才是北漂买房落户的那一刻。 但除了拓跋宏，没有人愿意当拆迁户，被连根拔起。拓跋宏自己也知道这一点。晓以大义？没用的，天底下最难的事，就是劝说别人放弃眼前的利益，去追求什么万世之业； 以皇帝的权威一意孤行？没有问题，但人心不齐，效果打折扣，既损威严，又于事无益。 那么迁都这个Proposal，到底怎么提呢？ 魏孝文帝的方式拓跋宏并没有在一开始就透露自己的意图，而是提出了一个更加”不得人心”的Proposal——亲自带队，攻打南朝。 如果说迁都不得人心，那么发动战争就更加让改革的主要阻力——深居平城的皇亲贵胄们如坐针毡。 因为迁都或许还可以讨论讨论，但南下伐齐“一统中国”那是北魏政权不容辩驳的“正统思想”，是政治正确，有拓跋氏列祖列宗的加持，以及冯太后的附魔。 这一年的八月，拓跋宏亲率三军开拔南下。 当然，皇帝都出去打仗了，除了太子监国以外，平日里的文武百官哪有在家呆着的道理，一起走吧！ 从山西大同往南，大军在秋雨连绵的泥泞中走了整整一个月，终于到达了宿命的重点——洛阳。 这个时候所有人都不想再走了。一路的狼狈或可忍受，但后面还有与齐国的恶战。而拓跋宏依然兴致不减，号令即刻开拔，继续南进。 这下文武百官们可都要“犯颜进谏”了，纷纷叩头不止，甚至不惜死谏以请求拓跋宏停止南征。 这个时候拓跋宏才说出他真正的目的： 今者兴动不小，动而无成，何以示后？苟欲班师，无以重之千载！朕世居幽朔，欲南迁中土，苟不南伐，当迁都于此，王公以为如何？欲迁者左，不欲者右！——《资治通鉴》 这里有三个要素： 我可以在南伐之事上让步 但我的让步有条件 不许考虑太久 最终的结果自然是大家都站到了左边。迁都这件事，就这么“取得”了大家的同意。 抽象提取在谈判领域存在一个让步/妥协的谈判技巧。 对每个人来说，如果对面已有所让步，那么心里将会产生同样让步的压力，趋向于同意对方提出的让步条件。 这种场景在生活中非常常见，例如： 12345678多少钱？10030吧最低9040低于85就赔本了你看我就50块钱行了80吧，今天好不容易开张 如果能成交，说明买家和卖家一开始的心理价位就都是80元左右，但买家必须要首先压到30，卖家也要提到100，互相留出这个让步的空间。 也许你觉得这种技巧太市侩，但它其实有很多变种版本，也许自己已经身堕瓠中而不自知。E.g.房产中介请你看房，首先是一间各方面条件都很差的房间，但却有一个让你惊讶的高额租金。然后带你看了一套各方面比第一间好非常多的房间，租金却和第一间一样，或者略多而已。如此你会觉得租了第二间是占了便宜。但其实中介的目标就是租给你第二间房，第一间就是让你产生这种对比让步的错觉的。 所以，每当打算提一个艰难的Proposal的时候，我都会效仿这种形式。","categories":[{"name":"history","slug":"history","permalink":"https://decodezp.github.io/categories/history/"}],"tags":[{"name":"history","slug":"history","permalink":"https://decodezp.github.io/tags/history/"}]},{"title":"ftrace uprobe使用填坑历程","slug":"ftrace-uprobe","date":"2018-12-04T04:25:59.000Z","updated":"2019-01-15T14:16:07.331Z","comments":true,"path":"2018/12/04/ftrace-uprobe/","link":"","permalink":"https://decodezp.github.io/2018/12/04/ftrace-uprobe/","excerpt":"准备打算用一下ftrace对用户态程序的trace支持。 测试用程序test.c：","text":"准备打算用一下ftrace对用户态程序的trace支持。 测试用程序test.c： 123456789101112131415161718192021static voidprint_curr_state_one(void)&#123; printf(\"This is the print current state one function\\n\");&#125;static voidprint_curr_state_two(void)&#123; printf(\"This is the print current state two function\\n\");&#125;int main() &#123; while(1) &#123; print_curr_state_one(); sleep(1); print_curr_state_two(); &#125;&#125; 编译：gcc -o test test.c Obtain Offset：objdump -d test 123456789101112131415000000000040055d &lt;print_curr_state_one&gt;: 40055d: 55 push %rbp 40055e: 48 89 e5 mov %rsp,%rbp 400561: bf 30 06 40 00 mov $0x400630,%edi 400566: e8 c5 fe ff ff callq 400430 &lt;puts@plt&gt; 40056b: 5d pop %rbp 40056c: c3 retq 000000000040056d &lt;print_curr_state_two&gt;: 40056d: 55 push %rbp 40056e: 48 89 e5 mov %rsp,%rbp 400571: bf 60 06 40 00 mov $0x400660,%edi 400576: e8 b5 fe ff ff callq 400430 &lt;puts@plt&gt; 40057b: 5d pop %rbp 40057c: c3 retq 添加uprobe trace event： 12echo 'p:print_current_state_one /root/test/uprobe/uprobe:0x55d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_eventsecho 'p:print_current_state_two /root/test/uprobe/uprobe:0x56d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_events 有时会出现Invalid argument的错误。用sudo su获取root权限。 这里注意，偏移的大小只写0x55d，不能写0x40055d 开启trace先启动test程序：./test echo 1 &gt; /sys/kernel/debug/tracing/event/enable 如果此时cat /sys/kernel/debug/tracing/event/enable显示为X echo 1 &gt; /sys/kernel/debug/tracing/event/uprobes/enable 最后cat /sys/kernel/debug/tracing/trace应该就能看到了","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"ftrace","slug":"ftrace","permalink":"https://decodezp.github.io/tags/ftrace/"}]},{"title":"ftrace trace-cmd kernelshark资料汇总","slug":"ftrace","date":"2018-11-30T06:22:55.000Z","updated":"2018-11-30T06:39:04.849Z","comments":true,"path":"2018/11/30/ftrace/","link":"","permalink":"https://decodezp.github.io/2018/11/30/ftrace/","excerpt":"一些关于这一类技术的资料和文档汇总。文章中可以找到比较详细的工具使用方法。如果想了解更多内容可以阅读linux/Documentation/trace下的文档以及源码。 以及git log ./kernel/trace :)","text":"一些关于这一类技术的资料和文档汇总。文章中可以找到比较详细的工具使用方法。如果想了解更多内容可以阅读linux/Documentation/trace下的文档以及源码。 以及git log ./kernel/trace :) ftrace Debugging the kernel using Ftrace - part 1 Debugging the kernel using ftrace - part 2 Kernel Documents: ftrace Secrets of the Ftrace function tracer PDF:Debugging Linux Kernel by ftrace Kernel Tracing with ftrace, Part 1 Kernel Tracing with ftrace, Part 2 ftrace: trace your kernel functions! Hooking Linux Kernel Functions, how to Hook Functions with Ftrace Understanding the Linux kernel via ftrace trace-cmd trace-cmd: A front-end for Ftrace Code:trace-cmd kernelshark Using KernelShark to analyze the real-time scheduler Video:KERNELSHARK 1.0; WHAT’S NEW AND WHAT’S COMING Video:Yordan Karadzhov - What’s Coming in Kernel Shark PDF:Swimming with the New KernelShark","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"linux","slug":"tech/linux","permalink":"https://decodezp.github.io/categories/tech/linux/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"ftrace","slug":"ftrace","permalink":"https://decodezp.github.io/tags/ftrace/"},{"name":"linux","slug":"linux","permalink":"https://decodezp.github.io/tags/linux/"}]},{"title":"测来测去1：DPDK no-huge模式性能对比测试","slug":"test1-dpdk-no-huge","date":"2018-11-29T05:20:58.000Z","updated":"2018-11-29T05:30:48.738Z","comments":true,"path":"2018/11/29/test1-dpdk-no-huge/","link":"","permalink":"https://decodezp.github.io/2018/11/29/test1-dpdk-no-huge/","excerpt":"no-hugeDPDK使用大页内存作为性能优化的一个手段。但大页内存在云计算等环境下可能会出现内存资源浪费的情况，作为售卖资源的云服务商，希望能找到更充分的内存资源利用的方法。在此背景下，DPDK引入了no-huge机制，即不使用hugepage，从而解放更多的系统资源。 那么这种配置下DPDK性能会下降多少呢？还是需要实际定量测试一下。","text":"no-hugeDPDK使用大页内存作为性能优化的一个手段。但大页内存在云计算等环境下可能会出现内存资源浪费的情况，作为售卖资源的云服务商，希望能找到更充分的内存资源利用的方法。在此背景下，DPDK引入了no-huge机制，即不使用hugepage，从而解放更多的系统资源。 那么这种配置下DPDK性能会下降多少呢？还是需要实际定量测试一下。 测试平台123456789101112131415161718192021222324lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 88On-line CPU(s) list: 0-87Thread(s) per core: 2Core(s) per socket: 22Socket(s): 2NUMA node(s): 2Vendor ID: GenuineIntelCPU family: 6Model: 85Model name: Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHzStepping: 4CPU MHz: 2100.393BogoMIPS: 4201.72Virtualization: VT-xL1d cache: 32KL1i cache: 32KL2 cache: 1024KL3 cache: 30976KNUMA node0 CPU(s): 0-21,44-65NUMA node1 CPU(s): 22-43,66-87 12345lspci | grep Ether86:00.0 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)86:00.1 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)86:00.2 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)86:00.3 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01) DPDK Version: 18.05.1Tester: IXIATest Plan: RFC2544DPDK APP: ./l2fwd -l 22-24 --no-huge -- -p 0x3 -T 5 测试结果 在64Byte包长时丢包率达到了50%以上，而使用大页内存时丢包率可以控制在0.05%以内。其他长度丢包和吞吐情况基本相同。根据业务情况，平均包长如果在300Byte以上–no-huge模式不妨一试。后续添加针对更大链路带宽(25Gbps/100Gbps)的网卡以及不同Xeon平台的测试结果。","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"dpdk","slug":"dpdk","permalink":"https://decodezp.github.io/tags/dpdk/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"}]},{"title":"云计算的发展需要向社区街道管理看齐","slug":"thoughts1-cloud-community","date":"2018-11-28T05:47:57.000Z","updated":"2019-01-19T06:34:19.606Z","comments":true,"path":"2018/11/28/thoughts1-cloud-community/","link":"","permalink":"https://decodezp.github.io/2018/11/28/thoughts1-cloud-community/","excerpt":"服务云计算本质上是一种服务。由各种不同的组件为租户提供计算、网络和存储服务。 用户对这些服务的要求除了功能之外，还有安全性、可用性、性能、成本、迁移难度、SLA等一系列要求。 与之类比，社区街道作为一个完整的功能单元，各个基层职能部门，也为社区内的居民提供各类生活服务。 如何做好基层工作，是需要费一番脑筋的。","text":"服务云计算本质上是一种服务。由各种不同的组件为租户提供计算、网络和存储服务。 用户对这些服务的要求除了功能之外，还有安全性、可用性、性能、成本、迁移难度、SLA等一系列要求。 与之类比，社区街道作为一个完整的功能单元，各个基层职能部门，也为社区内的居民提供各类生活服务。 如何做好基层工作，是需要费一番脑筋的。 服务网格下图是我在北京中关村某社区拍到的当地派出所的“网格团队”成员和工作职责。 如果你熟悉云计算，熟悉当前的领先理念，那么service mesh这个词你肯定不陌生，这是当前容器和微服务领域的最新热点，拥有Istio、Envoy等一众明星开源项目，并且有Google、AWS、Alibaba等大佬拥趸。这个词翻译过来就是服务网格。 而社区街道提出的这个“网格”的概念，明显领先于自诩为科技前沿的云计算。 如果仔细阅读一下上图中的“工作职责”，就能够轻易地将其内容与时下云计算和企业数字化转型热炒的概念对应起来： 管理网格单元：Microservice微服务 落实基信息采集：Digital Twin数字孪生 综合网格力量：Orchestration协同 加强依法自治：Decouple解耦/Distrubute分布式 排查隐患：Situational Awareness态势感知/Active Defence主动式防御 协调解决社会服务管理中存在的问题：Full Stack Management全栈管理 推进公共服务建设：Aglie敏捷/DevOps 监督管理网格力量，督促责任落实：Sidecar 及时上报网格工作数据：Telemetry遥测 完成街道交办的其他工作：Serverless无服务器 总结就是这个街道派出所就是Community-Native Microservice &amp; Service Mesh &amp; Serverless &amp; Security的典范，理念领先云计算至少5年。 好好学习为什么街道派出所的理念能领先云计算的发展？道理都是殊途同归的，很多理念（经验）的获得都是靠积攒年头。 云计算方兴未艾，但毕竟用户还不足够多，问题暴露还不足够全面，或者说，没太多管理经验。而派出所展开基层管理工作的时间至少比在坐的诸位岁数都长。同时基层群众形形色色，就像软件测试时的边界条件，绝对都能满足。 在此种“得天独厚”的条件下总结出的经验，云计算从业者除了好好消化吸收之外，也可以小小的自鸣得意一下，毕竟你仅仅用了10年就追上了街道派出所。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"},{"name":"cloud","slug":"cloud","permalink":"https://decodezp.github.io/tags/cloud/"}]},{"title":"几句话说清楚3:什么是False Sharing","slug":"quickwords3-falsesharing","date":"2018-11-27T05:12:54.000Z","updated":"2018-11-27T05:22:37.184Z","comments":true,"path":"2018/11/27/quickwords3-falsesharing/","link":"","permalink":"https://decodezp.github.io/2018/11/27/quickwords3-falsesharing/","excerpt":"不用图以为又要见到那几张网上已经用烂了的图了是不是？这次我们不用图来讲这个事。","text":"不用图以为又要见到那几张网上已经用烂了的图了是不是？这次我们不用图来讲这个事。 Cache line是64个Byte，我们经常操作(R/W)的变量是4个或者8个Byte。 于是一个Cache line里就可以放好几个变量，比如说其中有两个变量A和B。 当CPU0写入A，CPU1写入B的时候，就发生了False Sharing，就这么简单。 所谓“假共享”，其实就是你以为你俩自己操作自己的变量是共产国际按需分配互不影响，其实都是假象。 很多材料上说是因为不同的CPU核共享了相同的Cache Line，其实并不严谨。根本因素是不同的CPU核需要更新的缓存出现了地址上的重叠。 那么当其中一个核更新了它的变量A之后，CPU并不能识别出是哪4个Byte或8个Byte地址上的数据被更新，而只能认为该变量所在的整条64Byte Cache Line都应该被更新。 所有有和这64Byte重叠的Cache Line，不管在哪个CPU核上，都需要被更新，这样才能保证大家手头的数据是一致的。 于是乎，和这64Byte地址存在重叠的变量B所在的CPU1中的缓存也需要被更新，自然就影响到了性能。 如果只是读，就没有这个问题，因为不需要关心缓存一致这个事。 示例这里有一个活生生的代码的例子： https://github.com/PanZhangg/x86perf/blob/master/false_sharing_padding.c 12345678910struct counter_t &#123; uint32_t c1; #ifdef PADDING_64_BYTE uint32_t padding[15]; #elif PADDING_128_BYTE uint32_t padding[31]; #else #endif uint32_t c2;&#125;; 本来是打算用来验证在CPU预取开启的情况下到底是应该Padding 64还是128，但在Haswell和Skylake上验证，这两个长度都没有区别。 后来查找资料是在Sandy bridge上需要padding到128，但我这里没有这么老的CPU….先这样吧.. 上面的代码注意用-O0编译。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"几句话说清楚2:CPU缓存的组织形式","slug":"quickwords2-cacheassociativity","date":"2018-11-25T07:18:27.000Z","updated":"2018-12-24T13:11:50.490Z","comments":true,"path":"2018/11/25/quickwords2-cacheassociativity/","link":"","permalink":"https://decodezp.github.io/2018/11/25/quickwords2-cacheassociativity/","excerpt":"缓存缓存和其他存储形式在功能形式上没有太大区别，均是输入一个地址，还你一个数据。但作为一个缓存，要考虑如何在有限的容量下保证较高的命中率以及查找效率(相关阅读)。这个问题从本质上来说，就是如何建立缓存地址与内存地址的映射关系。","text":"缓存缓存和其他存储形式在功能形式上没有太大区别，均是输入一个地址，还你一个数据。但作为一个缓存，要考虑如何在有限的容量下保证较高的命中率以及查找效率(相关阅读)。这个问题从本质上来说，就是如何建立缓存地址与内存地址的映射关系。 组织形式缓存按照一个Cache Line的长度（主流长度为64Byte）为粒度来组织： 各种不同的映射形式就是在决定内存中某一个特定地址范围内的数据，具体可以放到哪一个Cacha Line里去。 能想出来的方式也无外乎三种： 哪个都可以放 只能放到第N个（N是内存地址的函数） 只能放到第N个至第M个（M也是内存地址的函数） 其实基本上这篇文章可以结束了，很多技术都不是什么新鲜的“创想”，只是给朴素的思想内核穿上了一层“术语”的外衣。 Direct Mapping这就是上面说的第二种方式，某一个内存地址段的数据，只能放在第N个Cache Line里 Pros:查找快，一次寻址，有就是有，没有就是没有，不啰嗦（因为只需要验证一个Cache Line中是否存在该地址） Cons:命中率低，CPU经常需要相邻地址的数据，而根据规则，同属于第N个Cache Line的数据会互相排斥，不会同时出现在缓存里 Fully Associative这就是第一种方式，随便放。 Pros:命中率高，过去和未来一段时间内需要的数据都可以被放在缓存内，同时不用担心被相邻地址上的数据踢出 Cons:查找慢，确认一个地址是否在缓存里通常需要遍历整个缓存（Miss的情况） n-Way Set Associative Cache这就是第三种方式了，颜色相同的内存地址范围和缓存Cache Line互相对应，不能越界。每一个颜色就是一个Way。 但如果单独拿出某一个颜色来看，是Fully Associative的方式。 这么做当然是为了充分发挥前两种方式的优势。既可以存在相邻内存中的数据以提高命中，同时也一定程度上减少了查找范围，提升查找效率。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"XXV710网卡Target Link Speed探秘","slug":"x710-target-link-speed","date":"2018-11-23T11:26:48.000Z","updated":"2018-12-18T12:26:57.396Z","comments":true,"path":"2018/11/23/x710-target-link-speed/","link":"","permalink":"https://decodezp.github.io/2018/11/23/x710-target-link-speed/","excerpt":"发现用lspci指令查看PCIe设备，特别是网卡设备经常会查看LnkCap及LnkSta字段，以确保网卡运行在期望的PCIe总线类型/带宽上，从而保证网卡的性能。 最近拿到一块XXV710-DA2，插上之后简单看了一下状态。LnkCap和LnkSta均显示为Speed 8GT/s，Width x8，没太大问题。这时候无意中瞥见LnkCtl2中Target Link Speed显示为2.5GT/s，引发了兴趣。","text":"发现用lspci指令查看PCIe设备，特别是网卡设备经常会查看LnkCap及LnkSta字段，以确保网卡运行在期望的PCIe总线类型/带宽上，从而保证网卡的性能。 最近拿到一块XXV710-DA2，插上之后简单看了一下状态。LnkCap和LnkSta均显示为Speed 8GT/s，Width x8，没太大问题。这时候无意中瞥见LnkCtl2中Target Link Speed显示为2.5GT/s，引发了兴趣。 1234LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not SupportedDevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF DisabledLnkCtl2: Target Link Speed: 2.5GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB Target Link Speed关于Target Link Speed是什么，查找到了Intel Skylake Processor External Design Specification(EDS)中的定义： For Downstream Ports, this field sets an upper limit on Link operational speed by restricting the values advertised by the Upstream component in its training sequences. 基本上LnkCap表示支持的速度，LnkCtl2设置你需要的速度，LnkSta显示实际Training好的速度，如果想要修改的话，都是改LnkCtl2的值。 现在的问题就是LnkSta和LnkCtl2矛盾。那么我们现在这块网卡的速度到底是多少？只能实际测试一下。 测试起个pktgen打个性能，是能直接到线速的，也就是说Target Link Speed没有实际起到限制速度的作用。 又查询了一些资料，从这里看到一个帖子：https://communities.intel.com/thread/106568 最终Intel的官方回复是，这个寄存器的值确实和实际速度没有关系。 规范也是你们写的，帖子也是你们回的，现在正话反话都让你说了，搞什么鬼。 最后查到了该寄存器的位置(D0h)，暴力修改一下： setpci -s 0000:18:00.0 d0.B=3 然后就乖乖地显示为8GT/s了，真是个毫无脾气的寄存器，你让别的遵守规范的设备如何自处。 1234LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not SupportedDevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF DisabledLnkCtl2: Target Link Speed: 8GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"}]},{"title":"程序员和工厂劳工有何不同","slug":"programmer-worker","date":"2018-11-22T12:54:07.000Z","updated":"2018-11-22T13:23:21.430Z","comments":true,"path":"2018/11/22/programmer-worker/","link":"","permalink":"https://decodezp.github.io/2018/11/22/programmer-worker/","excerpt":"如今流行的一个说法是，现在的程序员与工业时期的工厂工人并无二致。均是富集于人口密集的城市、均是超时劳动、均是遭受资本家的盘剥、均是一架大机器上的螺丝钉，在超过“劳动年龄”之后被弃如敝屣。基于这些相似点，有些人得出结论，程序员不过是这个时代的“无产阶级”，和以前的流水线工人，纺织厂女工属于同一社会分工和定位。是否当真如此，这个问题值得仔细推敲一下。","text":"如今流行的一个说法是，现在的程序员与工业时期的工厂工人并无二致。均是富集于人口密集的城市、均是超时劳动、均是遭受资本家的盘剥、均是一架大机器上的螺丝钉，在超过“劳动年龄”之后被弃如敝屣。基于这些相似点，有些人得出结论，程序员不过是这个时代的“无产阶级”，和以前的流水线工人，纺织厂女工属于同一社会分工和定位。是否当真如此，这个问题值得仔细推敲一下。 生产资料个人所处的社会阶层，取决于他能让属于他的生产资料产生的价值。传统的生产资料包括实体的机器、厂房、地皮、原材料、资本和人等等。而作为信息时代的标志，人人都可以通过网络获取一项虚拟的生产资料——信息。诚然，信息壁垒依然存在，但普通人能接触到的信息总量和质量与信息革命之前的时代相比已不可同日而语。程序员是与电子计算设备打交道的人，此类设备本质上是信息的产生、加工和分发工具。一台电脑加一条网线，程序员就可以以极其低廉的方式获得他所需要的生产资料。而拥有生产资料的人，就不能再称之为“无产阶级”。我们已经听过了太多程序员在车库创业的故事，也许这些故事仍然可以称之为“个例”，毕竟，哪个时代没有一些白手起家的人。但如果某个行业能在全社会掀起创业的热潮，那么就不能再以孤例的眼光看待。只有在该行业的生产资料极大丰富，且对再加工之后的产品有持续需求的情况下才有可能出现这类情况。是否能以足够廉价的方式获取生产资料，是程序员与工厂工人的第一个区别。 对生产资料的再分工注意这里强调的是再“分”工，而不是再加工。程序员能够开发出各种程序满足人们的需求，工人也能生产出各种生活必需品，所以在生产资料再加工这一点上，两者没有本质区别。专业细分是社会生产率提高的根本因素。每个人只负责整条产业链中的一环，愈发细致的分工与合作是现代生产活动的组织方式。程序员和工人均为某一细分领域的专家，但二者所处的分工链条深度不同。工人是分工链条的末端，他所能做的就是尽自己所能做好手头的事情。而程序员虽然仍然要听老板的，但他手下仍有电子设备作为分工的最后一环。程序员可以通过编码为这些电子设备“分工”，从而令其为程序员服务。从某种意义上说，程序员就是这些电子设备的“老板”。同时随着设备的计算能力越来越强，这些设备就能逐渐胜任更加精细的分工任务。随着分工的深入，一方面带动社会整体劳动生产率的提升，一方面更加高效地产生价值。一个大型工厂的老板最多能令数万工人为其服务，而所有能跑代码的设备都可能为程序员服务。在分工链所处的位置和对生产资料的再分工能力，是程序员与工厂工人的第二个区别。 程序员如何度过”中年危机”其实程序员是新时代的工厂工人这种论调，只不过是之前“青春饭”、“过了30岁不能再编程“等论调的新瓶装旧酒而已。但程序员面对的现实压力确实是不容忽视的问题。很多人学了很多技术，掉了很多头发，但最后仍被公司扫地出门，问题就在于做了无用的努力。解决之道其实就蕴含在前文论述的两点之内： 尽可能占有(处理)更多的生产资料——信息 为尽可能多的电子设备”分工” 实际执行的术便是一定要有自己的“产品”。这当然是一个程序，可以是公司的产品，也可以是个人作品。但需要关注两个关键点： 我的程序是否位于信息交叉的节点或能协助信息的获取、处理及分发 运行我的程序的设备是否在增长 可以看看这些久盛不衰的“产品”：操作系统、数据库、浏览器、服务器软件、办公处理、图像应用处理等等甚或编程语言本身，都是这两个关键点的很好的体现。当你拥有这样的产品时，操心的就不是公司会不会要你了，而是如何高效地指挥你自己这支被你分工的生产队，实践一些大胆的想法。最后附上我最喜欢的历史名人名言作为结尾： 臣但恐富贵来逼臣，臣无心图富贵。 ——杨素","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"几句话说清楚1:为什么CPU L1缓存容量始终很小","slug":"cachesize","date":"2018-11-20T11:45:45.000Z","updated":"2019-01-31T12:48:55.071Z","comments":true,"path":"2018/11/20/cachesize/","link":"","permalink":"https://decodezp.github.io/2018/11/20/cachesize/","excerpt":"问题CPU缓存是影响软件性能的关键因素之一。在做性能调优时，经常关注的一个指标就是缓存的命中率(hit rate)。缓存之所以不会达到100%的命中率，是因为缓存容量有限，不能将内存中的全部数据都同时放入其中。只能将当前最热，相邻最近的数据存入，同时还受多核CPU中缓存同步机制的影响。奇怪的是，CPU的制程、晶体管数量、核心数量一直都在增加，但L1缓存的容量始终维持在一个相当低的水平。为什么不加大L1缓存呢？","text":"问题CPU缓存是影响软件性能的关键因素之一。在做性能调优时，经常关注的一个指标就是缓存的命中率(hit rate)。缓存之所以不会达到100%的命中率，是因为缓存容量有限，不能将内存中的全部数据都同时放入其中。只能将当前最热，相邻最近的数据存入，同时还受多核CPU中缓存同步机制的影响。奇怪的是，CPU的制程、晶体管数量、核心数量一直都在增加，但L1缓存的容量始终维持在一个相当低的水平。为什么不加大L1缓存呢？ 缓存组织形式当然要考虑到成本和功耗，以及边界效益的问题，但这些不是本文讨论的重点。缓存存在的意义是当CPU需要某些数据时，能够以最快的速度给它。这个速度是以CPU时钟周期为计量单位的。在这一个周期内，CPU能处理的数据量并不大。作为L1缓存，首先需要做的就是把这几个周期内的数据保存好，这个确实缓存容量越大，可以做得越好。但把数据喂给CPU，还需要另外一步工作——缓存的查找。种种不同的缓存组织方式和对应的查找机制，其实是在命中率以及查找效率中寻找平衡。 直接映射(Direct Mapping)查找效率高，但命中率很低 全关联映射(Fully Associative Mapping)命中率会提高，但查找效率非常低，与缓存容量成反比 N路组相联映射(N-ways Set-Associative Mapping)折衷方案，平衡命中率和查找效率，也是缓存采用的组织方式 L1$对L1缓存来说，任务很艰巨，既要追求命中率，同时也要保证查找效率，那么解决方法就是缩小体积。既享受N-ways Set-Associative Mapping带来的命中率，同时因为每个Set的尺寸不大，仍然会有很高的查找效率。如果将缓存的容量增大，不仅仅是成本和功耗上得不偿失，也将会让缓存的查找效率降低而使缓存丧失意义。 “大曰逝，逝曰远，远曰反”，以退为进，以曲为直的道理在缓存中有了很好的体现。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"top命令使用方法补遗","slug":"topcmd","date":"2018-11-19T13:25:58.000Z","updated":"2018-11-20T12:11:01.048Z","comments":true,"path":"2018/11/19/topcmd/","link":"","permalink":"https://decodezp.github.io/2018/11/19/topcmd/","excerpt":"更改界面刷新频率 自动刷新 topd输入刷新时间（默认3秒，可调至0.5） 手动刷新空格","text":"更改界面刷新频率 自动刷新 topd输入刷新时间（默认3秒，可调至0.5） 手动刷新空格 屏幕滚动一个屏幕显示不完C使用方向键滚动 可用在使用c和V开启命令行及Forest view之后 查看线程top信息H 查看线程CPU绑定/亲和性状态F移动光标至Last Used Cpu空格q返回 与H配合使用可观察各线程是否与对应的CPU核绑定亲和性 排序M按驻留内存大小排序P按CPU使用率排序T按累计时间排序x高亮排序的列 按NUMA查看CPU使用情况2查看各NUMA节点CPU汇总使用信息3输入节点号，查看该节点各CPU使用信息 按条件过滤‘O’输入过滤条件，如:!COMMAND=top COMMAND栏中不包含top%CPU&gt;3.0 CPU占用率大于3%清除全部过滤条件 = 保存当前命令配置W下次再启动时恢复当前配置形式 其他信息man top","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"}]},{"title":"刚日读经，柔日读史","slug":"gangrirouri","date":"2018-11-18T11:27:23.000Z","updated":"2018-12-16T10:10:55.644Z","comments":true,"path":"2018/11/18/gangrirouri/","link":"","permalink":"https://decodezp.github.io/2018/11/18/gangrirouri/","excerpt":"在不知道什么时候，我们似乎被灌输了一种互补好，什么都是互补好的认知。资源要互补，团队要互补，思想要互补，连看个书也得掐着日子互补。","text":"在不知道什么时候，我们似乎被灌输了一种互补好，什么都是互补好的认知。资源要互补，团队要互补，思想要互补，连看个书也得掐着日子互补。 刚日读经，柔日读史，“刚日”就是阳数的日子，“柔日”就是阴数的日子。因为阴阳要互补，所以刚日要读致虚守弱恒常静笃的经；柔日便要读变动不居周行不殆的史。为此还有各位理论导师的笺注，比如南怀瑾： 亢阳激扬，刚也；卑幽忧昧，柔也。经主常，史主变。故刚日读经，理气养生也；柔日读史，生情造意也。有生有息，合乎天理，何乐而不为哉！ 感觉并不如我总结得那般言简意赅提要钩玄。如果说这种“互补”确实在指导我们的行为，那也无可厚非。而实际上我们日常行事，却和这种思想观念有很大出入。饮食上要以形补形，想要强要壮，自然是找来更强更壮的，绝对不会找短小“互补”的食材。婚嫁上要强强联合，至少至少也要找个“门当户对”的。至于相互互补的情节，不是出现在少儿童话故事里，就是出现在成人童话故事里。嘴里说的是阴阳互补，做的却是采阴补阳的勾当。而最重要的是，没有人觉得有问题。我们妄自接受了这些观念，很少去问这些到底是什么。只是在需要的场合，程式化地提出这一观念。什么是互补，什么是阴，什么是阳，什么是刚，什么是柔。如果我脑中只是一些不明来源，未经考究过的观念，那么什么是我自己。更诡吊的是，人与人之间最大的仇恨与惨剧，都滥觞于这种我们根本自己也没搞清楚的观念。不要说“互补”，即便是稍有不同，那便是异端邪说、是外族、是异教徒、是政治犯；那便会有党争、门户、正宗、政治清洗和宗教审判。信不知凭何而信，恨不知因何而恨。被左右的观念所左右，被迷惑的语言所迷惑，操纵感官输出的表象又被表象所操纵。无论刚日柔日，翻开经史，里面都是这样的故事。只要稍微读几页就会发现，与先前想的正好相反，教给你变化的其实是经，而教给你不变的是史。所以这句话并不是要教给你刚柔相济之道，而是提醒你认清人心之妄作，行为之颠倒，以及，追求真实的难能可贵。谨录于上，念念不忘。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"如何在偷偷搜索关键字后避免令人尴尬的广告","slug":"duckduckgo","date":"2018-11-17T13:13:36.000Z","updated":"2018-11-18T11:48:05.706Z","comments":true,"path":"2018/11/17/duckduckgo/","link":"","permalink":"https://decodezp.github.io/2018/11/17/duckduckgo/","excerpt":"转载自cloudwonders.info 当你在任意一个搜索引擎输入一个关键词之后，你就成了全网全平台追逐的流量热点。 平时大打口水战的各大平台在共享你的隐私数据方面异常团结，在B系网站搜索，在A系T系的应用APP上都会看到为你“量身定制”的推送和广告，延迟不超过一分钟。","text":"转载自cloudwonders.info 当你在任意一个搜索引擎输入一个关键词之后，你就成了全网全平台追逐的流量热点。 平时大打口水战的各大平台在共享你的隐私数据方面异常团结，在B系网站搜索，在A系T系的应用APP上都会看到为你“量身定制”的推送和广告，延迟不超过一分钟。 这一点即便是业界道德楷模G老师都未能免俗，毕竟它也要靠着广告收入维持其智能推荐算法引擎的研发投入。 最可气的是，推送些边栏广告也就算了，竟然连自己看的新闻和短视频内容也都要和搜索记录沾边，在聚会上随便刷下手机就暴露了自己到底是个什么货色。 网络对你的监视是全方位的，除了你主动输入的那些关键字，你平时的谈话、你的地理位置，你周围的环境照片都会被偷偷记录上传，用以支撑靠勤劳质朴的城镇劳动人民手动打标签的“人工”智能工程师们的高薪。 当个人隐私在巨头面前节节败退，当生而为人的尊严在利益机器面前粉碎，当你不能说的秘密被拿来公开叫卖和嘲弄，当互联网利用你心底的弱点反过来操控你之时，难道就没有一款可以放心解放双手，安全地释放自己的求知欲，满足人类最原始的好奇的搜索引擎吗？当然不是这样的鸭—— 这个创立于2008年的搜索引擎，十年来一直在巨头的夹击下惨淡经营。如果没有愈演愈烈的互联网隐私泄露事件、没棱镜门、没有小扎的听证会，恐怕Duckduckgo也不会有近来的长足发展。 Duckduckgo从创立之初秉承的理念就是不对用户的搜索做任何追踪与记录，不把用户的隐私和数据当作公司的资产，做好一个搜索引擎的本分。自2018年之初，该搜索引擎已每日接受多于两千万次的匿名搜索。 Duckduckgo的使用方式与其他搜索引擎没有区别，唯一的不同就是搜索之后在其他任何平台没有相关的广告推送。至于搜索本身的质量和水平，笔者简单做了个对比： 应当说完全可以满足日常应用，不说超越G老师，超越B老师应该是问题不大。同时不用担心在互联网大机器下无所遁形。已经有越来越多的朋友和公司将Duckduckgo设置为了默认搜索引擎。 如果说互联网早已是赢家通吃的寡头时代，用隐私交换在线服务已如缴纳“人头税“一般自然，而在这万马齐喑的时刻，Duckduckgo代表的是一豆星星点点的亮光，为所有在歌舞升平中“心怀鬼胎“的人们擎举起惊奇与愤怒的能力。可以放心大胆地搜索不可描述内容的传送门：https://www.duckduckgo.com","categories":[{"name":"wonder","slug":"wonder","permalink":"https://decodezp.github.io/categories/wonder/"}],"tags":[{"name":"resources","slug":"resources","permalink":"https://decodezp.github.io/tags/resources/"},{"name":"wonder","slug":"wonder","permalink":"https://decodezp.github.io/tags/wonder/"}]}]}