{"meta":{"title":"DecodeZ","subtitle":"刚日读经，柔日读史","description":"刚日读经，柔日读史","author":"Pan Zhang","url":"https://decodezp.github.io"},"pages":[{"title":"ABOUT","date":"2018-11-14T14:13:51.000Z","updated":"2018-11-14T14:56:02.276Z","comments":true,"path":"about/index.html","permalink":"https://decodezp.github.io/about/index.html","excerpt":"","text":"刚日读经柔日读史昼进其技夜付诸笔"},{"title":"DOWNLOADS","date":"2018-11-14T14:14:08.000Z","updated":"2018-12-25T10:16:03.813Z","comments":true,"path":"downloads/index.html","permalink":"https://decodezp.github.io/downloads/index.html","excerpt":"","text":"E-BooksProgramming PDF 深入理解计算机系统原书第2版英文版 PDF Clean Architecture - Robert C. Martin PDF 软件架构模式 - Mark Richards History mobi 世界文明史（英文全套）威尔杜兰特 Cool Technical Slides/Papers/Articles PDF Efficiency with Algorithms, Performance with Data Structures - Chandler Carruth"},{"title":"NOTES","date":"2018-12-25T09:49:14.000Z","updated":"2018-12-25T11:29:35.273Z","comments":true,"path":"notes/index.html","permalink":"https://decodezp.github.io/notes/index.html","excerpt":"","text":"资治通鉴 不知纪极 有1：终极；限度，2、引申为穷尽的意思。 会既败魏兵，矜很滋甚；隆屡训责之，会益忿恚。会以农、隆皆尝镇龙城，属尊位重，名望素出己右，恐至龙城，权政不复在己，已知终无为嗣之望，乃谋作乱。 “疑人不用，用人不疑”，宝既疑会，可为者四，一、速图之；二、委信之，益其兵，许爵荫子，卫辄之事毋再言；余者唯败与死战耳。今宝疑而用之，且夺其兵、树二王、断其所望而谋泄，是逼会反，为政之失，莫甚于此。 宝然之。而卫大将军麟每沮其议，隆成列而罢者，前后数四 御兵以气，当一鼓作之，成列而罢之再三者，是竭己而遗敌也。隆善谋而寡决，知时而亡势，过不在麟。 既而募兵无故自惊，互相斫射。 以财而聚，因财而败，正合其宜。 司马耿稚谏曰：“乾归勇略过人，安肯望风自溃？前破王广、杨定，皆羸师以诱之。今告者视高色动，殆必有奸， 视高色动：智伯从韩魏之君伐赵，韩魏用赵臣张孟谈之计，阴谋叛智伯。张孟谈因朝智伯，遇智果于辕门之外。智果入见智伯，曰：“二主殆将有变，臣遇张孟谈，察其志矜而行高，见二君色动而变，必背君矣。” 恭罢朝，叹曰：“榱栋虽新，便有黍离之叹！” 榱栋：指屋椽及栋梁。栋折榱崩，比喻当政的人倒台或死去。 燕主宝闻魏军将至，议于东堂。 魏军新胜，燕实应完守中山，但不可静待其弊。当密遣使于魏，说以一旦魏内有变，燕愿为应之意。则可令珪自顾不暇，而燕坐收渔利。 士大夫诣军门者，无少长，皆引入存慰，使人人尽言，少有才用，咸加擢叙。 言而用之，虚位待之，使人意己为多力，此创业之主延揽之要。 垂在平城积十日，疾转笃，乃筑燕昌城而还。夏，四月，癸未，卒于上谷之沮阳 滑虏此生，心向往之：） 燕军叛者告于魏云“垂已死，舆尸在军。” 垂实未死，且燕新胜，兵未易叛，此垂恐珪走脱，计而诱之；至于“珪欲追之，闻平城已没，乃引还阻山”云云，“阻山”当为“中山”；其料垂将死，故以收定人心为先。 宝之发中山也，燕主垂已有疾，既至五原，珪使人邀中山之路，伺其使者，尽执之，宝等数月不闻垂起居， 数月不归，音信两绝，又垂疾笃，当多发使者，求其速返，奈何闻而不问，误听伪信，乱惑人心，尸骨不还。 垂曰：“司徒意正与吾同。吾比老，叩囊底智，足以取之，终不复留此贼以累子孙也。”遂戒严。 囊，口袋。古称足智多谋的人为“智囊”。此指年虽老，智谋仍够用。 自河以南诸部悉降，获马三十馀万匹，牛羊四百馀万头，国用由是遂饶 非劫掠不足为饶用也；欲以安陈墨守而得富贵，吾知其不可也。 麟归，言于垂曰：“臣观拓跋珪举动，终为国患，不若摄之还朝，使其弟监国事。”垂不从。 此王猛言于苻坚垂终不为人下之事也，今麟奏而垂不省，正宜其分。 苌曰：“吾自结发以来，与人战，未尝如此之快，以千馀兵破三万之众，营地惟小为奇，岂以大为贵哉！” 此语前已述之，再读亦颇能为戏。 后秦主苌以秦战屡胜，谓得秦王坚之神助，亦于军中立坚像而祷之曰: 姚苌弑主篡逆，亦深自耻之。其师无正名，故虽屡胜而犹徨，苌亦行止无度，始戮尸而继求恕宥，是故心不平施，可欺于人，终不可自欺也。 后秦主苌掘秦主坚尸，鞭挞无数，剥衣倮形，荐之以棘，坎土而埋之。 有恩而见仇，是为最仇。姚苌如此自处，正当其理也。 苌曰；“苻登众盛，非旦夕可制；登迟重少决，必不能轻军深入。比两月间，吾必破贼而返，登虽至，无能为也。 苌庙算如神，非深悉三军之情者不能为，故大军之后，粮草继之，辎重未动，情报先行。 祚曰：“此乃卿之忠，固吾求也，前言戏之耳”。待之弥厚，以为中常侍。 此处应为“垂曰”,上亦有以诈为祚之误。 会七夕大宴，青抽剑而前曰：“今天下大乱，吾曹休戚同之，非贤主不可以济大事。卫公老，宜返初服以避贤路。狄道长苻登，虽王室疏属，志略雄明，请共立之，以赴大驾。诸君有不同者，即下异议！” 欲决不决之事，以正合，以奇胜，击而必断，击其节也。 魏王珪东如陵石，护佛侯部帅侯辰、乙佛部帅代题皆叛走。诸将请追之，珪曰：“侯辰等累世服役，有罪且当忍之。方今国家草创，人情未壹，愚者固宜前却，不足追也！” 如慕容农所言：当今岂可自相鱼肉，勇不堪战，志不固持，明不见机者，用之无益，不若纵之以宽，示天下延揽之心。 苌与群臣宴，酒酣，言曰：“诸卿皆与朕北面秦朝，今忽为君臣，得无耻乎！”赵迁曰：“天不耻以陛下为子，臣等何耻为臣！”苌大笑。 此实似抑实扬明贬暗褒之语，臣而能为此者，其智深而不可蠡测 坚之所以亡，由骤胜而骄故也。魏文侯问李克吴之所以亡，对曰：“数战数胜。”文侯曰：“数战数胜，国之福也，何故亡？”对曰：“数战则民疲，数胜则主骄，以骄主御疲民，未有不亡者也。”秦王坚 Cool&nbsp;光可为征引之功，此实李克之见也。 坚曰：“甚哀诸卿忠诚！然吾猛士如虎豹，利兵如霜雪，困于乌合之虏，岂非天乎？ “岂非天乎”、“殆非天乎”为此语者，前后不绝于册。坚不纳左右讽喻而执意灭晋，淝水败绩犹纵虎归山，终致“困于乌合之众”，而作天意杳远之语，知其不可为也。 后秦王苌使人谓苟辅曰：“吾方以义取天下，岂仇忠臣邪！卿但帅城中之人还长安，吾正欲得此城耳。”辅以为然，帅民五千口出城。苌围而坑之，男女无遗， 辅唯苦郡人无辜，苌之议，正中其怀，然前败苌军，杀其父兄，虽苌实欲纵之，不能平诸将也。 燕冠军将军宜都王凤每战，奋不顾身。前后大小二百五十七战，未尝无功。垂戒之曰：“今大业甫济，汝当先自爱！”使为车骑将军德之副，以抑其锐。 锐者易折，此垂琢磨之术；然不面讽其失，托以自爱其身，此其谢而能效之语。 秦王坚遣领军将军杨定击冲，大破之，虏鲜卑万馀人而还，悉坑之。 大梦初醒，悔恨交集，往日种种，皆为幻影，事与愿违，初心难觅，生亦何欢，死亦何苦。 十一月，嘉入长安，众闻之，以为坚有福，故圣人助之，三辅堡壁及四山氐、羌归坚者四万馀人。坚置嘉及沙门道安于外殿，动静咨之。 “不待两军相当而胜负存亡之机已然存于胸中矣，岂掩于众人之言而以冥冥决事哉”，势竭智枯，乃求于神，若仅示尊崇，或可一战 范阳王德、陈留王绍、骠骑大将军农皆曰：“翟斌兄弟恃功而骄，必为国患。”垂曰：“骄则速败，焉能为患？彼有大功，当听其自毙耳。”礼遇弥重。 谋无必胜，所以胜者，因人设谋也。翟斌之流，胸无城府，目短识浅，适速其败。倘如论以苻坚之待慕容，则必无可为也。 密遣使谓泓曰：“吾笼中之人，必无还理；且燕室之罪人也，不足复顾。汝勉建大业，以吴王为相国，中山王为太宰、领大司马，汝可为大将军、领司徒，承制封拜，听吾死问，汝便即尊位。” 坚待燕族甚厚，而不得其心，盖高位厚币，小惠也；家破国灭，大恨也。欲以小惠货大恨，愚者知其不可也。 农曰：“越有智勇之名，今不南拒大军而来此，是畏王而陵我也；必不设备，可以计取之。”越立栅自固，农笑谓诸将曰：“越兵精士众，不乘其初至之锐以击我，方更立栅，吾知其无能为也。” 农众新胜，其锋甚锐，越立栅自固，欲老其师，先为不可胜，亦无可摘。然秦大势已去，人心慌乱，婴守不出，实已生怯退之心，故胜者胜在已胜，不以力战。农之论越，亦不足观。 坚曰：“卿言是也。然朕已许之，匹夫犹不食言，况万乘乎？ 坚之所重者，崇戴也，垂即远离，已无崇戴之意，坚知其不可强求，乃纵之而去，非不可食言故也。 坚曰：“但引兵少却，使之半渡，我以铁骑蹙而杀之，蔑不胜矣！”融亦以为然，遂麾兵使却 秦军百万，十倍于晋，滚石难止，兵众易乱，此用正之时，而图以奇胜，非所以因势之画也。 夏，五月，桓冲帅众十万伐秦，攻襄阳 晋既知坚深欲图己，奈何兴此无功之师，开门揖盗，自为祸阶？及融马覆以败肥水，谢安夷然而垂军独全，前后思之，此恐燕晋分秦之谋也。 冠军、京兆尹慕容垂言于坚曰：“弱并于强，小并于大，此理势自然，非难知也。以陛下神武应期，威加海外，虎旅百万，韩、白满朝，而蕞尔江南，独违王命，岂可复留之以遗子孙哉！ 卧槽，慕容垂还能表现得再明显一点吗？ 于是群臣各言利害，久之不决。坚曰：“此所谓筑室道旁，无时可成。吾当内断于心耳！” 道傍之筑：比喻无法成功的事。 自以有灭代之功，求开府仪同三司，不得，由是怨愤 明则有暗，亏则由满，因其不平而间之，其怨而怒之，必引之以自斗而后取之，此以小博大之法也。 勇而多力，能坐制奔牛，射洞犁耳 犁耳即犁鏡，胡三省註：「犁耳之鐵厚而堅。」 十二月，临海太守郗超卒。初，超党于桓氏，以父愔忠于王室，不令知之。及病甚，出一箱书授门生曰：“公年尊，我死之后，若以哀惋害寝食者，可呈此箱；不尔，即焚之。”既而愔果哀惋成疾，门生呈 医足痛而斫足，疗手疾则断手，郗超之谓也:D 坚报曰：“朕方混六合为一家，视夷狄为赤子。汝宜息虑，勿怀耿介。夫惟修德可以禳灾，苟能内求诸己，何惧外患乎 此苻坚之所成，亦苻坚之所毁。“内求诸己”乃方家之语，“混六合为一家”此齐物之论，坚欲“垂拱而治”，为而不恃，以至不目而见，不听而闻，虽圣贤而不能也。 王彪之曰：“前世人主幼在襁褓，母子一体，故可临朝；太后亦不能决事，要须顾问大臣。今上年出十岁，垂及冠婚，反令从嫂临朝，示人君幼弱，岂所以光扬圣德乎！ 此明显之理，安岂不知也，所意者，乃桓温所遗之独断专裁之柄也。 坚召见，悦之，问以为治之本，对曰：“治本在得人，得人在审举，审举在核真，未有官得其人而国家不治者也。” 治本在得人，得人在心平，心平在得其所，得其所在审举.. 帝曰：“天下，倘来之运，卿何所嫌！” 倘来之物：指意外得到的或非本分应得的东西。同“傥来之物”。 秦王坚不以为诛首，又从而宠秩之，是爱一人而不爱一国之人也，其失人心多矣。是以施恩于人而人莫之恩，尽诚于人而人莫之诚。卒于功名不遂，容身无所，由不得其道故也。 秦王何爱评也，其所爱者，宽博之名也。后慕容垂叛秦自立，亦深得苻坚之恩。垂评二人，非坚有另待，乃此二人有别也。 大司马温恃其材略位望，阴蓄不臣之志，尝抚枕叹曰：“男子不能流芳百世，亦当遗臭万年！ 是故不能流芳百世之语也。 坚曰：“卿不能见几而作，虚称燕美，忠不自防，返为身祸，可谓智乎？”对曰：“臣闻‘几者动之微，吉凶之先见者也。’如臣愚暗，实所不及。然为臣莫如忠，为子莫如孝，自非有一至之心者，莫能保 为臣之要，忠为上，畏为中，敬为下，最下才略。 猛能容其所短，收其所长，若驯猛虎，驭悍马，以成大功。《诗》云：“采葑采菲，无以下体。”猛之谓矣。 猛已言明：今日之事，非将军不能破勍敌。成败之机，在兹一举。猛非量大之人，实不可不容耳。若羌前实欲向攻，以慕容垂之事观之，猛必以心计除之。羌后不见于书简，卒年不详，隐而不传，何也？ 猛弗许。羌怒，还营，严鼓勒兵，将攻猛。猛问其故，羌曰：“受诏讨远贼；今有近贼，自相杀，欲先除之！”猛谓羌义而有勇，使语之曰：“将军止，吾今赦之。”成既免，羌诣猛谢。 深疑此二（三）人早有计较，因而唱和，兵老势衰，强敌当前，可砺士气。 王猛言于坚曰：“慕容垂父子，譬如龙虎，非可驯之物，若借以风云，将不可复制，不如早除之。 慕容垂仇雠尚不背之，何为反其恩主。王猛今日之势，全仗苻坚之遇，遇之稍逊，则左右环伺而起，身必无幸，岂容他人共享，定除之以为弭患。 燕之诸将争欲追之，吴王垂曰：不可。温初退惶恐，必严设警备，简精锐为后拒，击之未必得志，不如缓之。彼幸吾未至，必昼夜疾趋；俟其士众力尽气衰，然后击之，无不克矣。 慕容垂不求近利，计划规矩，然贤名远播，不知藏拙，必见疑于燕主。"}],"posts":[{"title":"几句话说清楚8：Intel 700系列网卡内部结构概览","slug":"quickwords8-700-nic-arch","date":"2018-12-25T09:17:39.000Z","updated":"2018-12-25T09:23:59.044Z","comments":true,"path":"2018/12/25/quickwords8-700-nic-arch/","link":"","permalink":"https://decodezp.github.io/2018/12/25/quickwords8-700-nic-arch/","excerpt":"一不小心这个系列写到了第8期，原本打算写些别的东西，不过看到8这个数字就想到了Intel将要推出的800系列网卡…的小弟——命途多舛的700系列网卡。从目前市场(主要是云计算、互联网公司和数据中心)的情况看，700系列有逐渐推广的趋势，那么这一期就介绍一下700系列网卡的基本技术架构和特点吧。","text":"一不小心这个系列写到了第8期，原本打算写些别的东西，不过看到8这个数字就想到了Intel将要推出的800系列网卡…的小弟——命途多舛的700系列网卡。从目前市场(主要是云计算、互联网公司和数据中心)的情况看，700系列有逐渐推广的趋势，那么这一期就介绍一下700系列网卡的基本技术架构和特点吧。 Intel 700系列网卡的内部架构在处理完物理层的事情之后，数据包会进入网卡内部的处理流水线。 对于网络中的事情，所有参与者基本上就在做一个事情：分类-&gt;转发。大到核心路由器，小到iptables都是一样。只不过有些按IP地址的前缀分类，有些按报文的协议类型分类，有些按某些header字段分类罢了。 所以对Intel 700系列网卡来说，在物理层接收到帧之后，首先要做的就是”解析“一下，这个帧到底属于哪一类。 因此Parser解析器就是流水线的第一环。它会根据帧本身的特点，以及自己的识别解析能力，给每个包都打上一个标签(PTYPE和PCTYPE)。 而根据这些标签，会抽取帧中相应的字段(一般是标签所代表的协议中比较关键的字段)存入Field Vector，以备后用。 后面的Switch主要就是用Field Vector中的数据，包括DMAC VLAN ID等等，来决定该帧是应该进入PF还是VF。 流分类(RSS和fdir)在确定了进入哪一个PF或VF之后，就可以对帧进行RSS或者fdir的操作，来决定根据预设的配置，这个帧最终进入哪个队列，进而被哪些上层进程所消费。 Field Vector中的数据在这个时候就会被拿过来做Hash或者过滤，来计算出最终的结果。 而上面提到的PCTYPE，其为”Packet Classifier Type”的缩写。其实是每一种PCTYPE对应后面一套预设的处理过滤规则(Classifier)。比如IPV4 TCP和IPV6 TPC就分别是两种PCTYPE，那么对于这两种报文的处理就可以分别设定规则。e.g. IPV4 TCP的报文进入Queue2, IPV6 TCP的报文进入Queue3。 700系列网卡所谓的“灵活性”和“可编程性”也主要基于此。 最大支持64种PCTYPE，但网卡默认支持的只有…呃..几种。但可以通过DDP动态添加。可以参考前一篇关于DDP的说明文章。 收包流程再简单总结一下700系列网卡的收包流程。 二层帧到达之后，首先进入Parser解析器。解析器根据协议类型，给二层帧打上PTYPE和PCTYPE的“标签”。 同时，根据这些标签，提取标签规定的字段，存入到Field Vector中。Field Vector相当于该二层帧的一个meta data，一直跟随到从某一端口或队列发送出去。 然后在Switch阶段，网卡会根据该二层帧Field Vector中的某些字段判断该帧进入哪个PF或VF。 在进入PF和VF之后，会根据帧各自的PCTYPE，从Field Vector取数据(其实也就是各协议的关键字段e.g. 目的IP地址，VNI等等)参与计算或过滤规则匹配。最后按照规则转发或丢弃。 严格来说，是先经过fdir，再去RSS。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"}]},{"title":"几句话说清楚7：DPDK不同CPU平台交叉编译指令不支持的问题","slug":"quickwords7-dpdk-cross-compile","date":"2018-12-24T13:06:12.000Z","updated":"2018-12-24T13:11:48.307Z","comments":true,"path":"2018/12/24/quickwords7-dpdk-cross-compile/","link":"","permalink":"https://decodezp.github.io/2018/12/24/quickwords7-dpdk-cross-compile/","excerpt":"现象在比较高级的CPU平台(比如skylake)编译DPDK，会在编译的目标文件中加入一些高级指令集中的指令，比如AVX512。 如果运行最终可执行文件的机器的CPU架构(比如broadwell)不支持编译机器中的指令，则会在执行时报类似这种错误：","text":"现象在比较高级的CPU平台(比如skylake)编译DPDK，会在编译的目标文件中加入一些高级指令集中的指令，比如AVX512。 如果运行最终可执行文件的机器的CPU架构(比如broadwell)不支持编译机器中的指令，则会在执行时报类似这种错误： 1174146:Dec 21 10:56:30 n10-023-013 kernel: [57619.700220] traps: obj-name[861199] trap invalid opcode ip:501c31 sp:7fff9782d090 error:0 其实就是在0x501c31(ip是instruction pointer)这个位置上的指令不支持(invalid)。 原因那么如何查看具体是哪条指令呢? 用objdump -D obj-name查看一下目标文件的汇编代码，找到该位置上的指令。 我这里的例子中，这个指令是vmovdqa64，简单搜索一下可以知道这是个AVX512f的指令。 其他详细内容可以查看Intel SDM(Software Development Manual)下载链接 而这个指令在skylake上支持，broadwell上不支持。 可以通过在两个机器上执行cat /proc/cpuinfo | grep flags查看支持的指令集。或者执行gcc -march=native -Q --help=target查看。 方法在编译机器(skylake)DPDK的/mk/machine/native/rte.vars.mk中，设置MACHINE_CFLAGS= -march=native为-march=broadwell就可以了。 当然还有一些详细的交叉编译方法，可以参考这篇文章。 另外还有一点要提醒的是，如果你是在编译某些基于DPDK的应用，比如DPVS，要一并修改应用中的编译配置，例如DPVS就是在./src/dpdk.mk中，需要修改CFLAGS += -march=broadwell。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"dpdk","slug":"dpdk","permalink":"https://decodezp.github.io/tags/dpdk/"}]},{"title":"5分钟经典英文技术演讲2：软件设计真正的精髓-Scott Meyer","slug":"eng-talk2-things-matter","date":"2018-12-21T13:07:58.000Z","updated":"2018-12-21T13:20:43.840Z","comments":true,"path":"2018/12/21/eng-talk2-things-matter/","link":"","permalink":"https://decodezp.github.io/2018/12/21/eng-talk2-things-matter/","excerpt":"一个人的能力上限很大程度上取决于他获取信息的能力。 而能力增长的速度与获取信息的_质量_正相关。 不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。 最新内容将发布于DecodeZ: https://decodezp.github.io 往期回顾：如何快速掌握新技术 DConf2017：软件设计真正的精髓原视频 PPT/Slides下载 演讲者：Scott Meyer 上一张演讲者的照片，硬撸过C++的应该都很熟悉他: 摘要：成功的软件产品都有其共性。在Scott Meyer看来，这些共性由几个要素组成。在你的作品中考虑这些要素，将帮助你掌握软件设计真正的精髓。","text":"一个人的能力上限很大程度上取决于他获取信息的能力。 而能力增长的速度与获取信息的_质量_正相关。 不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。 最新内容将发布于DecodeZ: https://decodezp.github.io 往期回顾：如何快速掌握新技术 DConf2017：软件设计真正的精髓原视频 PPT/Slides下载 演讲者：Scott Meyer 上一张演讲者的照片，硬撸过C++的应该都很熟悉他: 摘要：成功的软件产品都有其共性。在Scott Meyer看来，这些共性由几个要素组成。在你的作品中考虑这些要素，将帮助你掌握软件设计真正的精髓。 效率/速度(Efficiency/Speed)效率高(所需要执行的指令数少)的软件在大多数情况下等于速度快性能高的软件。 在硬件性能普遍过剩的2C和移动市场，对软件效率的追求也可以带来更广泛的平台配适性和更好的功耗表现。 而在每增加100毫秒延时，年收入就掉几个百分点的电商、在线广告和高频交易领域，对服务器软件效率的追求没有止境。 追求软件的高性能肯定没错，但大家一定都熟悉一句话： “过早优化是万恶之源”(Pre-mature optimization is the root of all evil)。 很多人将这句话作为“先不忙优化，最后再说”的理由。但有多少人知道这句话的出处和上下文? 这句话出自Donald Knuth的一篇叫做”Structured Programming with go to Statements”的论文。而这句话的前面一句话和它连起来是： 如果你不能确定在哪里可以优化，就先不要优化。过早优化是万恶之源。 而在这篇总长度41页的论文的同一页，Donald写道： 可以简单获得(easily obtained)的性能提升，并非无足轻重。 当软件已届完成时再考虑性能优化，将是艰难甚至不可能的任务，例如单线程程序改为多线程，有锁替换为无锁结构等等。 所谓”过早优化“(我还是更喜欢将其直译为”不成熟的优化“)，并不是指“从软件的设计阶段就考虑性能”，而是指你还并不知道哪里能优化就一通乱搞的时候。 而能看出系统性能的瓶颈，可以给出“成熟的优化”方案，是需要长期的学习和实践积累的。 Side Note: 对软件性能优化，特别是结合CPU内存等硬件特性感兴趣的读者可以自行搜索一下笔者在青涩时期挖了还没填上的大坑: x86高性能编程笺注 可移植性(Portability)可移植性的出发点，是市场和客户。 Scott举出了一个他供职过的公司的例子：有自己的硬件平台、编译器、和操作系统。他们的产品跑在自己高度定制化的平台上，各方面的优化已臻完美，一切都很美好。 相形之下，那些跑在“拼凑”出来的平台上的竞品，就像一个拙劣的玩笑。 这一切都随着“通用硬件”性价比突飞猛进而结束，竞品提出的策略是：提供该公司80%的产品性能，但只需要20%的价格。 而这样的故事，在Scott二十余年的从业经历中重复发生着。 当你真的认真在考虑一个严肃的软件产品时，请通过可移植性给予它更多的市场适应能力，而不至于因为产品之外的因素影响产品本身的生命周期。 同时可移植性也可以帮助你在推出了一款成功的产品并在当前平台下达到市场饱和之后，开拓出更多的市场增长空间。有增长才有后续的融资嘛 :) 而做好产品的可移植性设计，其难度不亚于上一节提到的性能优化。有太多硬件的和软件的细节需要考虑，不但要做好不同平台之间的抽象，还要考虑如何充分利用不同平台的独有特性。 而这一切都将是你不断学习的内容。 修补性(Toolability)字典中出给的翻译是“修补性”，但我觉得这是一个不贴切的翻译。Toolability在这里的意思是，当你创造出某种产品的时候，需要考虑能够简单地让别人围绕它开发出工具(Tool-able)。 我个人的理解就是，预留出构建生态的能力。 如果把编程语言看作是一种产品，那么某种语言的重构工具就是它整个生态中重要的一环。 重构工具的一项基本功能，就是在一个项目工程中替换某一个函数的名字。在Java中我们有Intellij，有Eclipse，在对C++来说，我们还没有一个特别好使的重构工具。 因为在C++中，一个简单的f(x)可能是： 一个函数 一个函数指针 一个重载操作符 一个模板 一个宏 等等等等 这样的复杂度，让实现C++的重构工具变得几乎不可能。Comments: 现在确实出现了一些C++的重构工具，但相比于其他语言，晚了十余年。 但我们想强调的并不是C++如何重构，而是当没有这些工具，没有产品生态的时候，你的产品能发挥出多大作用，完全受限于使用者本身的能力。而如果他人能够迅速构建出一套工具，将会帮助你提升产品能力的下限。 简单来说就是，只靠产品一个人打天下不行，需要有组件团队的能力。同时当别人想加入你的团队时，最好不要有太多障碍。 一致性(Consistency)一致性是用户体验提升的核心，这里的用户既包括产品最终的消费者，同时也包括开发者。 所谓用户体验，是能够轻易的与以往的经验做类比。保持一致并不是处女座强迫症作祟，而是在软件设计领域有重要意义——带来有效的抽象和类比。一致性本质上是在为我们的大脑创造一种”模式“，既然是模式，就需要有保持一致的东西。 看一个iOS10上的例子： 删除按钮的图标都是一致的，但位置和颜色并没有保持一致。 试想，如果一系列相关的函数调用，它的相同类型的参数位置都不一样，如下面这个C语言的例子： 即便是编写了数十年C程序的程序员，每次也都需要查表才能确定自己把参数放对了位置。 又如Java中求得某个数据类型的长度的方法： 123array.lengthstring.length()List.size() 这种体验需要开发者针对每种不同的数据类型分别记忆不同的方法，而不能构建一个一致性的抽象。 现在当然有智能化的IDE可以帮助我们摆放好参数或者使用正确的方法，但我们想探究的正是，为什么IDE会加入这个功能——因为不一致的参数位置和方法名实在太恼人了。 而用户体验的核心，并非是扁平化设计，而是追求一致：产品本身性能一致，稳定性一致；用起来的时候，能把我以前的经验带到这里来，并且我一看就知道，这个产品如何操作。 接口(Interfaces)设计接口，既要考虑如何容易用对，同时也考虑如何很难用得不对。 而上一节提到的一致性，就是一个很好的指导原则。 毕竟会调用你接口的人，都是聪明人，都是有软件经验的人，同时他们也希望你实现的接口能够帮助他们自己，所以也愿意去读一点文档。 如果即便如此他们还是不能正确使用你的接口，那一定是你自己的问题。 而真正优秀的接口，是调用者凭借你提供的一致性，凭直觉就能使用的接口——“我也不知道为什么，但这个接口就是工作了”。 而一个设计不靠谱接口的开发人员的典型口头禅就是：他们会搞明白的。 这可能正是你的产品变得混乱不堪的开始。 以上就是Scott Meyer想要在本次演讲中传达给我们的内容。","categories":[{"name":"ENG_talk","slug":"ENG-talk","permalink":"https://decodezp.github.io/categories/ENG-talk/"}],"tags":[{"name":"English","slug":"English","permalink":"https://decodezp.github.io/tags/English/"},{"name":"Presentation","slug":"Presentation","permalink":"https://decodezp.github.io/tags/Presentation/"}]},{"title":"几句话说清楚6：什么是DDP(Dynamic Device Personalization)","slug":"quickwords6-ddp","date":"2018-12-18T12:25:40.000Z","updated":"2018-12-18T12:28:33.598Z","comments":true,"path":"2018/12/18/quickwords6-ddp/","link":"","permalink":"https://decodezp.github.io/2018/12/18/quickwords6-ddp/","excerpt":"要解决的问题通过网卡的多队列和RSS将网包根据一些关键字段散列(hash)到不同的队列已成为一种主流的在x86平台开发信通以及云计算领域产品的方式。 在整体产品架构规划中，不同的网卡队列(Rx/Tx Queues)往往对应/绑定着不同的CPU核(Worker)，以利用资源隔离的方式提高性能。 传统的RSS，往往是依据header的五元组来做散列。通常，网卡可以识别出的报文类型包括ipv4-tcp|ipv4-udp|ipv4-other|ipv6-tcp|l2-payload等等，然后根据能识别出的类型进行关键字段的提取。 但现在如此简单的识别能力已经不能满足业务的需求。在复杂的协议和隧道通讯场景下，往往还需要识别隧道内层header甚至私有字段才能实现业务能力的最优化。","text":"要解决的问题通过网卡的多队列和RSS将网包根据一些关键字段散列(hash)到不同的队列已成为一种主流的在x86平台开发信通以及云计算领域产品的方式。 在整体产品架构规划中，不同的网卡队列(Rx/Tx Queues)往往对应/绑定着不同的CPU核(Worker)，以利用资源隔离的方式提高性能。 传统的RSS，往往是依据header的五元组来做散列。通常，网卡可以识别出的报文类型包括ipv4-tcp|ipv4-udp|ipv4-other|ipv6-tcp|l2-payload等等，然后根据能识别出的类型进行关键字段的提取。 但现在如此简单的识别能力已经不能满足业务的需求。在复杂的协议和隧道通讯场景下，往往还需要识别隧道内层header甚至私有字段才能实现业务能力的最优化。 所以对RSS/Fdir来说，首先需要能“识别”出特定的协议报文，才能找到关键的字段进行散列操作。 在网卡出厂的时候，是可以预置一些协议类型的，但还是最好能有自定义的动态调整的能力。 DDP(Dynamic Device Personalization)名字起得很“大”，不过就是上面说的定制化的技能——动态地赋予网卡识别新协议的能力。 具有这种能力之后，就可以把任意协议的网包按用户意愿提取出关键字段(Key)，然后散列到网卡各个Rx队列里。比如VxLAN协议中的内层DIP等等。 下图是一个赋予网卡GTP-U协议(好吧，我并不知道这是什么…)识别能力，并可以依据TEID字段的值进行RSS计算的示例： 现在已经能被识别出的包括L2TPv3\\QUIC\\PPPOE\\SRv6\\RoE\\MQTT-SNoUDP等等，还有一些大客户做了自己私有协议的定制。 总得来说就是，可以把这部分classification的活儿offload到硬件上，减轻后续CPU处理/分发时的压力，同时均衡一下负载，提升整体性能。 DDP的需求： Intel 700系列网卡以上 固件版本6.01以上 一个由Intel官方出品的特定协议识别的binary package file(需要到官网下载) DPDK提供的配置接口 具体在DPDK上怎么搞后续会有文章说明。 Q&amp;A Q:如何自己制作binary package file?A:目前不支持自己制作，只能由Intel提供。 Q:一张网卡最多支持载入多少个binary package file(profile)?A:最多支持16个，但不推荐这么做，推荐同时只载入一个。 Q:载入之前需要首先关闭网卡设备吗？A:不需要，支持运行时直接载入，但会引起一些丢包","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"}]},{"title":"谁不是在像CPU一样活着","slug":"cpulized-life","date":"2018-12-16T10:06:40.000Z","updated":"2018-12-16T10:12:04.758Z","comments":true,"path":"2018/12/16/cpulized-life/","link":"","permalink":"https://decodezp.github.io/2018/12/16/cpulized-life/","excerpt":"上一次兴奋到浑身发热，还是把赛扬300A超频到450兆赫的时候。身体如摩尔定律般长高，觉得距离1GHz只差一罐液氮，心里装着只有一心一意才能装下的事情。 记得那时看到一篇报道，英特尔说“到2011年的时候，我们都能用上10GHz的电脑”。十几岁的你笑这家美国公司野心不大，现在你说出这件事，只是想给大家讲个笑话。","text":"上一次兴奋到浑身发热，还是把赛扬300A超频到450兆赫的时候。身体如摩尔定律般长高，觉得距离1GHz只差一罐液氮，心里装着只有一心一意才能装下的事情。 记得那时看到一篇报道，英特尔说“到2011年的时候，我们都能用上10GHz的电脑”。十几岁的你笑这家美国公司野心不大，现在你说出这件事，只是想给大家讲个笑话。 2018年，没等来10GHz的电脑，也再也没有一心一意的机会。学会了MMX、SSE、AVX，TSX和AEX等十八般武艺，领导说你是“业务中坚”，其实你知道你只是个挣扎着适应环境的执行人员。 好在熟稔让你变得老练，打点好前端后端的各种关系，再低的IPC也可以不动声色。毫无指摘地把锅甩给温吞的硬盘，你想你可能明白了什么是sophisticated，就是心里只寻思自己那点14nm的柴米。 但越是老练越让你厌恶风险，你给自己加了iCache、dCache、iTLB、dTLB，IOTLB等各种保险，但每次分支预测失败还是要彻底打乱你的流水线。即便凭借经验已能做到99%的正确，却能又让你掉入Spectre的窠臼。 真是怕什么来什么，左右为难的时候，自己的窘样又让心里有一点点好笑，能用一罐液氮解决的事情，偏要搞这么复杂。 突然有些怀念那个为450兆赫兴奋的自己，当时你只想完成这一件事。但此刻你心里不再只住着你自己，每个人都同时在跑好几个角色，你号称你是3GHz还能hyperthread，其实你知道你早已没了章法，所有的事情都不过是水来土掩的乱序执行。 但好在还有一块L3缓存，和你那些sophisticated的L1缓存相比，这里虽然慢，慢得就像曾经的赛扬300A，但却有一心一意的完整。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"几句话说清楚5：影响服务器内存性能的硬件知识","slug":"quickwords5-server-memory","date":"2018-12-13T14:20:51.000Z","updated":"2018-12-13T14:38:25.712Z","comments":true,"path":"2018/12/13/quickwords5-server-memory/","link":"","permalink":"https://decodezp.github.io/2018/12/13/quickwords5-server-memory/","excerpt":"发挥内存条理财的最大收益率内存条作为年度最佳理财产品除了能躺着赚钱之外，使用得好还可以一条当两条用。 在计算机系统中，内存的价值就体现在快速提供数据给CPU处理。当CPU需要的数据没有在缓存里时，CPU内部的Memory Controller就需要去内存中读取内容。","text":"发挥内存条理财的最大收益率内存条作为年度最佳理财产品除了能躺着赚钱之外，使用得好还可以一条当两条用。 在计算机系统中，内存的价值就体现在快速提供数据给CPU处理。当CPU需要的数据没有在缓存里时，CPU内部的Memory Controller就需要去内存中读取内容。 而Memory Controller为了尽快完成CPU交代的任务，用了多通道的方式增大内存存取带宽。 多通道这个概念很好理解，和多条车道是一个意思。比如CPU需要1MB大小的数据，单通道的话数据就只能在一条通道上老老实实排队；双通道就可以并行两个512KB的读取；四通道就是并行四个256KB的读取。 我知道你要问什么，这1MB大小的数据已经被Memory Controller通过一种叫做Interleave(交织)的技术“打散”在了两个通道或者四个通道对应的物理内存上。Interleave由硬件实现，细节不在这里深究，我们想说明的是发挥这些硬件组件的最大能力需要外界条件配合。 内存在硬件方面的性能优化，就围绕这个主题。 内存相关概念现在主流Intel E5 CPU的配置是一颗CPU上两个Memory Controller，每个Controller有两个通道，每个通道对应主板上三个内存插槽(DIMM)。 Interleave首先发生在通道层面，进而发生在通道的DIMM层面（使用的DIMM越多，交织得越充分） 同时每根内存条还有一个Rank的概念。这个概念可以理解为更进一步的Interleave，多Rank的内存条可以再进行一次Interleave。 充分平衡满足最优的内存配置就是四个字：充分平衡。 -充分：并不是要你插满所有插槽，而是充分利用每个Memory Controller和每条通道-平衡：每个Memory Controller和通道上的内存配置(Size, Rank和频率)都相同。 在实际应用中，首先绘制一个内存拓扑，如下图： 如何检查是否充分？看一下每个Memory Controller中的每个通道是否都有内存条如何检查是否平衡？将拓扑图从中垂线对折一次，检查图像是否能重合；再从水平中位线对折一次，检查是否能重合。如果两次回答都是yes，就平衡了。 实例1 实例2 实例3 实例4 软件检查工具为了不让每次内存检测都需要打开机箱…有一个开源工具可以通过读取dmidecode的信息自动化做检验：DPDKick","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"performance","slug":"performance","permalink":"https://decodezp.github.io/tags/performance/"},{"name":"memory","slug":"memory","permalink":"https://decodezp.github.io/tags/memory/"}]},{"title":"5分钟经典英文技术演讲1：如何快速掌握新技术 - Kathy Sierra","slug":"eng-talk1-fast-learn","date":"2018-12-12T14:51:14.000Z","updated":"2018-12-12T15:09:49.362Z","comments":true,"path":"2018/12/12/eng-talk1-fast-learn/","link":"","permalink":"https://decodezp.github.io/2018/12/12/eng-talk1-fast-learn/","excerpt":"一个人的能力上限很大程度上取决于他获取信息的能力。 而能力增长的速度与获取信息的质量正相关。 不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。 最新内容将发布于DecodeZ: decodezp.github.io Fluent: 如何快速掌握新技术原视频演讲者: Kathy Sierra 摘要：无论是谁，以有限的精力来面对层出不穷的新技术挑战都是不够的。你需要学会一套方法论来帮助你快速习得新的技能。而快速学习的秘诀却还不止这些…","text":"一个人的能力上限很大程度上取决于他获取信息的能力。 而能力增长的速度与获取信息的质量正相关。 不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。 最新内容将发布于DecodeZ: decodezp.github.io Fluent: 如何快速掌握新技术原视频演讲者: Kathy Sierra 摘要：无论是谁，以有限的精力来面对层出不穷的新技术挑战都是不够的。你需要学会一套方法论来帮助你快速习得新的技能。而快速学习的秘诀却还不止这些… 每个程序员都面临的挑战为了成为一名“合格”的程序员，你认为你需要掌握哪些技术？ 这将是一个长长长长长的名单，更可怕的是，每个人列出的内容都将各不相同。 所以这么提问并没有太大意义，更好的问题是： 我如何快速掌握新的技术？ 认知资源我们习得新的技能，需要依赖我们自己的认知资源（Cognitive resources）。 但作为一个正常的“人类”，我们的认知资源易耗且稀缺。 到底有多容易消耗？Kathy提到了一个大学里的实验：实验人员要求一半实验参与者记忆一个两位的数字，而另外一半参与者记忆一个七位的数字。 等确保每个人都记住了自己的数字之后，实验人员随即宣布实验结束，并邀请所有参与者去取用一些零食——蛋糕，或水果。 而实验结果也能猜到，仅仅是5位数字的差别，就让记忆七位数的实验者选取蛋糕的比例比记忆两位数的参与者高出一半。 你是否有想认真掌握一门新技能，但一拿起各类技术书籍、文档，很快就放弃的经历？你又是否在做一些让别人“选择蛋糕”的事情？比如让别人阅读你自己编写的项目文档。 当你想要快速掌握一项技能的时候，你需要学会管理自己的认知资源。 学习方法将你现在的技能分为三类： A还没有掌握，但需要掌握的 B经过一定努力可以掌握的 C已经掌握的 我们的目标其实是如何将AB的技能快速移动到C。在这个过程中我们会遇到两类典型问题： 没有进步 耗时太久 没有进步第一类问题的根本原因在于你的认知资源不足以支撑技能的学习需求。我们不能要求自己有无限的认知资源，在资源极度有限的情况下，仍有两种解决策略： 第一种，将更多的需要掌握的技能放在A，将精力集中于少量的B类技能。但在日常工作中，需要掌握哪些技能，解决哪些问题，都不是自己可以安排的。对此，我们还有第二种策略。 第二种策略，就是将B中的技能分解为更小的粒度。这种策略，在有限的认知资源的情况下效果等同于一个需要处理多任务并发的CPU，上面运行的程序都采用了更加细粒度的锁机制，带来了程序性能的提升。 那么如何界定分解之后的技能足够“细”？Kathy给出了一个她的评判标准： 从完全不会到十分熟练，最多经过3次练习，每次45-90分钟。 能满足上面的标准就可以认为分解到了合理的粒度。 耗时太久程序员不但要学习很多技能，还需要快速学习。所以从A开始，我们最好能够绕过B直接到C。 怎么可能从完全不懂，到突然就明白了？ Kathy给出了一个“极端”的例子：学习给分辨雏鸡的性别。 从视觉上，这是一件不可能的事，但日本却有一些非常擅长分别雏鸡性别的人。 人们希望这些“性别分辨大师”能够将他们的方法教授给别人，但这些人并不能讲出什么明确的“规则”。 这就是这件真正神奇的地方，我们的大脑能够在潜意识中处理一些信息，但却讲不出来为什么。 所以学习雏鸡性别分辨的人最开始只是随机判断雏鸡的性别，而这些“专家”则告诉他们结果是不是正确。 一段时间以后，这些学习分辨性别的人正确率越来越高，最终达到了专家的水平。 这些学习的人并没有记忆任何具体的“规则”，却能够不断提升自己的技能水平。这里产生核心影响的是：高质量的例子。 这非常类似机器学习的过程，模型的质量取决于训练这些模型的数据的质量。 关键的缺失——高质量的例子当要学习某样特殊技术的时候，你是找官方的、正式的、长而无味的文档，还是去找一个精悍的例子？ 当你能找到一个精确的示例来演示如何使用这样技术的时候，你几乎可以“瞬间”掌握这项技术。 你需要这些示例来让大脑自动地，潜意识地识别其中的模式。但现在的问题是，所有技术里又臭又长的文档很多，但短小精悍的示例很少。 所以是否可以利用社区的力量，将这些文档转换成一系列高质量的示例库呢？ 以上就是在本次演讲中，Kathy想要传达给我们的内容。 引申《庄子》中有这样一个故事： 桓公读书于堂上，轮扁斫轮于堂下，释椎凿而上，问桓公曰：“敢问：“公之所读者，何言邪？”公曰：“圣人之言也。”曰：“圣人在乎？”公曰：“已死矣。”曰：“然则君之所读者，古人之糟粕已夫！”桓公曰：“寡人读书，轮人安得议乎！有说则可，无说则死！”轮扁曰：“臣也以臣之事观之。斫轮，徐则甘而不固，疾则苦而不入，不徐不疾，得之于手而应于心，口不能言，有数存焉于其间。臣不能以喻臣之子，臣之子亦不能受之于臣，是以行年七十而老斫轮。古之人与其不可传也死矣，然则君之所读者，古人之糟粕已夫。“ 真正的精髓，都在手上，而不在文档里。","categories":[{"name":"ENG_talk","slug":"ENG-talk","permalink":"https://decodezp.github.io/categories/ENG-talk/"}],"tags":[{"name":"English","slug":"English","permalink":"https://decodezp.github.io/tags/English/"},{"name":"Presentation","slug":"Presentation","permalink":"https://decodezp.github.io/tags/Presentation/"}]},{"title":"几句话说清楚4：什么是Pointer Aliasing","slug":"quickwords4-pointer-aliasing","date":"2018-12-11T11:33:46.000Z","updated":"2018-12-11T11:45:43.584Z","comments":true,"path":"2018/12/11/quickwords4-pointer-aliasing/","link":"","permalink":"https://decodezp.github.io/2018/12/11/quickwords4-pointer-aliasing/","excerpt":"指向同一地址的两个相同类型的指针aliasing本身是一个信号处理方面的概念。是指在信号采样过程中，不同的信号不再能相互区分的现象。 如下图所示的波纹现象，相对于拍摄的采样频率（横纵像素分辨率），墙砖缝隙变化的频率要大于采样频率。或者换句话说，多条墙砖缝隙需要挤在一个像素里面。","text":"指向同一地址的两个相同类型的指针aliasing本身是一个信号处理方面的概念。是指在信号采样过程中，不同的信号不再能相互区分的现象。 如下图所示的波纹现象，相对于拍摄的采样频率（横纵像素分辨率），墙砖缝隙变化的频率要大于采样频率。或者换句话说，多条墙砖缝隙需要挤在一个像素里面。 同样的现象也会出现在程序员穿着“高密度”的格子衬衫接受电视采访时。 墙砖缝隙出现aliasing后无法再行区分，从字面意义来说，Pointer Aliasing就是不同的指针也无法区分。 指针无法区分，只有一种情况，就是指针的类型和指向的地址都是相同的，这就是Pointer Aliasing。 为什么会有性能影响12345void foo(int *array, int *size, int *value) &#123; for(int i=0; i &lt; *size; ++i) &#123; array[i] = 2 * *value; &#125;&#125; 如果让我们自己“优化”一下这段代码，我们可能会首先将value指向的值存入一个临时变量里，然后将临时变量在循环中直接赋值给array。 我们假设个array的初始状态：[0, 1, 2, 3, 4] 如果value指向的值等于3，那么按我们优化的方式，array最终的状态是：[6, 6, 6, 6, 6] 但这里存在一个问题，如果value指向array[3]，那么array最终的状态就是：[6, 6, 6, 12, 24] value和array[3]就是指向相同地址类型相同的指针。 编译器为了得到最终正确的结果，就不得不取消我们之前提到的”优化”方式。 预防方法使用__restrict关键字： 12345void foo(int * __restrict array, int *__restrict size, int *__restrict value) &#123; for(int i=0; i &lt; *size; ++i) &#123; array[i] = 2 * *value; &#125;&#125; 当然，前提是自己可以确定代码逻辑中不会引入aliasing。 怎么使用首先明确一点，不是加上了__restrict性能就会提升。 Pointer aliasing对性能根本的伤害不是需要每次重新去某个地址取值，而是因为引入了潜在的数据依赖关系，从而关闭了很多编译器优化代码的能力。 上面两段代码，在-O0优化时生成的汇编代码(gcc 4.8.5)完全相同。不同的地方在于，第一段代码在-O2和-O3时生成的汇编代码仍然相同；而第二段做了__restrict处理的代码则会在-O3时加入大量循环展开等优化方式。 在线查看汇编代码：链接 所以__restrict需要在打开较高等级的编译器优化的情况下使用才会有效果。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"},{"name":"performance","slug":"performance","permalink":"https://decodezp.github.io/tags/performance/"}]},{"title":"产品观察1：华为FabricInsight产品简要分析","slug":"product1-huawei-fabricinsight","date":"2018-12-07T22:26:24.000Z","updated":"2018-12-07T22:38:54.500Z","comments":true,"path":"2018/12/08/product1-huawei-fabricinsight/","link":"","permalink":"https://decodezp.github.io/2018/12/08/product1-huawei-fabricinsight/","excerpt":"123最近机缘巧合之下接触到了华为FabricInsight这款产品，简要谈谈看法。只针对2018年8月份左右发布的版本。另外注意，在Google搜索相关资料的时候，记得要把Fabric Insight这两个单词合并在一起搜索，中间不要加空格，别问我怎么知道的。","text":"123最近机缘巧合之下接触到了华为FabricInsight这款产品，简要谈谈看法。只针对2018年8月份左右发布的版本。另外注意，在Google搜索相关资料的时候，记得要把Fabric Insight这两个单词合并在一起搜索，中间不要加空格，别问我怎么知道的。 概述信息采集SNMP在使用FabricInsight之前需要配置华为设备的SNMP协议，主要作用为获取设备的MIB信息，并进行其他管理操作。 LLDP使能各设备的LLDP功能，以便FabricInsight据此（以及通过SNMP上送的MIB信息）绘制硬件连接拓扑图。 NetConf使能各设备的NetConf配置，以便FabricInsight能通过NetConf协议配置各设备的ERSPAN功能。 ERSPAN配置ERSPAN功能，destination IP配置为FabricInsight collector的地址。底层实现为：通过GRE隧道的方式将远程设备的流量路由/镜像至分析节点，以实现对流量可视化分析。ERSPAN可配置筛选特定的流量，并非全量镜像。从华为对交换机的配置： [~Device] observe-port 1 ​ destination-ip 10.10.10.20 ​ source-ip 10.1.1.1 [*Device] traffic-mirroring vxlan tag-format none tcp-flag fin syn rst observe-port 1 inbound [*Device] traffic-mirroring tcp-flag fin syn rst observe-port 1 inbound [*Device] commit 通过ERSPAN镜像给FabricInsight的流量包括带有FIN/SYN/RST等TCP flag的网包。对应其产品中对TCP事件的可视化能力。注*：据此可以看出FabricInsight没有全量流量镜像&amp;分析能力注*：命令中的vxlan可能是将流量通过vxlan封装，做三层转发，而非镜像全部vxlan流量 Telemetry华为的Telemetry指设备主动、以固定周期上报的一些设备信息，包括CPU\\MEM\\QUEUE等信息。 手动录入主要为用户业务信息，每一个业务的定义为一组IP和某一固定端口号的集合，需要用户手工录入。 功能分类Underlay拓扑可视化依据LLDP生成及SNMP上报的信息，可生成Underlay设备间的拓扑信息。流量事件统计依据ERSPAN镜像的含有SYN\\FIN\\RST等flag的TCP网包，可统计一条流（五元组）中的事件发生次数、时间及类型。并可据此进行简单的SYN重传、建立连接RTT、建连成功率分析。但缺少对网流完整过程（e.g.流量传输数据总量、pps、整体平均时延等）的统计和分析。 设备信息统计根据Telemetry信息给出CPU\\MEM等设备运行状态统计信息，以及对各网络端口IN/OUT总量、drop、error数量等的统计信息。 应用流量分类过滤其应用功能，本质为手动设置IP+端口号过滤规则，通过过滤的流量即为一个应用。应用间的流量状态展现，即为在流量事件统计数据库中分别为起止两端的流量配置两个应用的过滤规则，筛选出的流量即可作为应用间的流量状态展示。 FabricInsight特点强绑定性只能用于华为的硬件设备。并且后期会形成双向绑定，如若依赖FabricInsight，扩容时只能继续采购华为设备。 基于流量事件对于流的分析仅涉及五元组和TCP流量事件。可依据SYN、FIN、RST等TCP流量事件完成TCP SYN重传、RST等事件的侦测，并作为报警依据。 无流量全量分析当前观察，仅有TCP流量的事件信息，对UDP、ICMP、ARP等网络流量无采集分析能力。仅针对TCP流量，亦无流量全量分析能力，无法获取诸如流量总字节数、总包数、pps、平均时延、最大时延等信息。 Overlay能力暂无当前FabricInsight宣称的可分析虚拟网络是指，手工指定某一虚拟网元（Virtual NE）IP地址，手工指定其角色（e.g. FW\\LB\\Router）其与外界通讯的流量可以以与Underlay网络相同的方式采集。未发现针对虚拟网络VM间的采集分析能力。从其官方手册中针对ERSPAN的配置来看，可能或未来会具有一定的VXLAN隧道解封装及关联对应能力。但即便如此，在大规模网络流量的情况下，对全部VXLAN流量分析亦将为设备带来压力。另外，主机内的虚拟网络流量，FabricInsight以现在的形式是绝对无法取得的。 FabricInsight未来演进趋势推测In-band TelemetryFabricInsight的数据采集能力全部来自于设备提供的能力。在设备/芯片领域的发展趋势是提供更加精细化的In-band Telemetry遥测能力。从Cisco/Barefoot等厂商近期对P4芯片的动态来看，华为跟风也是早晚的事。In-band Telemetry可以提供诸如per packet的全生命周期、匹配的具体转发规则、更加精细的时间戳等能力。但如若采用新的芯片组提供In-band Telemetry，则会仅支持新款产品。除此之外，也将不仅仅将流量分析的范畴局限于TCP流量。 虚拟网络虚拟网络是行业演进的趋势，但需要考虑华为对FabricInsight这款产品本身的定位。如果添加虚拟网络能力，则其品牌名称、目标人群都将会有较大调整。但华为整体上缺乏虚拟网络可视化的产品和能力，因此推断会先对接华为自己的云平台FusionCloud，计算节点绑定探针。但先期仍会仅采用TCP流量事件的分析模式，不会全量采集和分析。 AIopsAI的概念在当前版本的FabricInsight中已有所体现，但当前仅是一些标准差方差的统计计算。演进的方式将是对网络中断和延迟的诊断以及自调优的赋能。但这种分析首先要求用户能够输入一定的专家经验作为数据训练的标记，同时对分析节点的部署要求较高（支持大数据分布式计算和存储）。 安全防御这是当前看起来最有实际效能的功能。其本身具有的TCP事件分析能力完全可以用来完成DDoS攻击的侦测和防御。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"product","slug":"tech/product","permalink":"https://decodezp.github.io/categories/tech/product/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"product","slug":"product","permalink":"https://decodezp.github.io/tags/product/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"}]},{"title":"可以预测交通路况的 APP","slug":"life-traffic-prediction","date":"2018-12-06T06:41:18.000Z","updated":"2018-12-06T06:45:25.440Z","comments":true,"path":"2018/12/06/life-traffic-prediction/","link":"","permalink":"https://decodezp.github.io/2018/12/06/life-traffic-prediction/","excerpt":"能不能有这样一款应用","text":"能不能有这样一款应用 或者地图 APP 实现这样一个功能 能通过历史路况大数据分析 告诉我今天晚上几点出发上路 东北四环不堵 把什么机器学习人工智能数字孪生 能加的都给它加上 感觉又是一个割 VC 韭菜的杀手应用 只要有人搭出来这个框架 我愿意帮忙实现所有的业务代码 因为只需要一句 return &quot;您期望的时间不存在&quot; 2018.12.6","categories":[{"name":"life","slug":"life","permalink":"https://decodezp.github.io/categories/life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://decodezp.github.io/tags/life/"}]},{"title":"测来测去2：CPU缓存读入策略","slug":"test2-cache-line-alignment","date":"2018-12-06T06:18:31.000Z","updated":"2018-12-06T06:29:21.926Z","comments":true,"path":"2018/12/06/test2-cache-line-alignment/","link":"","permalink":"https://decodezp.github.io/2018/12/06/test2-cache-line-alignment/","excerpt":"到底哪些数据写入了CPU缓存我们知道CPU会在要读写某个数据时，先将数据写入缓存。 我们也知道这个操作一般以Cache Line为操作粒度，并且Cache Line的长度一般为64Byte。","text":"到底哪些数据写入了CPU缓存我们知道CPU会在要读写某个数据时，先将数据写入缓存。 我们也知道这个操作一般以Cache Line为操作粒度，并且Cache Line的长度一般为64Byte。 那么这个Cache Line包含的数据到底是哪64Byte呢？ 如果要读写的数据的地址正好以64Byte对齐，那么肯定是这个数据和它之后的（64 - sizeof(数据)）Byte存在于这个缓存行里。 但是如果要读写的这个数据地址不以64Byte对齐，而是在两个64Byte对齐的地址中间的某个位置，CPU写入Cache Line里的数据还是它和它之后的64Byte吗？CPU会“向前”对64取整作为Cache Line中的数据吗？ 用False Sharing证明根据之前介绍False Sharing的原理链接，通过判断是否发生False Sharing可以判断某两个数据是否存在于同一条Cache Line里。 构造如下结构体： 123456struct counter_t &#123; uint32_t front_padding[15]; uint32_t c1; /* 64 bytes */ uint32_t c2;&#125;; 其中c1和c2是分别被两个CPU core写入的变量。 在构造counter_t的实例时，利用GCC attribute确保其起始地址与64Byte对齐： struct counter_t counter __attribute__((aligned(64))); 在两个CPU核分别开始操作c1和c2之前利用clflush指令清除所有相关缓存： 12345inline voidclflush(volatile void *p)&#123; asm volatile (\"clflush (%0)\" :: \"r\"(p));&#125; 如果发生了False Sharing，则说明这两个变量在一个Cache Line里，则证明CPU是取欲读写变量及其之后64Byte数据写入缓存如果没有发生False Sharing，则说明这两个变量不在一个Cache Line里，则证明CPU是取欲读写变量向前64取整地址上的数据写入缓存 结果结果当然是没有发生False Sharing。 不然还搞什么n-way set associative :) 代码：https://github.com/PanZhangg/x86perf/blob/master/cache_line_alignment.c","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"}]},{"title":"魏孝文帝教你提proposal","slug":"history-tuobahong","date":"2018-12-05T07:09:12.000Z","updated":"2018-12-05T07:14:40.277Z","comments":true,"path":"2018/12/05/history-tuobahong/","link":"","permalink":"https://decodezp.github.io/2018/12/05/history-tuobahong/","excerpt":"艰难的Proposal每个人都有独自一人面对全世界的时候，即便你是魏孝文帝拓跋宏。 北魏太和十七年，承平日久的北魏都城里正在酝酿一件大事——迁都。","text":"艰难的Proposal每个人都有独自一人面对全世界的时候，即便你是魏孝文帝拓跋宏。 北魏太和十七年，承平日久的北魏都城里正在酝酿一件大事——迁都。 自天兴元年拓跋圭定都平城起，北魏在此地经营了九十余年。此时的平城，早已是北魏王公贵族富商巨贾的乐土。 而拓跋宏却不想在这呆了，对这位一心思慕华夏风仪的少数民族首领来说，城狭地偏的平城终究不是久居之地。 迁都，迁往洛阳，只有住在这座每块城砖上都写满了厚重的城邑的中心，才是北漂买房落户的那一刻。 但除了拓跋宏，没有人愿意当拆迁户，被连根拔起。拓跋宏自己也知道这一点。晓以大义？没用的，天底下最难的事，就是劝说别人放弃眼前的利益，去追求什么万世之业； 以皇帝的权威一意孤行？没有问题，但人心不齐，效果打折扣，既损威严，又于事无益。 那么迁都这个Proposal，到底怎么提呢？ 魏孝文帝的方式拓跋宏并没有在一开始就透露自己的意图，而是提出了一个更加”不得人心”的Proposal——亲自带队，攻打南朝。 如果说迁都不得人心，那么发动战争就更加让改革的主要阻力——深居平城的皇亲贵胄们如坐针毡。 因为迁都或许还可以讨论讨论，但南下伐齐“一统中国”那是北魏政权不容辩驳的“正统思想”，是政治正确，有拓跋氏列祖列宗的加持，以及冯太后的附魔。 这一年的八月，拓跋宏亲率三军开拔南下。 当然，皇帝都出去打仗了，除了太子监国以外，平日里的文武百官哪有在家呆着的道理，一起走吧！ 从山西大同往南，大军在秋雨连绵的泥泞中走了整整一个月，终于到达了宿命的重点——洛阳。 这个时候所有人都不想再走了。一路的狼狈或可忍受，但后面还有与齐国的恶战。而拓跋宏依然兴致不减，号令即刻开拔，继续南进。 这下文武百官们可都要“犯颜进谏”了，纷纷叩头不止，甚至不惜死谏以请求拓跋宏停止南征。 这个时候拓跋宏才说出他真正的目的： 今者兴动不小，动而无成，何以示后？苟欲班师，无以重之千载！朕世居幽朔，欲南迁中土，苟不南伐，当迁都于此，王公以为如何？欲迁者左，不欲者右！——《资治通鉴》 这里有三个要素： 我可以在南伐之事上让步 但我的让步有条件 不许考虑太久 最终的结果自然是大家都站到了左边。迁都这件事，就这么“取得”了大家的同意。 抽象提取在谈判领域存在一个让步/妥协的谈判技巧。 对每个人来说，如果对面已有所让步，那么心里将会产生同样让步的压力，趋向于同意对方提出的让步条件。 这种场景在生活中非常常见，例如： 12345678多少钱？10030吧最低9040低于85就赔本了你看我就50块钱行了80吧，今天好不容易开张 如果能成交，说明买家和卖家一开始的心理价位就都是80元左右，但买家必须要首先压到30，卖家也要提到100，互相留出这个让步的空间。 也许你觉得这种技巧太市侩，但它其实有很多变种版本，也许自己已经身堕瓠中而不自知。E.g.房产中介请你看房，首先是一间各方面条件都很差的房间，但却有一个让你惊讶的高额租金。然后带你看了一套各方面比第一间好非常多的房间，租金却和第一间一样，或者略多而已。如此你会觉得租了第二间是占了便宜。但其实中介的目标就是租给你第二间房，第一间就是让你产生这种对比让步的错觉的。 所以，每当打算提一个艰难的Proposal的时候，我都会效仿这种形式。","categories":[{"name":"history","slug":"history","permalink":"https://decodezp.github.io/categories/history/"}],"tags":[{"name":"history","slug":"history","permalink":"https://decodezp.github.io/tags/history/"}]},{"title":"ftrace uprobe使用填坑历程","slug":"ftrace-uprobe","date":"2018-12-04T04:25:59.000Z","updated":"2018-12-04T04:28:56.558Z","comments":true,"path":"2018/12/04/ftrace-uprobe/","link":"","permalink":"https://decodezp.github.io/2018/12/04/ftrace-uprobe/","excerpt":"准备打算用一下ftrace对用户态程序的trace支持。 测试用程序test.c：","text":"准备打算用一下ftrace对用户态程序的trace支持。 测试用程序test.c： 123456789101112131415161718192021static voidprint_curr_state_one(void)&#123; printf(\"This is the print current state one function\\n\");&#125;static voidprint_curr_state_two(void)&#123; printf(\"This is the print current state two function\\n\");&#125;int main() &#123; while(1) &#123; print_curr_state_one(); sleep(1); print_curr_state_two(); &#125;&#125; 编译：gcc -o test test.c Obtain Offset：objdump -d test 123456789101112131415000000000040055d &lt;print_curr_state_one&gt;: 40055d: 55 push %rbp 40055e: 48 89 e5 mov %rsp,%rbp 400561: bf 30 06 40 00 mov $0x400630,%edi 400566: e8 c5 fe ff ff callq 400430 &lt;puts@plt&gt; 40056b: 5d pop %rbp 40056c: c3 retq 000000000040056d &lt;print_curr_state_two&gt;: 40056d: 55 push %rbp 40056e: 48 89 e5 mov %rsp,%rbp 400571: bf 60 06 40 00 mov $0x400660,%edi 400576: e8 b5 fe ff ff callq 400430 &lt;puts@plt&gt; 40057b: 5d pop %rbp 40057c: c3 retq 添加uprobe trace event： 12echo 'p:print_current_state_one /root/test/uprobe/uprobe:0x55d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_eventsecho 'p:print_current_state_two /root/test/uprobe/uprobe:0x56d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_events 有时会出现Invalid argument的错误。用sudo su获取root权限。 这里注意，偏移的大小只写0x55d，不能写0x40055d 开启trace先启动test程序：./test echo 1 &gt; /sys/kernel/debug/tracing/event/enable 如果此时cat /sys/kernel/debug/tracing/event/enable显示为X echo 1 &gt; /sys/kernel/debug/tracing/event/uprobes/enable 最后cat /sys/kernel/debug/tracing/trace应该就能看到了","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"ftrace","slug":"ftrace","permalink":"https://decodezp.github.io/tags/ftrace/"}]},{"title":"ftrace trace-cmd kernelshark资料汇总","slug":"ftrace","date":"2018-11-30T06:22:55.000Z","updated":"2018-11-30T06:39:04.849Z","comments":true,"path":"2018/11/30/ftrace/","link":"","permalink":"https://decodezp.github.io/2018/11/30/ftrace/","excerpt":"一些关于这一类技术的资料和文档汇总。文章中可以找到比较详细的工具使用方法。如果想了解更多内容可以阅读linux/Documentation/trace下的文档以及源码。 以及git log ./kernel/trace :)","text":"一些关于这一类技术的资料和文档汇总。文章中可以找到比较详细的工具使用方法。如果想了解更多内容可以阅读linux/Documentation/trace下的文档以及源码。 以及git log ./kernel/trace :) ftrace Debugging the kernel using Ftrace - part 1 Debugging the kernel using ftrace - part 2 Kernel Documents: ftrace Secrets of the Ftrace function tracer PDF:Debugging Linux Kernel by ftrace Kernel Tracing with ftrace, Part 1 Kernel Tracing with ftrace, Part 2 ftrace: trace your kernel functions! Hooking Linux Kernel Functions, how to Hook Functions with Ftrace Understanding the Linux kernel via ftrace trace-cmd trace-cmd: A front-end for Ftrace Code:trace-cmd kernelshark Using KernelShark to analyze the real-time scheduler Video:KERNELSHARK 1.0; WHAT’S NEW AND WHAT’S COMING Video:Yordan Karadzhov - What’s Coming in Kernel Shark PDF:Swimming with the New KernelShark","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"linux","slug":"tech/linux","permalink":"https://decodezp.github.io/categories/tech/linux/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"ftrace","slug":"ftrace","permalink":"https://decodezp.github.io/tags/ftrace/"},{"name":"linux","slug":"linux","permalink":"https://decodezp.github.io/tags/linux/"}]},{"title":"测来测去1：DPDK no-huge模式性能对比测试","slug":"test1-dpdk-no-huge","date":"2018-11-29T05:20:58.000Z","updated":"2018-11-29T05:30:48.738Z","comments":true,"path":"2018/11/29/test1-dpdk-no-huge/","link":"","permalink":"https://decodezp.github.io/2018/11/29/test1-dpdk-no-huge/","excerpt":"no-hugeDPDK使用大页内存作为性能优化的一个手段。但大页内存在云计算等环境下可能会出现内存资源浪费的情况，作为售卖资源的云服务商，希望能找到更充分的内存资源利用的方法。在此背景下，DPDK引入了no-huge机制，即不使用hugepage，从而解放更多的系统资源。 那么这种配置下DPDK性能会下降多少呢？还是需要实际定量测试一下。","text":"no-hugeDPDK使用大页内存作为性能优化的一个手段。但大页内存在云计算等环境下可能会出现内存资源浪费的情况，作为售卖资源的云服务商，希望能找到更充分的内存资源利用的方法。在此背景下，DPDK引入了no-huge机制，即不使用hugepage，从而解放更多的系统资源。 那么这种配置下DPDK性能会下降多少呢？还是需要实际定量测试一下。 测试平台123456789101112131415161718192021222324lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 88On-line CPU(s) list: 0-87Thread(s) per core: 2Core(s) per socket: 22Socket(s): 2NUMA node(s): 2Vendor ID: GenuineIntelCPU family: 6Model: 85Model name: Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHzStepping: 4CPU MHz: 2100.393BogoMIPS: 4201.72Virtualization: VT-xL1d cache: 32KL1i cache: 32KL2 cache: 1024KL3 cache: 30976KNUMA node0 CPU(s): 0-21,44-65NUMA node1 CPU(s): 22-43,66-87 12345lspci | grep Ether86:00.0 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)86:00.1 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)86:00.2 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)86:00.3 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01) DPDK Version: 18.05.1Tester: IXIATest Plan: RFC2544DPDK APP: ./l2fwd -l 22-24 --no-huge -- -p 0x3 -T 5 测试结果 在64Byte包长时丢包率达到了50%以上，而使用大页内存时丢包率可以控制在0.05%以内。其他长度丢包和吞吐情况基本相同。根据业务情况，平均包长如果在300Byte以上–no-huge模式不妨一试。后续添加针对更大链路带宽(25Gbps/100Gbps)的网卡以及不同Xeon平台的测试结果。","categories":[{"name":"test","slug":"test","permalink":"https://decodezp.github.io/categories/test/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"dpdk","slug":"dpdk","permalink":"https://decodezp.github.io/tags/dpdk/"},{"name":"test","slug":"test","permalink":"https://decodezp.github.io/tags/test/"}]},{"title":"云计算的发展需要向社区街道管理看齐","slug":"thoughts1-cloud-community","date":"2018-11-28T05:47:57.000Z","updated":"2018-11-28T05:53:19.517Z","comments":true,"path":"2018/11/28/thoughts1-cloud-community/","link":"","permalink":"https://decodezp.github.io/2018/11/28/thoughts1-cloud-community/","excerpt":"服务云计算本质上是一种服务。由各种不同的组件为租户提供计算、网络和存储服务。 用户对这些服务的要求除了功能之外，还有安全性、可用性、性能、成本、迁移难度、SLA等一系列要求。 与之类比，社区街道作为一个完整的功能单元，各个基层职能部门，也为社区内的居民提供各类生活服务。 如何做好基层工作，是需要费一番脑筋的。","text":"服务云计算本质上是一种服务。由各种不同的组件为租户提供计算、网络和存储服务。 用户对这些服务的要求除了功能之外，还有安全性、可用性、性能、成本、迁移难度、SLA等一系列要求。 与之类比，社区街道作为一个完整的功能单元，各个基层职能部门，也为社区内的居民提供各类生活服务。 如何做好基层工作，是需要费一番脑筋的。 服务网格下图是我在北京中关村某社区拍到的当地派出所的“网格团队”成员和工作职责。 如果你熟悉云计算，熟悉当前的领先理念，那么service mesh这个词你肯定不陌生，这是当前容器和微服务领域的最新热点，拥有Istio、Envoy等一众明星开源项目，并且有Google、AWS、Alibaba等大佬拥趸。这个词翻译过来就是服务网格。 而社区街道提出的这个“网格”的概念，明显领先于自诩为科技前沿的云计算。 如果仔细阅读一下上图中的“工作职责”，就能够轻易地将其内容与时下云计算和企业数字化转型热炒的概念对应起来： 管理网格单元：Microservice微服务 落实基信息采集：Digital Twin数字孪生 综合网格力量：Orchestration协同 加强依法自治：Decouple解耦/Distrubute分布式 排查隐患：Situational Awareness态势感知/Active Defence主动式防御 协调解决社会服务管理中存在的问题：Full Stack Management全栈管理 推进公共服务建设：Aglie敏捷/DevOps 监督管理网格力量，督促责任落实：Sidecar 及时上报网格工作数据：Telemetry遥测 完成街道交办的其他工作：Serverless无服务器 总结就是这个街道派出所就是Community-Native Microservice &amp; Service Mesh &amp; Serverless &amp; Security的典范，理念领先云计算至少5年。 好好学习为什么街道派出所的理念能领先云计算的发展？道理都是殊途同归的，很多理念（经验）的获得都是靠积攒年头。 云计算方兴未艾，但毕竟用户还不足够多，问题暴露还不足够全面，或者说，没太多管理经验。而派出所展开基层管理工作的时间至少比在坐的诸位岁数都长。同时基层群众形形色色，就像软件测试时的边界条件，绝对都能满足。 在此种“得天独厚”的条件下总结出的经验，云计算从业者除了好好消化吸收之外，也可以小小的自鸣得意一下，毕竟你仅仅用了10年就追上了街道派出所。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"},{"name":"cloud","slug":"cloud","permalink":"https://decodezp.github.io/tags/cloud/"}]},{"title":"几句话说清楚3:什么是False Sharing","slug":"quickwords3-falsesharing","date":"2018-11-27T05:12:54.000Z","updated":"2018-11-27T05:22:37.184Z","comments":true,"path":"2018/11/27/quickwords3-falsesharing/","link":"","permalink":"https://decodezp.github.io/2018/11/27/quickwords3-falsesharing/","excerpt":"不用图以为又要见到那几张网上已经用烂了的图了是不是？这次我们不用图来讲这个事。","text":"不用图以为又要见到那几张网上已经用烂了的图了是不是？这次我们不用图来讲这个事。 Cache line是64个Byte，我们经常操作(R/W)的变量是4个或者8个Byte。 于是一个Cache line里就可以放好几个变量，比如说其中有两个变量A和B。 当CPU0写入A，CPU1写入B的时候，就发生了False Sharing，就这么简单。 所谓“假共享”，其实就是你以为你俩自己操作自己的变量是共产国际按需分配互不影响，其实都是假象。 很多材料上说是因为不同的CPU核共享了相同的Cache Line，其实并不严谨。根本因素是不同的CPU核需要更新的缓存出现了地址上的重叠。 那么当其中一个核更新了它的变量A之后，CPU并不能识别出是哪4个Byte或8个Byte地址上的数据被更新，而只能认为该变量所在的整条64Byte Cache Line都应该被更新。 所有有和这64Byte重叠的Cache Line，不管在哪个CPU核上，都需要被更新，这样才能保证大家手头的数据是一致的。 于是乎，和这64Byte地址存在重叠的变量B所在的CPU1中的缓存也需要被更新，自然就影响到了性能。 如果只是读，就没有这个问题，因为不需要关心缓存一致这个事。 示例这里有一个活生生的代码的例子： https://github.com/PanZhangg/x86perf/blob/master/false_sharing_padding.c 12345678910struct counter_t &#123; uint32_t c1; #ifdef PADDING_64_BYTE uint32_t padding[15]; #elif PADDING_128_BYTE uint32_t padding[31]; #else #endif uint32_t c2;&#125;; 本来是打算用来验证在CPU预取开启的情况下到底是应该Padding 64还是128，但在Haswell和Skylake上验证，这两个长度都没有区别。 后来查找资料是在Sandy bridge上需要padding到128，但我这里没有这么老的CPU….先这样吧.. 上面的代码注意用-O0编译。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"几句话说清楚2:CPU缓存的组织形式","slug":"quickwords2-cacheassociativity","date":"2018-11-25T07:18:27.000Z","updated":"2018-12-24T13:11:50.490Z","comments":true,"path":"2018/11/25/quickwords2-cacheassociativity/","link":"","permalink":"https://decodezp.github.io/2018/11/25/quickwords2-cacheassociativity/","excerpt":"缓存缓存和其他存储形式在功能形式上没有太大区别，均是输入一个地址，还你一个数据。但作为一个缓存，要考虑如何在有限的容量下保证较高的命中率以及查找效率(相关阅读)。这个问题从本质上来说，就是如何建立缓存地址与内存地址的映射关系。","text":"缓存缓存和其他存储形式在功能形式上没有太大区别，均是输入一个地址，还你一个数据。但作为一个缓存，要考虑如何在有限的容量下保证较高的命中率以及查找效率(相关阅读)。这个问题从本质上来说，就是如何建立缓存地址与内存地址的映射关系。 组织形式缓存按照一个Cache Line的长度（主流长度为64Byte）为粒度来组织： 各种不同的映射形式就是在决定内存中某一个特定地址范围内的数据，具体可以放到哪一个Cacha Line里去。 能想出来的方式也无外乎三种： 哪个都可以放 只能放到第N个（N是内存地址的函数） 只能放到第N个至第M个（M也是内存地址的函数） 其实基本上这篇文章可以结束了，很多技术都不是什么新鲜的“创想”，只是给朴素的思想内核穿上了一层“术语”的外衣。 Direct Mapping这就是上面说的第二种方式，某一个内存地址段的数据，只能放在第N个Cache Line里 Pros:查找快，一次寻址，有就是有，没有就是没有，不啰嗦（因为只需要验证一个Cache Line中是否存在该地址） Cons:命中率低，CPU经常需要相邻地址的数据，而根据规则，同属于第N个Cache Line的数据会互相排斥，不会同时出现在缓存里 Fully Associative这就是第一种方式，随便放。 Pros:命中率高，过去和未来一段时间内需要的数据都可以被放在缓存内，同时不用担心被相邻地址上的数据踢出 Cons:查找慢，确认一个地址是否在缓存里通常需要遍历整个缓存（Miss的情况） n-Way Set Associative Cache这就是第三种方式了，颜色相同的内存地址范围和缓存Cache Line互相对应，不能越界。每一个颜色就是一个Way。 但如果单独拿出某一个颜色来看，是Fully Associative的方式。 这么做当然是为了充分发挥前两种方式的优势。既可以存在相邻内存中的数据以提高命中，同时也一定程度上减少了查找范围，提升查找效率。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"XXV710网卡Target Link Speed探秘","slug":"x710-target-link-speed","date":"2018-11-23T11:26:48.000Z","updated":"2018-12-18T12:26:57.396Z","comments":true,"path":"2018/11/23/x710-target-link-speed/","link":"","permalink":"https://decodezp.github.io/2018/11/23/x710-target-link-speed/","excerpt":"发现用lspci指令查看PCIe设备，特别是网卡设备经常会查看LnkCap及LnkSta字段，以确保网卡运行在期望的PCIe总线类型/带宽上，从而保证网卡的性能。 最近拿到一块XXV710-DA2，插上之后简单看了一下状态。LnkCap和LnkSta均显示为Speed 8GT/s，Width x8，没太大问题。这时候无意中瞥见LnkCtl2中Target Link Speed显示为2.5GT/s，引发了兴趣。","text":"发现用lspci指令查看PCIe设备，特别是网卡设备经常会查看LnkCap及LnkSta字段，以确保网卡运行在期望的PCIe总线类型/带宽上，从而保证网卡的性能。 最近拿到一块XXV710-DA2，插上之后简单看了一下状态。LnkCap和LnkSta均显示为Speed 8GT/s，Width x8，没太大问题。这时候无意中瞥见LnkCtl2中Target Link Speed显示为2.5GT/s，引发了兴趣。 1234LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not SupportedDevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF DisabledLnkCtl2: Target Link Speed: 2.5GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB Target Link Speed关于Target Link Speed是什么，查找到了Intel Skylake Processor External Design Specification(EDS)中的定义： For Downstream Ports, this field sets an upper limit on Link operational speed by restricting the values advertised by the Upstream component in its training sequences. 基本上LnkCap表示支持的速度，LnkCtl2设置你需要的速度，LnkSta显示实际Training好的速度，如果想要修改的话，都是改LnkCtl2的值。 现在的问题就是LnkSta和LnkCtl2矛盾。那么我们现在这块网卡的速度到底是多少？只能实际测试一下。 测试起个pktgen打个性能，是能直接到线速的，也就是说Target Link Speed没有实际起到限制速度的作用。 又查询了一些资料，从这里看到一个帖子：https://communities.intel.com/thread/106568 最终Intel的官方回复是，这个寄存器的值确实和实际速度没有关系。 规范也是你们写的，帖子也是你们回的，现在正话反话都让你说了，搞什么鬼。 最后查到了该寄存器的位置(D0h)，暴力修改一下： setpci -s 0000:18:00.0 d0.B=3 然后就乖乖地显示为8GT/s了，真是个毫无脾气的寄存器，你让别的遵守规范的设备如何自处。 1234LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not SupportedDevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF DisabledLnkCtl2: Target Link Speed: 8GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"network","slug":"network","permalink":"https://decodezp.github.io/tags/network/"}]},{"title":"程序员和工厂劳工有何不同","slug":"programmer-worker","date":"2018-11-22T12:54:07.000Z","updated":"2018-11-22T13:23:21.430Z","comments":true,"path":"2018/11/22/programmer-worker/","link":"","permalink":"https://decodezp.github.io/2018/11/22/programmer-worker/","excerpt":"如今流行的一个说法是，现在的程序员与工业时期的工厂工人并无二致。均是富集于人口密集的城市、均是超时劳动、均是遭受资本家的盘剥、均是一架大机器上的螺丝钉，在超过“劳动年龄”之后被弃如敝屣。基于这些相似点，有些人得出结论，程序员不过是这个时代的“无产阶级”，和以前的流水线工人，纺织厂女工属于同一社会分工和定位。是否当真如此，这个问题值得仔细推敲一下。","text":"如今流行的一个说法是，现在的程序员与工业时期的工厂工人并无二致。均是富集于人口密集的城市、均是超时劳动、均是遭受资本家的盘剥、均是一架大机器上的螺丝钉，在超过“劳动年龄”之后被弃如敝屣。基于这些相似点，有些人得出结论，程序员不过是这个时代的“无产阶级”，和以前的流水线工人，纺织厂女工属于同一社会分工和定位。是否当真如此，这个问题值得仔细推敲一下。 生产资料个人所处的社会阶层，取决于他能让属于他的生产资料产生的价值。传统的生产资料包括实体的机器、厂房、地皮、原材料、资本和人等等。而作为信息时代的标志，人人都可以通过网络获取一项虚拟的生产资料——信息。诚然，信息壁垒依然存在，但普通人能接触到的信息总量和质量与信息革命之前的时代相比已不可同日而语。程序员是与电子计算设备打交道的人，此类设备本质上是信息的产生、加工和分发工具。一台电脑加一条网线，程序员就可以以极其低廉的方式获得他所需要的生产资料。而拥有生产资料的人，就不能再称之为“无产阶级”。我们已经听过了太多程序员在车库创业的故事，也许这些故事仍然可以称之为“个例”，毕竟，哪个时代没有一些白手起家的人。但如果某个行业能在全社会掀起创业的热潮，那么就不能再以孤例的眼光看待。只有在该行业的生产资料极大丰富，且对再加工之后的产品有持续需求的情况下才有可能出现这类情况。是否能以足够廉价的方式获取生产资料，是程序员与工厂工人的第一个区别。 对生产资料的再分工注意这里强调的是再“分”工，而不是再加工。程序员能够开发出各种程序满足人们的需求，工人也能生产出各种生活必需品，所以在生产资料再加工这一点上，两者没有本质区别。专业细分是社会生产率提高的根本因素。每个人只负责整条产业链中的一环，愈发细致的分工与合作是现代生产活动的组织方式。程序员和工人均为某一细分领域的专家，但二者所处的分工链条深度不同。工人是分工链条的末端，他所能做的就是尽自己所能做好手头的事情。而程序员虽然仍然要听老板的，但他手下仍有电子设备作为分工的最后一环。程序员可以通过编码为这些电子设备“分工”，从而令其为程序员服务。从某种意义上说，程序员就是这些电子设备的“老板”。同时随着设备的计算能力越来越强，这些设备就能逐渐胜任更加精细的分工任务。随着分工的深入，一方面带动社会整体劳动生产率的提升，一方面更加高效地产生价值。一个大型工厂的老板最多能令数万工人为其服务，而所有能跑代码的设备都可能为程序员服务。在分工链所处的位置和对生产资料的再分工能力，是程序员与工厂工人的第二个区别。 程序员如何度过”中年危机”其实程序员是新时代的工厂工人这种论调，只不过是之前“青春饭”、“过了30岁不能再编程“等论调的新瓶装旧酒而已。但程序员面对的现实压力确实是不容忽视的问题。很多人学了很多技术，掉了很多头发，但最后仍被公司扫地出门，问题就在于做了无用的努力。解决之道其实就蕴含在前文论述的两点之内： 尽可能占有(处理)更多的生产资料——信息 为尽可能多的电子设备”分工” 实际执行的术便是一定要有自己的“产品”。这当然是一个程序，可以是公司的产品，也可以是个人作品。但需要关注两个关键点： 我的程序是否位于信息交叉的节点或能协助信息的获取、处理及分发 运行我的程序的设备是否在增长 可以看看这些久盛不衰的“产品”：操作系统、数据库、浏览器、服务器软件、办公处理、图像应用处理等等甚或编程语言本身，都是这两个关键点的很好的体现。当你拥有这样的产品时，操心的就不是公司会不会要你了，而是如何高效地指挥你自己这支被你分工的生产队，实践一些大胆的想法。最后附上我最喜欢的历史名人名言作为结尾： 臣但恐富贵来逼臣，臣无心图富贵。 ——杨素","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"几句话说清楚1:为什么CPU L1缓存容量始终很小","slug":"cachesize","date":"2018-11-20T11:45:45.000Z","updated":"2018-12-12T15:09:51.135Z","comments":true,"path":"2018/11/20/cachesize/","link":"","permalink":"https://decodezp.github.io/2018/11/20/cachesize/","excerpt":"问题CPU缓存是影响软件性能的关键因素之一。在做性能调优时，经常关注的一个指标就是缓存的命中率(hit rate)。缓存之所以不会达到100%的命中率，是因为缓存容量有限，不能将内存中的全部数据都同时放入其中。只能将当前最热，相邻最近的数据存入，同时还受多核CPU中缓存同步机制的影响。奇怪的是，CPU的制程、晶体管数量、核心数量一直都在增加，但L1缓存的容量始终维持在一个相当低的水平。为什么不加大L1缓存呢？","text":"问题CPU缓存是影响软件性能的关键因素之一。在做性能调优时，经常关注的一个指标就是缓存的命中率(hit rate)。缓存之所以不会达到100%的命中率，是因为缓存容量有限，不能将内存中的全部数据都同时放入其中。只能将当前最热，相邻最近的数据存入，同时还受多核CPU中缓存同步机制的影响。奇怪的是，CPU的制程、晶体管数量、核心数量一直都在增加，但L1缓存的容量始终维持在一个相当低的水平。为什么不加大L1缓存呢？ 缓存组织形式当然要考虑到成本和功耗，以及边界效益的问题，但这些不是本文讨论的重点。缓存存在的意义是当CPU需要某些数据时，能够以最快的速度给它。这个速度是以CPU时钟周期为计量单位的。在这一个周期内，CPU能处理的数据量并不大。作为L1缓存，首先需要做的就是把这几个周期内的数据保存好，这个确实缓存容量越大，可以做得越好。但把数据喂给CPU，还需要另外一步工作——缓存的查找。种种不同的缓存组织方式和对应的查找机制，其实是在命中率以及查找效率中寻找平衡。 直接映射(Direct Mapping)查找效率高，但命中率很低 全关联映射(Fully Associative Mapping)命中率会提高，但查找效率非常低，与缓存容量成反比 N路组相联映射(N-ways Set-Associative Mapping)折衷方案，平衡命中率和查找效率，也是缓存采用的组织方式 L1$对L1缓存来说，任务很艰巨，既要追求命中率，同时也要保证查找效率，那么解决方法就是缩小体积。既享受N-ways Set-Associative Mapping带来的命中率，同时因为每个Set的尺寸不大，仍然会有很高的查找效率。如果将缓存的容量增大，不仅仅是成本和功耗上得不偿失，也将会让缓存的查找效率降低而使缓存丧失意义。 “大曰逝，逝曰远，远曰反”，以退为进，以曲为直的道理在缓存中有了很好的体现。","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"},{"name":"quickwords","slug":"tech/quickwords","permalink":"https://decodezp.github.io/categories/tech/quickwords/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"},{"name":"hardware","slug":"hardware","permalink":"https://decodezp.github.io/tags/hardware/"},{"name":"CPU","slug":"CPU","permalink":"https://decodezp.github.io/tags/CPU/"}]},{"title":"top命令使用方法补遗","slug":"topcmd","date":"2018-11-19T13:25:58.000Z","updated":"2018-11-20T12:11:01.048Z","comments":true,"path":"2018/11/19/topcmd/","link":"","permalink":"https://decodezp.github.io/2018/11/19/topcmd/","excerpt":"更改界面刷新频率 自动刷新 topd输入刷新时间（默认3秒，可调至0.5） 手动刷新空格","text":"更改界面刷新频率 自动刷新 topd输入刷新时间（默认3秒，可调至0.5） 手动刷新空格 屏幕滚动一个屏幕显示不完C使用方向键滚动 可用在使用c和V开启命令行及Forest view之后 查看线程top信息H 查看线程CPU绑定/亲和性状态F移动光标至Last Used Cpu空格q返回 与H配合使用可观察各线程是否与对应的CPU核绑定亲和性 排序M按驻留内存大小排序P按CPU使用率排序T按累计时间排序x高亮排序的列 按NUMA查看CPU使用情况2查看各NUMA节点CPU汇总使用信息3输入节点号，查看该节点各CPU使用信息 按条件过滤‘O’输入过滤条件，如:!COMMAND=top COMMAND栏中不包含top%CPU&gt;3.0 CPU占用率大于3%清除全部过滤条件 = 保存当前命令配置W下次再启动时恢复当前配置形式 其他信息man top","categories":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/categories/tech/"}],"tags":[{"name":"tech","slug":"tech","permalink":"https://decodezp.github.io/tags/tech/"}]},{"title":"刚日读经，柔日读史","slug":"gangrirouri","date":"2018-11-18T11:27:23.000Z","updated":"2018-12-16T10:10:55.644Z","comments":true,"path":"2018/11/18/gangrirouri/","link":"","permalink":"https://decodezp.github.io/2018/11/18/gangrirouri/","excerpt":"在不知道什么时候，我们似乎被灌输了一种互补好，什么都是互补好的认知。资源要互补，团队要互补，思想要互补，连看个书也得掐着日子互补。","text":"在不知道什么时候，我们似乎被灌输了一种互补好，什么都是互补好的认知。资源要互补，团队要互补，思想要互补，连看个书也得掐着日子互补。 刚日读经，柔日读史，“刚日”就是阳数的日子，“柔日”就是阴数的日子。因为阴阳要互补，所以刚日要读致虚守弱恒常静笃的经；柔日便要读变动不居周行不殆的史。为此还有各位理论导师的笺注，比如南怀瑾： 亢阳激扬，刚也；卑幽忧昧，柔也。经主常，史主变。故刚日读经，理气养生也；柔日读史，生情造意也。有生有息，合乎天理，何乐而不为哉！ 感觉并不如我总结得那般言简意赅提要钩玄。如果说这种“互补”确实在指导我们的行为，那也无可厚非。而实际上我们日常行事，却和这种思想观念有很大出入。饮食上要以形补形，想要强要壮，自然是找来更强更壮的，绝对不会找短小“互补”的食材。婚嫁上要强强联合，至少至少也要找个“门当户对”的。至于相互互补的情节，不是出现在少儿童话故事里，就是出现在成人童话故事里。嘴里说的是阴阳互补，做的却是采阴补阳的勾当。而最重要的是，没有人觉得有问题。我们妄自接受了这些观念，很少去问这些到底是什么。只是在需要的场合，程式化地提出这一观念。什么是互补，什么是阴，什么是阳，什么是刚，什么是柔。如果我脑中只是一些不明来源，未经考究过的观念，那么什么是我自己。更诡吊的是，人与人之间最大的仇恨与惨剧，都滥觞于这种我们根本自己也没搞清楚的观念。不要说“互补”，即便是稍有不同，那便是异端邪说、是外族、是异教徒、是政治犯；那便会有党争、门户、正宗、政治清洗和宗教审判。信不知凭何而信，恨不知因何而恨。被左右的观念所左右，被迷惑的语言所迷惑，操纵感官输出的表象又被表象所操纵。无论刚日柔日，翻开经史，里面都是这样的故事。只要稍微读几页就会发现，与先前想的正好相反，教给你变化的其实是经，而教给你不变的是史。所以这句话并不是要教给你刚柔相济之道，而是提醒你认清人心之妄作，行为之颠倒，以及，追求真实的难能可贵。谨录于上，念念不忘。","categories":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/categories/thoughts/"}],"tags":[{"name":"thoughts","slug":"thoughts","permalink":"https://decodezp.github.io/tags/thoughts/"}]},{"title":"如何在偷偷搜索关键字后避免令人尴尬的广告","slug":"duckduckgo","date":"2018-11-17T13:13:36.000Z","updated":"2018-11-18T11:48:05.706Z","comments":true,"path":"2018/11/17/duckduckgo/","link":"","permalink":"https://decodezp.github.io/2018/11/17/duckduckgo/","excerpt":"转载自cloudwonders.info 当你在任意一个搜索引擎输入一个关键词之后，你就成了全网全平台追逐的流量热点。 平时大打口水战的各大平台在共享你的隐私数据方面异常团结，在B系网站搜索，在A系T系的应用APP上都会看到为你“量身定制”的推送和广告，延迟不超过一分钟。","text":"转载自cloudwonders.info 当你在任意一个搜索引擎输入一个关键词之后，你就成了全网全平台追逐的流量热点。 平时大打口水战的各大平台在共享你的隐私数据方面异常团结，在B系网站搜索，在A系T系的应用APP上都会看到为你“量身定制”的推送和广告，延迟不超过一分钟。 这一点即便是业界道德楷模G老师都未能免俗，毕竟它也要靠着广告收入维持其智能推荐算法引擎的研发投入。 最可气的是，推送些边栏广告也就算了，竟然连自己看的新闻和短视频内容也都要和搜索记录沾边，在聚会上随便刷下手机就暴露了自己到底是个什么货色。 网络对你的监视是全方位的，除了你主动输入的那些关键字，你平时的谈话、你的地理位置，你周围的环境照片都会被偷偷记录上传，用以支撑靠勤劳质朴的城镇劳动人民手动打标签的“人工”智能工程师们的高薪。 当个人隐私在巨头面前节节败退，当生而为人的尊严在利益机器面前粉碎，当你不能说的秘密被拿来公开叫卖和嘲弄，当互联网利用你心底的弱点反过来操控你之时，难道就没有一款可以放心解放双手，安全地释放自己的求知欲，满足人类最原始的好奇的搜索引擎吗？当然不是这样的鸭—— 这个创立于2008年的搜索引擎，十年来一直在巨头的夹击下惨淡经营。如果没有愈演愈烈的互联网隐私泄露事件、没棱镜门、没有小扎的听证会，恐怕Duckduckgo也不会有近来的长足发展。 Duckduckgo从创立之初秉承的理念就是不对用户的搜索做任何追踪与记录，不把用户的隐私和数据当作公司的资产，做好一个搜索引擎的本分。自2018年之初，该搜索引擎已每日接受多于两千万次的匿名搜索。 Duckduckgo的使用方式与其他搜索引擎没有区别，唯一的不同就是搜索之后在其他任何平台没有相关的广告推送。至于搜索本身的质量和水平，笔者简单做了个对比： 应当说完全可以满足日常应用，不说超越G老师，超越B老师应该是问题不大。同时不用担心在互联网大机器下无所遁形。已经有越来越多的朋友和公司将Duckduckgo设置为了默认搜索引擎。 如果说互联网早已是赢家通吃的寡头时代，用隐私交换在线服务已如缴纳“人头税“一般自然，而在这万马齐喑的时刻，Duckduckgo代表的是一豆星星点点的亮光，为所有在歌舞升平中“心怀鬼胎“的人们擎举起惊奇与愤怒的能力。可以放心大胆地搜索不可描述内容的传送门：https://www.duckduckgo.com","categories":[{"name":"wonder","slug":"wonder","permalink":"https://decodezp.github.io/categories/wonder/"}],"tags":[{"name":"resources","slug":"resources","permalink":"https://decodezp.github.io/tags/resources/"},{"name":"wonder","slug":"wonder","permalink":"https://decodezp.github.io/tags/wonder/"}]}]}