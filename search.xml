<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>商业供稿1：消除虚拟化环境网络盲点</title>
      <link href="/2019/03/05/commerical1-eliminate-vnet-blind-spot/"/>
      <url>/2019/03/05/commerical1-eliminate-vnet-blind-spot/</url>
      
        <content type="html"><![CDATA[<p><em>原载于云杉网络 <a href="http://www.yunshan.net" target="_blank" rel="noopener">www.yunshan.net</a> 微信公众号</em></p><p>网络盲点是引起虚拟化环境中业务中断、服务质量下降以及遭受安全威胁的最主要原因。当公司或组织缺乏网络可见性，无法完全掌握其虚拟化环境中业务的网络运行情况时，将必然面临频繁的业务中断、客户投诉以及恶意攻击带来的损失。据Gartner预测，到2019年，实现适当的网络可见性和控制工具的60%的企业将减少三分之一的安全故障。</p><p>随着业务规模的扩大，公司和组织对网络可见性的投入亦将会持续增加。但除了购买增强网络可见性的产品和服务之外，还应针对虚拟化环境中的业务特点，从以下几个导致网络盲点的原因出发，构建完善的网络监控和安全体系。<br><a id="more"></a></p><ul><li>缺乏虚拟网络监控手段<br>Gartner报告声称80%的虚拟化数据中心流量将是虚拟机或容器之间的东西向流量。这些流量可能永远不会到达ToR交换机，而仅仅发生在服务器内部。随着东西向流量规模的进一步增长，以及未来微服务和Serverless架构的盛行，对虚拟环境网络及流量的监控将成为决定业务健康的重头戏。据某金融行业资深专家反馈，当前大部分公司或组织仍依靠传统的从ToR交换机上获取镜像流量的采集方式或是采用功能薄弱，性能不完善的虚拟网络监控工具，将使自身在虚拟网络和云时代中身处盲人摸象的尴尬境地。</li><li>采集丢包<br>传统的流量采集方法多使用“采样”的方式采集大规模网络流量，这些信息一般会通过NetFlow/IPFIX等协议形式生成汇总信息。在采样的过程中将会不可避免地产生失真。这种失真虽然是一种折衷和妥协的产物，但却使得精细化的网络管理不再可行。在传统网络时代，采样的方式仍可以产生一定作用，但在虚拟网络时代，业务流量具有短连接多、并发与突发流量密集、转发路径复杂、虚拟机/容器E2E端点变化频繁等特点，使得原始的采样方法在构建真正能转化成生产力的网络全景视图方面显得力不从心，甚至因采样这种方式的天然缺点，可能会对网络运维人员产生误导。很多一线的网络运维人员反映，现有的工具无法满足他们在虚拟网络和云时代运维决策的制定需求。<br>除此之外，在应对激增的东西向流量时，只有经过精心调校的采集软件可以在不影响服务器生产业务效率的条件下全量采集流量。除此之外的产品都将会因为过载而产生丢包，使得产品能力无法得到充分发挥。随着10G/25G/100G网卡在数据中心的普及，性能将成为一项关键指标。</li><li>虚拟机/容器变动<br>虚拟化环境的特点就是可以针对不同的应用场景，从计算、存储和网络资源中灵活抽象出虚拟机/容器示例。当抽象的规模达到一定程度之后，将会逐渐失去对资源的掌控。在某金融企业1000台服务器规模的数据中心中，因回收不及时而闲置的虚拟机有将近100台的规模。另外，因一再删除添加的防火墙/安全组规则而产生的安全漏洞，以及在复杂的抽象层中丢失或延迟到达的网络流量，都将成为制约资源集约化利用，提供业务安全保障的网络盲点。</li><li>工具集关联<br>在大规模企业和组织中，都存在多种网络工具共存的情形。将不同的工具可以提供不同的互补的能力，但往往需要事先配置不同的工具使能方式。如有些工具需要网元提供NetFlow信息，有些需要配置ERSPAN，有些需要In-band串联等等。这种后台工具各自不一的使能方式在增加网络复杂度的同时，也进一步提升了工具的使用成本。据分析机构报告显示，企业将持续增加IT预算，并达到5%以上的年增长率，IT工具会持续增多。因工具获取信息“源”各不相同，无法对各自的分析结果进行有效综合，也就无法形成工具间的优势互补，进而导致本应可以实现的能力没有实现，损害企业投资。若能从单一信息源处获取网络信息，将产生1+1&gt;2的规模优势。</li><li>工具操作复杂<br>新的工具本身会很复杂，而让使用人员完全掌握新工具的特点，摸清它的“脾气”会是更复杂的事情。如何能最大效率地利用工具，为企业或组织带来最大的投资回报率并非是一件显然的事情。虚拟化环境以及云上环境本身正在变得越来越复杂，而针对它的工具也有同样的趋势。Gartner的报告显示，每增加25%的工具功能，将会提升100%的工具复杂度。而工具本身的复杂将从“工具盲点”最终传导为网络盲点。清晰、简明、强大的工具本身就是从最终用户的层面消除网络盲点的一种手段。</li></ul><p>网络中的盲点将最终成为业务问题。其所波及的并不仅仅是网络组件，而是所有身处这一网络之中的虚拟化以及物理组件。消除网络盲点的方式就是提高网络，特别是虚拟网络的可见性。</p>]]></content>
      
      
      <categories>
          
          <category> commerical </category>
          
      </categories>
      
      
        <tags>
            
            <tag> commerical </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚20：eBPF的机制</title>
      <link href="/2019/03/01/quickwords20-ebpf-intro/"/>
      <url>/2019/03/01/quickwords20-ebpf-intro/</url>
      
        <content type="html"><![CDATA[<h2 id="怎么出来的eBPF"><a href="#怎么出来的eBPF" class="headerlink" title="怎么出来的eBPF"></a>怎么出来的eBPF</h2><p>用Linux Kernel Module来做一个类比说明eBPF诞生的目的。<br><a id="more"></a></p><p>Kernel Module的主要目的就是让用户可以通过这种机制，实现对内核的“赋能”，动态添加一些内核本身不支持的功能，比如硬件的驱动能力，新的文件系统或是系统调用。当然也可以融合到现有的内核处理流程中，比如在netfilter的某个hook点中添加包处理方法等。</p><p>Kernel Module的优点：</p><ul><li>动态添加/删除，无需重新编译内核</li><li>减小内核体积</li></ul><p>缺点：</p><ul><li>一旦出现BUG可能导致内核直接崩溃</li><li>增加内核攻击面，影响内核安全</li></ul><p>eBPF要做的事情也非常类似，但它想要克服Kernel Module的缺点，即确保执行的代码绝对安全。</p><h2 id="eBPF的使用方式"><a href="#eBPF的使用方式" class="headerlink" title="eBPF的使用方式"></a>eBPF的使用方式</h2><p>为了达到这一目的，eBPF在内核中实现了一个虚拟机执行用户的指令。与Kernel Module直接在真实的物理硬件上执行用户的指令不同，eBPF提供给用户一个虚拟的RISC处理器，以及一组相关的指令。用户可以直接用这组指令编写程序。同时，程序在下发到该虚拟机之前也会经过eBPF的检查，比如会不会进入无限循环，会不会访问不合法的内存地址等等。只有在通过检查之后才可以进入执行的环节。</p><p>同时eBPF生态链中也有将高级语言转换成虚拟处理器指令的工具，这个主要靠LLVM提供。</p><h2 id="eBPF的架构"><a href="#eBPF的架构" class="headerlink" title="eBPF的架构"></a>eBPF的架构</h2><p><img src="https://478h5m1yrfsa3bbe262u7muv-wpengine.netdna-ssl.com/wp-content/uploads/2019/02/ebpf-architecture-1.png" alt=""></p><p>对eBPF来说，和Kernle Module一样，也是通过特定的Hook点监听内核中的特定事件，进而执行用户定义的处理。这些Hook点包括：</p><ul><li>静态tracepoint</li><li>动态内核态探针(Dynamic Kernel probes)</li><li>动态用户态探针(Dynamic User Probes)</li><li><a href="https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md#events--arguments" target="_blank" rel="noopener">其他hook点</a></li></ul><p>针对主要是监控、跟踪使用的eBPF应用来说，主要通过这种方式取得内核运行时的一些参数和统计信息。例如，系统调用的参数值、返回值，通过eBPF map将得到的信息送给用户态程序，进而在用户态完成后处理流程。</p><p>另外一类应用则直接在一些内核处理流程中加入自己的处理逻辑，例如<a href="https://www.iovisor.org/technology/xdp" target="_blank" rel="noopener">XDP</a>，就是在网卡驱动和内核协议栈之间插入了eBPF扩展的网包过滤、转发功能。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚19：描述性能优化成果的正确姿势</title>
      <link href="/2019/02/24/quickwords19-desc-perf-improvement/"/>
      <url>/2019/02/24/quickwords19-desc-perf-improvement/</url>
      
        <content type="html"><![CDATA[<h2 id="从10秒到1秒"><a href="#从10秒到1秒" class="headerlink" title="从10秒到1秒"></a>从10秒到1秒</h2><p>周末了说点不硬的技术。<br><a id="more"></a></p><p>自从摩尔定律不那么好使了之后，人们才真正开始关注软件性能。各类开源或者商业产品也经常以性能提升XXX作为卖点宣传。如果在搜索引擎以“性能提升[9, 8, 7, 6]0%”为关键字搜索一下，能看到连篇累牍的精确匹配的信息。但这些信息本身却并不“精确”，甚至都不正确。</p><p>经常能看到的一个错误与下面这个简化的例子相似：</p><blockquote><p>一辆汽车以前行驶100米需要10秒钟，新型号推出后，仅需要1秒钟。</p></blockquote><p>你会看到很多产品信息将这种提升描述为“性能提升90%”。</p><p>我猜测90%的计算方式是：</p><p><code>(10 - 1) / 10 = 90%</code></p><p>但实际上这完全错误。</p><h2 id="性能的表达"><a href="#性能的表达" class="headerlink" title="性能的表达"></a>性能的表达</h2><p>所有的性能都可以表达为：</p><p><code>性能 = 工作量 / 单位时间</code></p><p>其实就是单位时间内能完成的工作量。</p><p>在上面的例子中，工作量是移动距离（m），单位时间（s），性能其实就是m/s，也就是“速度”。</p><p>我们有很多常用的指标已经直接是这种形式，例如QPS、PPS、BPS等。</p><h2 id="性能优化的表达方式"><a href="#性能优化的表达方式" class="headerlink" title="性能优化的表达方式"></a>性能优化的表达方式</h2><p>那前后两次的速度是多少呢？分别是<code>10m/s</code>和<code>100m/s</code>。那性能提升就是<code>100m/s / 10m/s = 10x</code>。</p><p>所以上面的例子中，你可以说：</p><ul><li>性能（速度）10倍提升</li><li>快了10倍/1000%</li></ul><p>但不能说：</p><ul><li>性能提升90%</li><li>快了90%</li></ul><p>一定要用到90%的话，那就是：</p><ul><li>移动耗时减少90%</li></ul><p>如果真正按性能提升90%来计算，那么速度之前是10m/s，之后是<code>10 * ( 1 + 90% ) = 19m/s</code>，也就是1.9倍。</p><p>这个问题在英语世界里也很常见。例如经常会看到一些<code>Get something done 90% faster</code>的宣传，其实都应该改成<code>Get something done 10 times faster</code>。当然也有故意利用这部分认知漏洞，让人误以为性能提升了10倍的。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚18：PCIE带宽单位GT/s到Gbps转换方法</title>
      <link href="/2019/02/22/quickwords18-pcie-gtps-gbps/"/>
      <url>/2019/02/22/quickwords18-pcie-gtps-gbps/</url>
      
        <content type="html"><![CDATA[<h2 id="PCIE的表达方式"><a href="#PCIE的表达方式" class="headerlink" title="PCIE的表达方式"></a>PCIE的表达方式</h2><p>PCIE使用GT/s这个单位表达自己的带宽，这并不是为了标新立异，而是为了更好（直接）地表达PCIE的工作方式。<br><a id="more"></a></p><p>原始的数据在采用PCIE总线传输的时候，需要重新编码。因为PCIE是一种串行总线所以总线时钟要嵌入在串行的数据里。为了保证数据接收方能够正确地还原出时钟，需要提供足够多的信号电位变化（Level Transitions），电位的高低其实代表的就是传输的比特（0或者1）。所以对PCIE来说，它的传输效率并非在于传输了多少有效的数据，而是电位变化的频率。</p><p>GT/s其实就是GigaTransfers per second。而重新编码的电位变化频率也会高于原始数据的比特变化频率，从而导致PCIE传输对带宽有一些因为编码产生的Overhead。</p><p>一次电位变化从数据角度说就相当于传输了一个Bit。所以在下面的计算里GT/s可以等同于Gbps，不过这是编码后的数据。</p><h2 id="PCIE-Gen2-Gen3的区别"><a href="#PCIE-Gen2-Gen3的区别" class="headerlink" title="PCIE Gen2/Gen3的区别"></a>PCIE Gen2/Gen3的区别</h2><p>按上面介绍的原理，为了提高传输速率，一是提高最大可用电位变化频率，而是提高编码效率。</p><h3 id="变化频率"><a href="#变化频率" class="headerlink" title="变化频率"></a>变化频率</h3><ul><li>Gen2最大支持5GT/s</li><li>Gen3最大支持8GT/s</li></ul><h3 id="编码效率"><a href="#编码效率" class="headerlink" title="编码效率"></a>编码效率</h3><ul><li>Gen2编码8Bit原始数据需要10Bit的数据量</li><li>Gen3编码128Bit原始数据需要130Bit的数据量</li></ul><h2 id="GT-s到Gbps的转换"><a href="#GT-s到Gbps的转换" class="headerlink" title="GT/s到Gbps的转换"></a>GT/s到Gbps的转换</h2><ul><li>Gen2</li></ul><p>Gen2最大支持5GT/s/lane。相当于5Gbps的编码后的数据，乘以编码效率<br><code>5Gbps * (8/10) = 4Gbps = 500MBps</code>未编码的原始数据。</p><ul><li>Gen3</li></ul><p>Gen3最大支持8GT/s/lane。按上述算法：</p><p><code>8Gbps * (128/130) = 7876Gbps = 984.6MBps</code></p><p>如果是PCIE Gen3 x8那就是984.6MBps x 8</p><h2 id="速查表格"><a href="#速查表格" class="headerlink" title="速查表格"></a>速查表格</h2><p><img src="https://s2.ax1x.com/2019/02/22/kfycbq.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚17：用Makefile.am和configure.ac构建一个专业的Hello World</title>
      <link href="/2019/02/21/quickwords17-makefileam-configureac/"/>
      <url>/2019/02/21/quickwords17-makefileam-configureac/</url>
      
        <content type="html"><![CDATA[<p>首先感谢GUN的良好<a href="https://www.gnu.org/software/automake/manual/html_node/Creating-amhello.html" target="_blank" rel="noopener">教程</a>，这里主要是做一点点加工。</p><h2 id="GNU-Autotool"><a href="#GNU-Autotool" class="headerlink" title="GNU Autotool"></a>GNU Autotool</h2><p>现在写开源项目，如果只提供一个Makefile可能会令别人怀疑你项目的专业程度:D虽然其实并没有什么关系，但看着别的项目目录下面的<code>configure</code>, <code>configure.ac</code>, <code>Makefile.in</code>, <code>Makefile.am</code>, <code>aclocal.m4</code>等文件还是会觉得有必要也用这些东西“装点”一下。<br><a id="more"></a></p><p>这些文件其实都是由GNU Autotools生成的。Autotools的功能当然不止是装点一下，但我们不在这里深究这个问题，下面通过一个最简单的Hello World示例来解释一下Autotools的使用方法。</p><h2 id="构建必要的文件"><a href="#构建必要的文件" class="headerlink" title="构建必要的文件"></a>构建必要的文件</h2><h3 id="src-main-c"><a href="#src-main-c" class="headerlink" title="src/main.c"></a>src/main.c</h3><p>在项目根目录下新建一个<code>src</code>文件夹，放Hello World的<code>main.c</code></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;config.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">main (<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">puts</span> (<span class="string">"Hello World!"</span>);</span><br><span class="line">  <span class="built_in">puts</span> (<span class="string">"This is "</span> PACKAGE_STRING <span class="string">"."</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>特别注意一下与”传统”Hello World不同的是include了一个<code>config.h</code>，所以才会有<code>PACKAGE_STRING</code>这一变量。</p><p>不直接在根目录创建main.c是因为后续Autotools会自动创建一些额外的作为一个”专业”项目所需要的文件夹，例如<code>man/</code>和<code>data/</code>等等。</p><h3 id="README"><a href="#README" class="headerlink" title="README"></a>README</h3><p>这个直接放根目录就行了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">This is a demonstration package for GNU Automake.</span><br><span class="line">Type 'info Automake' to read the Automake manual.</span><br></pre></td></tr></table></figure><h3 id="根目录下的Makefile-am"><a href="#根目录下的Makefile-am" class="headerlink" title="根目录下的Makefile.am"></a>根目录下的Makefile.am</h3><p>这个这么写：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SUBDIRS = src</span><br><span class="line">dist_doc_DATA = README</span><br></pre></td></tr></table></figure><h3 id="src目录下的Makefile-am"><a href="#src目录下的Makefile-am" class="headerlink" title="src目录下的Makefile.am"></a>src目录下的Makefile.am</h3><p>是的，确实需要写两个Makefile.am：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin_PROGRAMS = hello</span><br><span class="line">hello_SOURCES = main.c</span><br></pre></td></tr></table></figure><h3 id="configure-ac"><a href="#configure-ac" class="headerlink" title="configure.ac"></a>configure.ac</h3><p>下面就可以写最后的<code>configure.ac</code>文件了，这个放在根目录下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">AC_INIT([amhello], [1.0], [bug-automake@gnu.org])</span><br><span class="line">AM_INIT_AUTOMAKE([-Wall -Werror foreign])</span><br><span class="line">AC_PROG_CC</span><br><span class="line">AC_CONFIG_HEADERS([config.h])</span><br><span class="line">AC_CONFIG_FILES([</span><br><span class="line"> Makefile</span><br><span class="line"> src/Makefile</span><br><span class="line">])</span><br><span class="line">AC_OUTPUT</span><br></pre></td></tr></table></figure><p>AC_INIT等等Autotools预定义的宏，看一下括号里的东西大概就能明白是什么意思了吧：D当然，除了这几个之外还有很多其他功能强大的操作，可以自行查找相关信息。</p><h2 id="实例化构建系统"><a href="#实例化构建系统" class="headerlink" title="实例化构建系统"></a>实例化构建系统</h2><p>运行<code>autoreconf</code>命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">autoreconf --install</span><br><span class="line">configure.ac: installing './install-sh'</span><br><span class="line">configure.ac: installing './missing'</span><br><span class="line">configure.ac: installing './compile'</span><br><span class="line">src/Makefile.am: installing './depcomp'</span><br></pre></td></tr></table></figure><p>这个时候你就可以看到你的目录下面多出了<code>configrure</code>, <code>config.h.in</code>, <code>Makefile.in</code>以及<code>src/Makefile.in</code>这几个文件。但<code>autoreconf</code>的目的不仅仅是创建这几个文件，而是为了在你的系统里创建GNU Build System。</p><h2 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h2><p>下面你就可以用平时你在开源项目里用到的操作手法编译生成安装了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">./configure</span><br><span class="line">checking for a BSD-compatible install... /usr/bin/install -c</span><br><span class="line">checking whether build environment is sane... yes</span><br><span class="line">checking for gawk... no</span><br><span class="line">checking for mawk... mawk</span><br><span class="line">checking whether make sets $(MAKE)... yes</span><br><span class="line">checking for gcc... gcc</span><br><span class="line">checking for C compiler default output file name... a.out</span><br><span class="line">checking whether the C compiler works... yes</span><br><span class="line">checking whether we are cross compiling... no</span><br><span class="line">checking for suffix of executables...</span><br><span class="line">checking for suffix of object files... o</span><br><span class="line">checking whether we are using the GNU C compiler... yes</span><br><span class="line">checking whether gcc accepts -g... yes</span><br><span class="line">checking for gcc option to accept ISO C89... none needed</span><br><span class="line">checking for style of include used by make... GNU</span><br><span class="line">checking dependency style of gcc... gcc3</span><br><span class="line">configure: creating ./config.status</span><br><span class="line">config.status: creating Makefile</span><br><span class="line">config.status: creating src/Makefile</span><br><span class="line">config.status: creating config.h</span><br><span class="line">config.status: executing depfiles commands</span><br></pre></td></tr></table></figure><p>用了<code>configure</code>之后就可以看到<code>Makefile</code>和<code>src/Makefile</code>以及<code>config.h</code>了。下面直接<code>make</code>就好。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">make</span><br><span class="line">…</span><br><span class="line">src/hello</span><br><span class="line">Hello World!</span><br><span class="line">This is amhello 1.0.</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> program </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚16：如何构建零干扰CPU Benchmark环境</title>
      <link href="/2019/02/20/quickwords16-noisy-free-benchmark-env/"/>
      <url>/2019/02/20/quickwords16-noisy-free-benchmark-env/</url>
      
        <content type="html"><![CDATA[<h2 id="CPU性能测试对环境的要求"><a href="#CPU性能测试对环境的要求" class="headerlink" title="CPU性能测试对环境的要求"></a>CPU性能测试对环境的要求</h2><p>即便是硬件配置完全一样，操作系统相同，工作负载也相同的硬件平台，性能测试的结果也可能会因为各项配置的不同出现较大出入。<br><a id="more"></a></p><p>除了硬件的Hyper Thread/Turbo等特性之外，OS对进程的调度、中断等等也可能会产生影响。当然如果你要测试的工作负载还要和网络、存储交互的话，那么就还需要把他们放在一起综合考虑。</p><p>这里的讨论只限于Linux系统。</p><h2 id="几种手段"><a href="#几种手段" class="headerlink" title="几种手段"></a>几种手段</h2><h3 id="识别系统架构"><a href="#识别系统架构" class="headerlink" title="识别系统架构"></a>识别系统架构</h3><p>先看一下系统NUMA的情况，以及与要测试的工作负载相关的硬件资源分布情况。选用合理的测试配置（e.g. CPU核与网卡在同一个NUMA节点上）。</p><h3 id="配置scaling-governor"><a href="#配置scaling-governor" class="headerlink" title="配置scaling_governor"></a>配置<code>scaling_governor</code></h3><p>将<code>scaling_governor</code>配成<code>performance</code>是一个比较常用的手段。</p><p><code>echo performance &gt; /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</code></p><p>可以仅配置参与测试的CPU核(cpu*)，也可以全部配置。另有<code>cpupower</code>工具可以协助完成，相关资料可以自行<code>man cpupower</code>。</p><h3 id="关闭Hyper-Thread"><a href="#关闭Hyper-Thread" class="headerlink" title="关闭Hyper Thread"></a>关闭Hyper Thread</h3><p>Intel的CPU如果打开Hyper Thread，同一个CPU核中有很多流水线资源是两个Thread共享的。详情可以参见<code>Skylake微架构剖析</code>系列文章。如果能操作BIOS，最好就是直接关闭Hyper Thread。如果不方便操作BIOS或者只想关闭与测试有关的CPU核的Hyper Thread也可以用：</p><p>查看该CPU核的siblings列表：</p><p><code>/sys/devices/system/cpu/cpuN/topology/thread_siblings_list</code></p><p>看到另外那个CPU X之后：</p><p><code>echo 0 &gt; /sys/devices/system/cpu/cpuX/online</code></p><h3 id="关闭Turbo"><a href="#关闭Turbo" class="headerlink" title="关闭Turbo"></a>关闭Turbo</h3><p>并不是说Turbo不好，其实Trubo能比较显著地提高性能，但我们这里追求的是一个”纯净”的测试环境，需要尽量排除Trubo在频率升降过程中产生的误差干扰。</p><p><code>echo 1 &gt; /sys/devices/system/cpu/intel_pstate/no_turbo</code></p><h3 id="屏蔽内核干扰"><a href="#屏蔽内核干扰" class="headerlink" title="屏蔽内核干扰"></a>屏蔽内核干扰</h3><p>内核有些时候也会对测试结果产生干扰，比如用户/内核线程到参与测试的CPU核，或者给CPU分配网卡等设备的中断等等。这些都有相应的内核参数可以配置，在这里推荐一个简单点的工具：</p><p><a href="https://github.com/lpechacek/cpuset" target="_blank" rel="noopener">cpuset</a>:<a href="https://github.com/lpechacek/cpuset" target="_blank" rel="noopener">https://github.com/lpechacek/cpuset</a> </p><p>那么预留出参与测试的CPU核就比较简单了：</p><p><code>cset shield -c N1,N2 -k on</code></p><p>N1,N2就是CPU的编号。</p><p>查看和分配中断的方法可以参考<a href="https://decodezp.github.io/2019/01/22/test5-linux-network-performance-optimization/">这篇</a></p><p>执行要测试的负载可以用<code>taskset</code>也可以继续使用<code>cset</code> e.g.</p><p><code>cset shield --exec -- perf stat -r 10 &lt;cmd&gt;</code></p><h3 id="关闭ASLR"><a href="#关闭ASLR" class="headerlink" title="关闭ASLR"></a>关闭ASLR</h3><p>ASLR(Address Space Layout Randomization)是一种安全机制，但可能会引入性能下降。我本人没有太深入研究具体原因，但可以参考一些现有的资料e.g.<a href="https://benpfaff.org/papers/asrandom.pdf" target="_blank" rel="noopener">On the Effectiveness of Address-Space Randomization</a>。</p><blockquote><p>Implementations of WX on CPUs whose memory-management units lack a per-page execute bit, for example, current x86 chips, incur a significant performance penalty.</p></blockquote><p>关闭的方法：</p><p><code>echo 0 &gt; /proc/sys/kernel/randomize_va_space</code></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去7：筛法求素数Loop Unrolling性能优化实例</title>
      <link href="/2019/02/19/test7-prime-opt/"/>
      <url>/2019/02/19/test7-prime-opt/</url>
      
        <content type="html"><![CDATA[<h2 id="筛法求素数"><a href="#筛法求素数" class="headerlink" title="筛法求素数"></a>筛法求素数</h2><p>最近拿到一段筛法求素数的代码，希望能够在不改变原有算法的基础上提高性能。<br><a id="more"></a></p><p>关于筛法求素数的算法，网络上有很多介绍。算法之间的效率存在差异，但我们的重点不在这里，而是如何在不改动现有算法的前提下提升性能。</p><blockquote><p>关于不同筛法算法可以参见<a href="https://www.cnblogs.com/grubbyskyer/p/3852421.html" target="_blank" rel="noopener">这里</a>，这段程序里使用的是埃拉托斯特尼筛法。</p></blockquote><p>核心代码段：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">count = <span class="number">0</span>; </span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">2</span>; i &lt;= <span class="number">8192</span>; i++) &#123;</span><br><span class="line">    flags[i] = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">2</span>; i &lt;= <span class="number">8192</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (flags[i]) &#123;</span><br><span class="line">               <span class="comment">/* remove all multiples of prime: i */</span></span><br><span class="line"><span class="keyword">for</span> (k=i+i; k &lt;= <span class="number">8192</span>; k+=i) &#123;</span><br><span class="line">    flags[k] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">count++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完整代码在：</p><p><code>wget https://raw.githubusercontent.com/llvm-mirror/test-suite/master/SingleSource/Benchmarks/Shootout/sieve.c</code></p><p>其实是<code>LLVM</code>编译器的性能测试代码。</p><h2 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CPU: Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHz</span><br><span class="line">Hyper-thread:OFF</span><br><span class="line">Power-governor: Performance</span><br><span class="line">GCC: 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC)</span><br><span class="line">GCC option: -O3</span><br></pre></td></tr></table></figure><h2 id="诊断"><a href="#诊断" class="headerlink" title="诊断"></a>诊断</h2><p>先运行一下原有代码看看时间：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gcc sieve.c -O3 -o sieve</span><br><span class="line">time -p ./sieve</span><br><span class="line"></span><br><span class="line">Count: 1028</span><br><span class="line">real 3.34</span><br><span class="line">user 3.34</span><br><span class="line">sys 0.00</span><br></pre></td></tr></table></figure><p>简单想象一下代码流程：</p><ul><li>处理的数据是8K Byte(char flags[])，相对于32K的L1缓存不算什么数据量，所以数据缓存似乎问题不大</li><li>生成的二进制文件也不大，指令缓存也没太大压力</li><li>前端这边处理的主要是带分支的循环，内层循环就算还好吧…但外层循环中有个if分支判断</li><li>涉及到这个判断，因为素数的出现/分布没太大规律，所以对CPU来说，这个分支判断结果相当于是随机的，有可能会影响前端流水线的性能</li></ul><p>然后用我们之前介绍的<a href="https://decodezp.github.io/2019/02/14/quickwords15-toplev/">Top-down方法和toplev工具</a>看看实际测试的情况：</p><p><code>./toplev.py -v --no-desc  -l1 /root/perfcontest/sieve</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Using level 1.</span><br><span class="line"><span class="meta">#</span> 3.4-full on Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHz</span><br><span class="line">perf stat -x\; --no-merge -e '&#123;cpu/event=0xc2,umask=0x2/,cpu/event=0xe,umask=0x1/,cpu/event=0xd,umask=0x3,cmask=1/,cpu/event=0x9c,umask=0x1/,cycles&#125;' /root/perfcontest/sieve</span><br><span class="line">Count: 1028</span><br><span class="line">FE             Frontend_Bound:          38.45 +-     0.00 % Slots       &lt;==</span><br><span class="line">BAD            Bad_Speculation:         16.45 +-     0.00 % Slots      </span><br><span class="line">BE             Backend_Bound:            8.92 +-     0.00 % Slots below</span><br><span class="line">RET            Retiring:                36.19 +-     0.00 % Slots below</span><br><span class="line">               MUX:                    100.00 +-     0.00 %</span><br></pre></td></tr></table></figure><p>基本上可以看到是前端Bound了，同时分支预测里出现了比较多的<code>Bad_Speculation</code>。</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>OK，先用个简单的方法处理一下分支：</p><p>结合业务的话，素数越到后面分布是越稀松的，所以外层循环中的那个判断应该大部分时间是false。所以，先套个likely/unlikely。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> likely(x)       __builtin_expect((x),1)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> unlikely(x)     __builtin_expect((x),0)</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i])) &#123;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>编译之后看一下时间：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">time -p ./sieve</span><br><span class="line">Count: 1028</span><br><span class="line">real 3.08</span><br><span class="line">user 3.08</span><br><span class="line">sys 0.00</span><br></pre></td></tr></table></figure><p>有些许提升，不过不太明显。如果此时再用<code>toplev</code>测试一下，可以发现分支预测的改善并不可观。</p><p>那么如何改善分支预测呢？最好的办法就是不要有分支；或者，如果完全没有不可能的话，就让分支出现规律性；如果这样也不行的话，就减少分支；如果减少也不可能的话，就搞大乱序并发。</p><p>对于我们这个算法来说，判断每个数字的标志位并做后续的置位是算法的要求。提升规律性的话，也没有什么特别好的办法（至少我没想出来）， 那就只能用最后一种办法了…</p><p>把循环展开，提升流水线并行性。</p><p>展开16级还不算那么激进吧…同时内层循环也可以适当展开…</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i=<span class="number">2</span>; i &lt;= <span class="number">8191</span>; i = i + <span class="number">16</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i; k &lt;= <span class="number">4096</span>; k+=(<span class="number">7</span> * i)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">        flags[k + i] = <span class="number">0</span>;</span><br><span class="line">        flags[k + (<span class="number">2</span> * i)] = <span class="number">0</span>;</span><br><span class="line">        flags[k + (<span class="number">3</span> * i)] = <span class="number">0</span>;</span><br><span class="line">        flags[k + (<span class="number">4</span> * i)] = <span class="number">0</span>;</span><br><span class="line">        flags[k + (<span class="number">5</span> * i)] = <span class="number">0</span>;</span><br><span class="line">        flags[k + (<span class="number">6</span> * i)] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count0++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">1</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">2</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">1</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count1++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">2</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">4</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">2</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count2++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">3</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">6</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">3</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count3++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">4</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i+<span class="number">8</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">4</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count4++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">5</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">10</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">5</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count5++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">6</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">12</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">6</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count6++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">7</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">14</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">7</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count7++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">8</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i+<span class="number">16</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">8</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count8++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">9</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">18</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">9</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count9++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">10</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">20</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">10</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count10++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">11</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">22</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">11</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count11++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">12</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i+<span class="number">24</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">12</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count12++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">13</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">26</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">13</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count13++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">14</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">28</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">14</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count14++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">15</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">30</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">15</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count15++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">"Count: %d\n"</span>, count0 + count1 + count2 + \</span><br><span class="line">                         count3 + count4 + count5 + \</span><br><span class="line">                         count6 + count7 + count8 + \</span><br><span class="line">                         count9 + count10 + count11 + \</span><br><span class="line">                         count12 + count13 + count14 + \</span><br><span class="line">                         count15);</span><br></pre></td></tr></table></figure><p>先直接刷一下时间：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">time -p ./sieve</span><br><span class="line">Count: 1028</span><br><span class="line">real 1.56</span><br><span class="line">user 1.56</span><br><span class="line">sys 0.00</span><br></pre></td></tr></table></figure><p>提升了120%</p><p>再用<code>toplev</code>看一下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">./toplev.py -v --no-desc  -l1 /root/perfcontest/sieve</span><br><span class="line">Using level 1.</span><br><span class="line"><span class="meta">#</span> 3.4-full on Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHz</span><br><span class="line">perf stat -x\; --no-merge -e '&#123;cpu/event=0xc2,umask=0x2/,cpu/event=0xe,umask=0x1/,cpu/event=0xd,umask=0x3,cmask=1/,cpu/event=0x9c,umask=0x1/,cycles&#125;' /root/perfcontest/opt1</span><br><span class="line">Count: 1028</span><br><span class="line">FE             Frontend_Bound:          11.60 +-     0.00 % Slots below</span><br><span class="line">BAD            Bad_Speculation:          3.30 +-     0.00 % Slots below</span><br><span class="line">BE             Backend_Bound:            8.43 +-     0.00 % Slots below</span><br><span class="line">RET            Retiring:                76.68 +-     0.00 % Slots       &lt;==</span><br><span class="line">               MUX:                    100.00 +-     0.00 %</span><br></pre></td></tr></table></figure><p>瓶颈已经不在分支预测上了。</p><p>用<code>perf stat</code>看一下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@server-P1 perfcontest]# perf stat ./sieve</span><br><span class="line">Count: 1028</span><br><span class="line"></span><br><span class="line"> Performance counter stats for './opt1':</span><br><span class="line"></span><br><span class="line">       2334.081187      task-clock (msec)         #    1.000 CPUs utilized          </span><br><span class="line">                 7      context-switches          #    0.003 K/sec                  </span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec                  </span><br><span class="line">               141      page-faults               #    0.060 K/sec                  </span><br><span class="line">     5,355,895,762      cycles                    #    2.295 GHz                    </span><br><span class="line">    19,038,809,322      instructions              #    3.55  insn per cycle         </span><br><span class="line">     4,209,500,410      branches                  # 1803.494 M/sec                  </span><br><span class="line">        10,114,763      branch-misses             #    0.24% of all branches        </span><br><span class="line"></span><br><span class="line">       2.334590616 seconds time elapsed</span><br></pre></td></tr></table></figure><p>branch-misses占比很小，同时IPC也在3.55，已经接近理论最大值(4)。</p><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>仅仅调了一个小时，应该还有继续优化的空间，比如利用PGO和SIMD指令。这个留在后续尝试。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> CPU </tag>
            
            <tag> performance </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>《居家男人》</title>
      <link href="/2019/02/15/thoughts5-family-man/"/>
      <url>/2019/02/15/thoughts5-family-man/</url>
      
        <content type="html"><![CDATA[<p>大约在2010年左右的时候，我会经常在PPS这种视频流软件上面看尼古拉斯凯奇的电影。他早期的一些作品还是令人印象深刻。相较于那些有名的动作片，《居家男人》应该只是一部家庭剧小品，但却成了我这些年重复播放最多的他的片子。<br><a id="more"></a></p><p>故事很普通，两个原本相爱的大学生在毕业时各奔前程，十几年后，一个成了家住曼哈顿上东区的金融巨子，一个是某律所的女合伙人，事业上都很成功，却都没有组建家庭。在圣诞这天，凯奇有了一次体验家庭生活的机会——如果毕业时他没有登上去往伦敦的飞机在巴克莱实习，而是选择与女主厮守，那么十几年后他们的家庭生活将会是什么样子。</p><p>当然有纽约一般中产的琐碎和烦恼，以及一儿一女等种种家庭生活的幸福。电影还是在宣扬“家庭幸福比世俗成功更重要”的主题，让人们认清什么是真正珍贵的东西。我对这种类似“说教”的信息并不反感，但这绝不至于让我把这部片子反复观看，甚至我个人认为，这应该是比《真爱至上》更好的圣诞电影。</p><p>之所以能这样认为，纯粹是因为观看这部影片时的私人体验。这种体验并不在于电影的镜头、布景、台词这些评判一部电影的“指标”，而仅仅在于片中场景的似曾相识，以及晏殊赋予”似曾相识“的另外一重意境——无可奈何。</p><p>面对生活中的各种取舍的时候，我们似乎有一个默认的“优先级”。这里面，个人的发展似乎是不言自明的第一位。因为逻辑是非常清晰的：你爱我，那么你会希望我好，你支持我追求我的发展，自然就是对我好。至于是否会为此失去其他，那倒不重要了。一旦有一方亮出这张牌，其他所有的理由都要退避三舍。这张牌往往还有一些别的登场方式，比如”这是为了我们共同的未来”、“这是我的梦想”等等。</p><p>影片的设定也是如此。凯奇为了追求自己的金融”梦”义无反顾地与女主在机场分道扬镳。登机前他向女主也基本上讲了一遍上面的逻辑，最后他说：</p><blockquote><p>在伦敦的一年并不会改变什么。</p></blockquote><p>正是这句话让我有了一种无可奈何的情状。一是因为世事难料，一是因为你无法指责别人的健忘。而更重要的是，即便你做了万全的计划，即便你为此舍弃了你自认为需要舍弃的东西，但最终真正能实现计划的人，却并没有多少。这和你的能力，你的决心以及外界的环境都没有关系。</p><p>因为一定要舍弃什么重要的东西才能实现的计划，要么是舍弃的东西并不那么重要，要么是这个计划并不值得实现。舍弃不重要的东西，不需要用这么”宏大“的计划作为说辞；而一旦没有了真正重要的东西，也很难“身残志坚”地应对挑战。这很像你打算爬上珠峰，却要先砍断一条腿一样。身处其中的人往往很难看清这一点，但拉开一段时间的距离，很快就能看清楚。</p><p>而所谓”为了我好”的逻辑，只不过是没有根据的臆想。往往在做这种幻梦的时候，我们还不够成熟，却喝了太多夹杂了催熟添加剂的鸡汤。归根到底，是没有真正地认识生活——生活的途径，永远不止一条。</p><p>不过还好，我虽然也有自己的安排，但似乎没有这种权衡和取舍，反而得到了所有想要的。理智给出的方案在很多时候确实是最优解，但首先要确保的是理智处在最优的状态。我从来不做难做的选择题，我宁愿在这种问题上交白卷，因为我知道“割舍”这个词其实就是“自戕”的另外一种写法，而你永远不会知道这张卷子后面哪里能找到一个加分题。</p><p>影片中凯奇得偿所愿，自己住在全球最贵的豪华公寓内俯瞰芸芸众生。我很喜欢当夜幕降临，他穿着条内裤独自躺在床上的片段，此时他的卧室因为刻意的灯光调整显得狭小而逼仄，我也曾经以同样的dress code，同样的姿势，躺在这样的房间里。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚15：Top-Down性能分析方法资料及Toplev使用</title>
      <link href="/2019/02/14/quickwords15-toplev/"/>
      <url>/2019/02/14/quickwords15-toplev/</url>
      
        <content type="html"><![CDATA[<h2 id="Top-down-Microarchitecture-Analysis-Method-TMAM-资料"><a href="#Top-down-Microarchitecture-Analysis-Method-TMAM-资料" class="headerlink" title="Top-down Microarchitecture Analysis Method(TMAM)资料"></a>Top-down Microarchitecture Analysis Method(TMAM)资料</h2><p>之前介绍过TMAM的具体内容，在这里对网络上相关的信息和资料做一个汇总：</p><p><a href="https://software.intel.com/en-us/vtune-amplifier-help-tuning-applications-using-a-top-down-microarchitecture-analysis-method" target="_blank" rel="noopener">Tuning Applications Using a Top-down Microarchitecture Analysis Method</a><br><a id="more"></a></p><p><a href="http://www.cs.technion.ac.il/~erangi/TMA_using_Linux_perf__Ahmad_Yasin.pdf" target="_blank" rel="noopener">Top-down Microarchitecture Analysis through Linux perf and toplev tools</a></p><p><a href="https://ieeexplore.ieee.org/document/6844459/metrics#metrics" target="_blank" rel="noopener">A Top-Down method for performance analysis and counters architecture</a></p><p><a href="https://doc.itc.rwth-aachen.de/download/attachments/28344675/08.Performance_Analysis_in_a_Nutshell.pdf?version=1&amp;modificationDate=1480665136000&amp;api=v2" target="_blank" rel="noopener">Performance_Analysis_in_a_Nutshell</a></p><p><a href="https://indico.cern.ch/event/280897/contributions/1628888/attachments/515367/711139/Top_Down_for_CERN_2nd_workshop_-_Ahmad_Yasin.pdf" target="_blank" rel="noopener">Top Down Analysis Never lost with Xeon® perf. counters</a></p><p><a href="https://dyninst.github.io/scalable_tools_workshop/petascale2018/assets/slides/TMA%20addressing%20challenges%20in%20Icelake%20-%20Ahmad%20Yasin.pdf" target="_blank" rel="noopener">How TMA* Addresses Challenges in Modern Servers and Enhancements Coming in IceLake</a></p><p>当然还有一些其他的相关信息，不过上面几个都可以覆盖（其实已经有点过量了）。</p><h2 id="Toplev使用"><a href="#Toplev使用" class="headerlink" title="Toplev使用"></a>Toplev使用</h2><p><code>toplev</code>是一个基于<code>perf</code>和TMAM方法的应用性能分析工具。从之前的<a href="https://decodezp.github.io/2019/01/27/quickwords13-tma/">介绍文章</a>中可以了解到TMAM本质上是对CPU Performance Counter的整理和加工。取得Performance Counter的读数需要<code>perf</code>来协助，对读数的计算进而明确是Frondend bound还是Backend bound等等。</p><p>在最终计算之前，你大概需要做三件事：</p><ul><li>明确CPU型号，因为不同的CPU，对应的PMU也不一样</li><li>读取TMAM需要的<code>perf event</code>读数</li><li>按TMAM规定的算法计算，具体算法在这个<a href="https://share.weiyun.com/5jNsb6o" target="_blank" rel="noopener">Excel表格</a>里</li></ul><p>这三步可以自动化地由程序来做。本质上<code>toplev</code>就是在做这件事。</p><p><code>toplev</code>的<a href="https://github.com/andikleen/pmu-tools" target="_blank" rel="noopener">Github地址</a>：<a href="https://github.com/andikleen/pmu-tools" target="_blank" rel="noopener">https://github.com/andikleen/pmu-tools</a></p><p>另外补充一下，TMAM作为一种<code>Top-down</code>方法，它一定是分级的。通过上一级的结果下钻，最终定位性能瓶颈。那么<code>toplev</code>在执行的时候，也一定是包含这个“等级”概念的。</p><p>下面是<code>toplev</code>使用方法的资料：</p><p><a href="https://github.com/andikleen/pmu-tools/wiki/toplev-manual" target="_blank" rel="noopener">toplev manual</a></p><p><a href="http://halobates.de/blog/p/262" target="_blank" rel="noopener">pmu-tools, part II: toplev</a></p><p>基本上都是由<code>toplev</code>的开发者自己写的，可以作为一个Quick Start Guide。</p><blockquote><p><code>toplev</code>仅针对系统瓶颈是CPU的场景，除此之外仍需要使用其他方法，如<code>pcm</code> tool。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚14：Skylake微架构(Microarchitecture)剖析(5)</title>
      <link href="/2019/02/03/quickwords14-skylake-pipeline-5/"/>
      <url>/2019/02/03/quickwords14-skylake-pipeline-5/</url>
      
        <content type="html"><![CDATA[<h2 id="Instruction-Decode-Queue-IDQ"><a href="#Instruction-Decode-Queue-IDQ" class="headerlink" title="Instruction Decode Queue(IDQ)"></a>Instruction Decode Queue(IDQ)</h2><p>IDQ也叫Allocation Queue(AQ)，也有时候会写成是Decode Queue。解码完成的uops在进入后端之前需要先在IDQ中做一下缓冲。作为一个”缓冲队列”，主要作用是将前端解码可能引入的流水线”气泡(bubbles)“消化掉，为后端提供稳定的uops供应(目标是6uop/cycle)。<br><a id="more"></a></p><p>Skylake的IDQ最大可以存放64个uops/thread，比Broadwell的28个多一倍还多。这些uop在IDQ中除了排一下队之外，还会被Loop Stream Detector(LSD)扫描一遍，用来发现这些uop是不是来自于一个循环。</p><h3 id="Loop-Stream-Detector-LSD"><a href="#Loop-Stream-Detector-LSD" class="headerlink" title="Loop Stream Detector(LSD)"></a>Loop Stream Detector(LSD)</h3><p>如果在IDQ中能被发现存在循环体uop，那么在下一次循环的时候，就不需要去重新解码这些循环体生成的uop，而是直接由LSD提供uops。这便可以省去指令fetch、解码、读uop cache、分支预测等所有之前的步骤，并且能进一步减少缓存占用。当然，当LSD起作用的时候，整个前端都是处于Disabled的状态。</p><p>Skylake的LSD需要在IDQ的长度（64uop）内发现循环，所以，循环体还是尽量紧凑一点吧:D</p><h2 id="后端（Backend）"><a href="#后端（Backend）" class="headerlink" title="后端（Backend）"></a>后端（Backend）</h2><p><img src="https://en.wikichip.org/w/images/thumb/6/64/skylake_rob.svg/450px-skylake_rob.svg.png" alt=""></p><p>还是首先介绍一下这个部分是否有别的名字。在有些文档里后端又直接被称为<code>Execution Engine</code>。后端的主要任务当然就是执行前端解码出来的这些uop。但后端和前端的设计都在围绕着“如何提高指令的并行性”来设计和优化。</p><p>在Skylake架构中，IDQ以最大6uop/cycle的速度将uop送入Re-order Buffer，后端的处理在Re-order Buffer中正式开始。</p><h2 id="Out-of-order-OOO-Execution-Engine"><a href="#Out-of-order-OOO-Execution-Engine" class="headerlink" title="Out-of-order(OOO)Execution/Engine"></a>Out-of-order(OOO)Execution/Engine</h2><p>先讲一下OOO（乱序）以便对后端的执行有一个整体的把握。</p><p>我们的程序虽然是按顺序编写的指令，但CPU并不（一定）会按相同的方式执行。为了提升整体效率，CPU采用的是乱序执行的方式。从一个“窗口”范围内选取可以执行的指令执行，并且这些操作对用户透明，在程序编写者的角度看来仍是在按他编写的指令顺序执行。</p><blockquote><p>从根本上来讲，OOO是用”数据流（Data flow）”的角度来看待程序，而非程序员的“指令流”视角。</p></blockquote><p>指令的目的就是以一种特定的方式操纵存在于内存/缓存中的数据，引起数据的变化，其实这就是我们通常所说的“写程序”。只不过这是人类习惯的逻辑方式，在机器看来并不一定高效。</p><p><img src="https://s2.ax1x.com/2019/02/03/kGeQiV.jpg" alt="截图出自Computer Architecture 2011 – out-of-order execution (lec 7) 1 Computer Architecture Out-of-order execution By Dan Tsafrir, 11/4/2011 Presentation"></p><p>在上图例子中，需要执行左上角的六个计算指令。<code>In-order execution</code>是假设完全按照程序顺序执行这六个指令的耗时。下面的`In-order(superscalar3)是合并了一些可以并行执行的指令的耗时。</p><p>因为指令(2)中的<code>r1</code>要依赖指令(1)的结果，所以指令(2)只能等(1)执行结束再执行。而本来可以并行执行的(3)(4)也因为要保证In-order顺序而只能一同放在(1)之后执行。</p><p>但从左下角的<code>Data flow</code>的角度来看，其实我们并不需要按照指令顺序运行程序：指令(2)完全可以放在后面执行，并重新安排并行计算顺序。这样就又节省了执行所需的时间。</p><p>OOO选择可执行指令的依据是：</p><ul><li>不依赖未执行指令操纵的数据</li><li>有可用的执行资源</li></ul><p>为了尽可能让进入后端的指令满足这两个条件，OOO采用了一系列的组件和技术。在后面的章节中将会进行介绍。</p><p><img src="http://hpca23.cse.tamu.edu/taco/utsa-www/cs5513-fall07/basic-concept.gif" alt=""></p><p>上图是一个OOO的概念示意图。前端输出给后端的都是顺序指令流，后端在一个窗口范围中选择可以执行的指令进行乱序执行。这里面没有强调的是，最终指令退出(retire)的顺序仍是按照程序的顺序。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序员学英语的几点实用经验</title>
      <link href="/2019/01/31/how-to-learn-english/"/>
      <url>/2019/01/31/how-to-learn-english/</url>
      
        <content type="html"><![CDATA[<p>学习英语当然要靠不断的练习，但同样的练习时间往往效果却大相径庭。以下是我结合自己的经历总结的一些经验和方法，希望能帮助大家提高学习英语的效率。</p><h2 id="Rubbish-in-rubbish-out"><a href="#Rubbish-in-rubbish-out" class="headerlink" title="Rubbish in, rubbish out"></a>Rubbish in, rubbish out</h2><p>把自己想象成一个处理英文的黑盒，输入就是听读，输出就是说写。和人工智能训练模型需要优质的标签数据一样，学习英语也需要优质的输入才能达到良好的学习效果。</p><p>在程序员的领域，最直接的优质的英文材料就是经典的英文原版技术书籍。编写这些书籍的大师不但是技术领域的巨擘，同时也是操纵语言的大师，他们的书籍往往最是简洁明快，逻辑清晰。<br><a id="more"></a></p><h2 id="复写"><a href="#复写" class="headerlink" title="复写"></a>复写</h2><p>但如果你是刚开始决定提高自己的英文水平，看这些书籍其实很容易产生挫败感。我的建议是，找自己这个领域最著名的开源项目，一般这种项目都会有很好的文档(教程)支持。这个项目的教程就是你英文的入门材料。</p><p>但不是说能看着教程，自己找了台电脑跟着操作了一遍就算学会了。在有了实际操作经验之后，你其实已经知道这一节教程内容是要告诉你什么了，这个时候把教程的窗口最小化，打开你最喜欢的文字编辑器，将刚刚教程的内容复写一遍。</p><p>就是要有那种“明明知道要表达什么，但就是忘了刚才教程里是怎么写的了”的焦灼感。</p><p>这种时候先用自己的“初中英语”硬把坑填上。等这一节都复写完成之后，把教程的窗口重新最大化，再看一遍，看看刚刚自己胡说八道的地方教程都是怎么写的，默默记下来，然后重新把窗口最小化，修改刚刚自己复写的内容。</p><p>别指望看了第二遍就能全部记住，重复这个过程，直到完全一致。注意单复数，be动词时态，以及a/an/the定冠词的用法。</p><p>慢慢你就会发现英语的表达，尤其是在技术领域，就那么几个套路。</p><h2 id="利用Google"><a href="#利用Google" class="headerlink" title="利用Google"></a>利用Google</h2><p>在练习了一段时间的复写之后，在工作中遇到开发或技术上的问题，不要用百D或是中文搜索，而是在Google上用英文搜索(bing也不行，只建议用Google)。</p><p>搜索栏里填什么关键词随便你，但最开始很可能找不到你要搜索的问题的答案。</p><p>尝试不断更换关键词，多往后翻几页，直到找到那个你认为你最需要的页面。这个时候不要Ctrl+C/V把页面里的代码一复制再来个git commit就完了，重新回到Google，重新调整你的关键词，用最短，最少的关键字让这个页面出现在搜索结果的第一页第一行。</p><p>能让自己的表达逐渐精确，就是语言能力的提升。</p><h2 id="建立全面的信息关联"><a href="#建立全面的信息关联" class="headerlink" title="建立全面的信息关联"></a>建立全面的信息关联</h2><p>两个人面对面说话，所传达的全部信息，纯粹语言的内容只能占30%。剩下的信息是由肢体语言、表情、语调语速传递的。</p><p>为什么很多人学了半天仍然觉得语言实际应用能力提高不大，就是因为只冲着那30%去的，实际能传达出要传达的20%就算不错了。</p><p>关键就是在于，没有将一句话放到实际中去关联场景，而大脑关联学习或关联记忆的效率是最高的。</p><p>在教程和搜索上小有成就了之后，你需要学习真正的语言。将语言划分为“听说读写”四项没有错，但如果你练习听力就只塞一个耳机那是效率很低的学习方法。</p><p>打开一个经典的技术视频，或者你感兴趣的TED演讲，不要关注演讲者说的你是不是都能听懂，而是关注演讲本身，关注他的肢体语言、关注观众的反馈、关注他如何使用他的PPT，关注他是如何表达，语言本身只是这一切的副产品。你的大脑会自己将这些都分门别类罗缕纪存。</p><p>之后自己尽最大的努力将要点复述(用嘴说)一遍，回想当时的场景，回想演讲者的动作和表情，回想他的语调和语速，回想当时的摄像机的角度和PPT的内容。然后把你能想到整场演讲的逻辑和每一环节的中心思想写下来。返回视频，和复写一样，对照修改，直到自己满意。</p><h2 id="输出的时候放空大脑"><a href="#输出的时候放空大脑" class="headerlink" title="输出的时候放空大脑"></a>输出的时候放空大脑</h2><p>最后一点想说的是，无论是说还是写，很多人遇到的问题是，英文输出的过程多了”翻译”这个步骤。先想中文的意思，再将这个意思翻译成英文，再转换为文字或者口语。而对听和读，也是要翻译一遍，大脑再去处理中文的意思。</p><p>这是很没效率的事情，就像Linux收发包要对数据报文做多次拷贝一样，很有可能成为你整个系统的瓶颈。这里放空大脑的意思和”零拷贝”技术十分类似，就是不要有任何翻译的过程。在练习的时候，不要用中文去想你要表达什么，不要让大脑中出现任何中文的”声音”，不要给你对面的哥们做同声传译。最开始可能不容易做到，但要不断强调这个意识。</p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>几句话说清楚13：什么是Top-Down性能分析方法</title>
      <link href="/2019/01/27/quickwords13-tma/"/>
      <url>/2019/01/27/quickwords13-tma/</url>
      
        <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>前几篇连续介绍了一些Skylake微架构的内容（还没有结束，还会继续填坑），主要目的并不是要对读者开启名词或者概念的Flood攻击，而是为了方便读者以后可以“有理有据”地进行软件的性能优化。<br><a id="more"></a></p><p>但不能否认的是，CPU微架构的学习还是有比较陡峭的曲线的。是不是一定要非常精通微架构之后，才能进行软件的性能优化呢？从我自己的经验来说，并非如此。</p><p>性能优化虽然是一门专业的技术，但它和其他所有技术一样，也有自己的整体思想和方法论。首先对其方法论有一个大概的认识之后，再去精研细节，在我看来是一个比较有效率的学习方法。</p><p>《三国志》诸葛亮传中曾载：</p><blockquote><p>亮在荆州，以建安初与颍川石广元、徐元直、汝南孟公威等俱游学。三人务于精熟，而亮独观其大略。</p></blockquote><p>先贤轨物范世在前，古今一辙，今日正当观其荦荦大端者。</p><h2 id="Top-down-Microarchitecture-Analysis-TMA"><a href="#Top-down-Microarchitecture-Analysis-TMA" class="headerlink" title="Top-down Microarchitecture Analysis(TMA)"></a>Top-down Microarchitecture Analysis(TMA)</h2><p>Top-down可以翻译成“自顶向下”，经常做一些有可有无的PPT架构设计的同学应该对这类词汇比较熟悉。当然也有一些“分析方法”喜欢用这个词。</p><p>TMA就是一套基于CPU微架构的“自顶向下”分析的方法。我对这个词的理解倒和具体的方位无关，而是紧紧抓住目标的一种思维方式。</p><p>这里就不得不提一下我的初中物理老师，她教给我们的一种解题方法似乎就可以概括为“自顶向下”，简单在这里介绍一下，希望这一类比能在后面叙述时帮助理解。</p><p>比如有一道很复杂的题目，题干很长，但最终的问题就是求密度。那么前面的东西可以先忽略，仅仅针对“密度”来说，那么就需要知道质量和体积。假设体积是已知的，那么问题“转化”为如何知道质量。质量等于匀速运动时的滑动摩擦力除以滑动摩擦系数。在题干中找出这些条件，或继续进行类似的推导。虽然最终在列公式时需要“反向”求得最终的密度，但思考方式是先从密度开始的。</p><p>基本上就是这个道理。同如何“求得密度”类似，TMA解决的问题就是如何“求得瓶颈”。</p><p>那么为了求得瓶颈，其实就是首先看CPU流水线总体上有多少时间没有真正在处理计算任务（aka流水线利用率）。继而，观察没有处理计算任务，是因为各方面没有协调好导致流水线空转(Stalled)还是虽然没有空转(Non-stalled)但却没有进行实际的计算（e.g.分支预测失败aka指令没有最终retired）。</p><p><img src="https://software.intel.com/sites/default/files/did_feeds_images/6E3B86B7-8072-4E6A-9E27-0CD21446ACB1/6E3B86B7-8072-4E6A-9E27-0CD21446ACB1-imageId=9681762B-D017-4429-B60E-E66D0E98B6AB.gif" alt=""></p><p>然后针对空转，看看是前端的原因还是后端的原因。然后再具体看是前/后端哪一个具体项目导致的空转，进而定位系统瓶颈。当然最终还是依赖PMU counter提供的基础数据。</p><h2 id="Pipeline-slots"><a href="#Pipeline-slots" class="headerlink" title="Pipeline slots"></a>Pipeline slots</h2><p>Pipeline slots是一个经常出现的概念。它是流水线利用率的一种抽象表达，并没有实际的硬件或软件对应于这一概念。这里尝试解释一下：想象一条组装汽车的流水线，一开始时，很多汽车外壳被“挂”在了一个钩子上面，这个钩子其实就可以类比为一个Pipeline slots，只不过这个slot里装的是一条指令，uop，确切地说。</p><p>这些汽车壳子在以一个均匀的速度往前走，进而在不同的流水线阶段完成不同的工作，最后组装成一台完整的汽车。向前走的速度可以类比为CPU的Clock cycle，最终下线出厂就是指令retired。只不过有可能这些slot有些挂上了汽车外壳，有些还是空的（指令没取到），有些挂的，是没有用的废品壳子（分支预测失败）。</p><p>在上图中，<code>Uop allocate</code>其实就是说Uop有没有挂到Pipeline slot中的意思。</p><h2 id="分析指标（Metric）"><a href="#分析指标（Metric）" class="headerlink" title="分析指标（Metric）"></a>分析指标（Metric）</h2><p>OK，有了总体的方法之后，下面的工作就是如何再量化一下了。比如如何确定流水线的利用率，如何确定是前端Stall还是后端Stall，判断的依据和计算方法，设定的阈值等等。这些不是本文的重点，但在后续介绍完Skylake微架构后详细介绍。心急的同学可以先下载Intel总结好的<a href="https://share.weiyun.com/5jNsb6o" target="_blank" rel="noopener">Excel表格</a>。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去6：Linux网络性能调优方法（补遗）</title>
      <link href="/2019/01/24/test6-linux-network-performance-optimization-2/"/>
      <url>/2019/01/24/test6-linux-network-performance-optimization-2/</url>
      
        <content type="html"><![CDATA[<h2 id="没提到的"><a href="#没提到的" class="headerlink" title="没提到的"></a>没提到的</h2><p><a href="https://decodezp.github.io/2019/01/22/test5-linux-network-performance-optimization/">上一篇</a>内容中介绍了一些Linux网络协议栈的调优方法，但遗漏了一些可以发挥重要作用的方法，在这一篇中补充一下。<br><a id="more"></a></p><h2 id="net-rx-action-budget"><a href="#net-rx-action-budget" class="headerlink" title="net_rx_action budget"></a><code>net_rx_action</code> budget</h2><p>这个参数可以决定NAPI可以占用多少CPU的处理能力，可以调到900</p><p><code>sysctl -w net.core.netdev_budget=900</code></p><h2 id="netdev-max-backlog"><a href="#netdev-max-backlog" class="headerlink" title="netdev_max_backlog"></a><code>netdev_max_backlog</code></h2><p><code>sysctl -w net.core.netdev_max_backlog=65535</code></p><h2 id="dev-weight"><a href="#dev-weight" class="headerlink" title="dev_weight"></a><code>dev_weight</code></h2><p><code>sysctl -w net.core.dev_weight=1024</code><br>这个参数在实际测试中影响也比较大</p><h2 id="ip-early-demux"><a href="#ip-early-demux" class="headerlink" title="ip_early_demux"></a><code>ip_early_demux</code></h2><p><code>sysctl -w net.ipv4.ip_early_demux=0</code><br>这个参数根据实际测试结果调整。改为0或1。</p><h2 id="关于RPS"><a href="#关于RPS" class="headerlink" title="关于RPS"></a>关于RPS</h2><p>在前面提到需要关闭RPS功能，但在实际测试中发现设定相应的CPU Mask还是能对性能有比较大的提升，具体原因在进一步挖掘的过程中，当前需要实际测试找出最适合的配置方法。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> network </tag>
            
            <tag> performance </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去5：Linux网络性能调优方法</title>
      <link href="/2019/01/22/test5-linux-network-performance-optimization/"/>
      <url>/2019/01/22/test5-linux-network-performance-optimization/</url>
      
        <content type="html"><![CDATA[<h2 id="换换口味"><a href="#换换口味" class="headerlink" title="换换口味"></a>换换口味</h2><p>老搞DPDK的人有一个毛病就是怎么也看不上内核网络，又是中断又是拷贝的，实在没有一脚地板油CPU直接100%炸街来得爽快。另外作为一个软件性能优化的“硬核”玩家，是很看不上内核这种改改参数，调调设置的玩法的。不过…既然自己主动跳了个大坑，该调内核性能的时候还是要调的…所以今天就换换口味，看看在Linux下通过配置调优网络性能怎么搞。</p><a id="more"></a><h2 id="了解你的设备"><a href="#了解你的设备" class="headerlink" title="了解你的设备"></a>了解你的设备</h2><p>性能调优只有一个任务，就是充分发挥现有资源的能力。因此，了解自己的设备，就成了一切的前提。</p><p>硬件软件的细节难以遍数，若从细处着手…傻子才从细处着手吧。在网络方面，需要从全局上搞清楚这样几个问题：</p><ul><li>网卡什么型号</li><li>网卡有几个口</li><li>每个口有几个队列</li><li>有什么硬件offloading的功能</li><li>CPU什么型号</li><li>CPU有几个核心</li><li>CPU有什么能调高主频的方法</li><li>CPU有什么指令集</li><li>有没有NUMA</li></ul><p>其他至于内存、存储的可以先放一边。搞清楚系统配置之后需要准备几样工具。</p><h2 id="几样工具"><a href="#几样工具" class="headerlink" title="几样工具"></a>几样工具</h2><ul><li>htop<br>和top相比确实更直观一些，没有的话用<code>top</code>凑活一下也行。难就难在有些自己裁剪的Linux系统（比如OpenWRT）里虽然有<code>top</code>，但和我们用的不是一个<code>top</code>….</li><li>ethtool<br>非常非常非常值得深度挖掘的工具，最近一个星期最后悔的事就是自己编译OpenWRT时没有勾上它。导致配代理配了个一六八开才把OpenWRT盒子挂上外网用<code>opkg</code>装上。</li><li>sysctl<br>主要用来修改内核参数。</li><li>perf<br>其实在这里用处不大，但一个系统里没装perf就会感觉少点什么。</li><li>常规工具<br><code>cat</code>、<code>echo</code>、<code>ifconfig</code>等基础自带的工具。</li></ul><h2 id="搞一搞"><a href="#搞一搞" class="headerlink" title="搞一搞"></a>搞一搞</h2><h3 id="测试拓扑及相关"><a href="#测试拓扑及相关" class="headerlink" title="测试拓扑及相关"></a>测试拓扑及相关</h3><p>拓扑如下：</p><p><img src="https://www.strongswan.org/testing/testresults/images/a-m-w-s-b.png" alt=""></p><p>其中Gateway Moon就是需要调优性能的OpenWRT盒子。Gateway Moon和Gateway Sun之间建立了IPsec加密隧道。进行Client Alice和Client Bob之间的路由转发。</p><p>在两个Client上分别运行<code>iperf3</code> server和client，来进行带宽（也即IPSec隧道的转发性能）测试。</p><p>目前除了Gateway Moon之外所有服务器都是用的高端服务器，所以瓶颈肯定在这片可怜的阿童木小盒子上。</p><p>IPsec相关的详细配置可以参考<a href="https://www.strongswan.org/testing/testresults/ikev2/net2net-psk/" target="_blank" rel="noopener">这里</a>。</p><blockquote><p>如果只是单纯测试转发速率完全不用这么复杂，两个盒子直连就可以。我这里只是最近需要搞IPsec隧道。</p></blockquote><h3 id="打开网卡多队列"><a href="#打开网卡多队列" class="headerlink" title="打开网卡多队列"></a>打开网卡多队列</h3><p>先看看你的网卡支持多少个队列：</p><p><code>ethtool -l eth3</code></p><p>这里面<code>RX</code>和<code>TX</code>等于0是说仅仅能用作接收或发送的队列个数为0，而下方<code>combined</code>是指既可以作为发送队列也可以作为接收队列的个数，一般看这个数字就知道可以有多少个接收队列和多少个发送队列了。</p><p>而<code>other</code>是指用作link interrupt或SR-IOV协调的队列，在我们这个场景下并没有什么卵用。</p><p>打开多队列：</p><p><code>ethtool -L eth3 combined 2</code></p><p>这样你就有了两个接收队列，以及两个发送队列。</p><p>这个时候看一下<code>cat /proc/interrupts</code>应该能看到eth3-rx-0/1的中断号。</p><h3 id="打开能打开的网卡Offloading"><a href="#打开能打开的网卡Offloading" class="headerlink" title="打开能打开的网卡Offloading"></a>打开能打开的网卡Offloading</h3><p>首先看一下你都有哪些offloading能力：</p><p><code>ethtool -k eth3</code></p><p>带<code>[fixed]</code>标识的就别多想了。如果有想打开的offloading能力，比如RX checksum：</p><p><code>ethtool -K eth3 rx on</code></p><blockquote><p>全部能力和操作方法参考<code>man ethtool</code>。</p></blockquote><h3 id="网卡队列深度"><a href="#网卡队列深度" class="headerlink" title="网卡队列深度"></a>网卡队列深度</h3><p>看一下最大支持深度和现在的配置情况：</p><p><code>ethtool -g eth3</code></p><p>将接收队列深度改为4096</p><p><code>ethtool -G eth3 rx 4096</code></p><h3 id="RSS队列配置"><a href="#RSS队列配置" class="headerlink" title="RSS队列配置"></a>RSS队列配置</h3><p>开了多队列最好配置一下RSS，先看一下RSS现在的配置：</p><p><code>ethtool -x eth3</code></p><p>能看到RSS indirection table和RSS hash key以及RSS hash function。</p><p>具体RSS是什么就不在这里讲解了，如果想比较均匀地让报文散列到前两个RX队列上：</p><p><code>ethtool -X eth3 equal 2</code></p><p>再看一下RSS indirection table，也许会有不一样的地方，当然也许没有 :D</p><p>如果想让某条RX队列收取更多的报文，可以配置报文的权重：</p><p><code>ethtool -X eth3 weight 6 2</code></p><p>这样RX queue 0的权重是6，会比RX queue 1收取更多的报文(一般情况下)。在需要更细粒度优化的情况下可以使用。</p><h3 id="RSS-Hash配置"><a href="#RSS-Hash配置" class="headerlink" title="RSS Hash配置"></a>RSS Hash配置</h3><p>这里可以决定针对不同的流量（IPv4-tcp, IPv4-udp, IPv6-tcp, Ethernet…)采用报文的哪些字段进行RSS Hash。</p><p>有没有体验过UDP流量换了端口号还是始终进入同一条队列的恐惧？</p><p>那是因为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@OpenWrt:~# ethtool -n eth0 rx-flow-hash udp4</span><br><span class="line">UDP over IPV4 flows use these fields for computing Hash flow key:</span><br><span class="line">IP SA</span><br><span class="line">IP DA</span><br></pre></td></tr></table></figure><p>针对UDP流量只用Src IP和dst IP做哈希…如果这两个字段没变化那么就只能进入同一条队列…</p><p>想添加上src和dst port一同作为RSS的字段：</p><p><code>ethtool -N eth3 rx-flow-hash udp4 sdfn</code></p><p>查看一下<code>man ethtool</code>可以明白<code>sdfn</code>的意义：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">m   Hash on the Layer 2 destination address of the rx packet.</span><br><span class="line">v   Hash on the VLAN tag of the rx packet.</span><br><span class="line">t   Hash on the Layer 3 protocol field of the rx packet.</span><br><span class="line">s   Hash on the IP source address of the rx packet.</span><br><span class="line">d   Hash on the IP destination address of the rx packet.</span><br><span class="line">f   Hash on bytes 0 and 1 of the Layer 4 header of the rx packet.</span><br><span class="line">n   Hash on bytes 2 and 3 of the Layer 4 header of the rx packet.</span><br><span class="line">r   Discard all packets of this flow type. When  this  option  is</span><br><span class="line">    set, all other options are ignored.</span><br></pre></td></tr></table></figure><blockquote><p>另外注意如果你搭建的是IPsec隧道，即便你加解密之前/后可能是UDP/TCP流量，但经过加密之后都是<code>esp4</code>类型的流量。</p></blockquote><h3 id="N-tuple-filters配置"><a href="#N-tuple-filters配置" class="headerlink" title="N-tuple filters配置"></a>N-tuple filters配置</h3><p>这个需要考虑自己的实际应用场景，比如在一个web服务器中将处理http流量的进程绑定在CPU1，同时将RX queue-1的中断都放在CPU1，这时如果将所有dst port是80的http流量都导入Rx queue-1将会在进程切换和缓存命中方面提供好处。</p><p>首先查看一下网卡是不是支持：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ethtool -k eth3</span><br><span class="line">...</span><br><span class="line">ntuple-filters: off</span><br></pre></td></tr></table></figure><p>打开：</p><p><code>ethtool -K eth3 ntuple on</code></p><p>配一条过滤规则：</p><p><code>ethtool -U eth3 flow-type tcp4 dst-port 80 action 1</code></p><p>具体流量的命中情况可以通过</p><p><code>ethtool -S eth3</code></p><p>中的<code>fdir_match</code>和<code>fdir_miss</code>查看。</p><h3 id="中断分布"><a href="#中断分布" class="headerlink" title="中断分布"></a>中断分布</h3><p>内核收包的一大瓶颈就是中断处理。一个常见的技巧就是让这些中断由所有CPU核共同分担。最优的配置就是一个NUMA节点中有多少个CPU核，该节点上的网卡就有多少个收包队列。当然我这里用的这个盒子是不敢奢望什么NUMA了….</p><p>先看一下都挂了哪些中断：<br><code>cat /proc/interrupts</code></p><p>然后把某个收包队列对应的中断号绑定到对应的CPU核上：</p><p><code>echo mask &gt; /proc/irq/$IRQ/smp_affinity</code></p><p>其中<code>mask</code>就是允许发送中断的CPU的bit位。mask=1就是CPU0, mask=2就是CPU1, mask=3就是CPU0和1.</p><blockquote><p>在自己手动设置中断分布之前，先检查一下系统里是不是已经在运行<code>irqbalance</code>守护进程。如果有先把它关掉。</p></blockquote><p>贴一个网上应用比较广泛的脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> setting up irq affinity according to /proc/interrupts</span><br><span class="line"><span class="meta">#</span> 2008-11-25 Robert Olsson</span><br><span class="line"><span class="meta">#</span> 2009-02-19 updated by Jesse Brandeburg</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> &gt; Dave Miller:</span><br><span class="line"><span class="meta">#</span> (To get consistent naming in /proc/interrups)</span><br><span class="line"><span class="meta">#</span> I would suggest that people use something like:</span><br><span class="line"><span class="meta">#</span>             char buf[IFNAMSIZ+6];</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>             sprintf(buf, "%s-%s-%d",</span><br><span class="line"><span class="meta">#</span>                 netdev-&gt;name,</span><br><span class="line"><span class="meta">#</span>                            (RX_INTERRUPT ? "rx" : "tx"),</span><br><span class="line"><span class="meta">#</span>                            queue-&gt;index);</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>  Assuming a device with two RX and TX queues.</span><br><span class="line"><span class="meta">#</span>  This script will assign:</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>             eth0-rx-0  CPU0</span><br><span class="line"><span class="meta">#</span>             eth0-rx-1  CPU1</span><br><span class="line"><span class="meta">#</span>             eth0-tx-0  CPU0</span><br><span class="line"><span class="meta">#</span>             eth0-tx-1  CPU1</span><br><span class="line"><span class="meta">#</span></span><br><span class="line">set_affinity()</span><br><span class="line">&#123;</span><br><span class="line">MASK=$((1&lt;&lt;$VEC))</span><br><span class="line">printf "%s mask=%X for /proc/irq/%d/smp_affinity\n" $DEV $MASK $IRQ</span><br><span class="line">printf "%X" $MASK &gt; /proc/irq/$IRQ/smp_affinity</span><br><span class="line">echo $DEV mask=$MASK for /proc/irq/$IRQ/smp_affinity</span><br><span class="line">echo $MASK &gt; /proc/irq/$IRQ/smp_affinity</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">if [ "$1" = "" ] ; then</span><br><span class="line">    echo "Description:"</span><br><span class="line">    echo "This script attempts to bind each queue of a multi-queue NIC"</span><br><span class="line">    echo "to the same numbered core, ie tx0|rx0 --&gt; cpu0, tx1|rx1 --&gt; cpu1"</span><br><span class="line">    echo "usage:"</span><br><span class="line">    echo "$0 eth0 [eth1 eth2 eth3]"</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> Set up the desired devices.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"> </span><br><span class="line">for DEV in $*</span><br><span class="line">do</span><br><span class="line">  for DIR in  rx tx</span><br><span class="line">  do</span><br><span class="line"> MAX=`grep $DEV-$DIR /proc/interrupts | wc -l`</span><br><span class="line"> if [ "$MAX" == "0" ] ; then</span><br><span class="line">   MAX=`egrep -i "$DEV:.*$DIR" /proc/interrupts | wc -l`</span><br><span class="line"> fi</span><br><span class="line"> if [ "$MAX" == "0" ] ; then</span><br><span class="line">   echo no vectors found on $DEV</span><br><span class="line">   exit 1</span><br><span class="line"> fi</span><br><span class="line"> for VEC in `seq 0 1 $MAX`</span><br><span class="line"> do</span><br><span class="line">    IRQ=`cat /proc/interrupts | grep -i $DEV-$DIR-$VEC"$"  \</span><br><span class="line">| cut  -d:  -f1 | sed "s/ //g"`</span><br><span class="line">    if [ -n  "$IRQ" ]; then</span><br><span class="line">          set_affinity</span><br><span class="line">    else</span><br><span class="line">           IRQ=`cat /proc/interrupts | egrep -i $DEV:v$VEC-$DIR"$"  \</span><br><span class="line">| cut  -d:  -f1 | sed "s/ //g"`</span><br><span class="line">           if [ -n  "$IRQ" ]; then</span><br><span class="line">             set_affinity</span><br><span class="line">           fi</span><br><span class="line">    fi</span><br><span class="line"> done</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="内核网络相关参数"><a href="#内核网络相关参数" class="headerlink" title="内核网络相关参数"></a>内核网络相关参数</h3><p>这一部分没太多好说的，下面给一个<code>/etc/sysctl.conf</code>的配置内容，可以参考，若是觉得有些数字还不够激进，可以自己再改大一点，最后别忘了用<code>sysctl -p</code>生效。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>## GENERAL NETWORK SECURITY OPTIONS ###</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Number of times SYNACKs for passive TCP connection.</span><br><span class="line">net.ipv4.tcp_synack_retries = 2</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Allowed local port range</span><br><span class="line">net.ipv4.ip_local_port_range = 2000 65535</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Protect Against TCP Time-Wait</span><br><span class="line">net.ipv4.tcp_rfc1337 = 1</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Control Syncookies</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Decrease the time default value for tcp_fin_timeout connection</span><br><span class="line">net.ipv4.tcp_fin_timeout = 15</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Decrease the time default value for connections to keep alive</span><br><span class="line">net.ipv4.tcp_keepalive_time = 300</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 5</span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 15</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span>## TUNING NETWORK PERFORMANCE ###</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Default Socket Receive Buffer</span><br><span class="line">net.core.rmem_default = 31457280</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Maximum Socket Receive Buffer</span><br><span class="line">net.core.rmem_max = 67108864</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Default Socket Send Buffer</span><br><span class="line">net.core.wmem_default = 31457280</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Maximum Socket Send Buffer</span><br><span class="line">net.core.wmem_max = 33554432</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase number of incoming connections</span><br><span class="line">net.core.somaxconn = 65535</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase number of incoming connections backlog</span><br><span class="line">net.core.netdev_max_backlog = 65536</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase the maximum amount of option memory buffers</span><br><span class="line">net.core.optmem_max = 25165824</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase the maximum total buffer-space allocatable</span><br><span class="line"><span class="meta">#</span> This is measured in units of pages (4096 bytes)</span><br><span class="line">net.ipv4.tcp_mem = 786432 1048576 26777216</span><br><span class="line">net.ipv4.udp_mem = 192576 256768 385152</span><br><span class="line"><span class="meta">#</span> Increase the read-buffer space allocatable</span><br><span class="line">net.ipv4.tcp_rmem = 8192 87380 33554432</span><br><span class="line">net.ipv4.udp_rmem_min = 131072</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase the write-buffer-space allocatable</span><br><span class="line">net.ipv4.tcp_wmem = 8192 65536 33554432</span><br><span class="line">net.ipv4.udp_wmem_min = 131072</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase the tcp-time-wait buckets pool size to prevent simple DOS attacks</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 1440000</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br></pre></td></tr></table></figure><h3 id="Interrupt-Coalescing"><a href="#Interrupt-Coalescing" class="headerlink" title="Interrupt Coalescing"></a>Interrupt Coalescing</h3><p>在大流量情况下需要考虑对NIC发送的中断进行一些“批量处理”，合并一些中断请求，从而减少CPU的压力。</p><p>看一下当前网卡的Interrupt Coalescing的配置情况：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@server-P1 ~]# ethtool -c eno3</span><br><span class="line">Coalesce parameters for eno3:</span><br><span class="line">Adaptive RX: off  TX: off</span><br><span class="line">stats-block-usecs: 0</span><br><span class="line">sample-interval: 0</span><br><span class="line">pkt-rate-low: 0</span><br><span class="line">pkt-rate-high: 0</span><br><span class="line"></span><br><span class="line">rx-usecs: 1</span><br><span class="line">rx-frames: 0</span><br><span class="line">rx-usecs-irq: 0</span><br><span class="line">rx-frames-irq: 0</span><br><span class="line"></span><br><span class="line">tx-usecs: 0</span><br><span class="line">tx-frames: 0</span><br><span class="line">tx-usecs-irq: 0</span><br><span class="line">tx-frames-irq: 0</span><br><span class="line"></span><br><span class="line">rx-usecs-low: 0</span><br><span class="line">rx-frame-low: 0</span><br><span class="line">tx-usecs-low: 0</span><br><span class="line">tx-frame-low: 0</span><br><span class="line"></span><br><span class="line">rx-usecs-high: 0</span><br><span class="line">rx-frame-high: 0</span><br><span class="line">tx-usecs-high: 0</span><br><span class="line">tx-frame-high: 0</span><br></pre></td></tr></table></figure><p>改动这些配置需要网卡硬件和驱动的支持。如果可以改动的话，比较简单的就是改成自适应模式：</p><p><code>ethtool -C eth3 adaptive-rx on</code></p><p>自适应模式就是自动在网络压力小或者大的时候调整参数，从而达到最小延迟/最大吞吐。</p><p>其他的参数的含义如下：</p><ul><li><code>rx-usecs</code>：从收到报文到发送中断delay的usec</li><li><code>rx-frames</code>：发送中断前最大收取的报文数量</li><li><code>rx-usecs-irq</code>：再次发送中断的delay的usec<br>等等…</li></ul><h3 id="Receive-Packet-Steering-RPS"><a href="#Receive-Packet-Steering-RPS" class="headerlink" title="Receive Packet Steering(RPS)"></a>Receive Packet Steering(RPS)</h3><p>RPS是一种软件实现的RSS。在多队列网卡系统上，这个东西是非常多余的…所以前面的中断和RSS都配置得没问题得话，一定要记得关闭RPS：</p><p><code>echo 0 &gt; /sys/class/net/&lt;dev&gt;/queues/rx-&lt;n&gt;/rps_cpus</code></p><p>关于RPS具体的说明，以及为什么它是多余的，可以参看<a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L138-L164" target="_blank" rel="noopener">这里</a>。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> network </tag>
            
            <tag> performance </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚12：Skylake微架构(Microarchitecture)剖析(4)</title>
      <link href="/2019/01/20/quickwords12-skylake-pipeline-4/"/>
      <url>/2019/01/20/quickwords12-skylake-pipeline-4/</url>
      
        <content type="html"><![CDATA[<h2 id="MSROM"><a href="#MSROM" class="headerlink" title="MSROM"></a>MSROM</h2><p><img src="https://en.wikichip.org/w/images/thumb/5/5e/skylake_decode.svg/425px-skylake_decode.svg.png" alt=""></p><p>MSROM(Micro-code sequencer ROM)就是在<a href="https://decodezp.github.io/2019/01/12/quickwords11-skylake-pipeline-3/">上一篇连载</a>中提到的专门处理输出大于4个uop的那块类似缓存的ROM。很多文档里面也直接将其称为<code>MS</code>，具体叫什么多需要结合上下文语境，知道是一回事就好了。</p><blockquote><p>我个人其实推荐读者在编写自己的文档时能注意这些名称上的“一致性”，同编写程序时给变量或函数命名时的一致性一样，这些看似没什么“技术含量”的工作，却能够极大地提高信息传达的效率，也就是提高文档或代码的可读性和可维护性。</p></blockquote><a id="more"></a><p>在Instruction Decoder收到一个输出要大于4个uop的指令之后，它就会将请求转发给MSROM。MSROM虽然是专门解码/查询大于4个uop的指令的组件，但它最大的传输效率是4uop/cycle。同时在它工作的时候，所有的Instruction Decoder都要处于Disable的状态。因此虽然它的工作不太需要“动脑子”，但却仍要尽量避免。</p><h2 id="Stack-Engine"><a href="#Stack-Engine" class="headerlink" title="Stack Engine"></a>Stack Engine</h2><p>Stack Engine是专门处理栈操作指令的专用组件。类似<code>PUSH</code>、<code>POP</code>、<code>CALL</code>、<code>RET</code>这样的指令都算栈操作指令。Stack Engine不算什么新鲜的黑科技，自从Pentium M时代起就已经出现在Intel的CPU中。它的主要目的是避免栈操作指令对后端资源的占用，从而为其他计算任务提供出更多的资源。为此，Stack Engine提供栈操作指令专用的加法器和其他所需的逻辑完成这一任务。</p><p>Stack Engine在Instruction Decoder之后，监控所有流出的uop，并且从中提取出栈操作指令，进而直接执行，从而减轻栈操作指令对后端资源的占用。</p><p>这也可能是为什么有些时候<code>inline</code>的函数性能还不如不<code>inline</code>的原因吧:D（不负责任猜测）</p><h2 id="Decoded-Stream-Buffer-DSB"><a href="#Decoded-Stream-Buffer-DSB" class="headerlink" title="Decoded Stream Buffer(DSB)"></a>Decoded Stream Buffer(DSB)</h2><p><img src="https://en.wikichip.org/w/images/thumb/5/58/skylake_ucache.svg/400px-skylake_ucache.svg.png" alt=""></p><h3 id="别名"><a href="#别名" class="headerlink" title="别名"></a>别名</h3><p>像DSB这种组件，首先要说明的就是它也叫uop cache或decoded icache。</p><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>无论是用Instruction Decoder还是用MSROM，终究还是要做一次“解码”的操作。但同所有Cache加速的原理一样，如果能把解码之后的结果(uop)存下来，下次再出现的时候直接使用，那么就可以显著提高解码速度，DSB就是这个目的。</p><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><p>DSB的组织形式是32个set，每个set有8条cache line，每条cache line最多保存6个uop。</p><p>每次cache hit可以传输最大6个uop/cycle，这6个uop最大可以对应到64 byte的前端fetch window size，并且完全不需要任何Instruction decoder参与，也没有繁琐的解码过程。在实际应用中，DSB的cache hit rate在80%或以上。</p><h3 id="与icache的关系"><a href="#与icache的关系" class="headerlink" title="与icache的关系"></a>与icache的关系</h3><p>CPU的icache一般存储的是最原始的从内存里读进来的程序的汇编指令(marco instruction)。而DSB或者uop cache虽然也是存instruction的cache，但如前所述，它存的是已经解码好的uop，所以这玩意有时候又被称为“decoded icache”。当然了，这些uop都是CPU的icache中的指令解码之后得到的。</p><h3 id="与MSROM的关系"><a href="#与MSROM的关系" class="headerlink" title="与MSROM的关系"></a>与MSROM的关系</h3><p>输出大于4个uop的指令依然只能由MSROM解码。DSB保存的也是那些小于等于4个uop指令的uop。</p><h2 id="MITE-Path和DSB-Path"><a href="#MITE-Path和DSB-Path" class="headerlink" title="MITE Path和DSB Path"></a>MITE Path和DSB Path</h2><p>这两个概念主要用于区分最终需要执行的uop是通过什么方式来的。在上一节<code>Decoded Stream Buffer</code>之前的所有内容，都算是MITE Path。MITE是(Micro-instruction Translation Engine)的缩写，同时它在有些文档里也被称作legacy decode pipeline或legacy path。这条线路上过来的uop都是从marco instruction一步一步解码来的。</p><p>DSB path就是直接从DSB那条道上过来的uop。当CPU需要在MITE Path、DSB Path以及MSROM之间切换(switch)以便取得所需的uop时，需要花费一定的CPU cycle完成这一工作。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>有时做梦</title>
      <link href="/2019/01/19/thoughts4-dream/"/>
      <url>/2019/01/19/thoughts4-dream/</url>
      
        <content type="html"><![CDATA[<p>活得年头多起来之后，很难再明确地忆起某件事发生在哪一年。时间变得不再激烈，但往事却在交织纠缠，许多不可能的事还以为理所当然，而那些早已发生的事实却总需要确认再三。</p><a id="more"></a><p>这些事往往都发生在梦里。纵使过了做梦的年纪，也依然会有美梦，有噩梦，有能轻易按照弗洛伊德按图索骥的梦，还有一些不知所云得让人拍案叫绝的梦。但与年少时的最大区别，是有越来越多明知是梦的梦。在这些梦里，有不曾实现的愿望，有毋须弥补的过错，有仇恨背后的和解，有始终羞于开口的依赖，还有离开了却又回来的人，他们在梦里，有一场亲切的重逢。</p><p>人们总是倾向于相信自己愿意相信的事，而不是真真正正的现实。所以这种梦做多了并不好，容易把梦境与现实混淆。同时，越多这样的梦，下次就会越早意识到自己是在做梦。</p><p>可能每个人始终在梦中反复出现的都是那几件同样的事。</p><p>当意识到自己是在做梦之后，以前会一下就惊醒，现在反而会摆摆手继续做下去，甚至闭着眼都能看到自己蜷缩在枕头里自嘲的笑容。既然又梦到这里，就这样吧。</p><p>更多时候，就只是“昼有所思，夜有所梦”，或者说，是那些起床之后蹲在马桶上能想起来搜索一下的梦。所有这些梦，在“周公解梦”里都能找出来好几个解释，有些能相互印证，有些凶吉完全相反。但不管怎样，看来大家除了明知是梦的梦之外，梦到过的东西都一样。在给解梦类网站带来几个点击之后，这些梦都在早高峰的时候统统被忘掉。</p><p>做梦同Sex一样，也是一项夜晚（或早晨:D）的福利。我想我应该不会听从那些“每天只睡4小时”的成功学鸡汤而把这样的大礼买椟还珠。每个白天，从马桶上站起来之后就是战斗状态。要并线、要抢道、要甩锅、要争功、要倾轧、要离间、要摆脱已经发生的事，却又总要等待还没发生的事…最后的结果就是，梦可以明知是梦，而生活却不知是否一定要是这样的生活。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>在OpenWRT中添加perf工具</title>
      <link href="/2019/01/15/openwrt-perf/"/>
      <url>/2019/01/15/openwrt-perf/</url>
      
        <content type="html"><![CDATA[<h2 id="OpenWRT性能调优的必要"><a href="#OpenWRT性能调优的必要" class="headerlink" title="OpenWRT性能调优的必要"></a>OpenWRT性能调优的必要</h2><p>如果仅仅是家庭网关，确实没太大必要，毕竟网络的瓶颈主要在运营商的出口那。OpenWRT之所以开始关注极致的性能，是由于OpenWRT的应用场景出现了变化。从SD-WAN和边缘计算概念，到混合云与智能网关，都催生出了在边缘接入侧uCPE或其他类似的小盒子中部署基于OpenWRT系统的必要。不同于满足家庭接入的需求，这些小盒子往往对应一间Office或公司分支的网络需求。增长的网络带宽和对安全性、QoS等能力的要求都对OpenWRT的性能提出了更高的要求。</p><a id="more"></a><h2 id="没有perf"><a href="#没有perf" class="headerlink" title="没有perf"></a>没有<code>perf</code></h2><p>按照官网的教程，在<code>make menuconfig</code>之后就可以选择要一起编译到系统里的工具了。首先查找一下perf在哪：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/perf</span><br></pre></td></tr></table></figure><p>显示在Development这个分类下面：</p><p><img src="https://s2.ax1x.com/2019/01/15/FzIp5V.png" alt=""></p><p>OK，在Development这个分类下面自然是找不到的，不然也没必要写这篇博客了。</p><h2 id="搞一搞"><a href="#搞一搞" class="headerlink" title="搞一搞"></a>搞一搞</h2><p>那么怎么把它搞出来呢？</p><p>首先进入<code>Global build settings</code>选项卡，然后找到<code>Kernel build options</code>，然后选上<code>Compile the kernel with performance events and counters</code>和<code>Compile the kernel with profiling enabled</code>，如下图：</p><p><img src="https://s2.ax1x.com/2019/01/15/FzIYVI.png" alt=""></p><p>再回到Development这里就可以看到perf了：</p><p><img src="https://s2.ax1x.com/2019/01/15/FzIP8U.png" alt=""></p><p>天下的知识分两类，一类是从这里学会了，在别处也能用的；一类是在一个地方学会了就只能在一个地方用的。本文中介绍的内容其实属于后者。但诡吊的是，掌握第二类知识往往更加费时费力。所以记录这一类的内容，主要出于节省他人时间的目的。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> openwrt </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>王朝兴亡周期律的本因</title>
      <link href="/2019/01/13/thoughts3-zhouqilv/"/>
      <url>/2019/01/13/thoughts3-zhouqilv/</url>
      
        <content type="html"><![CDATA[<h2 id="王朝兴亡周期律"><a href="#王朝兴亡周期律" class="headerlink" title="王朝兴亡周期律"></a>王朝兴亡周期律</h2><blockquote><p>六位参政员将要回重庆时，毛泽东问黄炎培有什么感想，黄炎培坦率地说：“我生六十多年，耳闻的不说，所亲眼看到的，真所谓‘其兴也勃焉’，‘其亡也忽焉’，一人，一家，一团体，一地方，乃至一国，不少单位都没有跳出这周期率的支配力。大凡初时聚精会神，没有一事不用心，没有一人不卖力，也许那时艰难困苦，只有从万死中觅取一生。既而环境渐渐好转了，精神也就渐渐放下了。有的因为历史长久，自然地惰性发作，由少数演变为多数，到风气养成，虽有大力，无法扭转，并且无法补救。也有为了区域一步步扩大，它的扩大，有的出于自然发展，有的为功业欲所驱使，强求发展，到干部人才渐见竭蹶、艰于应付的时候，环境倒越加复杂起来了，控制力不免趋于薄弱了。一部历史‘政怠宦成’的也有，‘人亡政息’的也有，‘求荣取辱’的也有。总之没有能跳出这周期率。中共诸君从过去到现在，我略略了解的了。就是希望找出一条新路，来跳出这周期率的支配。”</p></blockquote><a id="more"></a><p>不仅仅中国有此周期规律，任何国家，任何民族，任何团体，乃至任何个人，都有此周期规律。</p><p>这其实不是什么新鲜概念，我们的语言体系里早就有各种玄之又玄的词汇可以给出模棱两可的总结：物极必反、物壮则老，以及所有和消、息、盈、冲，相关的词汇。但既然人们早已总结出这样的规律，为何在事到临头之时，却都无法避免被裹挟而去的命运？这一“兴亡律”当真是万世不易的铁律吗？</p><h2 id="人与物质世界的根本矛盾"><a href="#人与物质世界的根本矛盾" class="headerlink" title="人与物质世界的根本矛盾"></a>人与物质世界的根本矛盾</h2><p>人是自然的造物，却也在永不停歇地与自然斗争。这种斗争从最初的生存之争，到现如今的索取与利用，再到以后可能的自然律改造，看似人在逐步认知物质世界，并取得了和谐共处的权利甚至一定程度的相对优势，但人与物质世界的根本矛盾仍然存在，并依旧支配着人类的所有活动。</p><h3 id="人对物质的认知"><a href="#人对物质的认知" class="headerlink" title="人对物质的认知"></a>人对物质的认知</h3><p>人类所认知的物质世界，从某种意义上讲，全部都是人类自己的臆造。</p><p>但这并非等同于物质不存在，或者是“缸中之脑”这种科幻玩笑。物质真实存在，人类也可以因为与物质的相互作用产生出对物质的认知，但这种认知仅仅是对真实物质世界的狭隘偏见。</p><p>这种偏见的产生由两方面原因造成：</p><ol><li>人类感官的局限</li><li>人类描述语言的局限</li></ol><p>感官的局限很好理解，如同可见光光谱仅仅占据电磁波谱很细小的一部分一样，即便我们可以自己发明现代仪器帮助我们一定程度地突破人类肉体的感官局限，但只要最终的信号仍需要由人类的肉体来接收，那么感官的局限就无法完全突破。</p><p>同样，人类的语言也无法描述真实的物质世界，因为无论是哪种自然语言，符号（形式）语言或者由人类技术衍生出的智能人造物的语言，都不可能描述出从来没见过的东西。</p><p>已有的认知在我们自己的体系里是自洽的，虽然这体系仅仅是真实的一个狭小的侧面，但也足够用了——这反倒成为我们应该感谢自身局限的理由。人类虽然一直在努力排除这种局限，我也相信我们在这条路上会继续打开局面，但同样的，随着认知越来越多，会越来越发觉我们的认知是如此之少。</p><h3 id="人类活动的根本目的"><a href="#人类活动的根本目的" class="headerlink" title="人类活动的根本目的"></a>人类活动的根本目的</h3><p>那么“认知”这件事本身是为了什么？我们大可以如同岩石那样安然接受周遭的一切，毕竟了解万万万万分之一和全然不了解，似乎也没什么差别。但人不会接受这样的安排。也许是出自动物的本能，也许是造物者的旨意，我们在这里不探究原因，只讨论这给我们带来什么。</p><blockquote><p>我们所做的一切活动，都是为了能让真实世界与我们认知的世界一致。</p></blockquote><p>这是我们内心中最原始也是最底层的驱动力。无论是群聚生产、巫术卜筮、屯田开荒、君权天授、两相攻伐、望气观星、揭竿而起、六艺俱佳、推导公式、狂敲代码，都是为了这一件事——即便我们并没有生活在“三体运动”的混乱之中，我们也一定要用那些最聪明的头脑来研究混乱的轨迹。</p><p>因为这种“一致”，为我们带来最基本的两点对物质世界的诉求：</p><ul><li>可控</li><li>可预期</li></ul><p>我可以接受我的农田远离河流，但我不能接受我开渠引水之后粮产依旧；我可以接受今年因为干旱导致赤地千里，但我不能接受风调雨顺时仍然欠收。这对任何拥有智能的生物都至关重要。</p><p>为了让感知的物质世界与认知的物质世界保持一致，人类必须一直处于与物质世界交互的状态。这种交互中的活动，要么是对物质世界进行改造，使其至少感知起来，与认知的情况一致；要么是调整自身对物质世界的认知（一般是进一步加深认知），继而达到更高层次的一致。</p><p>这便是所有人类活动的根本原因和内在驱动力，或者也可以说，即便你现在悲观厌世只想了此残生，你也同其他所有人一样，一直走在理想的路上。</p><h3 id="人类不能停止的心理摆动"><a href="#人类不能停止的心理摆动" class="headerlink" title="人类不能停止的心理摆动"></a>人类不能停止的心理摆动</h3><p>是否达成一致之后，人类就不再继续活动了呢？</p><p>这种静态的一致永远不可能达到。我想也不必用科学上的不断进步来举例说明。造成没有静态一致的原因，正是因为追求静态一致的原因：我们自身的认知有限。</p><p>因为认知有限，所以我们要追求一致，在追求一致的过程中，又总会有超出现有认知的发现，因此又要继续追求一致。如此，既可以类比于西西弗斯的意象，又可以从逻辑上解释叔本华对人生犹如钟摆的描述。</p><h2 id="王朝兴亡周期律的本因"><a href="#王朝兴亡周期律的本因" class="headerlink" title="王朝兴亡周期律的本因"></a>王朝兴亡周期律的本因</h2><p>王朝的兴亡，只不过是人类“追求一致”的一个产物。只不过它看起来宏大又神秘，所以被拿出来单说。</p><p>如开篇中黄炎培的引言中所述：大凡“聚精会神，用心卖力”，多是因为心中有一理想世界，却与现今的世界大不相同。因此人人可知，欲求得“一致”，非尽心竭力不可。而一旦达成目标，又会激发人心思寻新的“一致”——对这“理想世界”更多的可控与可预期的“理想”，这便是黄炎培所言之“惰性发作”，其实和科学探索并无本质区别。至于后续“环境愈加复杂”，乃是因为人人各有探索，因此也各有理想，人人都寻求各自的一致，而再无统一的一致。</p><p>如此社会又回到了需要建立一个“理想世界”的状态。所谓“理想世界”，就是指与大多数人的认知相一致的世界。而此时人的认知，因为前面所述不断发展的原因，已与建立上一个“理想世界”时大不相同，上一个“理想世界”自然也就“人亡政息”了。</p><p>从某一个王朝角度出发，这似乎是一个由盛而衰的过程，但从宏观上讲，这其实是一个再正常不过的自然发展的过程。所谓“盛极则衰”，背后的原因也是因为不同的人（多是不同阶级）所要求的“一致”出现了分裂和不可弥合的矛盾。</p><p>因此，跳出“周期律”的方式也非常简单，就是平衡这些人对“一致”的诉求。可以简单称之为“平衡各方利益，表达不同阶层人民诉求”，但这需要王朝实现自我革新，这并不是一个仅仅需要决心就能完成的事情。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚11：Skylake微架构(Microarchitecture)剖析(3)</title>
      <link href="/2019/01/12/quickwords11-skylake-pipeline-3/"/>
      <url>/2019/01/12/quickwords11-skylake-pipeline-3/</url>
      
        <content type="html"><![CDATA[<h2 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h2><p><img src="https://en.wikichip.org/w/images/thumb/5/5e/skylake_decode.svg/425px-skylake_decode.svg.png" alt=""></p><p>在拿到了经过“预解码”的<code>macro-ops</code>之后，开始正式进入解码过程。<code>marco-ops</code>进入Instruction Decode组件解码，最终的输出为定长的<code>micro-ops</code>。</p><p>Insturction Decode组件也有入口带宽限制，每个Cycle最多取3个unfused指令+2个fused指令，或者5个unfused指令（这里指macro ops）。所以说fused多了也不好，一个cycle最多取两个。同时如果开了Hyper Thread，则两个Thread按Cycle交替使用Instruction Decode。</p><a id="more"></a><p>在Instruction Decode组件里面的就是各个具体的Decoder。Decoder类型可以分类两类，一类是Simple Decoder，一类是Complex Decoder，感觉这句是在说废话。</p><p>顾名思义，Simple Decoder处理的是解码之后的输出为1个<code>fused-uop</code>的指令；Complex Decoder处理的是解码之后的输出为1个至4个<code>fused-uop</code>的指令。</p><h2 id="Fused-uop"><a href="#Fused-uop" class="headerlink" title="Fused-uop"></a>Fused-uop</h2><p>注意这里说的是fused-<code>uop</code>，不是fused-<code>marco</code>。在这里所有输出的<code>uop</code>都是做过<code>fused</code>处理的，目的是减少后续资源的占用。</p><blockquote><p>但这里有一个比较容易混淆的概念，就是<code>fused-uop</code>并非专指那些两个uop合并之后生成的“合并uop”，而是指所有经过了uop fusion处理的uop：有些指令可能两个uop变一个，但也有一些是一个还是一个，即便如此，输出的那一个也叫<code>fused-uop</code>。</p></blockquote><p>为了进一步澄清这个概念，我们稍微需要涉及一点后端的概念。在前端这里，生成<code>fused-uop</code>的部分还属于CPU流水线中的<code>uops fused domain</code>，而在后端需要将指令发射到执行单元去的时候，是不能执行<code>fused uop</code>的，所以<code>fused uop</code>还需要再分解为<code>unfused uop</code>才可以执行，这一部分就属于CPU流水线中的<code>uops unfused domain</code>。</p><p>有了这些概念之后，我们可以看一下<a href="https://www.agner.org/optimize/instruction_tables.pdf" target="_blank" rel="noopener">Instruction Tables.pdf</a>这份文档。</p><p>在P244中有对skylake指令的说明，上面有对一些概念的解释，下面是一张表格：<br><img src="https://s2.ax1x.com/2019/01/12/FjnbCV.png" alt=""></p><p>在这张表格里是最常见的<code>mov</code>命令的说明。但因为操作<br>数(operands)的不同在真正执行的时候也会有细节上的差别。第一行中的<code>mov</code>的两个操作数一个是register，另外一个是一个立即数。在<code>uops fused domain</code>和<code>uops unfused domain</code>两栏中的计数都是1。</p><p>这种指令也算在<code>uops fused domain</code>经过了fusion处理。只不过其实前后没什么区别。</p><p>但如果我们看一下所有在<code>uops unfused domain</code>里计数为2的<code>mov</code>指令，它们在<code>uops fused domain</code>中的计数都是1。这种<code>mov</code>指令就是真正做过2条uop合并的<code>mov</code>指令。</p><p>这份表格还有很多有趣的内容，推荐有时间的时候随手翻翻。</p><p>Skylake有4个Simple Decoder和1个Complex Decoder。但从表里我们可以看到<code>uops fused domain</code>计数为1，也就是可以被Simple Decoder处理的指令在所有指令中所占的比例似乎并没有达到4/5那么高。</p><p>这里需要说明的是，输出大于4个uop的指令，既不由Simple Decoder处理，也不由Complex Decoder处理，而是直接去查<code>Microcode Sequencer(MS)</code>，这是一块类似于缓存的ROM。</p><p>Complex Decoder的数量始终为1的原因是Complex Decoder解码出来的uop都很难在执行时进行并行化处理，同时Complex Decoder每多解码一个uop，就要有一个Simple Decoder处于不能工作的状态。</p><p>对CPU来说，它最希望的就是它要做的工作，它需要的数据，它要执行的指令，都已经在一块缓存里准备就绪了。这是CPU上班摸鱼的主要方法，但摸出了风格，摸出了水平。下一部分介绍一下在指令解码方面的缓存内容。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚10：Skylake微架构(Microarchitecture)剖析(2)</title>
      <link href="/2019/01/10/quickwords10-skylake-pipeline-2/"/>
      <url>/2019/01/10/quickwords10-skylake-pipeline-2/</url>
      
        <content type="html"><![CDATA[<h2 id="前端"><a href="#前端" class="headerlink" title="前端"></a>前端</h2><p>处理器在前端这一部分的时候还是顺序(in-order)处理的，主要是也确实没什么乱序的空间。虽然说是顺序，但前端因为贴近业务，所以受人写的代码的影响也比较大。如果仅仅只是“取指令-&gt;解码”，恐怕需要写程序的人是个非常聪明的程序员。前端很多组件的工作其实都是在填程序员的坑，这也是我比较心疼前端的地方。</p><a id="more"></a><h2 id="Fetch"><a href="#Fetch" class="headerlink" title="Fetch"></a>Fetch</h2><p><img src="https://en.wikichip.org/w/images/thumb/7/79/skylake_fetch.svg/300px-skylake_fetch.svg.png" alt=""></p><p>前端的任务，首先是从内存中取得指令。同读取数据类似，CPU通过查询页表获得指令所在的内存地址，同时把指令塞到CPU的L1指令缓存里。</p><p>具体要把哪个地址上的指令数据送到L1I$里，这是分支预测器(Branch predictor)的工作。作为CPU的核心技术，Intel并没有透露太多信息，我们这里也只好一笔带过。不过它的细节也许很复杂，但它的脾气很好掌握：和我们很多人不喜欢自己的工作一样，它的工作就是处理分支，但它最不喜欢分支。</p><p>在Skylake架构里，L1I$大小为32KB，组织形式为8-way set associative(关于CPU缓存组织形式的讲解可以参照<a href="https://decodezp.github.io/2018/11/25/quickwords2-cacheassociativity/">这篇</a>)，每个Cycle可以取16Byte长度(fetch window)的指令。如果你开了Hyper-thread，那么同一个物理核上的两个逻辑核均分这个fetch window，每个Cycle各占用一次。</p><blockquote><p>所以没事别开Hyper-thread，不过我这么说没有任何技术依据，单纯是帮Intel多卖几个核。</p></blockquote><p>在L1I$里的指令还都是变长的x86 <code>macro-ops</code>，也就是我们看到的那些编译之后的汇编指令。如果熟悉这些指令的话，就会知道这些指令的长度（就是那些二进制数字）都不一样，同时一条指令有时可以由好几个操作组成。</p><p>这种指令对CPU的执行单元来说是很不友好的，同时如果想要通过乱序执行提高指令的并行度，减小指令的粒度也是必须的步骤。因此需要把这些<code>marco-ops</code>“解码”为“micro-ops”。</p><p>当然具体的解码工作还在后面。从L1I$中取得指令数据后，首先要进入“预解码”阶段，在这里需要识别出在一个fetch window中取得的这16个Byte的数据里面有多少个指令。除此之外，还需要对一些特殊指令，比如分支转跳打上一些标记。</p><p>但因为指令变长的原因，16个Byte往往并不对应固定的指令数，还有可能最后一个指令有一半在这16Byte里，另一边还在后面。另外就是pre-decode在一个Cycle最多识别出6个指令，或者这16Byte的数据都解析完。如果你这16个Byte里包含有7个指令，那么第一个Cycle识别出前6个之后，还需要第二个Cycle识别最后一个，然后才能再读取后面16Byte。</p><p>那么pre-decode的效率就变成了3.5 instruction / cycle，比最理想的情况6 instruction / cycle降低了41%，现实就是这么残酷。</p><p>经过pre-decode之后，才真正从16Byte的二进制数据中识别出了指令，这些指令下一步要被塞到一个队列里(Instruction Queue)看看有没有什么能被优化的地方。一个最常见的优化方式就是<code>macro-op fusion</code>，就是把两个相邻的，且能被一个指令表示的指令，用那一个指令替换掉。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmp eax, [mem]</span><br><span class="line">jne loop</span><br></pre></td></tr></table></figure><p>直接换成<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmpjne eax, [mem], loop</span><br></pre></td></tr></table></figure></p><p>当然既然决定这么替换，新指令对流水线的开销肯定小于被替换的两个指令之和。如此可以减轻一部分后端执行单元的工作负荷和资源开销。</p><p>OK, 在取得了指令数据，识别出了数据中的指令，并对指令做了一些优化合并之后，就该开始正儿八经地解码了，这部分在后面的文章中介绍。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚9：Skylake微架构(Microarchitecture)剖析(1)</title>
      <link href="/2019/01/07/quickwords9-skylake-pipeline-1/"/>
      <url>/2019/01/07/quickwords9-skylake-pipeline-1/</url>
      
        <content type="html"><![CDATA[<h2 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h2><p>了解CPU的微架构是基于其开发“硬核”软件的必需步骤。由于一些历史遗留问题，现存的技术资料往往存在一些概念混淆、重复命名甚至自相矛盾之处。本文一来梳理Skylake微架构(主要是流水线)的组成和特性，二来试图厘清一些含混的概念用以帮助后来者。</p><p>另外在介绍完微架构之后，会继续结合<code>Perf</code>中的<code>Performance Event</code>来对照说明互为印证。</p><a id="more"></a><blockquote><p>需要强调的是，本文的重点是Skylake的流水线(pipeline)架构，core间的连接和架构方式不作重点说明。</p></blockquote><h2 id="Skylake简介"><a href="#Skylake简介" class="headerlink" title="Skylake简介"></a>Skylake简介</h2><p>Skylake是由Intel以色列研发中心于2015年发布的14nm CPU架构。作为Broadwell的继任者，Skylake在原有架构的基础上，对一些关键特性和组件做出了相当幅度的优化：</p><p><img src="https://en.wikichip.org/w/images/thumb/0/0d/skylake_buff_window.png/350px-skylake_buff_window.png" alt=""></p><p>上图简单列举了一些量化指标，现在不求甚解就好。</p><p>在指令集方面，引入了<code>AVX-512</code>、<code>CLFLUSHOPT</code>、<code>CLWB</code>等新的指令集，不过本文不打算介绍这些东西，写到这里只是觉得如果只用上一段话结束这一小节有些太突兀了。</p><h2 id="流水线总览"><a href="#流水线总览" class="headerlink" title="流水线总览"></a>流水线总览</h2><p><img src="https://en.wikichip.org/w/images/thumb/8/80/intel_common_arch_post_ucache.svg/428px-intel_common_arch_post_ucache.svg.png" alt=""></p><p>引用上面这张图是为了举一个反例，说明一下本文要解决的问题。这张图可以被当做是一张流水线的架构抽象，我可以指着每一个组件讲讲它们都是干嘛的，但这里的问题就是某一个相同的组件在不同的文档、资料、甚至语境下可能有两个甚至更多个名字。</p><p>比如蓝色方块最下面的<code>Allocation Queue</code>，它就还有一个名字叫做<code>Instruction Decode Queue</code>，同时它还有可能被叫做<code>IDQ</code>或<code>AQ</code>。而关于<code>Decoded Instruction Queue</code>、<code>Micro Instruction Sequencer</code>、<code>Re-order buffer</code>、<code>Scheduler</code>、<code>Reservation Station</code>等概念的辨析也是…需要下一番功夫。</p><p>本文将以全网最清晰的方式讲清楚这些概念。</p><p>从high-level的层面来讲，Skylake的流水线架构与Broadwell和Haswell没有太大出入。还是可以分为两个阶段：</p><h3 id="前端-Front-End"><a href="#前端-Front-End" class="headerlink" title="前端(Front-End)"></a>前端(Front-End)</h3><p>上图中蓝色部分就代表流水线的前端。它的主要作用就是获取指令、解码(Decode)指令。</p><p>为了最大限度的发挥CPU的能力，前端就需要尽可能高效率地把程序指令输送给后端。这里就面临两个挑战：</p><ol><li>如何更快更准确地取得要执行的指令</li><li>如何将取得的指令更快地解码为微指令(micro-ops/uops)</li></ol><p>有了更多的微指令输送给后端（执行单元），后端的工作量才能饱和。而前端的所有组件和机制，都是围绕这两个挑战进行的。</p><h3 id="后端-Back-End"><a href="#后端-Back-End" class="headerlink" title="后端(Back-End)"></a>后端(Back-End)</h3><p>上图中红色的部分就代表流水线的后端。一般来讲绿色的部分是存储子系统，虽然与后端交互，但严格讲不算在后端里面。</p><p>后端的主要任务就是执行前端送过来的指令。和前端类似，后端除了“来料加工”之外，也有它自己需要面对的挑战：</p><ol><li>如何提高指令的并行程度</li><li>如何充分利用已有的CPU能力</li></ol><p>如果将CPU比作一家餐厅，跑在上面的应用就是来餐厅就餐的食客。前端类似餐厅的服务生，需要接受客人的下单，同时将订单送到后厨。而后厨就类似后端，负责做出客人需要的菜品。</p><p>但如何能让上菜速度更快？前端是否可以在客人排位时就让其提前下单？后厨是否能够提前准备好本店热门的特色菜，或者一并煮好一大锅面条，根据需要浇上不同的浇头？</p><p>CPU说是高科技，其实干得也就是这些事情。</p><p>在下一篇文章中将详细介绍一下前端。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>汉光文帝教你如何提出领导无法拒绝的方案</title>
      <link href="/2019/01/05/history2-liuyuan/"/>
      <url>/2019/01/05/history2-liuyuan/</url>
      
        <content type="html"><![CDATA[<h2 id="在成为领导之前"><a href="#在成为领导之前" class="headerlink" title="在成为领导之前"></a>在成为领导之前</h2><p>只有开国皇帝的孙子生下来就是皇帝，开国皇帝往往都给别人打过工。</p><p>别人给老板打工，不高兴了可以换个老板，而开国皇帝给老板打工，不想干了还必须得干掉老板。<br><a id="more"></a></p><p>这次要说的就是汉赵的开国之君汉光文帝刘渊。当然在成为开国之君之前，刘渊也曾有过一位叫司马颖的老板。</p><p>司马颖是司马家“八王之乱”中的一乱。在还没有乱起来的时候，匈奴贵族出身的刘渊就被送到晋朝作质子(人质)。</p><p>说到做人质，这是一个投资收益比两极分化严重的工作。史书上出现过的人质，要么潜龙入海回归故国做了一番大事，要么就是成为第一个祭旗的祭品。</p><p>同样的问题也摆在了刘渊面前。在司马颖还没登上历史舞台的时候，司马家内部就有声音要除掉刘渊，以防其“非我族类其心必异”。虽然由于贵人的保荐逃过一劫，但刘渊一定不喜欢自己的命运捏在别人手上的滋味。</p><p>等到司马家的兄弟们相斫之时，刘渊和他的匈奴族人终于等来了机会——趁中原板荡，他要回到匈奴。</p><p>但司马颖不会不明白这么基本的道理。他一方面要利用刘渊领兵打仗的能力襄助自己，一方面也更不可能纵虎归山。</p><p>刘渊需要提出一个能让司马颖心甘情愿让他回到匈奴族人那里去的方案。</p><h2 id="还是要考虑历史的进程"><a href="#还是要考虑历史的进程" class="headerlink" title="还是要考虑历史的进程"></a>还是要考虑历史的进程</h2><p>如果司马颖一手平定了内乱成为了晋朝的中兴之主，那肯定也就没刘渊什么事了。</p><p>但司马颖此时正在遭受外部敌人的猛烈攻击。刘渊自然会利用这一时机，提出回部请匈奴部众救援的提议。</p><p>但司马颖必然还是会担心，所以他首先提出一个方案：</p><blockquote><p>颖曰：“五部之众，果可发否？就能发之，鲜卑、乌桓，未易当也。吾欲奉乘舆还洛阳以避其锋，徐传檄天下，以逆顺制之，君意何如？”——《资治通鉴》</p></blockquote><p>基本思想就是，你的方案我没太大把握(对你没什么信心)，即便可行，也不见得打得过敌人。我先带着皇帝回洛阳躲避一下锋芒，然后再挟天子慢慢想办法。</p><p>这个时候，切忌就领导的方案展开细节上的辩论。比如说一些什么“我一定能动员我的族人过来帮你”、“鲜卑乌桓，一帮乌合之众而已”，“皇帝早就不能号令天下了”等等。</p><p>那应该说什么？看一下刘渊怎么说的：</p><blockquote><p>渊曰：“殿下武皇帝之子，有大勋于王室，威恩远著，四海之内，孰不愿为殿下尽死力者！何难发之！王浚竖子，东嬴疏属，岂能与殿下争衡邪！殿下一发鄴宫，示弱于人，洛阳不可得而至；虽至洛阳，威权不复在殿下也。愿殿下抚勉士众，靖以镇之，渊请为殿下以二部摧东嬴，三部枭王浚，二竖之首，可指日而悬也。”——《资治通鉴》</p></blockquote><p>这段话可以分为三个部分：</p><h3 id="为什么这么做可行"><a href="#为什么这么做可行" class="headerlink" title="为什么这么做可行"></a>为什么这么做可行</h3><p>刘渊在陈述这一句的时候，并没有以“我”为主语。他没有说“我”在我的族人里多么有威信，“我”有哪些神奇的手段可以确保可行等等。而是将“你”，也就是领导作为了最主要的原因。</p><p>此时即便你说的是最没有逻辑的理由，在领导那里也是有逻辑的。因为领导首先是个人，而不是一架逻辑的机器。</p><p>当你将领导认为最能体现出他的特点和价值的东西拿出来说服他，如果你还说服不了他，那只能证明他已经神经错乱了，比八王之乱还要乱。</p><p>证明可行要用“正”，证明为什么要这么做要用“奇”，也就是从反面来论述。</p><h3 id="为什么要这么做"><a href="#为什么要这么做" class="headerlink" title="为什么要这么做"></a>为什么要这么做</h3><p>从反面来论述，就是假设你不这么做，会有什么危害。</p><p>会有什么危害呢？必须是失去其最看重的东西。</p><blockquote><p>虽至洛阳，威权不复在殿下也。</p></blockquote><p>也许能逃得性命，也许手里还能有“皇帝”这样一枚棋子，但在现在的世道，谁拳头大谁就是权威。你自己就是这么上来的，当然明白权威的价值。如果别人一吓唬就逃跑了，那别人就是新的权威。</p><p>你没有了权威，其他的一切还有什么意义？你要不这么做，还闹啥闹？</p><h3 id="具体怎么做"><a href="#具体怎么做" class="headerlink" title="具体怎么做"></a>具体怎么做</h3><p>关于这一部分，刘渊只用了最短的篇幅，却把所有需要说明的要素都覆盖了：</p><blockquote><p>渊请为殿下以二部摧东嬴，三部枭王浚，二竖之首，可指日而悬也。</p></blockquote><p>作为一个办公室里的白领，你一定听别人说过“要用SMART法则给领导提方案”。</p><p>那么我们就套用一下SMART法则的框架分析一下刘渊的这句话：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SMART法则</span><br><span class="line"></span><br><span class="line">*Specific:“二竖之首”</span><br><span class="line">*Measurable:“悬”</span><br><span class="line">*Achievable:“以二部摧东嬴，三部枭王浚”</span><br><span class="line">*Relevant: “渊请为殿下”</span><br><span class="line">*Time-bound:“指日”</span><br></pre></td></tr></table></figure><p>这TM简直是古典与现代的完美结合。</p><p>司马颖在听后终于放下了他对刘渊的芥蒂。不是因为他真的不再怀疑刘渊，而是刘渊的提议毫无破绽。</p><p>而刘渊也终于凭借这个提议回到了他的北方，在接下来的历史里开创了属于自己的时代。</p>]]></content>
      
      
      <categories>
          
          <category> history </category>
          
      </categories>
      
      
        <tags>
            
            <tag> history </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去4：82599在DPDK下使用fdir</title>
      <link href="/2019/01/04/test4-82599-fdir/"/>
      <url>/2019/01/04/test4-82599-fdir/</url>
      
        <content type="html"><![CDATA[<h2 id="文档过期"><a href="#文档过期" class="headerlink" title="文档过期"></a>文档过期</h2><p>近期有客户反馈82599的fdir(flow director)功能在DPDK环境下不生效，本想丢一个DPDK官网上的82599 fdir测试资料过去，但幸好我仔细看了一下测试流程，发现这个<a href="https://doc.dpdk.org/dts/test_plans/fdir_test_plan.html" target="_blank" rel="noopener">官方文档</a>里使用的<code>testpmd</code>命令已经过期了(时间戳：Jan 3rd, 2019)….所以…我自己写一个吧。</p><a id="more"></a><h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DPDK Version: 17.11</span><br><span class="line">NIC: 82599</span><br><span class="line">DUT: test-pmd</span><br><span class="line">Traffic Generator: scapy</span><br></pre></td></tr></table></figure><p>其中DUT与Traffic Generator 10G接口直连。</p><h2 id="Test-Cases"><a href="#Test-Cases" class="headerlink" title="Test Cases"></a>Test Cases</h2><h3 id="首先测试对ipv4-tcp报文的支持"><a href="#首先测试对ipv4-tcp报文的支持" class="headerlink" title="首先测试对ipv4-tcp报文的支持"></a>首先测试对<code>ipv4-tcp</code>报文的支持</h3><h4 id="perfect-mode"><a href="#perfect-mode" class="headerlink" title="perfect mode"></a>perfect mode</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=perfect --nb-ports=1</span><br><span class="line">set verbose 1</span><br><span class="line">set fwd rxonly</span><br><span class="line"></span><br><span class="line">flow_director_filter 0 mode IP add flow ipv4-tcp src 172.16.182.82 20 dst 2.2.2.3 80 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1</span><br><span class="line"></span><br><span class="line">start</span><br></pre></td></tr></table></figure><p>在Traffic Generator侧构造一个匹配的报文并发送：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p1=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.182.82", dst="2.2.2.3")/TCP(sport=20, dport=80)</span><br><span class="line">sendp(p1, iface="ens785f0")</span><br></pre></td></tr></table></figure><p>应该可以看到<code>testpmd</code>将该报文收到了Queue 1。</p><h4 id="signature-mode"><a href="#signature-mode" class="headerlink" title="signature mode"></a>signature mode</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=signature --nb-ports=1</span><br></pre></td></tr></table></figure><p>除在上面的命令行中<code>--pkt-filter-mode=signature</code>之外与前一个测试例完全一致。</p><blockquote><p>对<code>ipv4-udp</code>的测试也基本类似，不再赘述。</p></blockquote><h3 id="测试对ipv6-tcp报文的支持"><a href="#测试对ipv6-tcp报文的支持" class="headerlink" title="测试对ipv6-tcp报文的支持"></a>测试对<code>ipv6-tcp</code>报文的支持</h3><h4 id="Signature-mode"><a href="#Signature-mode" class="headerlink" title="Signature mode"></a>Signature mode</h4><blockquote><p>82599 DPDK ixgbe驱动不支持IPv6报文flow director的<code>perfect mode</code>，所以只能用<code>signature mode</code>。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=signature --nb-ports=1</span><br><span class="line">set verbose 1</span><br><span class="line">set fwd rxonly</span><br><span class="line"></span><br><span class="line">flow_director_filter 0 mode IP add flow ipv6-tcp src fcbd:dc01:1:222:0:0:0:3 8000 dst fcbd:dc01:1:222:0:0:0:12 1029 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1</span><br><span class="line"></span><br><span class="line">start</span><br></pre></td></tr></table></figure><p>在Traffic Generator侧构造一个匹配的报文并发送：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p1=Ether(src=get_if_hwaddr("ens785f0"))/IPv6(src="fcbd:dc01:1:222:0:0:0:3",dst="fcbd:dc01:1:222:0:0:0:12")/TCP(sport=8000,dport=1029)</span><br><span class="line">sendp(p1, iface="ens785f0")</span><br></pre></td></tr></table></figure><p>应该可以看到<code>testpmd</code>将该报文收到了Queue 1。</p><blockquote><p><code>ipv6-udp</code>报文的支持也基本类似。</p></blockquote><h3 id="添加Mask"><a href="#添加Mask" class="headerlink" title="添加Mask"></a>添加Mask</h3><p>问题主要在对Mask的支持上，首先用<code>ipv4-tcp</code>举个栗子：</p><h4 id="如果想mask掉-通配-全部的src-ip"><a href="#如果想mask掉-通配-全部的src-ip" class="headerlink" title="如果想mask掉(通配)全部的src ip"></a>如果想mask掉(通配)全部的<code>src ip</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=signature --nb-ports=1</span><br><span class="line">set verbose 1</span><br><span class="line">set fwd rxonly</span><br><span class="line">port stop 0</span><br><span class="line">flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFF dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFF</span><br><span class="line">port start 0</span><br></pre></td></tr></table></figure><p>这个配mask的命令长得令人发指，同时必须要先stop port 0。通配的方式就是src_mask后写<code>0.0.0.0</code>。<br>这时如果你希望所有源端口号是20，目的IP是2.2.2.3，目的端口号是80的报文都进入Queue 1，那么flow director的命令必须写成：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">flow_director_filter 0 mode IP add flow ipv4-tcp src 0.0.0.0 20 dst 2.2.2.3 80 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1</span><br><span class="line">start</span><br></pre></td></tr></table></figure></p><p>一般人的理解，设置了通配mask之后，<code>src IP</code>写成什么都无所谓了，但这里必须要写成<code>0.0.0.0</code>，不然匹配不到。</p><p>Traffic Generator侧构造任意<code>src IP</code>的且满足其他匹配条件的报文，并发送：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">p1=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.182.82", dst="2.2.2.3")/TCP(sport=20, dport=80)</span><br><span class="line">p2=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.182.8", dst="2.2.2.3")/TCP(sport=20, dport=80)</span><br><span class="line">p3=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.18.82", dst="2.2.2.3")/TCP(sport=20, dport=80)</span><br><span class="line"></span><br><span class="line">sendp(p1, iface="ens785f0")</span><br><span class="line">sendp(p2, iface="ens785f0")</span><br><span class="line">sendp(p3, iface="ens785f0")</span><br></pre></td></tr></table></figure></p><p>可以在<code>testpmd</code>中看到三个报文均进入了Queue 1。</p><h4 id="如果想mask掉-通配-全部的src-ip与scr-port"><a href="#如果想mask掉-通配-全部的src-ip与scr-port" class="headerlink" title="如果想mask掉(通配)全部的src ip与scr port"></a>如果想mask掉(通配)全部的<code>src ip</code>与<code>scr port</code></h4><p>与上一个类似，设置mask和fdir规则的命令分别为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0x0 dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFF</span><br><span class="line"></span><br><span class="line">flow_director_filter 0 mode IP add flow ipv4-tcp src 0.0.0.0 0 dst 2.2.2.3 80 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1</span><br></pre></td></tr></table></figure><p>与之前一样，fdir规则中，<code>src</code>后面必须写<code>0.0.0.0 0</code>才能达到预期效果。</p><p>此时仅由目的IP和目的端口号决定报文的去向。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">p1=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.182.82", dst="2.2.2.3")/TCP(sport=19, dport=80)</span><br><span class="line">p2=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.182.8", dst="2.2.2.3")/TCP(sport=2, dport=80)</span><br><span class="line">p3=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.18.82", dst="2.2.2.3")/TCP(sport=21, dport=80)</span><br><span class="line"></span><br><span class="line">sendp(p1, iface="ens785f0")</span><br><span class="line">sendp(p2, iface="ens785f0")</span><br><span class="line">sendp(p3, iface="ens785f0")</span><br></pre></td></tr></table></figure><p>可以在<code>testpmd</code>中看到三个报文均进入了Queue 1。</p><h4 id="IPv6的情况"><a href="#IPv6的情况" class="headerlink" title="IPv6的情况"></a>IPv6的情况</h4><p>如果想mask掉IPv6报文的<code>src ip</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">port stop 0</span><br><span class="line">flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 0:0:0:0:0:0:0:0 0x0 dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFF</span><br><span class="line">port start 0</span><br></pre></td></tr></table></figure><p>同理，fdir规则中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow_director_filter 0 mode IP add flow ipv6-tcp src 0:0:0:0:0:0:0:0 0 dst fcbd:dc01:1:222:0:0:0:12 1029 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1</span><br></pre></td></tr></table></figure><p><code>ipv6-tcp src</code>后必须写<code>0:0:0:0:0:0:0:0 0</code>以配合mask的设置。</p><blockquote><p>关键就是如果mask中某字段中某bit为0，那么fdir规则中该字段对应的bit位也必须为0，82599网卡才能按预期的方式工作。</p></blockquote><p>再举一个栗子，如果想将dst port的mask设置为0x00F0，对应的mask和fdir规则为：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 0:0:0:0:0:0:0:0 0x0 dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0x00F0</span><br><span class="line"></span><br><span class="line">flow_director_filter 0 mode IP add flow ipv6-tcp src 0:0:0:0:0:0:0:0 0 dst fcbd:dc01:1:222:0:0:0:12 240 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 2</span><br></pre></td></tr></table></figure></p><p>此时再发送目的端口号为240或241…的IPv6报文都可以匹配该fdir规则。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> network </tag>
            
            <tag> dpdk </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>唯识与C语言指针</title>
      <link href="/2018/12/31/thoughts2-weishi-c-pointer/"/>
      <url>/2018/12/31/thoughts2-weishi-c-pointer/</url>
      
        <content type="html"><![CDATA[<blockquote><p>旧文虽无殊胜处却最解少年意，重发于此，乃自喜其披坚执锐行而无返之气。</p></blockquote><h1 id="作者按"><a href="#作者按" class="headerlink" title="作者按"></a>作者按</h1><p>丙申孟春，始得熊君十力之微言宏旨，于《新唯识论》中得窥心外无物，体用不二，翕辟成变之理。数年兵、道、史、释之学，终为一脉贯通，于世间纷杂，万相罗织，始有定见。乃身蹈统摄之道，心得自在清凉，不免情动于衷，喜不自胜。</p><p>熊君为阐唯识之旨，于书中多举譬喻。举“海水与众沤”喻，“绳索与大麻”喻种种；更尝作图形，以穷其本旨，表其胜义，苦口婆心，令人动容，非沐手开卷不能彰其功，焚香斋戒不能铭其德。吾观乎此学，虽能以物物强为譬喻，然万物浩汤，皆为大化，果有以大化喻大化之理乎？终须另觅一人造之物，探幽寻明，见微知著，庶几可得于大化矣。今请试以指针喻之。</p><p>下面开始正常说话。<br><a id="more"></a></p><h1 id="这是要干什么？"><a href="#这是要干什么？" class="headerlink" title="这是要干什么？"></a>这是要干什么？</h1><p>没有人会对“世界到底是什么？”这个问题不感兴趣。科学、哲学、艺术，宗教都在以种种的方式诠释这个问题的答案。作为人生不可逃避的问题之一，每个人或多或少，也都会有自己或明朗或隐约的勾画。</p><p>但是在这个问题上，一直存在诸多的争论。且不说唯心唯物之争，在以确定性立身的科学领域，在人们得窥量子的堂奥之后，也观察到了诸如“二相性”、“测不准”，“非定域”等等的现象，虽然有各个理论都在尝试自圆其说，但不可否认的一点是，随着人类的进步，世界不是变得越来越简单，而是变得越来越复杂了。</p><p>而这恰恰是符合逻辑的。外物确为实有，却不曾脱离心而存在。人类的进步，自然伴随心智的成长，自然就会见到以前“视而不见”的东西。并非有新物凭空而生，而是原物之一“相”得显于成长了的心智。这一新“相”又成为心智继续成长的养料，从而使人认识到更多。这一过程永无休止，方生方死，方死方生。这不是简单的唯物或唯心，而是要结合两者各自的主张。</p><p>唯识论就是在做这一尝试。为表明物与心的关系，亦即如何认识世界的问题，熊君在其论述中做了种种譬喻。惜哉熊君，英才天纵，所举例证却仅限于瓶、罐、桌，绳之间，虽可强为譬喻，但恐有志于学者，不能于此中得其全旨。</p><p>计算机是人类创造的一个世界，人通过编程语言与这个世界发生相互作用。正可成为我们用以阐明世界本旨的绝佳实例。简单类比，计算机里的三极管，是真实存在的“物”，三极管的开关，是其呈现出的“相”，而对这些开关如何认识，就是我们的“心”。唯识精深，非我所能穷究，仅在此以C语言另作一譬喻，以望有启于同侪，足慰心愿。</p><h1 id="如何从C语言中领悟心外无物"><a href="#如何从C语言中领悟心外无物" class="headerlink" title="如何从C语言中领悟心外无物"></a>如何从C语言中领悟心外无物</h1><p>在Linux上编写的C语言是相对底层的语言，原因有很多，但可以直接操作允许范围内的系统内存一定是原因之一。内存的操作除了分配、释放和更改之外，还需要更加频繁地标记和指向，这便引入了指针的概念。一个指针也只是一个普通的变量，只是它的值是一个内存的地址，如此便“指向”了该内存。这些基础的知识，无需再赘言。本文所强调的，是指针、内存、程序之间的种种变换。</p><p>有如下基础代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*object struct*/</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"></span><br><span class="line">    element_type element;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*void pointer*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span>*ptr=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object</span> <span class="title">obj</span>;</span></span><br><span class="line"></span><br><span class="line">obj.element=element_value1;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*point to obj, cast to type struct object*/</span></span><br><span class="line"></span><br><span class="line">(struct object*)ptr=&amp;obj;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*modify obj's member value through pointer*/</span></span><br><span class="line"></span><br><span class="line">*ptr.element=element_value2;</span><br></pre></td></tr></table></figure><p>Line1-6 声明<code>object</code>结构体</p><p>Line 8 定义了一个指针，类型为<code>void*</code>,并指向NULL</p><p>Line 9 定义了<code>objecti</code>结构体对象<code>obji</code>，系统为其分配一片内存</p><p>Line 10 为i<code>obj</code>中的<code>elementi</code>成员赋值为<code>element_value1</code></p><p>Line 12 将对象i<code>obji</code>所在的内存首地址存入i<code>ptri</code>指针中，并将指针类型转换为<code>struct object *</code></p><p>Line 14 解析<code>ptri</code>指针，更改i<code>element</code>对应内存的内容，并赋值为i<code>element_value2</code></p><p>定义对象obj，系统在栈内存上划出了一片内存空间，其长度为obj的长度。但在完成这一步之后，这一部分内存并没有因此产生任何变化。内存里的每一个比特，并没有带上任何“这是obj的内存”的标记。从内存本身来看与没有obj时没有分别。内存作为载体，是一切变动的肇始，不增不减，不净不垢，是真实存在的。</p><h2 id="物是实有的"><a href="#物是实有的" class="headerlink" title="物是实有的"></a>物是实有的</h2><p>到这里，分配给obj的这片内存是有实体存在，却是没有任何“相”可言的。</p><p>在Line10中，我们为<code>elementi</code>赋值，相应的，会引起内存的变化。变化的内存的位置，程序可于<code>struct objecti</code>的定义中得知（计算element_type的offest，）。在赋值之后，这片内存有了第一个“相”，我们可以将这个“相”笼统称为“element的值为element_value1”的obj，就如同我们称呼一个“蓝色带横条纹的“皮球一样。这个值，可以为任何一个允许的值，于是obj就可以显现出任何一个对应的“相”。</p><h2 id="相是变动不居的"><a href="#相是变动不居的" class="headerlink" title="相是变动不居的"></a>相是变动不居的</h2><p>接下来是对指针的的操作。指针是什么？前面虽然已有技术上的说明，但还没有点出本文想阐明的主旨。指针可以让程序连接到相应的数据内存上，如果将程序本身比作自身的意识，内存比作实有的物质世界，那么指针就是我们用以认识世界的感官，是“眼耳鼻舌身意”，它将决定我们接触（看、听、嗅，触摸等等）到哪个实有的物质（指向内存），以及意识中对物质的“相”如何认识（依何种struct定义去解析内存）。</p><p>真正的关键，是指针类型的转换。只有将指针的类型转换为<code>struct object *i</code>，后续的代码才有意义。类型转换并没有改变指针本身，它所在的内存地址，它的长度，它的作用域等等并没有任何变化，但程序（意识）却懂得了，它所接触到的那片内存（实体），是一个<code>struct object</code>的区域（相），并且可以以此认识和改造obj此时显现出来的“相”。这便是常说的“相由心生”之意。</p><h2 id="人通过感官与物质的相发生作用"><a href="#人通过感官与物质的相发生作用" class="headerlink" title="人通过感官与物质的相发生作用"></a>人通过感官与物质的相发生作用</h2><p>就像我们的眼睛、口鼻，手足（指针本身）始终没有什么变化，但我们却可以将某一物质识为瓶瓶罐罐，桌子麻绳，皆是因为我们的意识通过感官注意于其上（Line12），并依照指针的类型给出了对此“相”解释。依照对“相”的理解，我们可以作用于物质，令起变为另外一种“相”(Line14)。</p><p>如果我们不能通过感官去注意(动宾用法，下同)此物，或对此物视而不见（即不能有相关的struct去解释此物，”视而不见”不等同于”看不到”），那么虽然该物是真实存在的，但其“相”在我们的心里是不存在的。此柏拉图洞穴壁影所喻之意，亦为王阳明“与花同归于寂，同起于明”之意。就像虽然内存中的数据是一直都有的，但如果我们没有指针类型的转换，甚至没有struct object的定义，那对程序（意识）来说，任何obj的“相”都是不存在的。唯其二者（指针与struct）皆备于心（意识），才可得obj之“相”。此所谓“心外无物”之意。</p><h1 id="如何从C语言中领悟翕辟成变"><a href="#如何从C语言中领悟翕辟成变" class="headerlink" title="如何从C语言中领悟翕辟成变"></a>如何从C语言中领悟翕辟成变</h1><p>一个某一类型的指针，只要该类型(struct)存在于程序（意识）中，就可以内存（实有的物质）作出相应的解析（物质的相）。通过对“相”的认识（struct中成员的定义），就可以使意识与物质发生作用，但所能改变的，及其改变后的形态，却始终不出“相”的范畴。若上述明了，可稍悟叔本华“意志与表象”之旨。</p><p>但我们需注意的是，指针的类型可以变为任意类型。如从i<code>void*</code>变为i<code>struct object*i</code>，其指向的内存并没有变化，内存本身也没有变化，但程序（意识）对这片内存的解释发生了变化。同一物质，转换成了另外的相，这便是熊君所述，物质转为心上之相的翕的势用。</p><p>如指针从<code>struct object*</code>类型转为<code>void*i</code>类型，则对程序而言，该处内存所显现出的相尽皆消失，只是一片混沌虚静，原有的“相”复返归于大化，此熊君所述，心上之相转为物质的辟的势用。翕辟两者结合，便是老子所谓“无为而无不为”之意。</p><p>从中亦说明一个道理，同一个物质，可计现万相。即同一片内存，可以接受任何类型的指针，其所显现的“相”，亦因指针类型的不同而可显为一组群相。而某一时刻我们所见得的一种”相“，只是此实在之物的“诈现”之相。“相”终是变动不居的，此即《心经》所述“一切有为法，皆如梦幻泡影，如电亦如露”之意。</p><h2 id="于万相中取其一相"><a href="#于万相中取其一相" class="headerlink" title="于万相中取其一相"></a>于万相中取其一相</h2><p>有如下基本代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object1</span>&#123;</span>intobject1_num;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object2</span>&#123;</span>intobject2_num;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span>*ptr=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object1</span> <span class="title">obj</span>;</span></span><br><span class="line"></span><br><span class="line">(struct object1*)ptr=&amp;obj;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*assign random_value to the first sizeof(int) bytes*/</span></span><br><span class="line"></span><br><span class="line">*ptr.object1_num=random_value;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*cast pointer type to struct object* and do the same thing*/</span></span><br><span class="line"></span><br><span class="line">*(struct object2*)ptr.object2_num=randome_value;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*cast pointer type to int* and do the same thing*/</span></span><br><span class="line"></span><br><span class="line">*(<span class="keyword">int</span>*)ptr=random_value;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*cast pointer type to char* and do the same thing*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> i=<span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(--i)&#123;</span><br><span class="line"></span><br><span class="line">*(<span class="keyword">char</span>*)(ptr+i)=random_value&amp;(<span class="number">0xFF000000</span>&gt;&gt;(i*<span class="number">8</span>));</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上的代码，从Line12开始，都是在对同一块内存进行相同的赋值操作。不同的指针类型，使程序对同一块内存的解释也不尽相同。struct可以从i<code>object1</code>至<code>object2</code>乃至于无穷，所有的struct皆可为&amp;obj处内存所诈现的任一之相。这也解释了，为什么同一事物，有人识得，却有人不识，或两人皆识得，却有不同的态度和看法。</p><p>人的一生，始终都在填充自己的头文件库。有了新的阅历，即是添加了新的struct；对事物有了新的认识，即是在原有的struct中添加了新的成员变量。意识将这些从感官搜集来的struct再重新注意于感官（指针类型转换）之上，便得出了我们所见的世界。</p><p>如果我们所见到的事物，只是真实本体诈现的一相，我们是否有可能穷尽事物所有的相？答案是不能。因为我们的感官无法无限拓展。虽然我们如今有了红外探测仪，X光机等等设备辅助我们的眼睛，声呐、雷达等设备辅助我们的耳朵，但即便是集合所有的外来辅助，甚至是未来所有的外来辅助，所能见到的也只是物质本体的一部分“相”。如一个红色的气球，在可见光范围内，红色是其一相，在红外线范围内，又呈另外一相，既有物质波的相，也有引力波的相，未来还会有新的相。这个过程，便是人对物质的逐步深入认识，即寻找出本体所呈现出的更多的相。但这永远不会止步，就如同struct的定义没有限制一样。所能得知的，就是在指针类型的转换中，在一翕一辟中，在对struct不断地添加调整修改中，形成了我们现在所身处的此在世界。就如同指针不能指向地址长度之外的内存一样，有些相，是我们永远也看不见的。但这些看不见的东西，离我们并不遥远，它是与我们能见到的“相”同时存在的，都是实有的物质本身。如同引力波是物质都具有的一个“相”，但在之前我们都不曾有所体认一样。我们始终在认识“相”的路上，而成就了一切“相”却又不是“相”的，是实有的物质。此即老子所谓“万物恃之以生而不辞，功成不名有，衣养万物而不为主”之谓。</p><h1 id="再论人生之意义"><a href="#再论人生之意义" class="headerlink" title="再论人生之意义"></a>再论人生之意义</h1><p>如果我们无法完全识却世界之本体万相，那我们岂非是活在自欺欺人之中。此言大谬。须知当指针指向一片内存的时候，程序便已可接触内存的每一位比特。易言之，当感官接收到某一实体显现的“相”时，意识已经注意到了实体本身。套用不同的struct会让同一片内存显为不同的“相”，但并不妨碍程序在此“相”中对内存的操作和功用。人生的意义，须在这里求得。</p><p>每一段程序，都有其特别的作用，即便是运行在同一台机器上，运行在同一片内存上（不同时刻），也都有其所特有的对内存的理解和操作。为完成程序自身的任务，体现其意义与价值，每段程序都要对内存有其自身的理解与互动。我们见不到实体全部的“相”，并不是对我们的一种限制，恰恰是对我们的一种褒奖。让我们可以于万相纷杂中取其一，并专注于此，完善自己的心智，完成自己的任务。</p><p>而人生的意义，不在于求得对实体的全部理解，因为那可能是别人的人生，是一种向外的追寻；真正的意义在于求得自身的圆满，而这一切都需要向内去寻求。写好自己的头文件，磨练自己的API，若能将自己这段“程序”补充完整，让它完成自己要去做的任务，吾不知复有何求矣。</p><p>2016.4.22</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>吃牛排的技术</title>
      <link href="/2018/12/28/steak/"/>
      <url>/2018/12/28/steak/</url>
      
        <content type="html"><![CDATA[<p>虽然不知道背后是什么原理，但烤出好吃的牛排一定是一门重要的技术。</p><p>因为重要的技术，门槛一般都很高。它的高不仅体现在如何掌握这门技术，还体现在如何使用这门技术。<br><a id="more"></a></p><p>作为一个普通的食客，一个“烤牛排”这门技术的用户，你首先得学会实例化牛的各个部位。必须要准确给出Rib Eye、T-Bone、Filet的名字，大小写敏感，但也许其实你根本不知道这具体是牛身上的哪个部分。</p><p>然后要学会在不同场景下调用一分熟、五分熟、九分熟和rare、medium、well-done这种多态接口，以及不要设置“十分熟”这种非法参数。</p><p>对于高级用户自然还会有cru、à point、bien cuit来丰富抽象接口的实现；同时还会用一杯Pinot Noir或者Sauvignon Blac作为必不可少的语法糖点缀。</p><p>但当品尝了食客、厨师、还有牛都付出了如此努力才端上来的珍馐之后，你很难在第二天回味起它是什么味道——仿佛残留在唇齿间的始终是当时在餐桌上没说的心思。</p><p>见过一个人吃火锅，但我始终没见过一个人吃牛排。似乎“技术”可以用来掩盖目的，越是高深的技术，掩盖得越不动声色，掩盖得越托物言志。</p><p>我也从来不自己一个人来这家店。周五的中午，没有太多项目和进度报表，没有轻描淡写的握手和佶屈聱牙的名片，更没有迷离的夜色温柔；我所仰仗的“技术”，不过是打开APP找一找团购的套餐，然后在咬上一口汁液四溢时捂住嘴，和对面的人说上一句含混不清的：</p><p>“新年快乐”   emmmm..</p><p><img src="https://s1.ax1x.com/2018/12/28/FWrgiV.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去3：抽象层直接调用实例方法性能提高百分之20</title>
      <link href="/2018/12/27/test3-indirectcall/"/>
      <url>/2018/12/27/test3-indirectcall/</url>
      
        <content type="html"><![CDATA[<blockquote><p>首先吐槽一下hexo标题不能以%结尾 -_-||</p></blockquote><h2 id="抽象层"><a href="#抽象层" class="headerlink" title="抽象层"></a>抽象层</h2><p>经常，我们会在相对比较成熟的软件中见到这样一类结构体：<br><a id="more"></a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">void</span> <span class="params">(*func)</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">abstraction_layer</span> &#123;</span></span><br><span class="line">    func f;</span><br><span class="line">    …</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>内部的成员变量，多以函数指针为主。</p><p>这种结构体主要作用是实现一个”抽象层”，用来解耦上层的业务需求和具体的实现。在操作系统、设备驱动等各种场合有很广泛的应用。</p><p>采用这种抽象形式，虽然增加了程序的灵活性和拓展性(其实就是OOP中多态的实现方式)，但最大的问题就是当真正需要调用某一实例的方法时，只能通过抽象层的函数指针间接调用(indirect call)，而这种调用是伤害性能的。</p><p>有没有在性能上更好的方式呢？</p><h2 id="测试对象"><a href="#测试对象" class="headerlink" title="测试对象"></a>测试对象</h2><p>我们构造这样一个抽象层和一组具体的实现：</p><p>抽象层<code>struct op</code>需要实现六个操作接口：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FUNC_RETURN_TYPE void</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FUNC_PARAMETER void</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OPS \</span></span><br><span class="line">    _(open) \</span><br><span class="line">    _(close) \</span><br><span class="line">    _(write) \</span><br><span class="line">    _(read) \</span><br><span class="line">    _(add) \</span><br><span class="line">    _(<span class="keyword">delete</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _(op) typedef FUNC_RETURN_TYPE (*op)(FUNC_PARAMETER);</span></span><br><span class="line">OPS <span class="comment">// typdef void (*open)(void) and so on...</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> _</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _(op) op op##_fp;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">op</span> &#123;</span></span><br><span class="line">    OPS <span class="comment">// open open_fp; and so on...</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> _</span></span><br></pre></td></tr></table></figure><p>而具体实现这些结构体的实例我们用不同的“颜色”表示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> LIST \</span></span><br><span class="line">    _(red) \</span><br><span class="line">    _(blue)\</span><br><span class="line">    _(yellow)\</span><br><span class="line">    _(black)\</span><br><span class="line">    _(white)</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FUNC_BODY &#123;int i=0; i++;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _(color) FUNC_RETURN_TYPE open_##color(FUNC_PARAMETER) FUNC_BODY \</span></span><br><span class="line">    FUNC_RETURN_TYPE close_#<span class="meta">#color(FUNC_PARAMETER) FUNC_BODY \</span></span><br><span class="line">    FUNC_RETURN_TYPE write_#<span class="meta">#color(FUNC_PARAMETER) FUNC_BODY \</span></span><br><span class="line">    FUNC_RETURN_TYPE read_#<span class="meta">#color(FUNC_PARAMETER) FUNC_BODY \</span></span><br><span class="line">    FUNC_RETURN_TYPE add_#<span class="meta">#color(FUNC_PARAMETER) FUNC_BODY \</span></span><br><span class="line">    FUNC_RETURN_TYPE delete_#<span class="meta">#color(FUNC_PARAMETER) FUNC_BODY</span></span><br><span class="line"></span><br><span class="line">LIST <span class="comment">// void open_red(void) &#123;int i=0; i++&#125; and so on...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> _</span></span><br></pre></td></tr></table></figure><p>然后我们分别把这几个“颜色”的具体实现与抽象层挂钩：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OP_TYPE_NUM 5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> types &#123;</span><br><span class="line">    red,</span><br><span class="line">    blue,</span><br><span class="line">    yellow,</span><br><span class="line">    black,</span><br><span class="line">    white</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">op</span> <span class="title">ops</span>[<span class="title">OP_TYPE_NUM</span>];</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _(color) ops[color].open_fp = &amp;open_##color; \</span></span><br><span class="line">    ops[color].close_fp = &amp;close_##color; \</span><br><span class="line">    ops[color].write_fp = &amp;write_##color; \</span><br><span class="line">    ops[color].read_fp = &amp;read_##color; \</span><br><span class="line">    ops[color].add_fp = &amp;add_##color; \</span><br><span class="line">    ops[color].delete_fp = &amp;delete_##color;</span><br><span class="line"></span><br><span class="line">LIST <span class="comment">// ops[red].open_fp = &amp;open_red; and so no...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> _</span></span><br></pre></td></tr></table></figure><p>准备好了被测对象之后，下面就是对比测试了。</p><h2 id="直接调用"><a href="#直接调用" class="headerlink" title="直接调用"></a>直接调用</h2><p>对每种实例中的方法，有两种调用方式：</p><ul><li>间接调用：</li></ul><p>以调用每个实例的<code>open</code>接口为例：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ops[idx].open_fp();</span><br></pre></td></tr></table></figure><p>这种是最常见的调用方式。因为需要先获取指针，再根据指针去调用，所以称为间接调用。</p><ul><li>直接调用：</li></ul><p>仍是以调用实例的<code>open</code>接口为例：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span>(idx) &#123;</span><br><span class="line"> <span class="meta">#<span class="meta-keyword">define</span> _(color) case color: open_##color(); break;</span></span><br><span class="line"> LIST <span class="comment">// case red: open_red(); break; and so on...</span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">undef</span> _</span></span><br><span class="line">     <span class="keyword">default</span>: open_red(); <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用一个<code>switch</code>结构先判断该欲调用的方法属于哪个实例，然后直接调用该方法。</p><p>看起来直接调用的方式不如间接调用“优雅”，但直接调用是否能带来性能提升呢？</p><h2 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CPU： Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHz</span><br><span class="line">OS：3.10.0-514.21.1.el7.x86_64</span><br><span class="line">GCC：4.8.5</span><br><span class="line"></span><br><span class="line">====RANDOM IDX -O0</span><br><span class="line">call_ops()                                  :  7936.000 cycles per input word (best)  8279.895 cycles per input word (avg)</span><br><span class="line">call_ops_directly()                         :  6287.000 cycles per input word (best)  6858.248 cycles per input word (avg)</span><br><span class="line">====FIX IDX -O0</span><br><span class="line">call_ops()                                  :  7862.000 cycles per input word (best)  8035.686 cycles per input word (avg)</span><br><span class="line">call_ops_directly()                         :  6713.000 cycles per input word (best)  7234.337 cycles per input word (avg)</span><br></pre></td></tr></table></figure><p>在两种不同的调用方式下（一种是随机选取实例调用，一种是固定调用一个实例），直接调用的方式都比间接调用快(消耗的cycle数少)，在随机调用模式下有接近20%((8279-6858)/8279)的性能提升。</p><p>完整代码已传到Github：<a href="https://github.com/PanZhangg/x86perf/blob/master/indirectcall.c" target="_blank" rel="noopener">https://github.com/PanZhangg/x86perf/blob/master/indirectcall.c</a></p><p>至于为什么会出现这个结果，会在后续的系列文章中探究。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> performance </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚8：Intel 700系列网卡内部结构概览</title>
      <link href="/2018/12/25/quickwords8-700-nic-arch/"/>
      <url>/2018/12/25/quickwords8-700-nic-arch/</url>
      
        <content type="html"><![CDATA[<p>一不小心这个系列写到了第8期，原本打算写些别的东西，不过看到8这个数字就想到了Intel将要推出的800系列网卡…的小弟——命途多舛的700系列网卡。从目前市场(主要是云计算、互联网公司和数据中心)的情况看，700系列有逐渐推广的趋势，那么这一期就介绍一下700系列网卡的基本技术架构和特点吧。<br><a id="more"></a></p><h2 id="Intel-700系列网卡的内部架构"><a href="#Intel-700系列网卡的内部架构" class="headerlink" title="Intel 700系列网卡的内部架构"></a>Intel 700系列网卡的内部架构</h2><p>在处理完物理层的事情之后，数据包会进入网卡内部的处理流水线。</p><p>对于网络中的事情，所有参与者基本上就在做一个事情：分类-&gt;转发。大到核心路由器，小到iptables都是一样。只不过有些按IP地址的前缀分类，有些按报文的协议类型分类，有些按某些header字段分类罢了。</p><p>所以对Intel 700系列网卡来说，在物理层接收到帧之后，首先要做的就是”解析“一下，这个帧到底属于哪一类。</p><p><img src="https://software.intel.com/sites/default/files/managed/f3/d2/Intel-Ethernet-Controller-700-series-Hash-and-Flow-Filters-fig01.png" alt="700系列网卡简易架构图"></p><p>因此Parser解析器就是流水线的第一环。它会根据帧本身的特点，以及自己的识别解析能力，给每个包都打上一个标签(PTYPE和PCTYPE)。</p><p>而根据这些标签，会抽取帧中相应的字段(一般是标签所代表的协议中比较关键的字段)存入<code>Field Vector</code>，以备后用。</p><p>后面的<code>Switch</code>主要就是用<code>Field Vector</code>中的数据，包括<code>DMAC</code> <code>VLAN ID</code>等等，来决定该帧是应该进入PF还是VF。</p><h2 id="流分类-RSS和fdir"><a href="#流分类-RSS和fdir" class="headerlink" title="流分类(RSS和fdir)"></a>流分类(RSS和fdir)</h2><p>在确定了进入哪一个PF或VF之后，就可以对帧进行RSS或者fdir的操作，来决定根据预设的配置，这个帧最终进入哪个队列，进而被哪些上层进程所消费。</p><p><code>Field Vector</code>中的数据在这个时候就会被拿过来做Hash或者过滤，来计算出最终的结果。</p><p>而上面提到的<code>PCTYPE</code>，其为”Packet Classifier Type”的缩写。其实是每一种<code>PCTYPE</code>对应后面一套预设的处理过滤规则(Classifier)。比如<code>IPV4 TCP</code>和<code>IPV6 TPC</code>就分别是两种<code>PCTYPE</code>，那么对于这两种报文的处理就可以分别设定规则。e.g. <code>IPV4 TCP</code>的报文进入Queue2, <code>IPV6 TCP</code>的报文进入Queue3。</p><p>700系列网卡所谓的“灵活性”和“可编程性”也主要基于此。</p><p>最大支持64种<code>PCTYPE</code>，但网卡默认支持的只有…呃..几种。但可以通过DDP动态添加。可以参考前一篇关于DDP的说明<a href="https://decodezp.github.io/2018/12/18/quickwords6-ddp/">文章</a>。</p><h2 id="收包流程"><a href="#收包流程" class="headerlink" title="收包流程"></a>收包流程</h2><p>再简单总结一下700系列网卡的收包流程。</p><p>二层帧到达之后，首先进入<code>Parser</code>解析器。解析器根据协议类型，给二层帧打上<code>PTYPE</code>和<code>PCTYPE</code>的“标签”。</p><p>同时，根据这些标签，提取标签规定的字段，存入到<code>Field Vector</code>中。<code>Field Vector</code>相当于该二层帧的一个meta data，一直跟随到从某一端口或队列发送出去。</p><p>然后在<code>Switch</code>阶段，网卡会根据该二层帧<code>Field Vector</code>中的某些字段判断该帧进入哪个PF或VF。</p><p>在进入PF和VF之后，会根据帧各自的<code>PCTYPE</code>，从<code>Field Vector</code>取数据(其实也就是各协议的关键字段e.g. 目的IP地址，VNI等等)参与计算或过滤规则匹配。最后按照规则转发或丢弃。</p><p>严格来说，是先经过fdir，再去RSS。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚7：DPDK不同CPU平台交叉编译指令不支持的问题</title>
      <link href="/2018/12/24/quickwords7-dpdk-cross-compile/"/>
      <url>/2018/12/24/quickwords7-dpdk-cross-compile/</url>
      
        <content type="html"><![CDATA[<h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>在比较高级的CPU平台(比如skylake)编译DPDK，会在编译的目标文件中加入一些高级指令集中的指令，比如AVX512。</p><p>如果运行最终可执行文件的机器的CPU架构(比如broadwell)不支持编译机器中的指令，则会在执行时报类似这种错误：<br><a id="more"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">174146:Dec 21 10:56:30 n10-023-013 kernel: [57619.700220] traps: obj-name[861199] trap invalid opcode ip:501c31 sp:7fff9782d090 error:0</span><br></pre></td></tr></table></figure><p>其实就是在0x501c31(ip是instruction pointer)这个位置上的指令不支持(invalid)。</p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>那么如何查看具体是哪条指令呢? </p><p>用<code>objdump -D obj-name</code>查看一下目标文件的汇编代码，找到该位置上的指令。</p><p>我这里的例子中，这个指令是<code>vmovdqa64</code>，简单搜索一下可以知道这是个<code>AVX512f</code>的指令。</p><blockquote><p>其他详细内容可以查看Intel SDM(Software Development Manual)<a href="https://software.intel.com/en-us/articles/intel-sdm" target="_blank" rel="noopener">下载链接</a></p></blockquote><p>而这个指令在<code>skylake</code>上支持，<code>broadwell</code>上不支持。</p><p>可以通过在两个机器上执行<code>cat /proc/cpuinfo | grep flags</code>查看支持的指令集。或者执行<code>gcc -march=native -Q --help=target</code>查看。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>在编译机器(skylake)DPDK的/mk/machine/native/rte.vars.mk中，设置<code>MACHINE_CFLAGS= -march=native</code>为<code>-march=broadwell</code>就可以了。</p><p>当然还有一些详细的交叉编译方法，可以参考这篇<a href="http://syswift.com/355.html" target="_blank" rel="noopener">文章</a>。</p><p>另外还有一点要提醒的是，如果你是在编译某些基于DPDK的应用，比如DPVS，要一并修改应用中的编译配置，例如DPVS就是在<code>./src/dpdk.mk</code>中，需要修改<code>CFLAGS += -march=broadwell</code>。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> dpdk </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>5分钟经典英文技术演讲2：软件设计真正的精髓-Scott Meyer</title>
      <link href="/2018/12/21/eng-talk2-things-matter/"/>
      <url>/2018/12/21/eng-talk2-things-matter/</url>
      
        <content type="html"><![CDATA[<blockquote><p>一个人的能力上限很大程度上取决于他获取信息的能力。</p><p>而能力增长的速度与获取信息的_质量_正相关。</p><p>不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。</p><p>最新内容将发布于<a href="https://decodezp.github.io">DecodeZ</a>: <a href="https://decodezp.github.io">https://decodezp.github.io</a></p><p><a href="https://decodezp.github.io/2018/12/12/eng-talk1-fast-learn/">往期回顾：如何快速掌握新技术</a></p></blockquote><h1 id="DConf2017：软件设计真正的精髓"><a href="#DConf2017：软件设计真正的精髓" class="headerlink" title="DConf2017：软件设计真正的精髓"></a>DConf2017：软件设计真正的精髓</h1><p><a href="https://www.youtube.com/watch?v=RT46MpK39rQ" target="_blank" rel="noopener">原视频</a></p><p><a href="http://dconf.org/2017/talks/meyers.pptx" target="_blank" rel="noopener">PPT/Slides下载</a></p><p>演讲者：Scott Meyer</p><p>上一张演讲者的照片，硬撸过C++的应该都很熟悉他:</p><p><img src="https://s1.ax1x.com/2018/12/21/FsMA2R.jpg" alt="Scott Meyer"></p><blockquote><p>摘要：成功的软件产品都有其共性。在Scott Meyer看来，这些共性由几个要素组成。在你的作品中考虑这些要素，将帮助你掌握软件设计真正的精髓。<br><a id="more"></a></p></blockquote><h2 id="效率-速度-Efficiency-Speed"><a href="#效率-速度-Efficiency-Speed" class="headerlink" title="效率/速度(Efficiency/Speed)"></a>效率/速度(Efficiency/Speed)</h2><p>效率高(所需要执行的指令数少)的软件在大多数情况下等于速度快性能高的软件。</p><p>在硬件性能普遍过剩的2C和移动市场，对软件效率的追求也可以带来更广泛的平台配适性和更好的功耗表现。</p><p>而在每增加100毫秒延时，年收入就掉几个百分点的电商、在线广告和高频交易领域，对服务器软件效率的追求没有止境。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsM5W9.jpg" alt=""></p><p>追求软件的高性能肯定没错，但大家一定都熟悉一句话：</p><blockquote><p>“过早优化是万恶之源”(Pre-mature optimization is the root of all evil)。</p></blockquote><p>很多人将这句话作为“先不忙优化，最后再说”的理由。但有多少人知道这句话的出处和上下文?</p><p>这句话出自Donald Knuth的一篇叫做”Structured Programming with go to Statements”的论文。而这句话的前面一句话和它连起来是：</p><blockquote><p>如果你不能确定在哪里可以优化，就先不要优化。过早优化是万恶之源。</p></blockquote><p>而在这篇总长度41页的论文的同一页，Donald写道：</p><blockquote><p>可以简单获得(easily obtained)的性能提升，并非无足轻重。</p></blockquote><p><img src="https://s1.ax1x.com/2018/12/21/FsMhi4.jpg" alt=""></p><p>当软件已届完成时再考虑性能优化，将是艰难甚至不可能的任务，例如单线程程序改为多线程，有锁替换为无锁结构等等。</p><p>所谓”过早优化“(我还是更喜欢将其直译为”不成熟的优化“)，并不是指“从软件的设计阶段就考虑性能”，而是指你还并不知道哪里能优化就一通乱搞的时候。</p><p>而能看出系统性能的瓶颈，可以给出“成熟的优化”方案，是需要长期的学习和实践积累的。</p><blockquote><p>Side Note: 对软件性能优化，特别是结合CPU内存等硬件特性感兴趣的读者可以自行搜索一下笔者在青涩时期挖了还没填上的大坑: <a href="https://www.baidu.com/s?wd=x86%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B%E7%AC%BA%E6%B3%A8&amp;rsv_spt=1&amp;rsv_iqid=0xe6a969f800013a74&amp;issp=1&amp;f=8&amp;rsv_bp=0&amp;rsv_idx=2&amp;ie=utf-8&amp;tn=baiduhome_pg&amp;rsv_enter=1&amp;rsv_sug3=34&amp;rsv_sug1=2&amp;rsv_sug7=100&amp;rsv_sug2=0&amp;inputT=6753&amp;rsv_sug4=6958" target="_blank" rel="noopener">x86高性能编程笺注</a></p></blockquote><h2 id="可移植性-Portability"><a href="#可移植性-Portability" class="headerlink" title="可移植性(Portability)"></a>可移植性(Portability)</h2><p>可移植性的出发点，是市场和客户。</p><p>Scott举出了一个他供职过的公司的例子：有自己的硬件平台、编译器、和操作系统。他们的产品跑在自己高度定制化的平台上，各方面的优化已臻完美，一切都很美好。</p><p>相形之下，那些跑在“拼凑”出来的平台上的竞品，就像一个拙劣的玩笑。</p><p>这一切都随着“通用硬件”性价比突飞猛进而结束，竞品提出的策略是：提供该公司80%的产品性能，但只需要20%的价格。</p><p>而这样的故事，在Scott二十余年的从业经历中重复发生着。</p><p>当你真的认真在考虑一个严肃的软件产品时，请通过可移植性给予它更多的市场适应能力，而不至于因为产品之外的因素影响产品本身的生命周期。</p><p>同时可移植性也可以帮助你在推出了一款成功的产品并在当前平台下达到市场饱和之后，开拓出更多的市场增长空间。有增长才有后续的融资嘛 :)</p><p>而做好产品的可移植性设计，其难度不亚于上一节提到的性能优化。有太多硬件的和软件的细节需要考虑，不但要做好不同平台之间的抽象，还要考虑如何充分利用不同平台的独有特性。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsMWoF.jpg" alt=""></p><p>而这一切都将是你不断学习的内容。</p><h2 id="修补性-Toolability"><a href="#修补性-Toolability" class="headerlink" title="修补性(Toolability)"></a>修补性(Toolability)</h2><p>字典中出给的翻译是“修补性”，但我觉得这是一个不贴切的翻译。<code>Toolability</code>在这里的意思是，当你创造出某种产品的时候，需要考虑能够简单地让别人围绕它开发出工具(Tool-able)。</p><p>我个人的理解就是，预留出构建生态的能力。</p><p>如果把编程语言看作是一种产品，那么某种语言的重构工具就是它整个生态中重要的一环。</p><p>重构工具的一项基本功能，就是在一个项目工程中替换某一个函数的名字。在Java中我们有Intellij，有Eclipse，在对C++来说，我们还没有一个特别好使的重构工具。</p><p>因为在C++中，一个简单的<code>f(x)</code>可能是：</p><ul><li>一个函数</li><li>一个函数指针</li><li>一个重载操作符</li><li>一个模板</li><li>一个宏</li><li>等等等等</li></ul><p>这样的复杂度，让实现C++的重构工具变得几乎不可能。<code>Comments: 现在确实出现了一些C++的重构工具，但相比于其他语言，晚了十余年。</code></p><p>但我们想强调的并不是C++如何重构，而是当没有这些工具，没有产品生态的时候，你的产品能发挥出多大作用，完全受限于使用者本身的能力。而如果他人能够迅速构建出一套工具，将会帮助你提升产品能力的下限。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsM4JJ.jpg" alt=""></p><p>简单来说就是，只靠产品一个人打天下不行，需要有组件团队的能力。同时当别人想加入你的团队时，最好不要有太多障碍。</p><h2 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性(Consistency)"></a>一致性(Consistency)</h2><p>一致性是用户体验提升的核心，这里的用户既包括产品最终的消费者，同时也包括开发者。</p><p>所谓用户体验，是能够轻易的与以往的经验做类比。保持一致并不是处女座强迫症作祟，而是在软件设计领域有重要意义——带来有效的抽象和类比。一致性本质上是在为我们的大脑创造一种”模式“，既然是模式，就需要有保持一致的东西。</p><p>看一个iOS10上的例子：<br><img src="https://s1.ax1x.com/2018/12/21/FsMRdU.jpg" alt=""></p><p>删除按钮的图标都是一致的，但位置和颜色并没有保持一致。</p><p>试想，如果一系列相关的函数调用，它的相同类型的参数位置都不一样，如下面这个C语言的例子：<br><img src="https://s1.ax1x.com/2018/12/21/FsMTQ1.jpg" alt=""></p><p>即便是编写了数十年C程序的程序员，每次也都需要查表才能确定自己把参数放对了位置。</p><p>又如Java中求得某个数据类型的长度的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array.length</span><br><span class="line">string.length()</span><br><span class="line">List.size()</span><br></pre></td></tr></table></figure><p>这种体验需要开发者针对每种不同的数据类型分别记忆不同的方法，而不能构建一个一致性的抽象。</p><p>现在当然有智能化的IDE可以帮助我们摆放好参数或者使用正确的方法，但我们想探究的正是，为什么IDE会加入这个功能——因为不一致的参数位置和方法名实在太恼人了。</p><p>而用户体验的核心，并非是扁平化设计，而是追求一致：产品本身性能一致，稳定性一致；用起来的时候，能把我以前的经验带到这里来，并且我一看就知道，这个产品如何操作。</p><h2 id="接口-Interfaces"><a href="#接口-Interfaces" class="headerlink" title="接口(Interfaces)"></a>接口(Interfaces)</h2><p>设计接口，既要考虑如何容易用对，同时也考虑如何很难用得不对。</p><p>而上一节提到的一致性，就是一个很好的指导原则。</p><p>毕竟会调用你接口的人，都是聪明人，都是有软件经验的人，同时他们也希望你实现的接口能够帮助他们自己，所以也愿意去读一点文档。</p><p>如果即便如此他们还是不能正确使用你的接口，那一定是你自己的问题。</p><p>而真正优秀的接口，是调用者凭借你提供的一致性，凭直觉就能使用的接口——“我也不知道为什么，但这个接口就是工作了”。</p><p>而一个设计不靠谱接口的开发人员的典型口头禅就是：他们会搞明白的。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsMIzR.jpg" alt=""></p><p>这可能正是你的产品变得混乱不堪的开始。</p><p>以上就是Scott Meyer想要在本次演讲中传达给我们的内容。</p>]]></content>
      
      
      <categories>
          
          <category> ENG_talk </category>
          
      </categories>
      
      
        <tags>
            
            <tag> English </tag>
            
            <tag> Presentation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚6：什么是DDP(Dynamic Device Personalization)</title>
      <link href="/2018/12/18/quickwords6-ddp/"/>
      <url>/2018/12/18/quickwords6-ddp/</url>
      
        <content type="html"><![CDATA[<h2 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h2><p>通过网卡的多队列和RSS将网包根据一些关键字段散列(hash)到不同的队列已成为一种主流的在x86平台开发信通以及云计算领域产品的方式。</p><p>在整体产品架构规划中，不同的网卡队列(Rx/Tx Queues)往往对应/绑定着不同的CPU核(Worker)，以利用资源隔离的方式提高性能。</p><p>传统的RSS，往往是依据header的五元组来做散列。通常，网卡可以识别出的报文类型包括<code>ipv4-tcp|ipv4-udp|ipv4-other|ipv6-tcp|l2-payload</code>等等，然后根据能识别出的类型进行关键字段的提取。</p><p>但现在如此简单的识别能力已经不能满足业务的需求。在复杂的协议和隧道通讯场景下，往往还需要识别隧道内层header甚至私有字段才能实现业务能力的最优化。<br><a id="more"></a></p><p>所以对RSS/Fdir来说，首先需要能“识别”出特定的协议报文，才能找到关键的字段进行散列操作。</p><p>在网卡出厂的时候，是可以预置一些协议类型的，但还是最好能有自定义的动态调整的能力。</p><h2 id="DDP-Dynamic-Device-Personalization"><a href="#DDP-Dynamic-Device-Personalization" class="headerlink" title="DDP(Dynamic Device Personalization)"></a>DDP(Dynamic Device Personalization)</h2><p>名字起得很“大”，不过就是上面说的定制化的技能——动态地赋予网卡识别新协议的能力。</p><p>具有这种能力之后，就可以把任意协议的网包按用户意愿提取出关键字段(Key)，然后散列到网卡各个Rx队列里。比如VxLAN协议中的内层DIP等等。</p><p>下图是一个赋予网卡<code>GTP-U</code>协议(好吧，我并不知道这是什么…)识别能力，并可以依据<code>TEID</code>字段的值进行RSS计算的示例：</p><p><img src="https://s1.ax1x.com/2018/12/18/FBJ5q0.png" alt="绿色的可以被用来RSS的字段增多"></p><p>现在已经能被识别出的包括L2TPv3\QUIC\PPPOE\SRv6\RoE\MQTT-SNoUDP等等，还有一些大客户做了自己私有协议的定制。</p><p>总得来说就是，可以把这部分classification的活儿offload到硬件上，减轻后续CPU处理/分发时的压力，同时均衡一下负载，提升整体性能。</p><h2 id="DDP的需求："><a href="#DDP的需求：" class="headerlink" title="DDP的需求："></a>DDP的需求：</h2><ul><li>Intel 700系列网卡以上</li><li>固件版本6.01以上</li><li>一个由Intel官方出品的特定协议识别的binary package file(需要到官网下载)</li><li>DPDK提供的配置接口</li></ul><p>具体在DPDK上怎么搞后续会有文章说明。</p><h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><blockquote><p>Q:如何自己制作binary package file?<br>A:目前不支持自己制作，只能由Intel提供。</p><p>Q:一张网卡最多支持载入多少个binary package file(profile)?<br>A:最多支持16个，但不推荐这么做，推荐同时只载入一个。</p><p>Q:载入之前需要首先关闭网卡设备吗？<br>A:不需要，支持运行时直接载入，但会引起一些丢包</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>谁不是在像CPU一样活着</title>
      <link href="/2018/12/16/cpulized-life/"/>
      <url>/2018/12/16/cpulized-life/</url>
      
        <content type="html"><![CDATA[<p>上一次兴奋到浑身发热，还是把赛扬300A超频到450兆赫的时候。身体如摩尔定律般长高，觉得距离1GHz只差一罐液氮，心里装着只有一心一意才能装下的事情。</p><p>记得那时看到一篇报道，英特尔说“到2011年的时候，我们都能用上10GHz的电脑”。十几岁的你笑这家美国公司野心不大，现在你说出这件事，只是想给大家讲个笑话。<br><a id="more"></a></p><p>2018年，没等来10GHz的电脑，也再也没有一心一意的机会。学会了MMX、SSE、AVX，TSX和AEX等十八般武艺，领导说你是“业务中坚”，其实你知道你只是个挣扎着适应环境的执行人员。</p><p>好在熟稔让你变得老练，打点好前端后端的各种关系，再低的IPC也可以不动声色。毫无指摘地把锅甩给温吞的硬盘，你想你可能明白了什么是sophisticated，就是心里只寻思自己那点14nm的柴米。</p><p>但越是老练越让你厌恶风险，你给自己加了iCache、dCache、iTLB、dTLB，IOTLB等各种保险，但每次分支预测失败还是要彻底打乱你的流水线。即便凭借经验已能做到99%的正确，却能又让你掉入Spectre的窠臼。</p><p>真是怕什么来什么，左右为难的时候，自己的窘样又让心里有一点点好笑，能用一罐液氮解决的事情，偏要搞这么复杂。</p><p>突然有些怀念那个为450兆赫兴奋的自己，当时你只想完成这一件事。但此刻你心里不再只住着你自己，每个人都同时在跑好几个角色，你号称你是3GHz还能hyperthread，其实你知道你早已没了章法，所有的事情都不过是水来土掩的乱序执行。</p><p>但好在还有一块L3缓存，和你那些sophisticated的L1缓存相比，这里虽然慢，慢得就像曾经的赛扬300A，但却有一心一意的完整。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚5：影响服务器内存性能的硬件知识</title>
      <link href="/2018/12/13/quickwords5-server-memory/"/>
      <url>/2018/12/13/quickwords5-server-memory/</url>
      
        <content type="html"><![CDATA[<h2 id="发挥内存条理财的最大收益率"><a href="#发挥内存条理财的最大收益率" class="headerlink" title="发挥内存条理财的最大收益率"></a>发挥内存条理财的最大收益率</h2><p>内存条作为年度最佳理财产品除了能躺着赚钱之外，使用得好还可以一条当两条用。</p><p>在计算机系统中，内存的价值就体现在快速提供数据给CPU处理。当CPU需要的数据没有在缓存里时，CPU内部的<code>Memory Controller</code>就需要去内存中读取内容。<br><a id="more"></a></p><p>而<code>Memory Controller</code>为了尽快完成CPU交代的任务，用了<code>多通道</code>的方式增大内存存取带宽。</p><p><code>多通道</code>这个概念很好理解，和多条车道是一个意思。比如CPU需要1MB大小的数据，单通道的话数据就只能在一条通道上老老实实排队；双通道就可以并行两个512KB的读取；四通道就是并行四个256KB的读取。</p><p>我知道你要问什么，这1MB大小的数据已经被<code>Memory Controller</code>通过一种叫做<code>Interleave(交织)</code>的技术“打散”在了两个通道或者四个通道对应的物理内存上。<code>Interleave</code>由硬件实现，细节不在这里深究，我们想说明的是发挥这些硬件组件的最大能力需要外界条件配合。</p><p>内存在硬件方面的性能优化，就围绕这个主题。</p><h2 id="内存相关概念"><a href="#内存相关概念" class="headerlink" title="内存相关概念"></a>内存相关概念</h2><p>现在主流Intel E5 CPU的配置是一颗CPU上两个<code>Memory Controller</code>，每个Controller有两个通道，每个通道对应主板上三个内存插槽(DIMM)。</p><p><img src="http://1.bp.blogspot.com/-Iaf9qQgC-zM/VdDIBPzscoI/AAAAAAAAABs/AU-vcOrCSck/s1600/6101_48_supermicro_x9dr7_tf_intel_c602j_server_motherboard_review.jpg" alt="内存插槽"></p><p><code>Interleave</code>首先发生在通道层面，进而发生在通道的DIMM层面（使用的DIMM越多，交织得越充分）</p><p>同时每根内存条还有一个<code>Rank</code>的概念。这个概念可以理解为更进一步的<code>Interleave</code>，多<code>Rank</code>的内存条可以再进行一次<code>Interleave</code>。</p><p><img src="https://cdn3.bigcommerce.com/s-3jjekk/product_images/uploaded_images/memory-rank.png?t=1518214379&amp;_ga=2.27767868.1254827790.1518192896-72491761.1493653618" alt="看序列号读取内存信息"></p><h2 id="充分平衡"><a href="#充分平衡" class="headerlink" title="充分平衡"></a>充分平衡</h2><p>满足最优的内存配置就是四个字：充分平衡。</p><p>-充分：并不是要你插满所有插槽，而是充分利用每个<code>Memory Controller</code>和每条通道<br>-平衡：每个<code>Memory Controller</code>和通道上的内存配置(Size, Rank和频率)都相同。</p><p>在实际应用中，首先绘制一个内存拓扑，如下图：<br><img src="https://s1.ax1x.com/2018/12/13/FNdSBT.png" alt="充分平衡"></p><blockquote><p>如何检查是否充分？看一下每个<code>Memory Controller</code>中的每个通道是否都有内存条<br>如何检查是否平衡？将拓扑图从中垂线对折一次，检查图像是否能重合；再从水平中位线对折一次，检查是否能重合。如果两次回答都是yes，就平衡了。</p></blockquote><h3 id="实例1"><a href="#实例1" class="headerlink" title="实例1"></a>实例1</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNwPqf.png" alt="平衡不充分"></p><h3 id="实例2"><a href="#实例2" class="headerlink" title="实例2"></a>实例2</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNazuV.png" alt="充分不平衡"></p><h3 id="实例3"><a href="#实例3" class="headerlink" title="实例3"></a>实例3</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNajcq.png" alt="不充分不平衡"></p><h3 id="实例4"><a href="#实例4" class="headerlink" title="实例4"></a>实例4</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNavj0.png" alt="充分平衡"></p><h2 id="软件检查工具"><a href="#软件检查工具" class="headerlink" title="软件检查工具"></a>软件检查工具</h2><p>为了不让每次内存检测都需要打开机箱…有一个开源工具可以通过读取<code>dmidecode</code>的信息自动化做检验：<a href="https://github.com/PanZhangg/DPDKick" target="_blank" rel="noopener">DPDKick</a></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> performance </tag>
            
            <tag> memory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>5分钟经典英文技术演讲1：如何快速掌握新技术 - Kathy Sierra</title>
      <link href="/2018/12/12/eng-talk1-fast-learn/"/>
      <url>/2018/12/12/eng-talk1-fast-learn/</url>
      
        <content type="html"><![CDATA[<blockquote><p>一个人的能力上限很大程度上取决于他获取信息的能力。</p><p>而能力增长的速度与获取信息的质量正相关。</p><p>不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。</p><p>最新内容将发布于DecodeZ: decodezp.github.io</p></blockquote><h2 id="Fluent-如何快速掌握新技术"><a href="#Fluent-如何快速掌握新技术" class="headerlink" title="Fluent: 如何快速掌握新技术"></a>Fluent: 如何快速掌握新技术</h2><p><a href="https://www.youtube.com/watch?v=FKTxC9pl-WM" target="_blank" rel="noopener">原视频</a><br>演讲者: Kathy Sierra</p><blockquote><p>摘要：无论是谁，以有限的精力来面对层出不穷的新技术挑战都是不够的。你需要学会一套方法论来帮助你快速习得新的技能。而快速学习的秘诀却还不止这些…<br><a id="more"></a></p></blockquote><h2 id="每个程序员都面临的挑战"><a href="#每个程序员都面临的挑战" class="headerlink" title="每个程序员都面临的挑战"></a>每个程序员都面临的挑战</h2><p>为了成为一名“合格”的程序员，你认为你需要掌握哪些技术？</p><p>这将是一个长长长长长的名单，更可怕的是，每个人列出的内容都将各不相同。</p><p>所以这么提问并没有太大意义，更好的问题是：</p><p>我如何快速掌握新的技术？</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0sqf.jpg" alt=""></p><h2 id="认知资源"><a href="#认知资源" class="headerlink" title="认知资源"></a>认知资源</h2><p>我们习得新的技能，需要依赖我们自己的认知资源（Cognitive resources）。</p><p>但作为一个正常的“人类”，我们的认知资源易耗且稀缺。</p><p>到底有多容易消耗？Kathy提到了一个大学里的实验：实验人员要求一半实验参与者记忆一个两位的数字，而另外一半参与者记忆一个七位的数字。</p><p>等确保每个人都记住了自己的数字之后，实验人员随即宣布实验结束，并邀请所有参与者去取用一些零食——蛋糕，或水果。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0rsP.jpg" alt=""></p><p>而实验结果也能猜到，仅仅是5位数字的差别，就让记忆七位数的实验者选取蛋糕的比例比记忆两位数的参与者高出一半。</p><p>你是否有想认真掌握一门新技能，但一拿起各类技术书籍、文档，很快就放弃的经历？你又是否在做一些让别人“选择蛋糕”的事情？比如让别人阅读你自己编写的项目文档。</p><p>当你想要快速掌握一项技能的时候，你需要学会管理自己的认知资源。<br><img src="https://s1.ax1x.com/2018/12/12/Ft0cdS.jpg" alt=""></p><h2 id="学习方法"><a href="#学习方法" class="headerlink" title="学习方法"></a>学习方法</h2><p>将你现在的技能分为三类：</p><ul><li>A还没有掌握，但需要掌握的</li><li>B经过一定努力可以掌握的</li><li>C已经掌握的</li></ul><p><img src="https://s1.ax1x.com/2018/12/12/Ft0DMt.jpg" alt=""></p><p>我们的目标其实是如何将AB的技能快速移动到C。在这个过程中我们会遇到两类典型问题：</p><ul><li>没有进步</li><li>耗时太久</li></ul><h3 id="没有进步"><a href="#没有进步" class="headerlink" title="没有进步"></a>没有进步</h3><p>第一类问题的根本原因在于你的认知资源不足以支撑技能的学习需求。我们不能要求自己有无限的认知资源，在资源极度有限的情况下，仍有两种解决策略：</p><p>第一种，将更多的需要掌握的技能放在A，将精力集中于少量的B类技能。但在日常工作中，需要掌握哪些技能，解决哪些问题，都不是自己可以安排的。对此，我们还有第二种策略。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0gIg.jpg" alt=""><br>第二种策略，就是将B中的技能分解为更小的粒度。这种策略，在有限的认知资源的情况下效果等同于一个需要处理多任务并发的CPU，上面运行的程序都采用了更加细粒度的锁机制，带来了程序性能的提升。<br><img src="https://s1.ax1x.com/2018/12/12/Ft06Z8.jpg" alt=""></p><p>那么如何界定分解之后的技能足够“细”？Kathy给出了一个她的评判标准：</p><blockquote><p>从完全不会到十分熟练，最多经过3次练习，每次45-90分钟。</p></blockquote><p>能满足上面的标准就可以认为分解到了合理的粒度。</p><h3 id="耗时太久"><a href="#耗时太久" class="headerlink" title="耗时太久"></a>耗时太久</h3><p>程序员不但要学习很多技能，还需要快速学习。所以从A开始，我们最好能够绕过B直接到C。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0fRs.jpg" alt=""><br>怎么可能从完全不懂，到突然就明白了？</p><p>Kathy给出了一个“极端”的例子：学习给分辨雏鸡的性别。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0RiQ.jpg" alt=""><br>从视觉上，这是一件不可能的事，但日本却有一些非常擅长分别雏鸡性别的人。</p><p>人们希望这些“性别分辨大师”能够将他们的方法教授给别人，但这些人并不能讲出什么明确的“规则”。</p><p>这就是这件真正神奇的地方，我们的大脑能够在潜意识中处理一些信息，但却讲不出来为什么。</p><p>所以学习雏鸡性别分辨的人最开始只是随机判断雏鸡的性别，而这些“专家”则告诉他们结果是不是正确。</p><p>一段时间以后，这些学习分辨性别的人正确率越来越高，最终达到了专家的水平。</p><p>这些学习的人并没有记忆任何具体的“规则”，却能够不断提升自己的技能水平。这里产生核心影响的是：高质量的例子。</p><blockquote><p>这非常类似机器学习的过程，模型的质量取决于训练这些模型的数据的质量。</p></blockquote><h2 id="关键的缺失——高质量的例子"><a href="#关键的缺失——高质量的例子" class="headerlink" title="关键的缺失——高质量的例子"></a>关键的缺失——高质量的例子</h2><p>当要学习某样特殊技术的时候，你是找官方的、正式的、长而无味的文档，还是去找一个精悍的例子？</p><p>当你能找到一个精确的示例来演示如何使用这样技术的时候，你几乎可以“瞬间”掌握这项技术。</p><p>你需要这些示例来让大脑自动地，潜意识地识别其中的模式。但现在的问题是，所有技术里又臭又长的文档很多，但短小精悍的示例很少。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0WGj.jpg" alt=""><br>所以是否可以利用社区的力量，将这些文档转换成一系列高质量的示例库呢？</p><p>以上就是在本次演讲中，Kathy想要传达给我们的内容。</p><h2 id="引申"><a href="#引申" class="headerlink" title="引申"></a>引申</h2><p>《庄子》中有这样一个故事：</p><blockquote><p>桓公读书于堂上，轮扁斫轮于堂下，释椎凿而上，问桓公曰：“敢问：“公之所读者，何言邪？”<br>公曰：“圣人之言也。”<br>曰：“圣人在乎？”<br>公曰：“已死矣。”<br>曰：“然则君之所读者，古人之糟粕已夫！”<br>桓公曰：“寡人读书，轮人安得议乎！有说则可，无说则死！”<br>轮扁曰：“臣也以臣之事观之。斫轮，徐则甘而不固，疾则苦而不入，不徐不疾，得之于手而应于心，口不能言，有数存焉于其间。臣不能以喻臣之子，臣之子亦不能受之于臣，是以行年七十而老斫轮。古之人与其不可传也死矣，然则君之所读者，古人之糟粕已夫。“</p></blockquote><p>真正的精髓，都在手上，而不在文档里。</p>]]></content>
      
      
      <categories>
          
          <category> ENG_talk </category>
          
      </categories>
      
      
        <tags>
            
            <tag> English </tag>
            
            <tag> Presentation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚4：什么是Pointer Aliasing</title>
      <link href="/2018/12/11/quickwords4-pointer-aliasing/"/>
      <url>/2018/12/11/quickwords4-pointer-aliasing/</url>
      
        <content type="html"><![CDATA[<h2 id="指向同一地址的两个相同类型的指针"><a href="#指向同一地址的两个相同类型的指针" class="headerlink" title="指向同一地址的两个相同类型的指针"></a>指向同一地址的两个相同类型的指针</h2><p><code>aliasing</code>本身是一个信号处理方面的概念。是指在信号采样过程中，不同的信号不再能相互区分的现象。</p><p>如下图所示的波纹现象，相对于拍摄的采样频率（横纵像素分辨率），墙砖缝隙变化的频率要大于采样频率。或者换句话说，多条墙砖缝隙需要挤在一个像素里面。<br><img src="https://svi.nl/wikiimg/StFargeaux_kasteel_buiten1_aliased.jpg" alt=""></p><a id="more"></a><p>同样的现象也会出现在程序员穿着“高密度”的格子衬衫接受电视采访时。</p><p>墙砖缝隙出现<code>aliasing</code>后无法再行区分，从字面意义来说，<code>Pointer Aliasing</code>就是不同的指针也无法区分。</p><p>指针无法区分，只有一种情况，就是指针的类型和指向的地址都是相同的，这就是<code>Pointer Aliasing</code>。</p><h2 id="为什么会有性能影响"><a href="#为什么会有性能影响" class="headerlink" title="为什么会有性能影响"></a>为什么会有性能影响</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> *<span class="built_in">array</span>, <span class="keyword">int</span> *size, <span class="keyword">int</span> *value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; *size; ++i) &#123;</span><br><span class="line">        <span class="built_in">array</span>[i] = <span class="number">2</span> * *value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果让我们自己“优化”一下这段代码，我们可能会首先将<code>value</code>指向的值存入一个临时变量里，然后将临时变量在循环中直接赋值给<code>array</code>。</p><p>我们假设个<code>array</code>的初始状态：<code>[0, 1, 2, 3, 4]</code></p><p>如果<code>value</code>指向的值等于3，那么按我们优化的方式，<code>array</code>最终的状态是：<code>[6, 6, 6, 6, 6]</code></p><p>但这里存在一个问题，如果<code>value</code>指向<code>array[3]</code>，那么<code>array</code>最终的状态就是：<code>[6, 6, 6, 12, 24]</code></p><p><code>value</code>和<code>array[3]</code>就是指向相同地址类型相同的指针。</p><p>编译器为了得到最终正确的结果，就不得不取消我们之前提到的”优化”方式。</p><h2 id="预防方法"><a href="#预防方法" class="headerlink" title="预防方法"></a>预防方法</h2><p>使用<code>__restrict</code>关键字：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> * __restrict <span class="built_in">array</span>, <span class="keyword">int</span> *__restrict size, <span class="keyword">int</span> *__restrict value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; *size; ++i) &#123;</span><br><span class="line">        <span class="built_in">array</span>[i] = <span class="number">2</span> * *value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然，前提是自己可以确定代码逻辑中不会引入<code>aliasing</code>。</p><h2 id="怎么使用"><a href="#怎么使用" class="headerlink" title="怎么使用"></a>怎么使用</h2><p>首先明确一点，不是加上了<code>__restrict</code>性能就会提升。</p><blockquote><p><code>Pointer aliasing</code>对性能根本的伤害不是需要每次重新去某个地址取值，而是因为引入了潜在的数据依赖关系，从而关闭了很多编译器优化代码的能力。</p></blockquote><p>上面两段代码，在<code>-O0</code>优化时生成的汇编代码(<code>gcc 4.8.5</code>)完全相同。不同的地方在于，第一段代码在<code>-O2</code>和<code>-O3</code>时生成的汇编代码仍然相同；而第二段做了<code>__restrict</code>处理的代码则会在<code>-O3</code>时加入大量循环展开等优化方式。</p><p>在线查看汇编代码：<a href="https://godbolt.org/z/2nXlNa" target="_blank" rel="noopener">链接</a></p><p>所以<code>__restrict</code>需要在打开较高等级的编译器优化的情况下使用才会有效果。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> CPU </tag>
            
            <tag> performance </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>产品观察1：华为FabricInsight产品简要分析</title>
      <link href="/2018/12/08/product1-huawei-fabricinsight/"/>
      <url>/2018/12/08/product1-huawei-fabricinsight/</url>
      
        <content type="html"><![CDATA[<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">最近机缘巧合之下接触到了华为FabricInsight这款产品，简要谈谈看法。</span><br><span class="line">只针对2018年8月份左右发布的版本。</span><br><span class="line">另外注意，在Google搜索相关资料的时候，记得要把Fabric Insight这两个单词合并在一起搜索，中间不要加空格，别问我怎么知道的。</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="信息采集"><a href="#信息采集" class="headerlink" title="信息采集"></a>信息采集</h3><h4 id="SNMP"><a href="#SNMP" class="headerlink" title="SNMP"></a>SNMP</h4><p>在使用FabricInsight之前需要配置华为设备的SNMP协议，主要作用为获取设备的MIB信息，<br>并进行其他管理操作。</p><h4 id="LLDP"><a href="#LLDP" class="headerlink" title="LLDP"></a>LLDP</h4><p>使能各设备的LLDP功能，以便FabricInsight据此（以及通过SNMP上送的MIB信息）绘制硬<br>件连接拓扑图。</p><h4 id="NetConf"><a href="#NetConf" class="headerlink" title="NetConf"></a>NetConf</h4><p>使能各设备的NetConf配置，以便FabricInsight能通过NetConf协议配置各设备的ERSPAN功<br>能。</p><h4 id="ERSPAN"><a href="#ERSPAN" class="headerlink" title="ERSPAN"></a>ERSPAN</h4><p>配置ERSPAN功能，destination IP配置为FabricInsight collector的地址。底层实现为：通过<br>GRE隧道的方式将远程设备的流量路由/镜像至分析节点，以实现对流量可视化分析。<br>ERSPAN可配置筛选特定的流量，并非全量镜像。从华为对交换机的配置： </p><pre><code class="shell">[~Device] observe-port 1​ destination-ip 10.10.10.20​ source-ip 10.1.1.1 [*Device] traffic-mirroring vxlan tag-format none tcp-flag fin syn rst observe-port 1 inbound [*Device] traffic-mirroring tcp-flag fin syn rst observe-port 1 inbound [*Device] commit</code></pre><p>通过ERSPAN镜像给FabricInsight的流量包括带有FIN/SYN/RST等TCP flag的网包。对应其<br>产品中对TCP事件的可视化能力。<br><em>注*：据此可以看出FabricInsight没有全量流量镜像&amp;分析能力</em><br><em>注*：命令中的vxlan可能是将流量通过vxlan封装，做三层转发，而非镜像全部vxlan流量</em></p><h4 id="Telemetry"><a href="#Telemetry" class="headerlink" title="Telemetry"></a>Telemetry</h4><p>华为的Telemetry指设备主动、以固定周期上报的一些设备信息，包括CPU\MEM\QUEUE等信<br>息。 </p><h4 id="手动录入"><a href="#手动录入" class="headerlink" title="手动录入"></a>手动录入</h4><p>主要为用户业务信息，每一个业务的定义为一组IP和某一固定端口号的集合，需要用户手工录<br>入。</p><p><img src="https://i.ytimg.com/vi/uVcXxn30qqY/maxresdefault.jpg" alt=""></p><h3 id="功能分类"><a href="#功能分类" class="headerlink" title="功能分类"></a>功能分类</h3><h4 id="Underlay拓扑可视化"><a href="#Underlay拓扑可视化" class="headerlink" title="Underlay拓扑可视化"></a>Underlay拓扑可视化</h4><p>依据LLDP生成及SNMP上报的信息，可生成Underlay设备间的拓扑信息。<br>流量事件统计<br>依据ERSPAN镜像的含有SYN\FIN\RST等flag的TCP网包，可统计一条流（五元组）中的事件<br>发生次数、时间及类型。并可据此进行简单的SYN重传、建立连接RTT、建连成功率分析。但<br>缺少对网流完整过程（e.g.流量传输数据总量、pps、整体平均时延等）的统计和分析。 </p><h4 id="设备信息统计"><a href="#设备信息统计" class="headerlink" title="设备信息统计"></a>设备信息统计</h4><p>根据Telemetry信息给出CPU\MEM等设备运行状态统计信息，以及对各网络端口IN/OUT总<br>量、drop、error数量等的统计信息。 </p><h4 id="应用流量分类过滤"><a href="#应用流量分类过滤" class="headerlink" title="应用流量分类过滤"></a>应用流量分类过滤</h4><p>其应用功能，本质为手动设置IP+端口号过滤规则，通过过滤的流量即为一个应用。应用间的<br>流量状态展现，即为在流量事件统计数据库中分别为起止两端的流量配置两个应用的过滤规则<br>，筛选出的流量即可作为应用间的流量状态展示。 </p><h2 id="FabricInsight特点"><a href="#FabricInsight特点" class="headerlink" title="FabricInsight特点"></a>FabricInsight特点</h2><h3 id="强绑定性"><a href="#强绑定性" class="headerlink" title="强绑定性"></a>强绑定性</h3><p>只能用于华为的硬件设备。并且后期会形成双向绑定，如若依赖FabricInsight，扩容时只能继<br>续采购华为设备。 </p><h3 id="基于流量事件"><a href="#基于流量事件" class="headerlink" title="基于流量事件"></a>基于流量事件</h3><p>对于流的分析仅涉及五元组和TCP流量事件。可依据SYN、FIN、RST等TCP流量事件完成<br>TCP SYN重传、RST等事件的侦测，并作为报警依据。 </p><h3 id="无流量全量分析"><a href="#无流量全量分析" class="headerlink" title="无流量全量分析"></a>无流量全量分析</h3><p>当前观察，仅有TCP流量的事件信息，对UDP、ICMP、ARP等网络流量无采集分析能力。仅<br>针对TCP流量，亦无流量全量分析能力，无法获取诸如流量总字节数、总包数、pps、平均时<br>延、最大时延等信息。</p><h3 id="Overlay能力暂无"><a href="#Overlay能力暂无" class="headerlink" title="Overlay能力暂无"></a>Overlay能力暂无</h3><p>当前FabricInsight宣称的可分析虚拟网络是指，手工指定某一虚拟网元（Virtual NE）IP地址<br>，手工指定其角色（e.g. FW\LB\Router）其与外界通讯的流量可以以与Underlay网络相同的<br>方式采集。<br>未发现针对虚拟网络VM间的采集分析能力。从其官方手册中针对ERSPAN的配置来看，可能<br>或未来会具有一定的VXLAN隧道解封装及关联对应能力。但即便如此，在大规模网络流量的<br>情况下，对全部VXLAN流量分析亦将为设备带来压力。<br>另外，主机内的虚拟网络流量，FabricInsight以现在的形式是绝对无法取得的。 </p><h2 id="FabricInsight未来演进趋势推测"><a href="#FabricInsight未来演进趋势推测" class="headerlink" title="FabricInsight未来演进趋势推测"></a>FabricInsight未来演进趋势推测</h2><h3 id="In-band-Telemetry"><a href="#In-band-Telemetry" class="headerlink" title="In-band Telemetry"></a>In-band Telemetry</h3><p>FabricInsight的数据采集能力全部来自于设备提供的能力。在设备/芯片领域的发展趋势是提<br>供更加精细化的In-band Telemetry遥测能力。从Cisco/Barefoot等厂商近期对P4芯片的动态来<br>看，华为跟风也是早晚的事。In-band Telemetry可以提供诸如per packet的全生命周期、匹配<br>的具体转发规则、更加精细的时间戳等能力。但如若采用新的芯片组提供In-band Telemetry<br>，则会仅支持新款产品。<br>除此之外，也将不仅仅将流量分析的范畴局限于TCP流量。 </p><h3 id="虚拟网络"><a href="#虚拟网络" class="headerlink" title="虚拟网络"></a>虚拟网络</h3><p>虚拟网络是行业演进的趋势，但需要考虑华为对FabricInsight这款产品本身的定位。如果添加<br>虚拟网络能力，则其品牌名称、目标人群都将会有较大调整。但华为整体上缺乏虚拟网络可视<br>化的产品和能力，因此推断会先对接华为自己的云平台FusionCloud，计算节点绑定探针。但<br>先期仍会仅采用TCP流量事件的分析模式，不会全量采集和分析。 </p><h3 id="AIops"><a href="#AIops" class="headerlink" title="AIops"></a>AIops</h3><p>AI的概念在当前版本的FabricInsight中已有所体现，但当前仅是一些标准差方差的统计计算。<br>演进的方式将是对网络中断和延迟的诊断以及自调优的赋能。但这种分析首先要求用户能够输<br>入一定的专家经验作为数据训练的标记，同时对分析节点的部署要求较高（支持大数据分布式<br>计算和存储）。 </p><h3 id="安全防御"><a href="#安全防御" class="headerlink" title="安全防御"></a>安全防御</h3><p>这是当前看起来最有实际效能的功能。其本身具有的TCP事件分析能力完全可以用来完成<br>DDoS攻击的侦测和防御。 </p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> product </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>可以预测交通路况的 APP</title>
      <link href="/2018/12/06/life-traffic-prediction/"/>
      <url>/2018/12/06/life-traffic-prediction/</url>
      
        <content type="html"><![CDATA[<blockquote><p>能不能有这样一款应用<br><a id="more"></a></p><p>或者地图 APP 实现这样一个功能</p><p>能通过历史路况大数据分析</p><p>告诉我今天晚上几点出发上路</p><p>东北四环不堵</p><p>把什么机器学习人工智能数字孪生</p><p>能加的都给它加上</p><p>感觉又是一个割 VC 韭菜的杀手应用</p><p>只要有人搭出来这个框架</p><p>我愿意帮忙实现所有的业务代码</p><p>因为只需要一句</p><p><code>return &quot;您期望的时间不存在&quot;</code></p></blockquote><p><em><em>2018.12.6</em></em></p>]]></content>
      
      
      <categories>
          
          <category> life </category>
          
      </categories>
      
      
        <tags>
            
            <tag> life </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去2：CPU缓存读入策略</title>
      <link href="/2018/12/06/test2-cache-line-alignment/"/>
      <url>/2018/12/06/test2-cache-line-alignment/</url>
      
        <content type="html"><![CDATA[<h2 id="到底哪些数据写入了CPU缓存"><a href="#到底哪些数据写入了CPU缓存" class="headerlink" title="到底哪些数据写入了CPU缓存"></a>到底哪些数据写入了CPU缓存</h2><p>我们知道CPU会在要读写某个数据时，先将数据写入缓存。</p><p>我们也知道这个操作一般以Cache Line为操作粒度，并且Cache Line的长度一般为64Byte。<br><a id="more"></a></p><p>那么这个Cache Line包含的数据到底是哪64Byte呢？</p><p>如果要读写的数据的地址正好以64Byte对齐，那么肯定是这个数据和它之后的<code>（64 - sizeof(数据)）</code>Byte存在于这个缓存行里。</p><p>但是如果要读写的这个数据地址不以64Byte对齐，而是在两个64Byte对齐的地址中间的某个位置，CPU写入Cache Line里的数据还是它和它之后的64Byte吗？CPU会“向前”对64取整作为Cache Line中的数据吗？</p><h2 id="用False-Sharing证明"><a href="#用False-Sharing证明" class="headerlink" title="用False Sharing证明"></a>用False Sharing证明</h2><p>根据之前介绍False Sharing的原理<a href="https://decodezp.github.io/2018/11/27/quickwords3-falsesharing/">链接</a>，通过判断是否发生False Sharing可以判断某两个数据是否存在于同一条Cache Line里。</p><p>构造如下结构体：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> front_padding[<span class="number">15</span>];</span><br><span class="line">    <span class="keyword">uint32_t</span> c1;</span><br><span class="line">    <span class="comment">/* 64 bytes */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> c2;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中<code>c1</code>和<code>c2</code>是分别被两个CPU core写入的变量。</p><p>在构造counter_t的实例时，利用<code>GCC attribute</code>确保其起始地址与64Byte对齐：</p><p><code>struct counter_t counter __attribute__((aligned(64)));</code></p><p>在两个CPU核分别开始操作<code>c1</code>和<code>c2</code>之前利用<code>clflush</code>指令清除所有相关缓存：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span></span><br><span class="line">clflush(<span class="keyword">volatile</span> <span class="keyword">void</span> *p)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span> <span class="params">(<span class="string">"clflush (%0)"</span> :: <span class="string">"r"</span>(p))</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>如果发生了False Sharing，则说明这两个变量在一个Cache Line里，则证明CPU是取欲读写变量及其之后64Byte数据写入缓存<br>如果没有发生False Sharing，则说明这两个变量不在一个Cache Line里，则证明CPU是取欲读写变量向前64取整地址上的数据写入缓存</p></blockquote><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>结果当然是没有发生False Sharing。</p><p>不然还搞什么n-way set associative :)</p><p>代码：<a href="https://github.com/PanZhangg/x86perf/blob/master/cache_line_alignment.c" target="_blank" rel="noopener">https://github.com/PanZhangg/x86perf/blob/master/cache_line_alignment.c</a></p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>魏孝文帝教你提proposal</title>
      <link href="/2018/12/05/history-tuobahong/"/>
      <url>/2018/12/05/history-tuobahong/</url>
      
        <content type="html"><![CDATA[<h2 id="艰难的Proposal"><a href="#艰难的Proposal" class="headerlink" title="艰难的Proposal"></a>艰难的Proposal</h2><p>每个人都有独自一人面对全世界的时候，即便你是魏孝文帝拓跋宏。</p><p>北魏太和十七年，承平日久的北魏都城里正在酝酿一件大事——迁都。<br><a id="more"></a></p><p>自天兴元年拓跋圭定都平城起，北魏在此地经营了九十余年。此时的平城，早已是北魏王公贵族富商巨贾的乐土。</p><p>而拓跋宏却不想在这呆了，对这位一心思慕华夏风仪的少数民族首领来说，城狭地偏的平城终究不是久居之地。</p><p>迁都，迁往洛阳，只有住在这座每块城砖上都写满了厚重的城邑的中心，才是北漂买房落户的那一刻。</p><p>但除了拓跋宏，没有人愿意当拆迁户，被连根拔起。拓跋宏自己也知道这一点。晓以大义？没用的，天底下最难的事，就是劝说别人放弃眼前的利益，去追求什么万世之业；</p><p>以皇帝的权威一意孤行？没有问题，但人心不齐，效果打折扣，既损威严，又于事无益。</p><p>那么迁都这个Proposal，到底怎么提呢？</p><h2 id="魏孝文帝的方式"><a href="#魏孝文帝的方式" class="headerlink" title="魏孝文帝的方式"></a>魏孝文帝的方式</h2><p>拓跋宏并没有在一开始就透露自己的意图，而是提出了一个更加”不得人心”的Proposal——亲自带队，攻打南朝。</p><p>如果说迁都不得人心，那么发动战争就更加让改革的主要阻力——深居平城的皇亲贵胄们如坐针毡。</p><p>因为迁都或许还可以讨论讨论，但南下伐齐“一统中国”那是北魏政权不容辩驳的“正统思想”，是政治正确，有拓跋氏列祖列宗的加持，以及冯太后的附魔。</p><p>这一年的八月，拓跋宏亲率三军开拔南下。</p><p>当然，皇帝都出去打仗了，除了太子监国以外，平日里的文武百官哪有在家呆着的道理，一起走吧！</p><p>从山西大同往南，大军在秋雨连绵的泥泞中走了整整一个月，终于到达了宿命的重点——洛阳。</p><p>这个时候所有人都不想再走了。一路的狼狈或可忍受，但后面还有与齐国的恶战。而拓跋宏依然兴致不减，号令即刻开拔，继续南进。</p><p>这下文武百官们可都要“犯颜进谏”了，纷纷叩头不止，甚至不惜死谏以请求拓跋宏停止南征。</p><p>这个时候拓跋宏才说出他真正的目的：</p><blockquote><p>今者兴动不小，动而无成，何以示后？苟欲班师，无以重之千载！朕世居幽朔，欲南迁中土，苟不南伐，当迁都于此，王公以为如何？欲迁者左，不欲者右！——《资治通鉴》</p></blockquote><p>这里有三个要素：</p><ol><li>我可以在南伐之事上让步</li><li>但我的让步有条件</li><li>不许考虑太久</li></ol><p>最终的结果自然是大家都站到了左边。迁都这件事，就这么“取得”了大家的同意。</p><p><img src="http://5b0988e595225.cdn.sohucs.com/images/20170720/b36a2fde600f4b909885b0a76ada9876.jpeg" alt=""></p><h2 id="抽象提取"><a href="#抽象提取" class="headerlink" title="抽象提取"></a>抽象提取</h2><p>在谈判领域存在一个让步/妥协的谈判技巧。</p><p>对每个人来说，如果对面已有所让步，那么心里将会产生同样让步的压力，趋向于同意对方提出的让步条件。</p><p>这种场景在生活中非常常见，例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">多少钱？</span><br><span class="line">100</span><br><span class="line">30吧</span><br><span class="line">最低90</span><br><span class="line">40</span><br><span class="line">低于85就赔本了</span><br><span class="line">你看我就50块钱</span><br><span class="line">行了80吧，今天好不容易开张</span><br></pre></td></tr></table></figure><p>如果能成交，说明买家和卖家一开始的心理价位就都是80元左右，但买家必须要首先压到30，卖家也要提到100，互相留出这个让步的空间。</p><p>也许你觉得这种技巧太市侩，但它其实有很多变种版本，也许自己已经身堕瓠中而不自知。<br>E.g.<br>房产中介请你看房，首先是一间各方面条件都很差的房间，但却有一个让你惊讶的高额租金。然后带你看了一套各方面比第一间好非常多的房间，租金却和第一间一样，或者略多而已。<br>如此你会觉得租了第二间是占了便宜。但其实中介的目标就是租给你第二间房，第一间就是让你产生这种对比让步的错觉的。</p><p>所以，每当打算提一个艰难的Proposal的时候，我都会效仿这种形式。</p>]]></content>
      
      
      <categories>
          
          <category> history </category>
          
      </categories>
      
      
        <tags>
            
            <tag> history </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ftrace uprobe使用填坑历程</title>
      <link href="/2018/12/04/ftrace-uprobe/"/>
      <url>/2018/12/04/ftrace-uprobe/</url>
      
        <content type="html"><![CDATA[<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>打算用一下<code>ftrace</code>对用户态程序的trace支持。</p><h3 id="测试用程序test-c："><a href="#测试用程序test-c：" class="headerlink" title="测试用程序test.c："></a>测试用程序<code>test.c</code>：</h3><a id="more"></a><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">print_curr_state_one(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is the print current state one function\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">print_curr_state_two(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is the print current state two function\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        print_curr_state_one();</span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">        print_curr_state_two();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="编译："><a href="#编译：" class="headerlink" title="编译："></a>编译：</h3><p><code>gcc -o test test.c</code></p><h3 id="Obtain-Offset："><a href="#Obtain-Offset：" class="headerlink" title="Obtain Offset："></a>Obtain Offset：</h3><p><code>objdump -d test</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">000000000040055d &lt;print_curr_state_one&gt;:</span><br><span class="line">  40055d:55                   push   %rbp</span><br><span class="line">  40055e:48 89 e5             mov    %rsp,%rbp</span><br><span class="line">  400561:bf 30 06 40 00       mov    $0x400630,%edi</span><br><span class="line">  400566:e8 c5 fe ff ff       callq  400430 &lt;puts@plt&gt;</span><br><span class="line">  40056b:5d                   pop    %rbp</span><br><span class="line">  40056c:c3                   retq   </span><br><span class="line"></span><br><span class="line">000000000040056d &lt;print_curr_state_two&gt;:</span><br><span class="line">  40056d:55                   push   %rbp</span><br><span class="line">  40056e:48 89 e5             mov    %rsp,%rbp</span><br><span class="line">  400571:bf 60 06 40 00       mov    $0x400660,%edi</span><br><span class="line">  400576:e8 b5 fe ff ff       callq  400430 &lt;puts@plt&gt;</span><br><span class="line">  40057b:5d                   pop    %rbp</span><br><span class="line">  40057c:c3                   retq</span><br></pre></td></tr></table></figure><p>添加uprobe trace event：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 'p:print_current_state_one /root/test/uprobe/uprobe:0x55d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_events</span><br><span class="line">echo 'p:print_current_state_two /root/test/uprobe/uprobe:0x56d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_events</span><br></pre></td></tr></table></figure><p>有时会出现Invalid argument的错误。用<code>sudo su</code>获取<code>root</code>权限。</p><blockquote><p>这里注意，偏移的大小只写0x55d，不能写0x40055d</p></blockquote><h2 id="开启trace"><a href="#开启trace" class="headerlink" title="开启trace"></a>开启trace</h2><p>先启动<code>test</code>程序：<code>./test</code></p><p><code>echo 1 &gt; /sys/kernel/debug/tracing/event/enable</code></p><p>如果此时<code>cat /sys/kernel/debug/tracing/event/enable</code>显示为<code>X</code></p><p><code>echo 1 &gt; /sys/kernel/debug/tracing/event/uprobes/enable</code></p><p>最后<code>cat /sys/kernel/debug/tracing/trace</code>应该就能看到了</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> ftrace </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ftrace trace-cmd kernelshark资料汇总</title>
      <link href="/2018/11/30/ftrace/"/>
      <url>/2018/11/30/ftrace/</url>
      
        <content type="html"><![CDATA[<p>一些关于这一类技术的资料和文档汇总。<br>文章中可以找到比较详细的工具使用方法。如果想了解更多内容可以阅读<code>linux/Documentation/trace</code>下的文档以及源码。</p><p>以及<code>git log ./kernel/trace</code> :)<br><a id="more"></a></p><h2 id="ftrace"><a href="#ftrace" class="headerlink" title="ftrace"></a>ftrace</h2><ul><li><a href="https://lwn.net/Articles/365835/" target="_blank" rel="noopener">Debugging the kernel using Ftrace - part 1</a></li><li><a href="https://lwn.net/Articles/366796/" target="_blank" rel="noopener">Debugging the kernel using ftrace - part 2</a></li><li><a href="https://www.kernel.org/doc/Documentation/trace/ftrace.txt" target="_blank" rel="noopener">Kernel Documents: ftrace</a></li><li><a href="https://lwn.net/Articles/370423/" target="_blank" rel="noopener">Secrets of the Ftrace function tracer</a></li><li><a href="https://people.canonical.com/~acelan/coscup-2010/Debugging%20Linux%20Kernel%20by%20Ftrace.pdf" target="_blank" rel="noopener">PDF:Debugging Linux Kernel by ftrace</a></li><li><a href="https://opensourceforu.com/2010/11/kernel-tracing-with-ftrace-part-1/" target="_blank" rel="noopener">Kernel Tracing with ftrace, Part 1</a></li><li><a href="http://opensourceforu.com/2010/12/kernel-tracing-with-ftrace-part-2/" target="_blank" rel="noopener">Kernel Tracing with ftrace, Part 2</a></li><li><a href="https://jvns.ca/blog/2017/03/19/getting-started-with-ftrace/" target="_blank" rel="noopener">ftrace: trace your kernel functions!</a></li><li><a href="https://movaxbx.ru/2018/10/12/hooking-linux-kernel-functions-how-to-hook-functions-with-ftrace/" target="_blank" rel="noopener">Hooking Linux Kernel Functions, how to Hook Functions with Ftrace</a></li><li><a href="https://www.slideshare.net/ennael/kernel-recipes-2017-understanding-the-linux-kernel-via-ftrace-steven-rostedt" target="_blank" rel="noopener">Understanding the Linux kernel via ftrace</a></li></ul><h2 id="trace-cmd"><a href="#trace-cmd" class="headerlink" title="trace-cmd"></a>trace-cmd</h2><ul><li><a href="https://lwn.net/Articles/410200/" target="_blank" rel="noopener">trace-cmd: A front-end for Ftrace</a></li><li><a href="https://github.com/rostedt/trace-cmd" target="_blank" rel="noopener">Code:trace-cmd</a></li></ul><h2 id="kernelshark"><a href="#kernelshark" class="headerlink" title="kernelshark"></a>kernelshark</h2><ul><li><a href="https://lwn.net/Articles/425583/" target="_blank" rel="noopener">Using KernelShark to analyze the real-time scheduler</a></li><li><a href="https://kernel-recipes.org/en/2018/talks/kernelshark-1-0-whats-new-and-whats-coming/" target="_blank" rel="noopener">Video:KERNELSHARK 1.0; WHAT’S NEW AND WHAT’S COMING</a></li><li><a href="https://www.youtube.com/watch?v=RwVnnuGrb_c" target="_blank" rel="noopener">Video:Yordan Karadzhov - What’s Coming in Kernel Shark</a></li><li><a href="https://events.linuxfoundation.org/wp-content/uploads/2017/12/Swimming-with-the-New-KernelShark-Yordan-Karadzhov-VMware.pdf" target="_blank" rel="noopener">PDF:Swimming with the New KernelShark</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> ftrace </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去1：DPDK no-huge模式性能对比测试</title>
      <link href="/2018/11/29/test1-dpdk-no-huge/"/>
      <url>/2018/11/29/test1-dpdk-no-huge/</url>
      
        <content type="html"><![CDATA[<h2 id="no-huge"><a href="#no-huge" class="headerlink" title="no-huge"></a>no-huge</h2><p>DPDK使用大页内存作为性能优化的一个手段。但大页内存在云计算等环境下可能会出现内存资源浪费的情况，作为售卖资源的云服务商，希望能找到更充分的内存资源利用的方法。在此背景下，DPDK引入了no-huge机制，即不使用hugepage，从而解放更多的系统资源。</p><p>那么这种配置下DPDK性能会下降多少呢？还是需要实际定量测试一下。<br><a id="more"></a></p><h2 id="测试平台"><a href="#测试平台" class="headerlink" title="测试平台"></a>测试平台</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                88</span><br><span class="line">On-line CPU(s) list:   0-87</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    22</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 85</span><br><span class="line">Model name:            Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHz</span><br><span class="line">Stepping:              4</span><br><span class="line">CPU MHz:               2100.393</span><br><span class="line">BogoMIPS:              4201.72</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              30976K</span><br><span class="line">NUMA node0 CPU(s):     0-21,44-65</span><br><span class="line">NUMA node1 CPU(s):     22-43,66-87</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep Ether</span><br><span class="line">86:00.0 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.1 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.2 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.3 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br></pre></td></tr></table></figure><p>DPDK Version: <code>18.05.1</code><br>Tester: IXIA<br>Test Plan: RFC2544<br>DPDK APP: <code>./l2fwd -l 22-24 --no-huge  -- -p 0x3 -T 5</code></p><h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p><img src="https://s1.ax1x.com/2018/11/29/FZIYcT.png" alt=""></p><p>在64Byte包长时丢包率达到了50%以上，而使用大页内存时丢包率可以控制在0.05%以内。<br>其他长度丢包和吞吐情况基本相同。<br>根据业务情况，平均包长如果在300Byte以上–no-huge模式不妨一试。<br>后续添加针对更大链路带宽(25Gbps/100Gbps)的网卡以及不同Xeon平台的测试结果。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> dpdk </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>云计算的发展需要向社区街道管理看齐</title>
      <link href="/2018/11/28/thoughts1-cloud-community/"/>
      <url>/2018/11/28/thoughts1-cloud-community/</url>
      
        <content type="html"><![CDATA[<h2 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h2><p>云计算本质上是一种服务。由各种不同的组件为租户提供计算、网络和存储服务。</p><p>用户对这些服务的要求除了功能之外，还有安全性、可用性、性能、成本、迁移难度、SLA等一系列要求。</p><p>与之类比，社区街道作为一个完整的功能单元，各个基层职能部门，也为社区内的居民提供各类生活服务。</p><p>如何做好基层工作，是需要费一番脑筋的。<br><a id="more"></a></p><h2 id="服务网格"><a href="#服务网格" class="headerlink" title="服务网格"></a>服务网格</h2><p>下图是我在北京中关村某社区拍到的当地派出所的“网格团队”成员和工作职责。</p><p><img src="https://s1.ax1x.com/2018/11/28/FV0v3q.jpg" alt=""><br>如果你熟悉云计算，熟悉当前的领先理念，那么<code>service mesh</code>这个词你肯定不陌生，这是当前容器和微服务领域的最新热点，拥有Istio、Envoy等一众明星开源项目，并且有Google、AWS、Alibaba等大佬拥趸。这个词翻译过来就是<code>服务网格</code>。</p><p>而社区街道提出的这个“网格”的概念，明显领先于自诩为科技前沿的云计算。</p><p>如果仔细阅读一下上图中的“工作职责”，就能够轻易地将其内容与时下云计算和企业数字化转型热炒的概念对应起来：</p><ul><li>管理网格单元：Microservice微服务</li><li>落实基信息采集：Digital Twin数字孪生</li><li>综合网格力量：Orchestration协同</li><li>加强依法自治：Decouple解耦/Distrubute分布式</li><li>排查隐患：Situational Awareness态势感知/Active Defence主动式防御</li><li>协调解决社会服务管理中存在的问题：Full Stack Management全栈管理</li><li>推进公共服务建设：Aglie敏捷/DevOps</li><li>监督管理网格力量，督促责任落实：Sidecar</li><li>及时上报网格工作数据：Telemetry遥测</li><li>完成街道交办的其他工作：Serverless无服务器</li></ul><p>总结就是这个街道派出所就是Community-Native Microservice &amp; Service Mesh &amp; Serverless &amp; Security的典范，理念领先云计算至少5年。</p><h2 id="好好学习"><a href="#好好学习" class="headerlink" title="好好学习"></a>好好学习</h2><p>为什么街道派出所的理念能领先云计算的发展？道理都是殊途同归的，很多理念（经验）的获得都是靠积攒年头。</p><p>云计算方兴未艾，但毕竟用户还不足够多，问题暴露还不足够全面，或者说，没太多管理经验。而派出所展开基层管理工作的时间至少比在坐的诸位岁数都长。同时基层群众形形色色，就像软件测试时的边界条件，绝对都能满足。</p><p>在此种“得天独厚”的条件下总结出的经验，云计算从业者除了好好消化吸收之外，也可以小小的自鸣得意一下，毕竟你仅仅用了10年就追上了街道派出所。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> thoughts </tag>
            
            <tag> cloud </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚3:什么是False Sharing</title>
      <link href="/2018/11/27/quickwords3-falsesharing/"/>
      <url>/2018/11/27/quickwords3-falsesharing/</url>
      
        <content type="html"><![CDATA[<h2 id="不用图"><a href="#不用图" class="headerlink" title="不用图"></a>不用图</h2><p>以为又要见到那几张网上已经用烂了的图了是不是？这次我们不用图来讲这个事。<br><a id="more"></a></p><p>Cache line是64个Byte，我们经常操作(R/W)的变量是4个或者8个Byte。</p><p>于是一个Cache line里就可以放好几个变量，比如说其中有两个变量A和B。</p><p>当CPU0写入A，CPU1写入B的时候，就发生了False Sharing，就这么简单。</p><p>所谓“假共享”，其实就是你以为你俩自己操作自己的变量是共产国际按需分配互不影响，其实都是假象。</p><p>很多材料上说是因为不同的CPU核共享了相同的Cache Line，其实并不严谨。根本因素是不同的CPU核需要更新的缓存出现了地址上的重叠。</p><p>那么当其中一个核更新了它的变量A之后，CPU并不能识别出是哪4个Byte或8个Byte地址上的数据被更新，而只能认为该变量所在的整条64Byte Cache Line都应该被更新。</p><p>所有有和这64Byte重叠的Cache Line，不管在哪个CPU核上，都需要被更新，这样才能保证大家手头的数据是一致的。</p><p>于是乎，和这64Byte地址存在重叠的变量B所在的CPU1中的缓存也需要被更新，自然就影响到了性能。</p><p>如果只是读，就没有这个问题，因为不需要关心缓存一致这个事。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>这里有一个活生生的代码的例子：</p><p><a href="https://github.com/PanZhangg/x86perf/blob/master/false_sharing_padding.c" target="_blank" rel="noopener">https://github.com/PanZhangg/x86perf/blob/master/false_sharing_padding.c</a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> c1;</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifdef</span> PADDING_64_BYTE</span></span><br><span class="line">    <span class="keyword">uint32_t</span> padding[<span class="number">15</span>];</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">elif</span> PADDING_128_BYTE</span></span><br><span class="line">    <span class="keyword">uint32_t</span> padding[<span class="number">31</span>];</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">uint32_t</span> c2;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>本来是打算用来验证在CPU预取开启的情况下到底是应该Padding 64还是128，但在Haswell和Skylake上验证，这两个长度都没有区别。</p><p>后来查找资料是在Sandy bridge上需要padding到128，但我这里没有这么老的CPU….先这样吧..</p><p>上面的代码注意用<code>-O0</code>编译。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚2:CPU缓存的组织形式</title>
      <link href="/2018/11/25/quickwords2-cacheassociativity/"/>
      <url>/2018/11/25/quickwords2-cacheassociativity/</url>
      
        <content type="html"><![CDATA[<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>缓存和其他存储形式在功能形式上没有太大区别，均是输入一个地址，还你一个数据。但作为一个缓存，要考虑如何在有限的容量下保证较高的命中率以及查找效率(<a href="https://decodezp.github.io/2018/11/20/cachesize/">相关阅读</a>)。这个问题从本质上来说，就是如何建立缓存地址与内存地址的映射关系。</p><a id="more"></a><h2 id="组织形式"><a href="#组织形式" class="headerlink" title="组织形式"></a>组织形式</h2><p>缓存按照一个Cache Line的长度（主流长度为64Byte）为粒度来组织：</p><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140538/481_051.gif" alt=""><br>各种不同的映射形式就是在决定内存中某一个特定地址范围内的数据，具体可以放到哪一个Cacha Line里去。</p><p>能想出来的方式也无外乎三种：</p><ul><li>哪个都可以放</li><li>只能放到第N个（N是内存地址的函数）</li><li>只能放到第N个至第M个（M也是内存地址的函数）</li></ul><blockquote><p>其实基本上这篇文章可以结束了，很多技术都不是什么新鲜的“创想”，只是给朴素的思想内核穿上了一层“术语”的外衣。</p></blockquote><h3 id="Direct-Mapping"><a href="#Direct-Mapping" class="headerlink" title="Direct Mapping"></a>Direct Mapping</h3><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140525/481_061.gif" alt=""><br>这就是上面说的第二种方式，某一个内存地址段的数据，只能放在第N个Cache Line里</p><ul><li>Pros:查找快，一次寻址，有就是有，没有就是没有，不啰嗦（因为只需要验证一个Cache Line中是否存在该地址）</li><li>Cons:命中率低，CPU经常需要相邻地址的数据，而根据规则，同属于第N个Cache Line的数据会互相排斥，不会同时出现在缓存里</li></ul><h3 id="Fully-Associative"><a href="#Fully-Associative" class="headerlink" title="Fully Associative"></a>Fully Associative</h3><p>这就是第一种方式，随便放。</p><ul><li>Pros:命中率高，过去和未来一段时间内需要的数据都可以被放在缓存内，同时不用担心被相邻地址上的数据踢出</li><li>Cons:查找慢，确认一个地址是否在缓存里通常需要遍历整个缓存（Miss的情况）</li></ul><h3 id="n-Way-Set-Associative-Cache"><a href="#n-Way-Set-Associative-Cache" class="headerlink" title="n-Way Set Associative Cache"></a>n-Way Set Associative Cache</h3><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140450/481_081.gif" alt=""><br>这就是第三种方式了，颜色相同的内存地址范围和缓存Cache Line互相对应，不能越界。每一个颜色就是一个Way。</p><p>但如果单独拿出某一个颜色来看，是Fully Associative的方式。</p><p>这么做当然是为了充分发挥前两种方式的优势。既可以存在相邻内存中的数据以提高命中，同时也一定程度上减少了查找范围，提升查找效率。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>XXV710网卡Target Link Speed探秘</title>
      <link href="/2018/11/23/x710-target-link-speed/"/>
      <url>/2018/11/23/x710-target-link-speed/</url>
      
        <content type="html"><![CDATA[<h2 id="发现"><a href="#发现" class="headerlink" title="发现"></a>发现</h2><p>用lspci指令查看PCIe设备，特别是网卡设备经常会查看LnkCap及LnkSta字段，以确保网卡运行在期望的PCIe总线类型/带宽上，从而保证网卡的性能。</p><p>最近拿到一块XXV710-DA2，插上之后简单看了一下状态。LnkCap和LnkSta均显示为Speed 8GT/s，Width x8，没太大问题。这时候无意中瞥见LnkCtl2中Target Link Speed显示为2.5GT/s，引发了兴趣。<br><a id="more"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</span><br><span class="line">DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not Supported</span><br><span class="line">DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled</span><br><span class="line">LnkCtl2: Target Link Speed: 2.5GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB</span><br></pre></td></tr></table></figure><h2 id="Target-Link-Speed"><a href="#Target-Link-Speed" class="headerlink" title="Target Link Speed"></a>Target Link Speed</h2><p>关于Target Link Speed是什么，查找到了Intel Skylake Processor External Design Specification(EDS)中的定义：</p><blockquote><p>For Downstream Ports, this field sets an upper limit on Link operational speed by restricting the values advertised by the Upstream component in its training sequences.</p></blockquote><p>基本上LnkCap表示支持的速度，LnkCtl2设置你需要的速度，LnkSta显示实际Training好的速度，如果想要修改的话，都是改LnkCtl2的值。</p><p>现在的问题就是LnkSta和LnkCtl2矛盾。那么我们现在这块网卡的速度到底是多少？只能实际测试一下。</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>起个<code>pktgen</code>打个性能，是能直接到线速的，也就是说Target Link Speed没有实际起到限制速度的作用。</p><p>又查询了一些资料，从这里看到一个帖子：<a href="https://communities.intel.com/thread/106568" target="_blank" rel="noopener">https://communities.intel.com/thread/106568</a></p><p>最终Intel的官方回复是，这个寄存器的值确实和实际速度没有关系。</p><p>规范也是你们写的，帖子也是你们回的，现在正话反话都让你说了，搞什么鬼。</p><p>最后查到了该寄存器的位置(D0h)，暴力修改一下：</p><p><code>setpci -s 0000:18:00.0 d0.B=3</code></p><p>然后就乖乖地显示为8GT/s了，真是个毫无脾气的寄存器，你让别的遵守规范的设备如何自处。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</span><br><span class="line">DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not Supported</span><br><span class="line">DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled</span><br><span class="line">LnkCtl2: Target Link Speed: 8GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序员和工厂劳工有何不同</title>
      <link href="/2018/11/22/programmer-worker/"/>
      <url>/2018/11/22/programmer-worker/</url>
      
        <content type="html"><![CDATA[<p>如今流行的一个说法是，现在的程序员与工业时期的工厂工人并无二致。<br>均是富集于人口密集的城市、均是超时劳动、均是遭受资本家的盘剥、均是一架大机器上的螺丝钉，在超过“劳动年龄”之后被弃如敝屣。<br>基于这些相似点，有些人得出结论，程序员不过是这个时代的“无产阶级”，和以前的流水线工人，纺织厂女工属于同一社会分工和定位。<br>是否当真如此，这个问题值得仔细推敲一下。<br><a id="more"></a></p><h2 id="生产资料"><a href="#生产资料" class="headerlink" title="生产资料"></a>生产资料</h2><p>个人所处的社会阶层，取决于他能让属于他的生产资料产生的价值。传统的生产资料包括实体的机器、厂房、地皮、原材料、资本和人等等。<br>而作为信息时代的标志，人人都可以通过网络获取一项虚拟的生产资料——信息。诚然，信息壁垒依然存在，但普通人能接触到的信息总量和质量与信息革命之前的时代相比已不可同日而语。<br>程序员是与电子计算设备打交道的人，此类设备本质上是信息的产生、加工和分发工具。一台电脑加一条网线，程序员就可以以极其低廉的方式获得他所需要的生产资料。而拥有生产资料的人，就不能再称之为“无产阶级”。<br>我们已经听过了太多程序员在车库创业的故事，也许这些故事仍然可以称之为“个例”，毕竟，哪个时代没有一些白手起家的人。<br>但如果某个行业能在全社会掀起创业的热潮，那么就不能再以孤例的眼光看待。只有在该行业的生产资料极大丰富，且对再加工之后的产品有持续需求的情况下才有可能出现这类情况。<br>是否能以足够廉价的方式获取生产资料，是程序员与工厂工人的第一个区别。<br><img src="http://www.xinhuanet.com/politics/2015-05/05/127763760_14307851178281n.jpg" alt=""></p><h2 id="对生产资料的再分工"><a href="#对生产资料的再分工" class="headerlink" title="对生产资料的再分工"></a>对生产资料的再分工</h2><p>注意这里强调的是再“分”工，而不是再加工。<br>程序员能够开发出各种程序满足人们的需求，工人也能生产出各种生活必需品，所以在生产资料再加工这一点上，两者没有本质区别。<br>专业细分是社会生产率提高的根本因素。每个人只负责整条产业链中的一环，愈发细致的分工与合作是现代生产活动的组织方式。<br>程序员和工人均为某一细分领域的专家，但二者所处的分工链条深度不同。<br>工人是分工链条的末端，他所能做的就是尽自己所能做好手头的事情。<br>而程序员虽然仍然要听老板的，但他手下仍有电子设备作为分工的最后一环。<br>程序员可以通过编码为这些电子设备“分工”，从而令其为程序员服务。<br>从某种意义上说，程序员就是这些电子设备的“老板”。同时随着设备的计算能力越来越强，这些设备就能逐渐胜任更加精细的分工任务。<br>随着分工的深入，一方面带动社会整体劳动生产率的提升，一方面更加高效地产生价值。<br>一个大型工厂的老板最多能令数万工人为其服务，而所有能跑代码的设备都可能为程序员服务。<br>在分工链所处的位置和对生产资料的再分工能力，是程序员与工厂工人的第二个区别。<br><img src="http://s2.51cto.com/oss/201811/05/d0c5758831b1df8bcac6728d848e014a.jpg-wh_651x-s_1764483471.jpg" alt=""></p><h2 id="程序员如何度过”中年危机”"><a href="#程序员如何度过”中年危机”" class="headerlink" title="程序员如何度过”中年危机”"></a>程序员如何度过”中年危机”</h2><p>其实程序员是新时代的工厂工人这种论调，只不过是之前“青春饭”、“过了30岁不能再编程“等论调的新瓶装旧酒而已。<br>但程序员面对的现实压力确实是不容忽视的问题。很多人学了很多技术，掉了很多头发，但最后仍被公司扫地出门，问题就在于做了无用的努力。<br>解决之道其实就蕴含在前文论述的两点之内：</p><ul><li>尽可能占有(处理)更多的生产资料——信息</li><li>为尽可能多的电子设备”分工”</li></ul><p>实际执行的术便是一定要有自己的“产品”。<br>这当然是一个程序，可以是公司的产品，也可以是个人作品。但需要关注两个关键点：</p><ul><li>我的程序是否位于信息交叉的节点或能协助信息的获取、处理及分发</li><li>运行我的程序的设备是否在增长</li></ul><p>可以看看这些久盛不衰的“产品”：操作系统、数据库、浏览器、服务器软件、办公处理、图像应用处理等等甚或编程语言本身，都是这两个关键点的很好的体现。<br>当你拥有这样的产品时，操心的就不是公司会不会要你了，而是如何高效地指挥你自己这支被你分工的生产队，实践一些大胆的想法。<br>最后附上我最喜欢的历史名人名言作为结尾：</p><blockquote><p>臣但恐富贵来逼臣，臣无心图富贵。</p></blockquote><p>——杨素</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚1:为什么CPU L1缓存容量始终很小</title>
      <link href="/2018/11/20/cachesize/"/>
      <url>/2018/11/20/cachesize/</url>
      
        <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>CPU缓存是影响软件性能的关键因素之一。在做性能调优时，经常关注的一个指标就是缓存的命中率(hit rate)。<br>缓存之所以不会达到100%的命中率，是因为缓存容量有限，不能将内存中的全部数据都同时放入其中。只能将当前最热，相邻最近的数据存入，同时还受多核CPU中缓存同步机制的影响。<br>奇怪的是，CPU的制程、晶体管数量、核心数量一直都在增加，但L1缓存的容量始终维持在一个相当低的水平。为什么不加大L1缓存呢？<br><a id="more"></a></p><p><img src="https://cenalulu.github.io/images/linux/cache_line/latency.png" alt=""></p><h2 id="缓存组织形式"><a href="#缓存组织形式" class="headerlink" title="缓存组织形式"></a>缓存组织形式</h2><p>当然要考虑到成本和功耗，以及边界效益的问题，但这些不是本文讨论的重点。<br>缓存存在的意义是当CPU需要某些数据时，能够以最快的速度给它。<br>这个速度是以CPU时钟周期为计量单位的。在这一个周期内，CPU能处理的数据量并不大。<br>作为L1缓存，首先需要做的就是把这几个周期内的数据保存好，这个确实缓存容量越大，可以做得越好。<br>但把数据喂给CPU，还需要另外一步工作——缓存的查找。<br>种种不同的缓存组织方式和对应的查找机制，其实是在命中率以及查找效率中寻找平衡。</p><p><img src="https://cs.nyu.edu/~gottlieb/courses/2000s/2007-08-fall/arch/lectures/diagrams/cache-set-assoc.png" alt=""></p><ul><li>直接映射(Direct Mapping)查找效率高，但命中率很低</li><li>全关联映射(Fully Associative Mapping)命中率会提高，但查找效率非常低，与缓存容量成反比</li><li>N路组相联映射(N-ways Set-Associative Mapping)折衷方案，平衡命中率和查找效率，也是缓存采用的组织方式</li></ul><h2 id="L1"><a href="#L1" class="headerlink" title="L1$"></a>L1$</h2><p>对L1缓存来说，任务很艰巨，既要追求命中率，同时也要保证查找效率，那么解决方法就是缩小体积。既享受N-ways Set-Associative Mapping带来的命中率，同时因为每个Set的尺寸不大，仍然会有很高的查找效率。<br>如果将缓存的容量增大，不仅仅是成本和功耗上得不偿失，也将会让缓存的查找效率降低而使缓存丧失意义。</p><p>“大曰逝，逝曰远，远曰反”，以退为进，以曲为直的道理在缓存中有了很好的体现。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>top命令使用方法补遗</title>
      <link href="/2018/11/19/topcmd/"/>
      <url>/2018/11/19/topcmd/</url>
      
        <content type="html"><![CDATA[<h2 id="更改界面刷新频率"><a href="#更改界面刷新频率" class="headerlink" title="更改界面刷新频率"></a>更改界面刷新频率</h2><ul><li>自动刷新</li></ul><p><code>top</code><br><code>d</code><br>输入刷新时间（默认3秒，可调至0.5）</p><ul><li>手动刷新<br>空格</li></ul><a id="more"></a><h2 id="屏幕滚动"><a href="#屏幕滚动" class="headerlink" title="屏幕滚动"></a>屏幕滚动</h2><p>一个屏幕显示不完<br><code>C</code><br>使用方向键滚动</p><p>可用在使用<code>c</code>和<code>V</code>开启命令行及Forest view之后</p><h2 id="查看线程top信息"><a href="#查看线程top信息" class="headerlink" title="查看线程top信息"></a>查看线程top信息</h2><p><code>H</code></p><h2 id="查看线程CPU绑定-亲和性状态"><a href="#查看线程CPU绑定-亲和性状态" class="headerlink" title="查看线程CPU绑定/亲和性状态"></a>查看线程CPU绑定/亲和性状态</h2><p><code>F</code><br>移动光标至<code>Last Used Cpu</code><br>空格<br><code>q</code>返回</p><p>与<code>H</code>配合使用<br>可观察各线程是否与对应的CPU核绑定亲和性</p><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p><code>M</code>按驻留内存大小排序<br><code>P</code>按CPU使用率排序<br><code>T</code>按累计时间排序<br><code>x</code>高亮排序的列</p><h2 id="按NUMA查看CPU使用情况"><a href="#按NUMA查看CPU使用情况" class="headerlink" title="按NUMA查看CPU使用情况"></a>按NUMA查看CPU使用情况</h2><p><code>2</code>查看各NUMA节点CPU汇总使用信息<br><code>3</code>输入节点号，查看该节点各CPU使用信息</p><h2 id="按条件过滤"><a href="#按条件过滤" class="headerlink" title="按条件过滤"></a>按条件过滤</h2><p>‘O’<br>输入过滤条件，如:<br><code>!COMMAND=top</code> COMMAND栏中不包含top<br><code>%CPU&gt;3.0</code> CPU占用率大于3%<br>清除全部过滤条件 <code>=</code></p><h2 id="保存当前命令配置"><a href="#保存当前命令配置" class="headerlink" title="保存当前命令配置"></a>保存当前命令配置</h2><p><code>W</code><br>下次再启动时恢复当前配置形式</p><h2 id="其他信息"><a href="#其他信息" class="headerlink" title="其他信息"></a>其他信息</h2><p><code>man top</code></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>刚日读经，柔日读史</title>
      <link href="/2018/11/18/gangrirouri/"/>
      <url>/2018/11/18/gangrirouri/</url>
      
        <content type="html"><![CDATA[<p>在不知道什么时候，我们似乎被灌输了一种互补好，什么都是互补好的认知。<br>资源要互补，团队要互补，思想要互补，连看个书也得掐着日子互补。</p><a id="more"></a><p>刚日读经，柔日读史，“刚日”就是阳数的日子，“柔日”就是阴数的日子。因为阴阳要互补，所以刚日要读致虚守弱恒常静笃的经；柔日便要读变动不居周行不殆的史。<br>为此还有各位理论导师的笺注，比如南怀瑾：</p><blockquote><p>亢阳激扬，刚也；卑幽忧昧，柔也。经主常，史主变。故刚日读经，理气养生也；柔日读史，生情造意也。有生有息，合乎天理，何乐而不为哉！</p></blockquote><p>感觉并不如我总结得那般言简意赅提要钩玄。<br>如果说这种“互补”确实在指导我们的行为，那也无可厚非。而实际上我们日常行事，却和这种思想观念有很大出入。<br>饮食上要以形补形，想要强要壮，自然是找来更强更壮的，绝对不会找短小“互补”的食材。<br>婚嫁上要强强联合，至少至少也要找个“门当户对”的。至于相互互补的情节，不是出现在少儿童话故事里，就是出现在成人童话故事里。<br>嘴里说的是阴阳互补，做的却是采阴补阳的勾当。<br>而最重要的是，没有人觉得有问题。我们妄自接受了这些观念，很少去问这些到底是什么。只是在需要的场合，程式化地提出这一观念。<br>什么是互补，什么是阴，什么是阳，什么是刚，什么是柔。如果我脑中只是一些不明来源，未经考究过的观念，那么什么是我自己。<br>更诡吊的是，人与人之间最大的仇恨与惨剧，都滥觞于这种我们根本自己也没搞清楚的观念。<br>不要说“互补”，即便是稍有不同，那便是异端邪说、是外族、是异教徒、是政治犯；那便会有党争、门户、正宗、政治清洗和宗教审判。<br>信不知凭何而信，恨不知因何而恨。被左右的观念所左右，被迷惑的语言所迷惑，操纵感官输出的表象又被表象所操纵。<br>无论刚日柔日，翻开经史，里面都是这样的故事。只要稍微读几页就会发现，与先前想的正好相反，教给你变化的其实是经，而教给你不变的是史。<br>所以这句话并不是要教给你刚柔相济之道，而是提醒你认清人心之妄作，行为之颠倒，以及，追求真实的难能可贵。<br>谨录于上，念念不忘。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>如何在偷偷搜索关键字后避免令人尴尬的广告</title>
      <link href="/2018/11/17/duckduckgo/"/>
      <url>/2018/11/17/duckduckgo/</url>
      
        <content type="html"><![CDATA[<blockquote><p>转载自<a href="https://cloudwonders.info" target="_blank" rel="noopener">cloudwonders.info</a></p></blockquote><p>当你在任意一个搜索引擎输入一个关键词之后，你就成了全网全平台追逐的流量热点。</p><p>平时大打口水战的各大平台在共享你的隐私数据方面异常团结，在B系网站搜索，在A系T系的应用APP上都会看到为你“量身定制”的推送和广告，延迟不超过一分钟。</p><a id="more"></a><p>这一点即便是业界道德楷模G老师都未能免俗，毕竟它也要靠着广告收入维持其智能推荐算法引擎的研发投入。</p><p>最可气的是，推送些边栏广告也就算了，竟然连自己看的新闻和短视频内容也都要和搜索记录沾边，在聚会上随便刷下手机就暴露了自己到底是个什么货色。</p><p>网络对你的监视是全方位的，除了你主动输入的那些关键字，你平时的谈话、你的地理位置，你周围的环境照片都会被偷偷记录上传，用以支撑靠勤劳质朴的城镇劳动人民手动打标签的“人工”智能工程师们的高薪。</p><p>当个人隐私在巨头面前节节败退，当生而为人的尊严在利益机器面前粉碎，当你不能说的秘密被拿来公开叫卖和嘲弄，当互联网利用你心底的弱点反过来操控你之时，难道就没有一款可以放心解放双手，安全地释放自己的求知欲，满足人类最原始的好奇的搜索引擎吗？当然不是这样的鸭——</p><p><img src="http://ww1.sinaimg.cn/large/73403117ly1fhsqrvtg20j223w1kwq8e.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt=""></p><p>这个创立于2008年的搜索引擎，十年来一直在巨头的夹击下惨淡经营。如果没有愈演愈烈的互联网隐私泄露事件、没棱镜门、没有小扎的听证会，恐怕Duckduckgo也不会有近来的长足发展。</p><p><img src="https://i.loli.net/2018/11/05/5be057be3a57f.jpg" alt=""></p><p>Duckduckgo从创立之初秉承的理念就是不对用户的搜索做任何追踪与记录，不把用户的隐私和数据当作公司的资产，做好一个搜索引擎的本分。自2018年之初，该搜索引擎已每日接受多于两千万次的匿名搜索。</p><p>Duckduckgo的使用方式与其他搜索引擎没有区别，唯一的不同就是搜索之后在其他任何平台没有相关的广告推送。至于搜索本身的质量和水平，笔者简单做了个对比：</p><p><img src="https://i.loli.net/2018/11/05/5be057fe2c0e7.png" alt=""></p><p>应当说完全可以满足日常应用，不说超越G老师，超越B老师应该是问题不大。同时不用担心在互联网大机器下无所遁形。已经有越来越多的朋友和公司将Duckduckgo设置为了默认搜索引擎。</p><p>如果说互联网早已是赢家通吃的寡头时代，用隐私交换在线服务已如缴纳“人头税“一般自然，而在这万马齐喑的时刻，Duckduckgo代表的是一豆星星点点的亮光，为所有在歌舞升平中“心怀鬼胎“的人们擎举起惊奇与愤怒的能力。可以放心大胆地搜索不可描述内容的传送门：<a href="https://www.duckduckgo.com" target="_blank" rel="noopener">https://www.duckduckgo.com</a></p>]]></content>
      
      
      <categories>
          
          <category> wonder </category>
          
      </categories>
      
      
        <tags>
            
            <tag> resources </tag>
            
            <tag> wonder </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
