<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>测来测去23:i40e_vlan_tpid_set():Set switch config failed aq_err:14</title>
      <link href="/2020/01/06/test23-Set-switch-config-failed-aq-err/"/>
      <url>/2020/01/06/test23-Set-switch-config-failed-aq-err/</url>
      
        <content type="html"><![CDATA[<p>把X722网卡的固件升级到4.10或4.11版本之后运行DPDK-19.02及之前的版本都会出这个问题：<br><a id="more"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">i40e_vlan_tpid_set(): Set switch config failed aq_err: 14</span><br><span class="line">eth_i40e_dev_init(): Failed to set the default outer VLAN ether type</span><br><span class="line">EAL: ethdev initialisation failedEAL: Requested device 0000:43:00.0 cannot be used</span><br><span class="line">EAL: PCI device 0000:43:00.1 on NUMA socket 0</span><br><span class="line">EAL:   probe driver: 8086:37d0 net_i40e</span><br><span class="line">i40e_vlan_tpid_set(): Set switch config failed aq_err: 14</span><br><span class="line">eth_i40e_dev_init(): Failed to set the default outer VLAN ether type</span><br><span class="line">EAL: ethdev initialisation failedEAL: Requested device 0000:43:00.1 cannot be used</span><br></pre></td></tr></table></figure><p>在DPDK19.08和19.11上是没啥问题的。</p><p>可以选择升级DPDK，如果还是要坚持使用老版本的DPDK可以在升级了X722网卡固件之后给DPDK的代码打上这个Patch<a href="https://patches.dpdk.org/patch/56718/" target="_blank" rel="noopener">链接</a></p><p>本质上是新的固件和老版本的驱动不兼容，存在一些需要配适的问题。只是最近这个问题好像频繁爆发，所以在此注明一下。</p><blockquote><p>好像也可以选择不升级X722的固件，但是不升级的话又会出现一些别的问题。总之如果网卡出了些奇奇怪怪的错误，第一先选择升级固件。升级完了之后还有问题的话，就把问题丢给Intel吧…</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>其远而无所至极</title>
      <link href="/2020/01/03/thoughts13-the-farthest-place/"/>
      <url>/2020/01/03/thoughts13-the-farthest-place/</url>
      
        <content type="html"><![CDATA[<p>故事要怎么开始呢，仿佛本就没有什么开始。直到去年下半年之前，我都无法确切地说出自己要成为怎样的人。心里虽有些模模糊糊的轮廓，却没有再看清楚一点的念头，因为害怕清晰的影像反而会让自己失望。</p><p>去年4月有一个很神奇的契机，成为了点燃浩浩苍穹的星火。我现在犹记得接完电话之后的那股强烈的预感。但这仍然不是故事的开始，甚至2017年12月取得那张凭证也不是开始，应该说，所有我们以为是开始的，都可以找到另外一件事，那些开始不过是这件事的结果。<br><a id="more"></a></p><p>从去年4月开始至今，于我是一段前所未有的旅程。上了大学稍微明白一些世理之后开始准备的那些不知所谓的东西都仿佛有了更多实用角度的意义。那些熟悉的记载在故纸堆中的人物，当我意识到我也正在做像他们一样的事，甚至侧身其中，经历类似的挫折和屈辱，处理完全可以类比的问题时，虽然我还没有像他们中有些人那样封侯入相，但于我已是十数年如一日之后的如愿以偿。</p><p>如果说我能有什么愿望，那必定是以平生所学经世致用。但之前这么说太空洞了，太没有说服力了，就像某些腐儒自知无望的喃喃呓语。我一直期望着能有一天我可以不带任何惭愧地讲出这句话，就像我真的有了什么实实在在的践行，就像我不是一个只会自欺欺人的骗子，就像现在一样。</p><p>人最终的欲望还是眼前的现实能够符合脑中的期望，这种保持一致的冲动所带来的折磨是一切故事之所以动人的唯一原因，即便故事只是一种想象中的现实。但脑中为何会有这样那样的期望？这又都来自于前人的故事。如果不是人们甘愿这种折磨，想来也不会有这样的期望。</p><p>单纯的折磨很难说有人会喜欢，但人们是对解脱之后的那种感觉更加上瘾。在折磨的过程中最令人不能忍受的并非是意识不到这一点，而是没有着手之处。没有现实给的反馈，也就无从知晓自己是不是期望得太高了，还是期望得刚刚好，这动摇了等式两边最基本的一个符号。但好消息是，这种期望从来就有，即便现在还不知道从何下手，但你已会开始为此准备，就像那些没有开始的开始，故事已经在悄无声息之处漫延。</p><p>有时候会想起来在10.01实验室调汇编的情景，没有什么经世致用的理想，但可以感觉到一种充盈的快乐。当时我也并不知道这除了在简历技能栏里加上一条之外还有什么其他的用途。现在想来，所谓天道往复，并非仅仅指天理昭彰，报应不爽，而应是天网恢恢，疏而不失，当前的事情都有伏笔，很多被遗忘的细节，在未来闪回之时，却是故事背后的故事。</p><p>这种巧合，任何一种严密的逻辑都无法解释，只能把它归结为一种不可言说的神秘。所有试图解释的努力都是在描述，而从不在解构上着力。但这些描述就已经足够动人，像是故事里面还有故事，逻辑背后还有逻辑，引人遐思又引人追寻。</p><p>讲这种故事讲得最好的自然是道家。20岁左右的时候有一段时间沉迷于老庄勾勒的幻境，以为世间之事，无过于此，天道杳远，也不过是章节中的几个起落。寒鸦凫水，羚羊挂角，在实务面前却又总是逡巡不前，别无良策。只能随手抽出某某经典，遁匿于世，以求暂时的安慰。</p><p>道家经典里，最喜欢的是《南华经》，《南华经》内篇里，最喜欢的是《大宗师》。开篇那句“知天之所为，知人之所为者，至矣”，是喜欢上老庄的第一个理由。至于内篇第一的《逍遥游》，其实并没有给我太多触动——鲲鹏很大，大到没有知觉，北海和南溟很深，深到不知所措。以前以为《逍遥游》讲的是一个关乎眼界和格局的故事，“小知不及大知，小年不及大年”。我也不知道为什么会看上了《逍遥游》中出镜率很少的一句话：</p><blockquote><p>天之苍苍，其正色耶，其远而无所至极耶</p></blockquote><p>很有可能和我那段时间一直在看唯识论有关。我没有想到的是，这两者在这句话里达到了“高度的统一”，这仿佛是我发现了一个藏匿起来的彩蛋——逍遥游并不是在讲什么是大，什么是小，而是在讲如何认知自己的认知。仅仅依靠感官产生的认知，是局限且不可信的。之所以会这样，是因为真实不是仅仅只有一面，而是有无穷无尽的可能。如果仅有一种真实，那么这必定不是真实。那是否所有所见所闻都是不真实的了吗？天空蓝是它本来的颜色吗？是因为它“远而无所至极”所以无法看到它本来的颜色吗？如果认知中的“远而无所至极”也仅仅是真实的一面，是否意味着我们还有机会穷尽它的边界？</p><p>我愿意试一下。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚37:Skylake Non-inclusive缓存和Snoop Filter的关系</title>
      <link href="/2019/12/23/quickwords37-skylake-cache-snoop-filter/"/>
      <url>/2019/12/23/quickwords37-skylake-cache-snoop-filter/</url>
      
        <content type="html"><![CDATA[<p>Skylake的缓存设计使用了Non-inclusive的架构设计，同时调大了L2缓存的大小。简单来说，区别就是以前从内存读入的数据会同时进入L3和L2缓存，而现在会只进入L2缓存，当该数据从L2缓存中清除的时候，才会进入L3缓存。</p><p>在以前的缓存架构中，L2缓存中的数据是L3缓存数据的真子集。而Skylake的架构中，L2和L3的数据在绝大部分时间中是独占的(exclusive)的，即二者所缓存的数据没有重叠。但注意，Skylake的架构是Non-inclusive，而不是严格的exclusive，是因为当同一条Cache Line在多个CPU核的L2缓存中都存在时，L3缓存中也有该Cache Line的数据。<br><a id="more"></a></p><p>还有一些别的区别，比如Skylake的Cache Line支持”Forward”状态，具备专用的snoop filter等。Snoop filter主要用来追踪记录在L2和L1中的Cache Line，Skylake之前的架构是用L3缓存充当的，因为L2和L1的数据都存在于L3缓存中。</p><p>Snoop filter还是一个特点是，如果一条Snoop filter中的记录需要被清除，那么就需要将该条记录对应的，存在于L2和L1 Cache中的数据invalid掉，该数据会进入L3缓存。这个叫做”Back invalidation”。这个东西有可能会成为导致一些应用在Skylake上性能下降的原因。</p><p>下面是一个读取过程：</p><ul><li><p>CPU核心A请求数据地址addr-&gt;L2 Cache Miss-&gt;从内存中加载addr数据进入L2-&gt;Snoop filter记录addr</p></li><li><p>当核心A的L2缓存清除addr对应的数据后，该数据进入L3缓存，同时在Snoop filter中也清除addr的记录</p></li><li><p>如果此时核心A又需要addr上的数据，则直接从L3读取，并在Snoop filter中添加记录</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> perf </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>怎样讲一个好故事</title>
      <link href="/2019/12/22/thoughts12-how-to-make-a-good-story/"/>
      <url>/2019/12/22/thoughts12-how-to-make-a-good-story/</url>
      
        <content type="html"><![CDATA[<p>   人的一切知识和学问都是从故事中获取的。讲故事不仅仅是人类传承知识和文化的手段，同时也是获得理解和支持的最有效的方式。并且，一个经过设计(Engineered)的故事具备以虚驭实的能力，这种一种让人着迷的力量。怎样讲出一个好的故事，就是这篇文章想要讲的故事。</p><p>所有故事都有一个开头，这个开头的作用不在于交代背景，也不在于用离奇的描述“抓住眼球”，而在于将读者代入到故事中去。一定要出现读者所熟悉的元素、符号、场景和经历，或者没有直接出现，但能够激发读者去联想，去自己的认知库中检索和关联的意象。<br><a id="more"></a></p><p>因为这里讲的代入并不是将读者代入到你的故事中，而是让读者把自己代入到自己的认知框架中。</p><p>但这并不是一个好的开头的全部，在读者完成了第一步的代入之后，需要进而给出超出这个一般认知框架的东西，这个东西有人叫“矛盾”，有人叫“悬念”，但实际上它只是每个人原有框架中一些“不正常”的颠倒，或者，更正式的说法，是一些“不符合预期”的事件。</p><p>而整个故事的任务，就是将这些“不符合预期”的事件变得符合读者的预期。人类有很多种深入骨髓的预期，或者说，对世界认知的底层逻辑。比如自由、尊严、求生、认同、公平……这些底层的预期将是你的故事之所以动人的唯一依靠。</p><p>在故事开头之后会是故事的主要情节。如果说开头的主要任务是“代入”，那么情节的作用就是调动情绪——无论多么鲜明的人物，多么精彩的修辞，多么曲折的线路，如果不能调动读者的情绪，那么就是失败的情节，失败的故事。</p><p>而对情绪的把握，一定要在情节的前面以“抑”为主，不如此故事无法得以继续。用负面事件更容易调动人们的情绪。毕竟所有那些人类公认的好事情，都是在没有这样的好事时才显得足够有吸引力，同样的，那些预期中的一切，都是因为没有发生才更要去预期。</p><p>对这部分情节最好避免直接描写，而要用侧面描写的方式，利用种种意象去渲染。这并不是因为直接描写更难处理，而是为了留给读者更多的“脑补”的空间，让读者自发地与情节相勾连，进而在故事中进一步浸染情绪。在这个方面，没有人能比读者自己更高明。</p><p>情节从“抑”转“扬”的关键，一定不能是从天而降的某某神邸解决了一切问题，而应该是故事的自然延续，在故事的前半段就应该可以找到伏笔。这部分一般是整个故事最出彩的地方，而作者如何去安排这些伏笔和逻辑关系，并且如何为结尾服务，将会是一般作者和故事大师的分野之处。</p><p>对于故事的结尾，如前所述，是将一切的“不合预期”都转变为了“符合预期”。所谓“符合预期”，就是满足了人类长久以来的基本心理需求。无论是催人奋进还是催人泪下，都是对整个故事的情绪节奏的收束，这需要一个坚实的落点，一个能承载全部盈满流溢出来的情绪的容器，一个读者自己心中已有意识但却从没有明确落实到语言的脚本。</p><p>写出任何一个精彩故事的前提，是故事的作者必须是一个精彩的人。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>快乐清单</title>
      <link href="/2019/12/05/thoughts11-happiness-list/"/>
      <url>/2019/12/05/thoughts11-happiness-list/</url>
      
        <content type="html"><![CDATA[<p>开始了一项早就打算开始的项目：把每天快乐的瞬间都记录下来。Google Drive中这个简单的Excel表格，被我命名为“快乐清单”。<br><a id="more"></a></p><p>已持续了差不多一周的时间，有的一天写了两件事，有的一天写了三件事，还有周日那天因为在家废弛了一天什么也没写。但这份表格是我写过的最让我流连的文档，每次打开它，仿佛像打开了一本存了私房钱的存折，而且存折上的数字，每天都在增长。</p><p>这几乎是我近期最成功的一个项目：没有什么投入，就是把最想记的事情记下来，然后每天都能重复产生复利。除此之外，还有一个有益的副产品，就是能把那些不想记住的坏事情挤占掉，用快乐的事情挤占掉，真是ROI爆表。</p><p>如果能对我记下的这些事情做个分类，就会发现里面并没有赚了多少钱这一项，当然也没有赔了多少钱，很多事情都是很小很小的一句话或者一个需要稍微冒些风险的决定。涉及在里面的，不仅是个人的主观意愿，更多的是人与人之间的互动和反馈。有些理论似乎过高地强调了“人际关系”的重要性，但实践下来之后，尤其是有了“数据支持”之后，人际关系对一个人的支撑作用，还是非常明显的。</p><p>刚才用储蓄和这个表格类比，其实不是十分贴切。因为储蓄的增长虽然也会令人愉快，但钱有一天可能会消失，而这里面储蓄的内容不会。2019年于我是一个很特别的年份，开始认识到自己真正的方向，同时也认识到身体对一个人的重要性，当然最重要的，是逐渐学会了重视以前那些不起眼的价值。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去22：DPDK i40e fdir+rss+reta实现相同flow type不同input_set散列</title>
      <link href="/2019/11/26/test22-fdir-rss-reta/"/>
      <url>/2019/11/26/test22-fdir-rss-reta/</url>
      
        <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>i40e网卡，同样的flow type，比如<code>RTE_ETH_FLOW_NONFRAG_IPV4_UDP</code>，需求是某一特定Dst Port的报文到rx队列1，某一特定Src IP + Dst IP的报文到rx队列2，或其他类似的针对相同flow type的需求。<br><a id="more"></a></p><h2 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h2><p>用fdir的话，针对某一种flow type只能配置一种固定的<code>input_set</code>，这两种报文各自需要不同的<code>input_set</code>，所以无法单独使用fdir实现。</p><p>但i40e网卡包匹配的过程是：先匹配fdir规则，如果能匹配则优先按fdir规则操作，如果不能匹配，则去匹配rss规则；如果能匹配则按rss规则操作，如果不能匹配则发送到默认rx队列0。</p><p>如果fdir针对某一种情况设定<code>input_set</code>，例如仅设定Dst Port，rss针对另一种情况设定<code>input_set</code>则可以实现对两种报文的匹配。此时还需要解决一个问题就是rss匹配的报文是对<code>input_set</code>字段中数值的哈希，不一定会哈希到某一个特定rx队列。</p><p>此问题可以利用重新配置rss redirection table的方式解决。需求中特定的Src IP + Dst IP的rss哈希值是一个固定的值，该值去查找redirection table中某固定的条目获得最终去往的rx队列，修改改条目至特定队列即可。</p><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>首先打开port的fdir和rss的功能：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_conf</span> <span class="title">port_conf</span> = &#123;</span></span><br><span class="line">    .rxmode = &#123;</span><br><span class="line">        .mq_mode = ETH_MQ_RX_RSS,</span><br><span class="line">        .max_rx_pkt_len = ETHER_MAX_LEN,</span><br><span class="line">        .split_hdr_size = <span class="number">0</span>,</span><br><span class="line">        .ignore_offload_bitfield = <span class="number">1</span>,</span><br><span class="line">        .offloads = (DEV_RX_OFFLOAD_CRC_STRIP |</span><br><span class="line">                 DEV_RX_OFFLOAD_CHECKSUM),</span><br><span class="line">    &#125;,</span><br><span class="line">    .rx_adv_conf = &#123;</span><br><span class="line">        .rss_conf = &#123;</span><br><span class="line">            .rss_key = <span class="literal">NULL</span>,</span><br><span class="line">            .rss_hf = ETH_RSS_UDP,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    .txmode = &#123;</span><br><span class="line">        .mq_mode = ETH_MQ_TX_NONE,</span><br><span class="line">    &#125;,</span><br><span class="line">    .fdir_conf = &#123; </span><br><span class="line">        .mode = RTE_FDIR_MODE_PERFECT,</span><br><span class="line">        .pballoc = RTE_FDIR_PBALLOC_64K,</span><br><span class="line">        .status = RTE_FDIR_REPORT_STATUS,</span><br><span class="line">        .drop_queue = <span class="number">127</span>,</span><br><span class="line">     &#125;,</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>然后配置一条fdir规则，可以针对第一种需求，Dst Port为4096的UDP报文进入rx队列1：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_fdir_filter</span> <span class="title">arg_udpport</span> = &#123;</span></span><br><span class="line">        .soft_id = <span class="number">1</span>,</span><br><span class="line">        .input   = &#123;</span><br><span class="line">            .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP,</span><br><span class="line">            .flow = &#123;</span><br><span class="line">               .udp4_flow = &#123;</span><br><span class="line">                   .dst_port = <span class="number">0x10</span>, <span class="comment">//4096=&gt;0x1000</span></span><br><span class="line">               &#125;,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        .action  = &#123;</span><br><span class="line">            .rx_queue  =  <span class="number">1</span>,</span><br><span class="line">            .behavior  = RTE_ETH_FDIR_ACCEPT,</span><br><span class="line">            .report_status = RTE_ETH_FDIR_REPORT_ID,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;;</span><br></pre></td></tr></table></figure><p>然后分别配置fdir和rss的<code>input_set</code>：</p><p>首先配置rss的<code>input_set</code>为Src IP + Dst IP：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_hash_filter_info</span> <span class="title">info</span>;</span> </span><br><span class="line"><span class="built_in">memset</span>(&amp;info, <span class="number">0</span>, <span class="keyword">sizeof</span>(info));</span><br><span class="line">info.info_type = RTE_ETH_HASH_FILTER_INPUT_SET_SELECT;</span><br><span class="line">info.info.input_set_conf.flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP;</span><br><span class="line">info.info.input_set_conf.field[<span class="number">0</span>] = RTE_ETH_INPUT_SET_L3_DST_IP4;</span><br><span class="line">info.info.input_set_conf.field[<span class="number">1</span>] = RTE_ETH_INPUT_SET_L3_SRC_IP4;</span><br><span class="line">info.info.input_set_conf.inset_size = <span class="number">2</span>;</span><br><span class="line">info.info.input_set_conf.op = RTE_ETH_INPUT_SET_SELECT;</span><br></pre></td></tr></table></figure><p>然后配置fdir的<code>input_set</code>为Dst Port：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_fdir_filter_info</span> <span class="title">fdir_filter_info</span>;</span></span><br><span class="line"><span class="built_in">memset</span>(&amp;fdir_filter_info, <span class="number">0</span>, <span class="keyword">sizeof</span>(fdir_filter_info));</span><br><span class="line">fdir_filter_info.info_type = RTE_ETH_FDIR_FILTER_INPUT_SET_SELECT;</span><br><span class="line">fdir_filter_info.info.input_set_conf.flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP;</span><br><span class="line">fdir_filter_info.info.input_set_conf.field[<span class="number">0</span>] = RTE_ETH_INPUT_SET_L4_UDP_DST_PORT;</span><br><span class="line">fdir_filter_info.info.input_set_conf.inset_size = <span class="number">1</span>;</span><br><span class="line">fdir_filter_info.info.input_set_conf.op = RTE_ETH_INPUT_SET_SELECT;</span><br></pre></td></tr></table></figure><p>然后令rss+fdir配置生效，同时添加一条fdir规则：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ret = rte_eth_dev_filter_ctrl(<span class="number">0</span>, RTE_ETH_FILTER_HASH,RTE_ETH_FILTER_SET,&amp;info);</span><br><span class="line"></span><br><span class="line">ret = rte_eth_dev_filter_ctrl(<span class="number">0</span>, RTE_ETH_FILTER_FDIR, RTE_ETH_FILTER_SET, &amp;fdir_filter_info);</span><br><span class="line"></span><br><span class="line">ret = rte_eth_dev_filter_ctrl(<span class="number">0</span>, RTE_ETH_FILTER_FDIR, RTE_ETH_FILTER_ADD, &amp;arg_udpport);</span><br></pre></td></tr></table></figure><p>然后需要配置redirection table，需要拿到特定报文的rss hash的值。在<code>mbuf</code>结构体中有一个记录rss hash的字段，可以用<code>gdb</code>看。</p><p>启动DPDK应用，发送一个符合需求的UDP报文，随便你在哪里设置一个断点，能看到这个<code>mbuf</code>即可，在我的例子中打印出来的<code>mbuf</code>是这样的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(gdb) p *$2</span><br><span class="line"><span class="meta">$</span>3 = &#123;cacheline0 = 0x7f9c7ed64d40, buf_addr = 0x7f9c7ed64dc0, &#123;buf_iova = 68699966912, buf_physaddr = 68699966912&#125;, rearm_data = 0x7f9c7ed64d50, data_off = 128, &#123;</span><br><span class="line">    refcnt_atomic = &#123;cnt = 1&#125;, refcnt = 1&#125;, nb_segs = 1, port = 0, ol_flags = 386, rx_descriptor_fields1 = 0x7f9c7ed64d60, &#123;packet_type = 657, &#123;l2_type = 1, l3_type = 9, </span><br><span class="line">      l4_type = 2, tun_type = 0, &#123;inner_esp_next_proto = 0 '\000', &#123;inner_l2_type = 0 '\000', inner_l3_type = 0 '\000'&#125;&#125;, inner_l4_type = 0&#125;&#125;, pkt_len = 60, </span><br><span class="line">  data_len = 60, vlan_tci = 0, hash = &#123;rss = 2719877416, fdir = &#123;&#123;&#123;hash = 2344, id = 41502&#125;, lo = 2719877416&#125;, hi = 0&#125;, sched = &#123;lo = 2719877416, hi = 0&#125;, </span><br><span class="line">    usr = 2719877416&#125;, vlan_tci_outer = 0, buf_len = 2176, timestamp = 0, cacheline1 = 0x7f9c7ed64d80, &#123;userdata = 0x0, udata64 = 0&#125;, pool = 0x7f9c7fc36cc0, next = 0x0, &#123;</span><br><span class="line">    tx_offload = 0, &#123;l2_len = 0, l3_len = 0, l4_len = 0, tso_segsz = 0, outer_l3_len = 0, outer_l2_len = 0&#125;&#125;, priv_size = 0, timesync = 0, seqn = 0, shinfo = 0x0&#125;</span><br></pre></td></tr></table></figure><p>这里面显示了该报文rss hash值是2719877416；</p><p>拿到这个数字之后，需要进一步打开祖传的X710网卡的datasheet，查看一下7.1.8节的中关于Queue Index LUT的介绍。这个玩意就是redirection table，统一命名还是非常重要的:)</p><p>里面写的是：</p><blockquote><p>The LUT in each PF gets the 9 LS bits of the hash output having either 128 or 512 entries</p></blockquote><p>OK，这个rss hash值9 LS bits是：100101000，十进制是296。</p><p>有了这个值需要先准备一下配置redirection table所需的<code>struct rte_eth_rss_reta_entry64</code>结构体：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_rss_reta_entry64</span> &#123;</span></span><br><span class="line">     <span class="keyword">uint64_t</span> mask;</span><br><span class="line">     <span class="comment">/**&lt; Mask bits indicate which entries need to be updated/queried. */</span></span><br><span class="line">     <span class="keyword">uint16_t</span> reta[RTE_RETA_GROUP_SIZE];</span><br><span class="line">     <span class="comment">/**&lt; Group of 64 redirection table entries. */</span></span><br><span class="line"> &#125;;</span><br></pre></td></tr></table></figure><p>注释也写得比较清楚，就是mask代表需要修改哪个entry，也就是和296对应的那个entry，reta就是需要进入哪个队列。因为mask是一个64bit的值，欲表达512个entry，需要一个该结构体的数组：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_rss_reta_entry64</span> <span class="title">reta_conf</span>[8];</span></span><br></pre></td></tr></table></figure><p>8个是因为64x8=512；</p><p>求出具体要改那个index和偏移要这么计算：</p><blockquote><p>296 / 64 = 4<br>296 % 64 = 40</p></blockquote><p>于是代码中可以写为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">memset</span>(reta_conf, <span class="number">0</span>, <span class="keyword">sizeof</span>(reta_conf));</span><br><span class="line">reta_conf[<span class="number">4</span>].mask |= (<span class="number">1U</span>LL &lt;&lt; <span class="number">40</span>);</span><br><span class="line">reta_conf[<span class="number">4</span>].reta[<span class="number">40</span>] = <span class="number">2</span>;</span><br><span class="line">   </span><br><span class="line">    ret = rte_eth_dev_rss_reta_update(<span class="number">0</span>,</span><br><span class="line">            reta_conf, <span class="number">512</span>);</span><br></pre></td></tr></table></figure><p>此时可以实现第一节中提到的需求。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>怎样做好市场工作</title>
      <link href="/2019/11/17/thoughts10-how-to-do-marketing/"/>
      <url>/2019/11/17/thoughts10-how-to-do-marketing/</url>
      
        <content type="html"><![CDATA[<p>市场工作是提高产品价值所要进行的最重要的工作。市场工作并不是围绕产品的工作，也不是围绕客户的工作，而是围绕<strong>符号</strong>的工作——构建关于一个特定符号的意象。这个符号代表你想要卖出去的东西，而意象的作用在于，它不会改变人们对你产品的认知，而是让人们改变对<strong>自我</strong>的认知，即便那只是一种想象。<br><a id="more"></a></p><p>符号仅仅是一种可以被人类感官所接收的信号刺激。人们对某种符号产生喜爱或厌恶的情绪，并不在于该符号所代表的事物本身，而在于人们是否接受符号所代表的意象。意象是一种主观故意的预期——“当我与这个符号产生联系时我将会怎样”——这种预期并不是逻辑的产物，而是不加推敲的无条件接受。这就是市场工作之所以能产生作用的根本依据。</p><p>人们永远需要不断加强对自我认知的掌控感，这是一切人类心理活动和外发行为的根源。所谓掌控感，就是能让他们感觉自己的行为符合自我认知的预期。“我是一个高效、细心、机敏、勇敢、悲悯、负责、可靠、少言多做、嫉恶如仇、反抗权威、独辟蹊径……的人”。当有一个能满足他们预期的意象出现时，他们就会在行为上追随这个意象。这种行为可以是对符合预期的意象的追捧，亦或是对不符合预期的意象的贬损，这两者其实是同一样东西。</p><p>构筑起关于符号的意象需要用一种最原始但也是最有效的方法——讲故事。你不必一定要从“很久很久以前”开始，但永远不要直接谈论你的产品特性或者参数，而是谈论谁在使用它，谈论他们在哪些场景下和你的产品产生联系，谈论他们的故事，进而引出这些人具有哪些特质。所要传达出来的信息无非是：所有具有这些特质的人都在使用我们的产品，如果你也使用我们的产品，那么你也将具有相同的特质，你将成为和故事中的那些人一样的人，这就是市场工作需要完成的具体内容。如果这种意象正好命中了人们对自我的预期，人们会自动开动所有想象将这种意象附会于这个符号之上，因为人们太需要这种掌控感了。</p><p>而如何通过故事表现出人物的特质，如何讲好一个故事，如何讲一个好故事，是需要不断琢磨和练习的。这一部分内容将会单独写一篇文章介绍。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>QuickWords 35： Perf probe usage</title>
      <link href="/2019/11/07/quickwords35-perf-probe-usage/"/>
      <url>/2019/11/07/quickwords35-perf-probe-usage/</url>
      
        <content type="html"><![CDATA[<p>查看用户空间binary/.so文件可用函数</p><p><code>perf probe -F -x /usr/lib64/libopenvswitch-2.so.7.0.0</code></p><p>查看可以被probe的源码行<br><a id="more"></a></p><p><code>perf probe -x /usr/lib64/libopenvswitch-2.so.7.0.0 -L conntrack_execute</code></p><p>查看源码行处可被probe的本地变量</p><p><code>perf probe -x /usr/lib64/libopenvswitch-2.so.7.0.0 -V conntrack_execute:xx</code></p><p>添加probe event:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">perf probe -x /usr/lib64/libopenvswitch-2.so.7.0.0 conntrack_execute</span><br><span class="line"></span><br><span class="line">Added new event:</span><br><span class="line">  probe_libopenvswitch:conntrack_execute (on conntrack_execute in /usr/lib64/libopenvswitch-2.so.7.0.0)</span><br><span class="line">You can now use it in all perf tools, such as:</span><br><span class="line">    perf record -e probe_libopenvswitch:conntrack_execute -aR sleep 1</span><br></pre></td></tr></table></figure><p>若添加本地变量trace：</p><p><code>perf probe -x /usr/lib64/libopenvswitch-2.so.7.0.0 &#39;conntrack_execute dl_type&#39;</code></p><p>查看现有probe event:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">perf probe --list</span><br><span class="line"></span><br><span class="line">probe_libopenvswitch:conntrack_execute (on conntrack_execute@lib/conntrack.c in /usr/lib64/libopenvswitch-2.so.7.0.0)</span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">perf list | grep probe</span><br><span class="line">probe_libopenvswitch:conntrack_execute             [Tracepoint event]</span><br></pre></td></tr></table></figure><p>记录perf record</p><p><code>perf record -e probe_libopenvswitch:conntrack_execute -aR -g sleep 10</code></p><p>查看记录</p><p><code>perf script</code></p><p>记录函数第一个参数</p><p><code>perf probe -x /usr/lib64/libopenvswitch-2.so.7.0.0 -a &#39;another=conntrack_execute %ax&#39;</code></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> perf </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Loadbalancer Product Trends</title>
      <link href="/2019/10/31/product2-loadbalancer-trends/"/>
      <url>/2019/10/31/product2-loadbalancer-trends/</url>
      
        <content type="html"><![CDATA[<p>So what is going on? There are mainly 4 kinds of work.<br><a id="more"></a></p><h2 id="100G"><a href="#100G" class="headerlink" title="100G"></a>100G</h2><p>Customers are trying to migrate to 100G NIC on their hardware platform.</p><h2 id="CloudNative"><a href="#CloudNative" class="headerlink" title="CloudNative"></a>CloudNative</h2><p>Customers are trying to adopt their load balancer projects to cloud native scenario, trying to deploy load balancer in a purely containerized environment and orchestrated by K8S. That is a trend should be noticed.</p><h2 id="IPv6"><a href="#IPv6" class="headerlink" title="IPv6"></a>IPv6</h2><p>Customers are adding IPv6 support to their product. Politically this progress is pushed by the government. China is trying to build its next generation internet infrastructure and IPv6 is a big part of it. So we received a lot of requests regarding how to enable RSS or FDIR to support IPv6 traffic.</p><h2 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h2><p>Customers are trying to integrate more feature to load balancer and most of them are hardware based solution for encryption and HTTPS offloading.</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> product </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去21：在ftrace中拿到event的user-space stack trace</title>
      <link href="/2019/10/30/test21-uprobe-userstacktrace/"/>
      <url>/2019/10/30/test21-uprobe-userstacktrace/</url>
      
        <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>在开启了ftrace中的一些事件之后，可以用function_graph的trace拿到在<strong><em>内核态</em></strong>的callstack。但有些时候我们希望能拿到用户态程序的callstack，这样我们就能知道是那些方法触发了某一事件，或者我们直接希望uprobe的事件发生时，能够看到该事件对应的callstack，也会是一个很有价值的信息。</p><h2 id="阅读文档"><a href="#阅读文档" class="headerlink" title="阅读文档"></a>阅读文档</h2><p>本来的计划是，搞一个什么ftrace callback的内核模块，模块里面调用一些<code>save_stack_trace_user()</code>这类的方法，但是感觉虽然理论上行得通，但是实际上系统里敢让你塞一个内核模块进去的企业太少，所以暂时先放弃这个方案。<br><a id="more"></a></p><p>然后自然是网上搜索了一下，结果就在ftrace的官方文档里发现了这个：</p><blockquote><p><strong><em>userstacktrace</em></strong><br>This option changes the trace. It records a stacktrace of the current user space thread after each trace event.</p></blockquote><p>并且只需要<code>echo userstacktrace &gt; trace_options</code>一下就好了，写一个简单的用户态程序测试一下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdint.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">inner_func_2(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is inner func 2\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">inner_func(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is inner func\n"</span>);</span><br><span class="line">    inner_func_2();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">print_curr_state_one(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is the print current state one function\n"</span>);</span><br><span class="line">    inner_func();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">print_curr_state_two(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is the print current state two function\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        print_curr_state_one();</span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">        print_curr_state_two();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>加个uprobe，看看效果：</p><p><code>echo &#39;p:inner2 /root/test/uprobe/uprobe:0x55d&#39; &gt;&gt; /sys/kernel/debug/tracing/uprobe_events</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@server-P1 tracing]# cat trace | tail</span><br><span class="line"> =&gt;  &lt;00000000004005b0&gt;</span><br><span class="line"> =&gt;  &lt;00007f30b84dd445&gt;</span><br><span class="line">           &lt;...&gt;-173862 [021] d... 4769407.922362: inner2: (0x40055d)</span><br><span class="line">           &lt;...&gt;-173862 [021] d... 4769407.922367: &lt;stack trace&gt;</span><br><span class="line"> =&gt; retint_signal</span><br><span class="line">           &lt;...&gt;-173862 [021] d... 4769407.922367: &lt;user stack trace&gt;</span><br><span class="line"> =&gt;  &lt;000000000040055d&gt;</span><br><span class="line"> =&gt;  &lt;0000000000400595&gt;</span><br><span class="line"> =&gt;  &lt;00000000004005b0&gt;</span><br><span class="line"> =&gt;  &lt;00007f30b84dd445&gt;</span><br></pre></td></tr></table></figure><p>摔，只能看到hex地址嘛。</p><p>继续搜一下，在这篇狗哥的<a href="https://github.com/brendangregg/perf-tools/blob/master/examples/uprobe_example.txt#L264" target="_blank" rel="noopener">文章</a>里有提到：</p><blockquote><p>The output has the raw hex addresses. If this is too much of a nuisance, then try tracing this using perf_events which should automate the translation.</p></blockquote><p>然而他并没有说怎么用<code>perf_event</code>。</p><p>自己用<code>perf probe</code>的形式定义了这个uprobe：</p><p><code>perf probe -x ./uprobe &#39;inner_func_2&#39;</code></p><p>Record一下：</p><p><code>perf record -e probe_uprobe:inner_func_2 -aR -g sleep 10</code></p><p>最后看一下结果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@server-P1 uprobe]# perf script</span><br><span class="line">uprobe 178595 [021] 4771386.748810: probe_uprobe:inner_func_2: (40055d)</span><br><span class="line">                     55d inner_func_2 (/root/test/uprobe/uprobe)</span><br><span class="line">                     595 print_curr_state_one (/root/test/uprobe/uprobe)</span><br><span class="line">                     5b0 main (/root/test/uprobe/uprobe)</span><br><span class="line">                   22445 __libc_start_main (/usr/lib64/libc-2.17.so)</span><br><span class="line"></span><br><span class="line">uprobe 178595 [021] 4771387.748964: probe_uprobe:inner_func_2: (40055d)</span><br><span class="line">                     55d inner_func_2 (/root/test/uprobe/uprobe)</span><br><span class="line">                     595 print_curr_state_one (/root/test/uprobe/uprobe)</span><br><span class="line">                     5b0 main (/root/test/uprobe/uprobe)</span><br><span class="line">                   22445 __libc_start_main (/usr/lib64/libc-2.17.so)</span><br><span class="line"></span><br><span class="line">uprobe 178595 [021] 4771388.749118: probe_uprobe:inner_func_2: (40055d)</span><br><span class="line">                     55d inner_func_2 (/root/test/uprobe/uprobe)</span><br><span class="line">                     595 print_curr_state_one (/root/test/uprobe/uprobe)</span><br><span class="line">                     5b0 main (/root/test/uprobe/uprobe)</span><br><span class="line">                   22445 __libc_start_main (/usr/lib64/libc-2.17.so)</span><br></pre></td></tr></table></figure><p>但是我后来又去关闭了<code>userstacktrace</code>选项，结果还是能用，呃。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>QuickWords 34： DPDK i40e 82599网卡发送Tx丢包问题</title>
      <link href="/2019/10/17/quickwords34-dpdk-tx-hang/"/>
      <url>/2019/10/17/quickwords34-dpdk-tx-hang/</url>
      
        <content type="html"><![CDATA[<h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>表现为在DPDK场景下网卡丢包或者发送队列Hang住。如果用GDB跟进去的话会发现是网卡的DD标志位未置位。<br><a id="more"></a></p><h2 id="根因"><a href="#根因" class="headerlink" title="根因"></a>根因</h2><p>因为DPDK ixgbe或者i40e驱动可以直接操作网卡的寄存器和Buffer，当上层业务存在问题，发送一些“不合规”的数据包时，这些有问题的数据包会直接进入网卡，引发硬件问题。</p><p>而在内核态时，这些有问题的数据包会被内核驱动过滤掉。</p><h2 id="具体原因"><a href="#具体原因" class="headerlink" title="具体原因"></a>具体原因</h2><p>引发发送丢包或发送队列Hang住的数据包包括以下几类：</p><ul><li>包长小于17Byte</li><li>包长大于9674Byte</li><li>TCP报文分段数目大于8</li><li>TSO MSS小于256Byte</li><li>TSO MSS大于9674Byte</li><li>Mbuf链里mbuf个数和第一个mbuf的nb_segs值不一样</li><li>Mbuf链里任意一个mbuf的data_len=0</li><li>Mbuf链长度大于8</li><li>其他目前还位置的原因</li></ul><h2 id="Workaround"><a href="#Workaround" class="headerlink" title="Workaround"></a>Workaround</h2><p>在调用rte_eth_tx*()方法之前，调用ixgbe或i40e驱动提供的[ixgbe | i40e]_prep_pkts()方法，可排除大部分导致该问题的报文。目前已在几个客户生产环境下解决了问题。</p><p>同时不必过度担心此类检查会影响性能，经过实际测试影响很小。</p><p>根源上，还是需要业务层面找到产生“异常”报文的代码。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> NIC </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>金罍深深酌</title>
      <link href="/2019/10/12/leuven-mem/"/>
      <url>/2019/10/12/leuven-mem/</url>
      
        <content type="html"><![CDATA[<h1 id="一"><a href="#一" class="headerlink" title="一"></a>一</h1><p>2012年3月，我在布鲁塞尔南站7号站台见到了高中同学L。<br><a id="more"></a><br>他刚刚结束巴黎之行，而我则一路掐算着时间从鲁汶赶去接他。在成功闪避了车站里汹涌的原教旨小偷之后，我随着缓缓上升的扶梯，看到他从头到脚“渐次绽放”。<br>直到现在，我还记得当时L的样子：许久未见，他看起来还是那个等着下课去网吧的高个子男生，双手插兜，若有所思，背对着月台，站在阳光和阴影的分界。</p><h1 id="二"><a href="#二" class="headerlink" title="二"></a>二</h1><p>在很长的一段时间里，我并不是现在这个样子。十三年前，我刚上高中，每天最大的幸福就是在一间脏兮兮的网吧里打CS，或者一边上课一边和同班的基友们讨论战术安排。每天上课携带的文件夹，只有前几页是装模作样的模拟卷，后面全是每个人提交的赛后总结，按地图、战术、枪械分门别类，罗缕纪存。然后学着好学生的样子在页眉贴上五颜六色的娘炮书签，写上数学、英语和理综。在保定市生活了十八年，最后说起某个地方在哪，哪条街哪栋楼不如换作”在某某网吧旁边”。全市的网吧我都去过，某些网吧里甚至会有我专用的机位。我当时以为，世界就是从农大西校区到北边植物园之间的这片地方，这世界之上的商阜酒肆，只是空许众生的雾霭流岚；广厦高楼，全是渺渺茫茫的白云出岫；学校和各种教育机构，更是异教徒用幻术变造的如电亦如露；只有向未成年人敞开大门的网吧，才是跳脱去真实正理的接引殿，甚深微妙的不二法。我就在这纤毫微尘里，以邻座点燃的烟火为灵媒，以每一次键盘的敲击为供奉，以控制台的命令和脚本为经文，以催我续费的网管为图腾，渡过了青春期最战战兢兢如履薄冰的那段时期。一直到上大学之后，才离开这个北方的小城。十八岁那年，没有太多游历的经历，更谈不上有什么见识，有的只是对远方的向往和踏实的自信——只要有网吧的地方，就可以是我的家。</p><h1 id="三"><a href="#三" class="headerlink" title="三"></a>三</h1><p>十三年前，是甲申猴年。那年我和L刚刚在伟大的高一四班成为同学，就利用职务之便，在教室的电脑上打起了《合金弹头》。中午没老师的时候，拉下投影，关闭窗帘，调低音量，讲台上的“多媒体教学系统”就变成了一个功能齐全的游戏演示系统，台下还有一批看直播却不刷火箭的同学当观众。随后的结果自然是被午间巡视老师听到喧哗抓个现行，再然后就是例行的低头认错和语重心长。但那一次，我在打开电脑之前就非常强烈地预感到要写检查。在巡视老师办公室的时候我一再请缨，必须要让我写检查，要写大检查，要写从来没有人写过的检查，要写“华枝春满，天心月圆”的检查。当时的我已有无数文辞要崩出胸臆，在十五岁“沛莫能御”的肾上腺素的作用下，我只有不断踮起脚尖才能让自己不至于跳起来。唯一感到意外的是，我在跃跃之余隐约觉得，L竟然也是同样的心意。不约而同的，我们每个人都在下午第一节下课前各自用300字的稿纸写了将近二十页。那个下午，文如泉涌，意象叠生，风云际会，俊彩星驰，不再感到流逝的时间，眼前只有锦绣铺延，只有风行水上的变幻。直写得夏淑云强装镇定，巡视组悔不当初，两个人如渴得饮，酣畅淋漓。其时已是深秋，下午的阳光里已有了“猎马带禽归”的味道，交完检查，我们像有了一次配合。嘴上不说，心里却痒痒得要踮起脚尖的配合。</p><p>那之后不久，一身书生气的语文老师就让我们采集校园里的银杏落叶做成标本，并在上面写上诗句当作作业提交。我想起那天的情景，就写了“相顾无相识，长歌怀采薇”在上面。但那次最受同学们欢迎的，是一片“执子之手，与子偕老”。</p><p>高中毕业之后，L和我一同考去了西南地区的大学，各自被火锅、串串、冒菜，钵钵鸡，512地震等等洗礼了一番之后，又先后来到了极端主义泛滥的西欧。就像他会从巴黎来找我一样，住在布鲁塞尔的温和社区骨干，也会跑去巴黎屠杀。而上高中的时候又怎么会想到，我们会在人杰地“林”的布鲁塞尔重逢呢。我甚至那时根本不知道这个城市在什么位置，对“布鲁塞尔”唯一的了知，是家里马桶旁堆积的读者杂志，某期里面有一篇《布鲁塞尔松饼的天空》。因为没有人会定期更换厕所里的杂志，但每天早上又都要去拉屎，所以所有文章都被翻来覆去看了几十遍。我当时还想，像“布鲁塞尔”这种地方，自己这辈子有没有机会去一次呢？但直到我已经离开比利时回到北京的时候，才恍然大悟，原来松饼就是常说的scone，原来这篇文章，早就为将来写好了脚本。</p><p>“松饼永远应该热着吃，爱也一样。”</p><h1 id="四"><a href="#四" class="headerlink" title="四"></a>四</h1><p>我把L接回了我在鲁汶的家。鲁汶并没有网吧（如果计算机学院的机房不算的话），但我还是将这里称之为家，因为我已经很久不去网吧，也很久没有回家了。我拿出准备已久的啤酒，火锅底料和一整個冰箱的储备。 因为将这里当家的缘故，我的生活用品一应俱全。有切肉的主厨刀，有斩骨刀，有剔骨刀，有锯骨刀，有切菜的三德刀，有处理水产的海鲜刀，还有剥洋葱的木柄小刀；有各种啤酒，还有每种啤酒专用的酒杯；有装香油的碟子，有装麻酱的碟子，有装蚝油的碟子，还有盛糖蒜和韭菜花的碟子。我其实很少自己做饭，也没有在这里招待过多少客人，但我搜集每一样用得到或者用不到的生活用品。我必须在我想招待别人的时候有万全的准备，可以带着一些骄傲地说，“欢迎来到我的家，这里有你所需要的一切”。即便这一切可能只是不禁推敲的自娱自乐，但赌上四川人的尊严，这一次，一定是鲁汶有史以来最奢华的双人火锅。如果只读过两年书也能算作是四川人的话。</p><p>我和L都很高兴，显然他比我更高兴。在孤独的西欧，日子和食物一样平淡无味，留学生只能依靠他人感知自己，并依靠火锅纪年。香辣的味道渐渐弥散在了整个楼层，牛肉、鸡翅、虾仁，在超市里第一次关注了物品的价签，只挑最贵的。酒精慢慢发挥了作用，两个都不敢号称能喝的人，却一上来就不留余地。两瓶杜威下肚，就搞出了bps，我们新发明的吞吐速率单位，bottles per second。在吞吐之余，我们当然会说起四班，说起成都和重庆的美女，说起那些共同的同学和朋友。摇晃着酒杯里的泡沫，仿佛能从水晶球的迷雾中看到过去。在这扇布满了水汽的玻璃窗后面，并没有任何“他乡遇故知”的欣喜若狂，因为一旦说起熟悉的事情，因为一旦说起共同的熟悉的事情，因为但使主人能醉客，不知何处是他乡。</p><p>“他乡”是一个时变概念，昨天这里还是所谓的“第三故乡”，今天就变成了归期未期的他乡。来鲁汶的几年里，慢慢熟稔了这里的一切，也熟稔了周围同学的脾气秉性。哪些是温和宽厚的朋友，哪些是班里的Bitch，哪些需要以远为近，哪些需要以曲为直，慢慢已经是自然而然的事情。有时会想，所谓的熟稔，终究是一种不断屏蔽细节的过程。不如此，我们就只能迷失于无法穷尽的细枝末节之中。因此，大脑必须要学会两件事：以偏概全和歪曲事实。一年的时间可以压缩成一天，而一天又可以在反复加工的过程中铺陈成一年。大脑似乎是可以操纵时间的四维造物，这也就是为什么，我们总会觉得往事历历，却又总会讶异于这些年的转瞬即逝。“实时性”在大脑看来并不重要，重要的是，记忆里留下的样本越来越少，印象里时间也就越过越快，直至采样的信号发生aliasing——事件在时间轴上被拉伸——直至脑海里的映像都铺展成了漫漶无涘的时光丘野。</p><p>我曾经试图将上面的话讲给教FPGA的Bienstman，他问我，为什么不用锁相环拉升时钟频率。我说哦，你说的好有道理。</p><h1 id="五"><a href="#五" class="headerlink" title="五"></a>五</h1><p>很多时候难以确认，人生究竟是不是一场谵妄。</p><p>感受到的世界，会被局限于自身的感官之中，而感官却只产生概念。看到红的花绿的草（&amp;），只是感官输入的已经存储好的符号（#include）。人真正精巧的地方，是外染熏习之后，对这套符号系统的运用(*p)。但真正的世界，却在符号之外的地方。这套精巧的体系，可以仅凭一个符号就能使心为形役（malloc）；而人也完全可以仅靠操作这些符号（pointer cast），就能够满足对实证的虚妄颠倒。唯物论依然成立，只是永远无法触及。</p><p>我曾经是一个坚定的唯物主义者，没入党都可惜。但后来发现以前的自己真是个快乐的小二逼。物起万端，人言妄作，俗学蔽心，每个人拿在手里的，只是用一些符号构筑的唯我世界。而作为建筑材料的符号，还多来自于外界的熏染。从成都时代起，就在研究所谓的“内求诸己”，自以为有了精当的理解，快能配得上“辩才无碍”这四字了，却不过只是刚刚开始。成都是肇始，在鲁汶积攒素材，终于回到北京加工提炼。多年以后，L从青海寄给过我一张明信片，他说我们从保定到西南，从西南到西欧，又到北京，在地图上画了一个大三角。我不知道这玩得是他妈什么战术，不过让我又一次想起那次配合，以及，甲申年的猎马与黄叶。</p><p>火锅慢慢干涸，用漏勺打捞粘稠的记忆。那些明明放在跟前满怀期待的，已经不知去向；能打捞上来的，都只是掺杂不清的残破不堪，在浓汤的熬煮下，全部已经褪为浅淡的影翳。“人们往往被对事物的看法迷惑，而不是事物本身”，在微信还没有流行的年代，这是我第一份工作中一位同事的QQ签名。虽然我们更多的是去海淀黄庄买电子元件，但这句话还是让我没事就把玩他的QQ资料。我和这位同事也一起吃过火锅，却从来没有问过他这句话的出处，以及他写上这句话时的心情。就像所有火锅一样，不能再打捞出来的，才真正变成了它的一部分。火锅慢慢冷却，对一锅残羹不再期待，甚至有了一丝丝厌恶。表相再美，也只是感官的快感。我和L一杯接一杯地喝酒，也许只有用酒精麻痹了五感，才能找到本心罢。现在想来，那个时间点其实是个很好的时间。不是因为已经发生了什么，而是因为很多地方还没有去，很多事物还没有见过，很多人还没有遇到，很多故事，也还没有结束。</p><h1 id="六"><a href="#六" class="headerlink" title="六"></a>六</h1><p>第二天早上我带着宿醉陪L回到鲁汶车站，送他登上返回法国的列车。自从来到欧洲之后，我就一直期望着能有高中同学来，而当时的我并不知道，这是最后一次在鲁汶见到高中同学了。我和L并没有作任何形式上的告别，握了握手便各自回头。我很难忘怀的一件事是，在布鲁塞尔南站欧洲之星专用候车室门口，我曾在这里见到一位白人大妈突然就哭得凭肤色看不出是来自弗拉芒还是青藏高原。也许人年长之后，确实可以凭经验预见很多事情，但更多的经验是，明白了很多事情不可预见，比如不知道哪次见面，就是最后一次。</p><p>同年9月我抛下所有能抛在比利时的东西，带着最简单的行李返回北京。我那些一件一件积攒的家什，也全部都送给了留在当地的同学。返程那天正好是中秋，红眼航班，一下飞机就可以看到机场上方的一轮圆月，但凄迷得如同路边困倦的路灯。</p><p>在北京租了一个小房子，租金只有在鲁汶的一半。也不再添置各种各样的生活用品，一有时间就回保定。那时已经有了高铁，以300公里的时速独来独往，似乎可以甩掉所有的妄想，哪怕只有40分钟，也足以让人上瘾。L不久之后也回到北京工作，我们陆陆续续又有了屈指可数的几次碰面。毕业之后的生活一下就和学生时代没有了关系，不是在参加婚礼，就是在谈论工作。好在偶尔也搞一搞喝酒撸串的活动，只是这种局里面，没有主人，也没有客人，更没有他乡。</p><p>毕业很久之后，又去过一次布鲁塞尔。时隔四年，已经快忘了怎么看月台上的列车时刻表。那天很早，早到小偷还没有上班，站台上只有我和几个凌乱的MSL（密苏里）青年。我们眼神交流了几下，心下里就了然了对方同在异乡为异客的心态。抬头看到了城际列车的车头灯，与国内的高铁相比，慢得无法将你带回记忆里。很快天空下起了小雨，火车车窗外的鲁汶已锁在重重迷雾之中。</p><p>2012年末的那个冬天，有着难以抵挡的北京的严寒。我一边裹紧衣领，一边在北五环开荒。好在一直靠《道德经》维持信念，才没有在那个冬天加入圣战。冬天过后果然就是春天，之后的生活一如流水。换了份工作，不再是一个人，也在北京安了家。这个地方，北有朝阳公园和蓝色港湾，西有三里屯和侨福芳草地，东有朝阳大悦城，南有国贸三期和星光天地。旁边两块地也正在跃跃欲试，传说是建医院或学校。但我又何必关心这些，和我又有什么关系？我只关心小区门口原本已经倒闭的网吧在“装修”了半年之后重新开业，我的欣喜就像，左一口火锅，右一口松饼。我宁愿绕远一点的路回家，也想到它门口去看看。这让我觉得，“有网吧的地方就是家”并不是年少时的一句戏言，它和与它相关的一切都真真切切的存在过。很多事情早已随风飘散，心中却越来越有了一种强烈的冲动，也许所有关于主观唯心的迷思都会被证伪，但所有的冲动，真的只是一种乡愁。</p>]]></content>
      
      
      <categories>
          
          <category> life </category>
          
      </categories>
      
      
        <tags>
            
            <tag> life </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Shell命令行中感叹号!的运用</title>
      <link href="/2019/09/25/exclamation-mark-shell/"/>
      <url>/2019/09/25/exclamation-mark-shell/</url>
      
        <content type="html"><![CDATA[<h2 id="重复执行上一条命令"><a href="#重复执行上一条命令" class="headerlink" title="!!重复执行上一条命令"></a>!!重复执行上一条命令</h2><p>直接输入<code>!!</code>，不过我更喜欢按上方向键…<br><a id="more"></a></p><h2 id="数字执行history对应命令"><a href="#数字执行history对应命令" class="headerlink" title="!+数字执行history对应命令"></a>!+数字执行history对应命令</h2><p>!后面跟对应编号可以执行对应history记录中编号的命令</p><p>但是好像Ctrl+r更方便一些…</p><h2 id="导入对应命令的参数"><a href="#导入对应命令的参数" class="headerlink" title="导入对应命令的参数"></a>导入对应命令的参数</h2><p>这是我个人感觉惊叹号最好用的地方。</p><p>基本格式是，如果要取history记录第N条命令的第M个参数：</p><p><code>!N:M</code></p><p>如果不输入N则代表上一条命令。</p><p>举例：</p><p><code>cp aa/aaa/aaa bb/bbb/bbb</code></p><p>此时如果输入</p><p><code>ls !:2</code>就相当于直接<code>ls bb/bbb/bbb</code></p><p>如果需要所有参数，可以</p><p><code>!:*</code></p><p>如果需要某一段参数，可以</p><p><code>!:1-2</code></p><p>如果需要用以前输入命令的参数但是觉得用<code>history</code>找一下比较麻烦，可以仅输入最开始的几个关键字，会自动匹配最新的那条命令（类似Ctrl+r）。</p><p>如在一些操作（非cp操作）之后又需要用到刚才的<code>cp</code>命令的参数，可以直接</p><p><code>ls !cp:2</code></p><p>同样也相当于<code>ls bb/bbb/bbb</code></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>热烈庆祝8总力克猫传腹病魔康复痊愈</title>
      <link href="/2019/09/22/8-recovery/"/>
      <url>/2019/09/22/8-recovery/</url>
      
        <content type="html"><![CDATA[<p>8总是今年3月出生的一只蓝白相间的英国短毛猫，因为脑袋上的蓝色花斑从中间裂开一个“八”字形的缝，因此被称为8总。</p><p><img src="https://s2.ax1x.com/2019/09/22/u93Xm4.jpg" alt="8总和母亲"><br><a id="more"></a></p><p>8总最开始被当成是一只小母猫，主要是因为他的母亲，另外一只蓝白，生的一窝小猫里面，只有它是蓝白相间的小猫。其他所有小猫都随了父亲，都是纯色的蓝猫。不过后来事实证明，这一窝小猫里，8总其实是唯一的公猫。</p><p><img src="https://s2.ax1x.com/2019/09/22/u98P1K.jpg" alt="第一张单人照"></p><p><img src="https://s2.ax1x.com/2019/09/22/u98K9P.jpg" alt="还未睁眼的8总"></p><p>甫一降世，8总就是这一窝小猫里面表现最活跃的那只。第一个翻越猫产房，第一个爬上沙发，第一个在成猫的饮水机里喝水…还经常挑起和其他小猫的战斗。8总虽然淘气，但有一点非常好，就是从来不咬人，也不会用爪子抓人，最多就是用手掌上的粉色小肉垫把你推走。</p><p><img src="https://s2.ax1x.com/2019/09/22/u988BQ.jpg" alt="8总的小JJ"></p><p><img src="https://s2.ax1x.com/2019/09/22/u98YAs.jpg" alt="肩上猫"></p><p><img src="https://s2.ax1x.com/2019/09/22/u98a90.jpg" alt="给您劈个叉"></p><p><img src="https://s2.ax1x.com/2019/09/22/u98DuF.jpg" alt="越长越大"></p><p>一天天长大，其他的小猫陆陆续续都找到了新的人家，但我和张老师却打算留下8总自己抚养。因为性格，也因为颜值，也因为他经常摆出一些逗趣的造型，比如四脚平伸趴在地上，还有蹲在墙角借酒浇愁的模样。</p><p><img src="https://s2.ax1x.com/2019/09/22/u98g41.jpg" alt="必须趴着"></p><p>最开始我们只是觉得好玩，并不知道这种蹲坐的姿势其实是猫传腹的早期症状。</p><p><img src="https://s2.ax1x.com/2019/09/22/u98fgK.jpg" alt="装在瓶子里"></p><p><img src="https://s2.ax1x.com/2019/09/22/u98IDe.jpg" alt="邪魅狂狷"></p><p>猫传腹全称“猫传染性腹膜炎”，在不久的过去，是一种猫的绝症。关于这种病的病因、症状和各种细分信息网上介绍的都很全面了，但所有信息里面都提到，这种病一旦确诊，对患病的猫咪来说，就只剩延缓痛苦和安乐了。</p><p>最开始发现8总不正常的还是心细的张老师。她有一天晚上在家写PPT，听到在旁边的8总的呼吸声不正常——比较短促，还带有杂音。又联想到最近几天8总精神好像差了好多，不再成天跑来跑去，于是，算是女人的直觉吧，张老师觉得8总应该是病了。</p><p><img src="https://s2.ax1x.com/2019/09/22/u9GM5R.jpg" alt="放飞自我"></p><p>第二天张老师放下了热爱的工作岗位，带8总去附近的宠物医院检查，我没有在一起。据不完全考证，张老师在得知8总得了猫传腹，并从宠物医院的医生那里得知了这种病的相关信息之后还哭了一鼻子。当然，只是不完全考证啊。</p><p><img src="https://s2.ax1x.com/2019/09/22/u9GdIA.jpg" alt="捉迷藏"></p><p>如果猫传腹必死，其实也就没我什么戏份了。但宠物医院的医生还是给了8总一线生机。从今年(2019)以前，猫传腹确实是绝症，但今年市面上出现了一种叫做441的新药（旧药叫375），已经有了大概70%的治愈率。再加上8总发现得比较早，还是有较大希望能够治愈的。但问题就是这种药价格比较昂贵，以此时8总的体重（3kg）来算，第一期大概需要4万块钱，第二期是否继续要看第一期的疗效如何。</p><p><img src="https://s2.ax1x.com/2019/09/22/u9Grxf.jpg" alt="少男怀春"></p><p>我知道张老师其实是非常希望去治疗的，但她的朋友，其中还包括一个自家的猫咪就是因猫传腹去世的，都劝张老师放弃，理由无非是花钱不少，但希望渺茫，至于新药是否能发挥作用，其实谁也没亲眼见过。在重大抉择面前，就体现出了我的战略定力和大局观；在张老师迷茫摇摆的时刻，是我给了她信心和动力——我们治。</p><p><img src="https://s2.ax1x.com/2019/09/22/u9GyM8.jpg" alt="父与子"></p><p><img src="https://s2.ax1x.com/2019/09/22/u9G6sS.jpg" alt="装死大赛"></p><p>于是我们去中国农大的宠物医院（感觉是宠物医院界的协和？）又做了一遍检查之后，潇洒地刷了支付宝，提了药，过上了每天两次带8总打针的日子。</p><p><img src="https://s2.ax1x.com/2019/09/22/u9G2ZQ.jpg" alt="得知8总生病后张老师的朋友圈"></p><p>这种病是否痊愈除了表面上是否恢复了精力、是否呼吸频率降低、不再发烧之外，主要看一个验血的“白球比”指标。这个指标的正常范围是0.8-1.5，8总第一次检查是0.4。</p><p><img src="https://s2.ax1x.com/2019/09/22/u9G7sU.jpg" alt="借酒浇愁，注意这其实是猫传腹的早期症状"></p><p>第一个星期我们还幻想过早上在家自己给8总打针，确实打进去几次，但后来8总早上一见到我们从卧室出来就溜，打针的时候也挣扎得非常厉害，以至基本无法操作。所以后来还是交由医生去打。但即便是医生来打，8总看起来也是非常痛苦。每次打完针，都要自己舔好久针口，并且后腿上逐渐有了一块不能摸的地方。</p><p>我们除了每次要带他打针很耗时费力之外，每次还都担心他承受不住这种针的痛苦。因为有一段时间8总需要一天注射5针，白天1针，晚上要连打4针，有几次还扎出了血。但8总是医院医生所有见过的猫里最听话的，从不咬人，也不抓人，实在疼得受不了了，就用舌头舔人。那一刻我觉得我和8总其实挺像的，不想把自己承受的表露给别人。</p><p>因为打针很疼这件事，8总和我们的关系不再像过去那么“不设防”。有时候他趴在桌子上，我摸摸他他就会坐起来看着我。到了打针的时间，他一定在哪个自以为我看不见的墙角里躲着我。我有时候也想知道，8总知不知道我们是在救他，还是仅仅以为我们在折磨他。虽然永远不可能知道答案，但我知道他一定觉得自己变得越来越好了——肯定是这样，本来我们打算买东西的钱都给他看病了，他现在挎着张老师的包，戴着我的表，一定美得不得了。</p><p>新药的效果还是不错的，8总的精神头逐渐恢复，连逃避打针时的挣扎都越来越有劲了。第一个星期去做了一次复查，虽然看起来好了不少，但白球比仍然是0.4，还没有恢复到正常水平，并且和第一次检查没有任何变化。说实话我们是有点心急的，这钱也花了，劲也费了，却没什么变好的迹象。关键时候，又体现出了我的战略….所以我们老老实实又打了两个星期。</p><p>这两个星期对我们也是一个考验。既要不间断地给他打针，又要安排好工作和生活的各种事情。因为从家里到宠物医院还有一段不远不近的距离，我又重新下载了一个共享单车的APP，还买了张优惠卡。</p><p>两个星期说快也快，这个周六，张老师又带小八去做检查，希望白球比恢复正常，能够停针。在去之前其实我们心里都有些忐忑，如果还没有恢复正常，就又是4万块钱和三个星期的连续打针，还不说中间的各种检查和搭进去的时间精力。但8总在遭受了那么多痛苦之后，看起来已经完全正常了，这多少给了我们一点信心。</p><p>这次抽血结果出来的那一刻，张老师说她感觉自己都要蹦起来了，白球比恢复正常了。</p><p><img src="https://s2.ax1x.com/2019/09/22/u9J9sO.jpg" alt="怡然自得"></p><p><img src="https://s2.ax1x.com/2019/09/22/u9JEFA.jpg" alt="马杀鸡"></p><p>我们救了8总。虽然他只是一只微不足道的小猫，但这竟然是我手上第一次产生了挽救生命的记录，并且是在最开始一切都不确定的情况下。我突然觉得这是我今年从开始到现在做得最好的一件事情。</p><p><img src="https://s2.ax1x.com/2019/09/22/u9JZWt.jpg" alt="保护妹妹"></p><p>最后总结一下治疗猫传腹的要点：</p><p>注意观察，提早发现，早治早好<br>新药有效，经济允许，可以尝试<br>坚持打针，安抚情绪，及时复查</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去20：快速定位short-lived进程对性能的负面影响</title>
      <link href="/2019/09/19/test20-troubleshoot-short-lived-process/"/>
      <url>/2019/09/19/test20-troubleshoot-short-lived-process/</url>
      
        <content type="html"><![CDATA[<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><p>遇到过的一个案例是这样：DPDK应用在小流量的情况下丢包，并且是间歇性地丢。很自然的，会怀疑有其他进程抢占分配给DPDK的CPU核。<br><a id="more"></a></p><blockquote><p>这个案例里Kernel里面CPU隔离的参数都是配好的，不过并非所有的进程都完全按照内核的要求行事。比如一些自己在代码里面调用了<code>sched_setaffinity</code>方法的程序。</p></blockquote><p>比较特殊的是，抢占这个CPU核的进程是一个生命周期非常短(short-lived)的进程，从启动到退出只有几毫秒的时间。所以很难在一些类似<code>top</code>，<code>ps</code>等一般查看进程状态的工具中“逮住”它。</p><h2 id="perf"><a href="#perf" class="headerlink" title="perf"></a>perf</h2><p>无论再短的进程都可以通过追踪Kernel里的方法观察到。一般这个时候想到的是利用<code>ftrace</code>来抓取，但<code>perf</code>提供了一些更为简便的操作和事件统计。</p><p>首先看一下<code>perf</code>里面关于调度器的事件：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">[root@server-P1 ~]<span class="meta"># perf list | grep sched</span></span><br><span class="line">  irq_vectors:reschedule_entry                       [Tracepoint event]</span><br><span class="line">  irq_vectors:reschedule_exit                        [Tracepoint event]</span><br><span class="line">  sched:sched_kthread_stop                           [Tracepoint event]</span><br><span class="line">  sched:sched_kthread_stop_ret                       [Tracepoint event]</span><br><span class="line">  sched:sched_migrate_task                           [Tracepoint event]</span><br><span class="line">  sched:sched_move_numa                              [Tracepoint event]</span><br><span class="line">  sched:sched_pi_setprio                             [Tracepoint event]</span><br><span class="line">  sched:sched_process_exec                           [Tracepoint event]</span><br><span class="line">  sched:sched_process_exit                           [Tracepoint event]</span><br><span class="line">  sched:sched_process_fork                           [Tracepoint event]</span><br><span class="line">  sched:sched_process_free                           [Tracepoint event]</span><br><span class="line">  sched:sched_process_hang                           [Tracepoint event]</span><br><span class="line">  sched:sched_process_wait                           [Tracepoint event]</span><br><span class="line">  sched:sched_stat_blocked                           [Tracepoint event]</span><br><span class="line">  sched:sched_stat_iowait                            [Tracepoint event]</span><br><span class="line">  sched:sched_stat_runtime                           [Tracepoint event]</span><br><span class="line">  sched:sched_stat_sleep                             [Tracepoint event]</span><br><span class="line">  sched:sched_stat_wait                              [Tracepoint event]</span><br><span class="line">  sched:sched_stick_numa                             [Tracepoint event]</span><br><span class="line">  sched:sched_swap_numa                              [Tracepoint event]</span><br><span class="line">  sched:sched_switch                                 [Tracepoint event]</span><br><span class="line">  sched:sched_wait_task                              [Tracepoint event]</span><br><span class="line">  sched:sched_wake_idle_without_ipi                  [Tracepoint event]</span><br><span class="line">  sched:sched_wakeup                                 [Tracepoint event]</span><br><span class="line">  sched:sched_wakeup_new                             [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_get_priority_max          [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_get_priority_min          [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_getaffinity               [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_getattr                   [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_getparam                  [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_getscheduler              [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_rr_get_interval           [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_setaffinity               [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_setattr                   [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_setparam                  [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_setscheduler              [Tracepoint event]</span><br><span class="line">  syscalls:sys_enter_sched_yield                     [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_get_priority_max           [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_get_priority_min           [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_getaffinity                [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_getattr                    [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_getparam                   [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_getscheduler               [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_rr_get_interval            [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_setaffinity                [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_setattr                    [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_setparam                   [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_setscheduler               [Tracepoint event]</span><br><span class="line">  syscalls:sys_exit_sched_yield                      [Tracepoint event]</span><br></pre></td></tr></table></figure><p>基本上够用了..其实真正重要的也就是<code>*exec</code>，<code>*exit</code>和<code>*switch</code>这仨。为了避免要抓取的short-lived进程仅仅存在于想象之中，我们先搞一些具体统计数据涨涨信心。</p><h3 id="perf-stat"><a href="#perf-stat" class="headerlink" title="perf stat"></a>perf stat</h3><p>可以先用<code>perf stat</code>看看具体事件的计数：</p><p><code>perf stat -e sched:sched_switch -a -I 1000 sleep 10</code></p><p>这里面会给出当前整个系统调度器发生switch的统计情况，每1秒输出一次，总计10秒。</p><p>如果想针对某一个特定的CPU，可以把<code>-a</code>替换成<code>-C 4</code>这类。其他事件的统计也可以用类似的方法。</p><p>如果<code>switch</code>事件比较多，那么可以继续看一下<code>shced:sched_process_exec</code>事件在某个CPU上发生的频率，当然了，这个CPU一般是正在跑DPDK或其他生产业务的CPU。</p><h2 id="详细内容"><a href="#详细内容" class="headerlink" title="详细内容"></a>详细内容</h2><p>如果想看到该事件的一些详细信息，比如具体是哪个程序在频繁启动，对应的PID，以及程序在哪个CPU上启动，可执行文件的路径是什么等信息，可以用<code>ftrace</code>的方式实现。</p><p>首先使能该trace事件：</p><p><code>echo 1 &gt; /sys/kernel/debug/tracing/events/sched/sched_process_exec/enable</code></p><p>然后<code>cat /sys/kernel/debug/tracing/trace</code></p><p>应该就可以看到了。</p><p>也可以用<code>perf-tools</code>里的<code>execsnoop</code>工具，不过本质上都是一样的。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去19：Enable DPDK i40e vector rx function</title>
      <link href="/2019/09/04/test19-enable-dpdk-i40e-vector-rx-function/"/>
      <url>/2019/09/04/test19-enable-dpdk-i40e-vector-rx-function/</url>
      
        <content type="html"><![CDATA[<h2 id="Vector-Rx-Function"><a href="#Vector-Rx-Function" class="headerlink" title="Vector Rx Function"></a>Vector Rx Function</h2><p>在DPDK i40e网卡的驱动中提供有利用向量指令收包的方法，在一般场景下可以大幅提升性能。当针对基于DPDK的应用做性能诊断时可以用<code>perf top</code>命令直观观察有没有<code>i40e_recv_pkts_vec</code>这个方法出现，如果没有则可以判定当前的应用没有使用向量指令集优化过的收/发包方法。<br><a id="more"></a></p><h2 id="i40e-set-rx-function"><a href="#i40e-set-rx-function" class="headerlink" title="i40e_set_rx_function"></a>i40e_set_rx_function</h2><p>一般来说，DPDK和编译器会根据当前编译机器（或者指定的交叉编译CPU型号）对向量指令的支持情况来决定是否使用向量化指令。当支持向量指令时优先采用向量指令。不过在一些客户那边也遇到过编译环境支持向量化指令，但应用实际跑起来时却没有采用的情况。对于这种问题的根因需要看一下i40e驱动中决定采用哪种收发方法的逻辑究竟是怎样的。</p><p><code>i40e_set_rx_function</code>方法在<code>./drivers/net/i40e/i40e_rxtx.c</code>文件中，其中会调用<code>i40e_rx_vec_dev_conf_condition_check()</code>子方法来检查是否采用vector方法。</p><p>在<code>i40e_rx_vec_dev_conf_condition_check()</code>方法中又包了一层<code>i40e_rx_vec_dev_conf_condition_check_default()</code>在这个方法里有详细的配置检查逻辑，截取一部分：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* no fdir support */</span></span><br><span class="line"><span class="keyword">if</span> (fconf-&gt;mode != RTE_FDIR_MODE_NONE)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line"> <span class="comment">/* no header split support */</span></span><br><span class="line"><span class="keyword">if</span> (rxmode-&gt;offloads &amp; DEV_RX_OFFLOAD_HEADER_SPLIT)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* no QinQ support */</span></span><br><span class="line"><span class="keyword">if</span> (rxmode-&gt;offloads &amp; DEV_RX_OFFLOAD_VLAN_EXTEND)</span><br><span class="line">         <span class="keyword">return</span> <span class="number">-1</span>;</span><br></pre></td></tr></table></figure><p>我当时遇到的情况是i40e网卡打开了fdir的支持，这样在第一个<code>if</code>判断时方法返回-1，会导致外层逻辑放弃使用向量化收包方法。其他原因都可以使用<code>-O0 -g</code>的方式用gdb调试出来。</p><p>这也可以看出当需要使用网卡的fdir功能和另外两个hardware offloading功能时，是不能使用向量化收包方法的。</p><p>当然，除此之外还有另外一些因素会影响DPDK最终的选择，例如<code>config</code>文件夹下面那个<code>common_base</code>中的一些配置，但这些配置一般采用默认即可。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Quickwords33:How uprobe works</title>
      <link href="/2019/08/25/quickwords33-how-uprobe-work/"/>
      <url>/2019/08/25/quickwords33-how-uprobe-work/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>用uprobe也有一段时间了，确实是一个很有价值的工具。我这个人有个特点，就是如果不知道这件事背后的原理，即便工具很好用，但用起来始终心里不踏实，像是房本上没加名字，住着没有安全感。对于uprobe这么fancy的工具还是很有必要了解一下具体的工作机制。一方面是打消“神秘感”，一方面是看看是否能激发别的灵感。<br><a id="more"></a></p><h2 id="添加uprobe之后发生了什么"><a href="#添加uprobe之后发生了什么" class="headerlink" title="添加uprobe之后发生了什么"></a>添加uprobe之后发生了什么</h2><p>我们可以猜到的是，给二进制文件添加uprobe之后，一定可以在汇编代码里看到一些改变。既然如此，我们就找个二进制文件看一下。</p><p>在uprobe界有一个“网红”示例：<code>bash</code>中的<code>readline</code>方法。该方法能够用uprobe读取出用户在bash命令行中输入的命令的字符串。</p><p>我们先看一下原始的<code>bash</code>二进制文件中，<code>readline</code>方法的汇编代码：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">$</span> gdb --pid &lt;target bash PID&gt;</span><br><span class="line">(gdb) disassemble /r readline</span><br><span class="line">Dump of assembler code for function readline:</span><br><span class="line">   0x000000000049a520 &lt;+0&gt;:  83 3d 81 5e 26 00 ff     cmpl   $0xffffffff,0x265e81(%rip)</span><br><span class="line">   0x000000000049a527 &lt;+7&gt;:  53                       push   %rbx</span><br><span class="line">   0x000000000049a528 &lt;+8&gt;:  74 6e                    je     0x49a598 &lt;readline+120&gt;</span><br><span class="line">   0x000000000049a52a &lt;+10&gt;: e8 21 ee ff ff           callq  0x499350 &lt;rl_set_prompt&gt;</span><br><span class="line">   0x000000000049a52f &lt;+15&gt;: e8 3c fd ff ff           callq  0x49a270 &lt;rl_initialize&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>如果此时添加了<code>&#39;r:bash:readline &quot;%s&quot; retval</code>这样一条<code>uprobe</code>之后，再来看一下现在的<code>bash</code>二进制文件中<code>readline</code>方法的情况：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(gdb) disassemble /r readline</span><br><span class="line">Dump of assembler code for function readline:</span><br><span class="line">   0x000000000049a520 &lt;+0&gt;:  cc                       int3</span><br><span class="line">   0x000000000049a521 &lt;+1&gt;:  3d 81 5e 26 00           cmp    $0x265e81,%eax</span><br><span class="line">   0x000000000049a526 &lt;+6&gt;:  ff 53 74                 callq  *0x74(%rbx)</span><br><span class="line">   0x000000000049a529 &lt;+9&gt;:  6e                       outsb  %ds:(%rsi),(%dx)</span><br><span class="line">   0x000000000049a52a &lt;+10&gt;: e8 21 ee ff ff           callq  0x499350 &lt;rl_set_prompt&gt;</span><br><span class="line">   0x000000000049a52f &lt;+15&gt;: e8 3c fd ff ff           callq  0x49a270 &lt;rl_initialize&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>现在可以看到的是，<code>readline</code>方法的二进制文件中，第一个字节从<code>0x83</code>变成了<code>0xcc</code>。这个是一个叫做<code>INT3</code>的指令。</p><h2 id="INT3"><a href="#INT3" class="headerlink" title="INT3"></a>INT3</h2><p>既然出现在了汇编代码中，<code>INT</code>其实也是一个汇编指令。在x86 CPU中，<code>INT</code>是用来产生software interrupt的指令，它后面的数字代表对应的中断表的表项，同时触发该表项对应的回调函数。</p><p><code>INT3</code>其实是用来触发软件<code>break point</code>的指令，其实就是我们用gdb时设定的“断点”，在CPU运行到这个指令的时候触发。</p><p>同时<code>INT3</code>比较特殊的地方在于，它的二进制指令只有一个字节。因为足够短，它可以在程序的任意位置设置。</p><h2 id="总体流程"><a href="#总体流程" class="headerlink" title="总体流程"></a>总体流程</h2><p>在了解了<code>INT3</code>这个机关之后，说明一下uprobe的工作原理：</p><p><img src="https://dev.framing.life/assets/images/post/kernel-and-user-probes-magic/instruction-probes-workflow-z1-escaped.svg" alt=""></p><p>首先把原先的<code>readline</code>的二进制程序<code>83 3d 81 5e 26 00 ff</code>的第一个字节替换为<code>cc</code>，这样当程序运行到这里的时候，就直接进入<code>INT3</code>中断。</p><p>进入中断之后，首先保存当前进程的上下文信息，然后做我们给它做的事：在原二进制程序上单步前进，在运行到<code>ret</code>指令时保存相关寄存器里的值并记录。然后恢复进程原来的上下文信息，令程序继续执行。</p><p>如此就完成了uprobe的功能。Kprobe也是类似的原理：</p><p><img src="http://jake.dothome.co.kr/wp-content/uploads/2015/12/kprobes2.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>十八岁这天的日记</title>
      <link href="/2019/08/11/diary-on-18th-b-day/"/>
      <url>/2019/08/11/diary-on-18th-b-day/</url>
      
        <content type="html"><![CDATA[<p>上中学的时候，按历任语文老师的要求，写过好几本日记。这里面有一本是最不一样的，因为高三了，语文老师可能也认为“写日记”这个事确实太闲情逸致了一些，所以不再像以前一样要求上交日记本批改。我因此也得以在上面写了一些真正的日记。<br><a id="more"></a></p><p>高中时期正是有了心思的年纪，也是刚刚掌握了一点“文学技巧”就手痒痒的时候。所以那时的日记很多都是一些喃喃的梦呓。但不得不承认，这一时期对我影响很大，确实刻意练习过一种适合自己的“文学风格”，也从一个角度体现和塑造了我的人格。</p><p>我要说的这篇神奇的日记就是在这个日记本上，我写在自己十八岁生日那天的日记。这篇日记还特别有一个题目，叫“写在十八岁这天的决定”。我估计我当时写完这篇日记就直接将它抛诸脑后，因为直到我二十八岁了我也从来没想起过我曾经写过这么一篇东西。甚至这个日记本也因为我离家上学而下落不明了一段时间，直到最近某一次收拾车库时才重见天日。</p><p>看自己十好几年前写的日记真是一种奇妙的体验，旧时光在泛黄的故纸上依旧鲜活。而里面的那个自己，在现在看来，就像深夜里写这些日记时看到的在窗户上自己的倒影，在一片未知中憧憬着远方。日记写的都是当天的事情，唯有这篇“写在十八岁这天的决定”写的是未来。</p><blockquote><p>今天我十八岁，我在今天做了一系列决定，有关我今后人生的发展。我将它们写到这个不起眼的本子上，以供后人瞻仰。</p></blockquote><p>我承认我笑了，十八岁的我真是太牛逼了。这篇日记其实是当时对今后人生的规划。从那天起，一直写到了我五六十岁的时候。详细地划分成了几个阶段，当然越年轻的时候划分得越细，等到不惑之年之后就可能还要靠那时的自己了。</p><p>如果只是少年人的一篇胡言乱语，我自然也不会拿出来说事。我仔细看了一下我当时写的18-25和26-30这两个年龄阶段的规划，我不知道18岁的我是怎么想的，里面写的内容竟然和真实的经历，分毫不差。当然不可能像算命一样写什么你考上了哪所大学，读没读硕士，谈了几次恋爱，多大结的婚等等，但都明确地写出了这段时间的任务和目标。而我吃惊的点是在于，在这些岁月里，我有很长一段时间其实自己并不知道自己适合干什么，想要干什么，直到现在才渐渐有了些眉目。之前仅仅凭借一些隐隐约约的“导航”在寻觅。而这一切竟然已经被我自己清清楚楚地写在了18岁生日那天的日记上，而我竟然一直都不曾忆起，这让我突然有了一种见到了“神谕”的激动。</p><p>我更加相信，每个人都有自己终究要走的路，无论中间会经历什么，命运都会让你走上你注定的轨迹。至于这是不是由一位至高的“意志”所决定，并不是我关心的内容。我关心的仅仅是，我要怎样度过我自己的一生。</p><p>感谢我当时的语文老师，决定不再收日记本批阅，不然我肯定不会在这个本上写这篇日记。如果说现在问我对未来有什么规划和打算，我希望30-35这个阶段也如日记所述。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚32：Git命令极简使用指南</title>
      <link href="/2019/08/09/quickwords32-simplest-git-manual/"/>
      <url>/2019/08/09/quickwords32-simplest-git-manual/</url>
      
        <content type="html"><![CDATA[<blockquote><p>基本上可以Cover 90%以上的工作场景。</p></blockquote><h2 id="要开始在现有Master上搞点什么"><a href="#要开始在现有Master上搞点什么" class="headerlink" title="要开始在现有Master上搞点什么"></a>要开始在现有Master上搞点什么</h2><h3 id="确保你在master分支上"><a href="#确保你在master分支上" class="headerlink" title="确保你在master分支上"></a>确保你在master分支上</h3><p><code>git checkout master</code><br><a id="more"></a></p><h3 id="创建一个新的分支"><a href="#创建一个新的分支" class="headerlink" title="创建一个新的分支"></a>创建一个新的分支</h3><p><code>git checkout -b mydevbranch</code></p><h3 id="修改了代码之后"><a href="#修改了代码之后" class="headerlink" title="修改了代码之后"></a>修改了代码之后</h3><p>可以先用<code>git diff</code>看看自己的修改详情，然后再看一眼<code>git status</code>，修改的文件。如果没问题</p><p><code>git add -u</code>，把已经被追踪的文件加进去。</p><p>如果有代码修改涉及创建新文件，就用<code>git add /path/to/file</code>把这个也加进去。</p><p>然后简单写写<code>commit info</code>：<code>git commit -m “commit info”</code></p><h3 id="推到远端去"><a href="#推到远端去" class="headerlink" title="推到远端去"></a>推到远端去</h3><p>到这里只是把修改commit到了本地分支。如果你是第一次在这个分支上推送，那么就用：<code>git push -u origin master HEAD</code>。</p><p>这个时候如果你是用github的话，就会发现你直接创建了一个<code>pull request</code>。</p><p>如果不是第一次推了，那么先重复一下<code>修改了代码之后</code>的步骤，在<code>git commit</code>之后：</p><p><code>git push origin mydevbranch</code></p><p>推到远端。</p><p>如果你这个分支代码更新了比较长的时间，主线master已经发生了变化，可以及时现在master上pull一下，然后checkout回mydevbranch，然后做一个rebase</p><p><code>git rebase master</code></p><p>再往远端推。有冲突可以及时解决，不必等到最后。</p><h2 id="要抓一个分支下来"><a href="#要抓一个分支下来" class="headerlink" title="要抓一个分支下来"></a>要抓一个分支下来</h2><p>一般<code>git clone</code>可以拿到master分支，拿其他分支的话：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git fetch origin remotebranch</span><br><span class="line">git checkout -b remotebranch origin/remotebranch</span><br><span class="line">git pull origin remotebranch</span><br></pre></td></tr></table></figure><p>就可以在本地有一个和远端同步的分支代码了</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去18：使用LD_PRELOAD搞砸一切</title>
      <link href="/2019/08/09/test18-ld-preload-mess-up/"/>
      <url>/2019/08/09/test18-ld-preload-mess-up/</url>
      
        <content type="html"><![CDATA[<h2 id="LD-PRELOAD"><a href="#LD-PRELOAD" class="headerlink" title="LD_PRELOAD"></a>LD_PRELOAD</h2><p><code>LD_PRELOAD</code>是一个神奇的指令，关于它的介绍可以参考这篇<a href="http://www.goldsborough.me/c/low-level/kernel/2016/08/29/16-48-53-the_-ld_preload-_trick/" target="_blank" rel="noopener">文章</a>，这篇<a href="https://catonmat.net/simple-ld-preload-tutorial" target="_blank" rel="noopener">文章</a>。<br><a id="more"></a></p><h2 id="有用的事"><a href="#有用的事" class="headerlink" title="有用的事"></a>有用的事</h2><p>用<code>LD_PRELOAD</code>可以做很多有用的事情，比如替换<code>malloc</code>和<code>free</code>来检测内存泄露，这里有一个实际的Github开源<a href="https://github.com/jrfonseca/memtrail" target="_blank" rel="noopener">软件</a>。</p><h2 id="搞点别的"><a href="#搞点别的" class="headerlink" title="搞点别的"></a>搞点别的</h2><p><code>LD_PRELOAD</code>虽然很强大，但针对不是动态链接的方法就无能为力。检查一个ELF文件中哪些方法是可以被<code>LD_PRELOAD</code>改造的，可以用：</p><p><code>readelf --dyn-syms /path/to/elf/file</code></p><p>比如我这里写了一个很简单的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@server-P1 build]# readelf --dyn-syms test</span><br><span class="line"></span><br><span class="line">Symbol table '.dynsym' contains 6 entries:</span><br><span class="line">   Num:    Value          Size Type    Bind   Vis      Ndx Name</span><br><span class="line">     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND </span><br><span class="line">     1: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND puts@GLIBC_2.2.5 (2)</span><br><span class="line">     2: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND printf@GLIBC_2.2.5 (2)</span><br><span class="line">     3: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __libc_start_main@GLIBC_2.2.5 (2)</span><br><span class="line">     4: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND __gmon_start__</span><br><span class="line">     5: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND fopen@GLIBC_2.2.5 (2)</span><br></pre></td></tr></table></figure><p>这里能看到可以被<code>LD_PRELOAD</code>利用的方法包括<code>puts</code>, <code>printf</code>这类<code>glibc</code>提供的动态符号。</p><p>这里比较特殊的是这个叫<code>__libc_start_main</code>的方法，如果我们写了一个<code>.so</code>文件去替换这个符号的话…比如：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span></span><br><span class="line">__libc_start_main(<span class="keyword">void</span>)  &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"Here comes the injected function!\n"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>gcc -shared -fPIC -o preload.so preload.c</code></p><p>然后</p><p><code>export LD_PRELOAD=$PWD/preload.so</code></p><p>之后就可以抓狂了~</p><p>消除的方法也很简单：</p><p><code>unset LD_PRELOAD</code></p><p>现在比较关心的是如何将静态链接的方法也用<code>LD_PRELOAD</code>替换。不过如果它替换不了，用<code>ftrace</code>加Hook应该是可以的。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去17：Adding dynamic probe to gain insight of DPDK application</title>
      <link href="/2019/08/07/test17-dyn-probe-dpdk/"/>
      <url>/2019/08/07/test17-dyn-probe-dpdk/</url>
      
        <content type="html"><![CDATA[<h2 id="Dynamic-Trace-Framework"><a href="#Dynamic-Trace-Framework" class="headerlink" title="Dynamic Trace Framework"></a>Dynamic Trace Framework</h2><p>曾经想给DPDK添加一个trace framework，但使用的方法是添加一个专门的rte_trace库，涉及一整套trace buffer和控制相关的操作，同时需要修改原本DPDK应用的代码，使用起来成本还是比较高的。在逐渐熟悉了<code>uprobe</code>的操作之后，其实可以用uprobe完成绝大部分这个trace framework所做的工作，例如方法执行时间戳、方法参数、返回值、内部变量值的记录工作，并且有性能开销方面的保障。<br><a id="more"></a></p><h2 id="l3fwd"><a href="#l3fwd" class="headerlink" title="l3fwd"></a>l3fwd</h2><p>这里就用DPDK自带的<code>l3fwd</code>程序作一个简单的使用示例。</p><blockquote><p>我们的目的是追踪<code>l3fwd</code>中<code>l3fwd_lpm_send_packets</code>这个方法的调用情况。这个方法是在<code>l3fwd</code>收到数据包之后处理转发的时候调用的。</p></blockquote><p>先用<code>perf</code>检查一下编译出来的二进制文件中包含该方法：</p><p><code>perf probe -F -x ./l3fwd | grep lpm_send_packets</code></p><p>我们看一下这个方法的的原型：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">void</span></span><br><span class="line">l3fwd_lpm_send_packets(<span class="keyword">int</span> nb_rx, struct rte_mbuf **pkts_burst,</span><br><span class="line">                    <span class="keyword">uint8_t</span> portid, struct lcore_conf *qconf)</span><br></pre></td></tr></table></figure><p>也就是不带返回值，然后4个参数。</p><p>然后添加一个新的<code>uprobe</code></p><p><code>perf probe -x ./l3fwd &#39;l3fwd_lpm_send_packets %di %si %dx %cx&#39;</code></p><p>后面<code>%di %si %dx %cx</code>对应x86_64架构中函数的4个参数寄存器。详见下图：</p><p><img src="https://s2.ax1x.com/2019/08/07/e52gIg.png" alt=""></p><p>OK， 这个时候应该可以在<code>/sys/kernel/debug/tracing/events</code>路径下面看到一个叫<code>probe_l3fwd</code>的文件夹了，进去之后<code>echo 1 &gt; enable</code>就算准备完毕。</p><p>启动<code>l3fwd</code>:</p><p><code>./l3fwd -c 0x1ffff -- -p 0x3 -P --config=&quot;(0,0,1),(0,1,2),(0,2,3),(1,0,4),(1,1,5),(1,2,6)&quot;</code></p><h2 id="查看结果"><a href="#查看结果" class="headerlink" title="查看结果"></a>查看结果</h2><p>首先给<code>l3fwd</code>发几个包，用<code>scapy</code>一个一个发就可以。然后</p><p><code>cat /sys/kernel/debug/tracing/trace</code></p><p>就可以看到如下结果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> tracer: nop</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> entries-in-buffer/entries-written: 11/11   #P:36</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>                              _-----=&gt; irqs-off</span><br><span class="line"><span class="meta">#</span>                             / _----=&gt; need-resched</span><br><span class="line"><span class="meta">#</span>                            | / _---=&gt; hardirq/softirq</span><br><span class="line"><span class="meta">#</span>                            || / _--=&gt; preempt-depth</span><br><span class="line"><span class="meta">#</span>                            ||| /     delay</span><br><span class="line"><span class="meta">#</span>           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION</span><br><span class="line"><span class="meta">#</span>              | |       |   ||||       |         |</span><br><span class="line">           &lt;...&gt;-105187 [003] d... 9864775.255783: l3fwd_lpm_send_packets: (0x464f42) arg1=0x1 arg2=0x7f728add44b0 arg3=0x0 arg4=0x1407140</span><br><span class="line">           &lt;...&gt;-106508 [003] d... 9864984.831907: l3fwd_lpm_send_packets: (0x464f42) arg1=0x1 arg2=0x7f8f219dc4b0 arg3=0x0 arg4=0x1407140</span><br><span class="line">           &lt;...&gt;-106508 [003] d... 9865065.328194: l3fwd_lpm_send_packets: (0x464f42) arg1=0x1 arg2=0x7f8f219dc4b0 arg3=0x0 arg4=0x1407140</span><br><span class="line">           &lt;...&gt;-106508 [003] d... 9865121.933159: l3fwd_lpm_send_packets: (0x464f42) arg1=0x1 arg2=0x7f8f219dc4b0 arg3=0x0 arg4=0x1407140</span><br><span class="line">           &lt;...&gt;-106508 [003] d... 9865318.618119: l3fwd_lpm_send_packets: (0x464f42) arg1=0x1 arg2=0x7f8f219dc4b0 arg3=0x0 arg4=0x1407140</span><br><span class="line">           &lt;...&gt;-106508 [003] d... 9865340.393096: l3fwd_lpm_send_packets: (0x464f42) arg1=0x1 arg2=0x7f8f219dc4b0 arg3=0x0 arg4=0x1407140</span><br></pre></td></tr></table></figure><p>这是发了6个packet之后的结果，这里面给出了每次该方法调用的时间戳、执行CPU序号、以及每次执行时4个参数的值。</p><h2 id="核对结果"><a href="#核对结果" class="headerlink" title="核对结果"></a>核对结果</h2><p>那么这些值都对不对呢？为了验证可以用gdb attach上去看一下：</p><p><code>gdb attach</code>pidof l3fwd<code></code></p><p>在<code>l3fwd_lpm_send_packets</code>处设置一个断点：</p><p><code>b /root/dpdk-stable-18.05.1/examples/l3fwd-fdir/l3fwd_lpm.c:243</code></p><p>然后继续<code>continue</code>，发送一个数据包，查看当前变量的值：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">(gdb) info locals</span><br><span class="line">pkts_burst = &#123;0x7f8739502e40, 0x2, 0x7f8f219dd770, 0x7f8f23d4b757 &lt;__memmove_ssse3+3895&gt;, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x11, 0x2, 0x452330 &lt;rte_log+138&gt;, </span><br><span class="line">  0x0, 0x3000000018, 0x7f8f219dc610, 0x7f8f219dc550, 0x0, 0x4e1a46 &lt;eal_thread_dump_affinity+262&gt;, 0x4, 0x2, 0x219de700, 0x7f8f219dc630, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0&#125;</span><br><span class="line">lcore_id = 2</span><br><span class="line">prev_tsc = 22639728109674980</span><br><span class="line">diff_tsc = 28037</span><br><span class="line">cur_tsc = 22639728109703017</span><br><span class="line">i = 1</span><br><span class="line">***nb_rx = 1***</span><br><span class="line">***portid = 0***</span><br><span class="line">queueid = 2 '\002'</span><br><span class="line">***qconf = 0x1407140 &lt;lcore_conf+19456&gt;***</span><br><span class="line">drain_tsc = 230000</span><br></pre></td></tr></table></figure><p>这里可以看到nb_rx = 1，与trace中第一个参数的值相同，portid = 0与trace中第三个参数的值相同，qconf = 0x1407140与trace中第四个参数的值相同。queueid虽然在参数中没有体现，但根据我们的设置，port0的第二个rx queue由CPU3负责轮询，可以从trace中CPU的信息中对应上。</p><p>如果在gdb中打印pkts_burst的地址：</p><blockquote><p>p &amp;pkts_burst</p></blockquote><p><code>$1 = (struct rte_mbuf *(*)[32]) 0x7f8f219dc4b0</code></p><p>也可以对应起来。</p><blockquote><p>实际上queueid可以通过对qconf做偏移取得。但我的机器似乎内核版本较低（需要大于3.14)，暂时无法提供。方法也很简单就是+8(%cx)，表示往后偏移8个字节。</p></blockquote><p>通过这些数据，完全可以计算出l3fwd这个应用转发速率是多少，每个队列的速率是多少，平均一次收多少包，没有收到包的轮询比例有多少等所有信息。</p><p>也可以看一些内部变量的情况，前提是编译器没给你优化掉，这个后面再介绍。</p><p>如果可以预置一些此类探针，或者制作一个方便添加/删除的框架，应当可以在多个方面帮助用户。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去16：Adding new kprobe to ftrace tracing</title>
      <link href="/2019/07/19/test16-adding-new-kprobe/"/>
      <url>/2019/07/19/test16-adding-new-kprobe/</url>
      
        <content type="html"><![CDATA[<h2 id="添加ftrace新事件"><a href="#添加ftrace新事件" class="headerlink" title="添加ftrace新事件"></a>添加ftrace新事件</h2><p>Ftrace自己带很多事件，之前一直以为在内核方面ftrace的触角就到此为止了。今天才了解到kprobe也可以像uprobe一样自己动态定义一个出来。这样默认的ftrace没有的事件也就可以通过添加新kprobe事件的方式添加了。<br><a id="more"></a></p><blockquote><p>kproble + uprobe都支持动态自定义添加，感觉这个电脑在做什么终于可以有一个比较全面的认识了。</p></blockquote><h2 id="为什么不用eBPF"><a href="#为什么不用eBPF" class="headerlink" title="为什么不用eBPF?"></a>为什么不用eBPF?</h2><p>像bcc这类的工具有很多预定义好的方法，直接拿来用确实很方便。但eBPF现在有一个比较大的缺陷就是对内核版本有要求。很多企业用户的生产系统上根本没有4.1版本以上的内核，同时对往内核里加东西（容易被类比为内核模块）比较敏感，所以需要用ftrace作为eBPF的替代方案。</p><p>另外插一句题外话，像银行、金融、政府这类客户还是以稳定为中心的，不能有一点点让领导背锅的风险 XD</p><h2 id="添加kprobe-event"><a href="#添加kprobe-event" class="headerlink" title="添加kprobe event"></a>添加kprobe event</h2><h3 id="找到目标方法"><a href="#找到目标方法" class="headerlink" title="找到目标方法"></a>找到目标方法</h3><p>可以在<code>System.map</code>文件里找一下有没有你要观察的内核函数方法。这个文件其实相当于内核的符号表（symbol table）。如果拿不准内核方法名的时候可以在这里面<code>grep</code>一下看看。</p><h3 id="增加指令"><a href="#增加指令" class="headerlink" title="增加指令"></a>增加指令</h3><p>以内核方法<code>blk_start_request</code>为例，这个方法在默认的ftrace事件中是找不到的（至少在我当前的机器上哈）。当我们也需要用ftrace的方式追踪（trace）这个方法的时候，就可以自己给它添加一个。</p><p>如果只是想看具体执行的时间、执行它的进程、使用的CPU等信息，指令也非常简单：</p><p><code>echo &#39;p:myprobe blk_start_request&#39; &gt; /sys/kernel/debug/tracing/kprobe_events</code></p><p>执行之后可以在<code>kprobe_events</code>中看到该事件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@Server-N3 tracing]# cat /sys/kernel/debug/tracing/kprobe_events </span><br><span class="line">p:kprobes/myprobe blk_start_request</span><br></pre></td></tr></table></figure><p>同时在<code>/sys/kernel/debug/tracing/events/kprobes/</code>目录下新出现了一个<code>myprobe</code>文件夹。</p><p>进来看看<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@Server-N3 myprobe]# ls /sys/kernel/debug/tracing/events/kprobes/myprobe/</span><br><span class="line">enable  filter  format  id</span><br></pre></td></tr></table></figure></p><p>此时直接给该目录下的<code>enable</code>文件写入个1，<code>echo 1 &gt; enable</code>就使能了针对该方法的追踪机制。</p><p>回到<code>/sys/kernel/debug/tracing</code>看一下追踪的结果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@Server-N3 tracing]# cat trace|tail</span><br><span class="line">           &lt;...&gt;-92844 [001] d... 8125310.179907: myprobe: (blk_start_request+0x0/0x50)</span><br><span class="line">          &lt;idle&gt;-0     [001] dNs. 8125310.179953: myprobe: (blk_start_request+0x0/0x50)</span><br><span class="line">           &lt;...&gt;-51846 [020] d... 8125310.329592: myprobe: (blk_start_request+0x0/0x50)</span><br><span class="line">           &lt;...&gt;-51846 [021] d... 8125310.329824: myprobe: (blk_start_request+0x0/0x50)</span><br><span class="line">           &lt;...&gt;-92844 [001] d... 8125310.329979: myprobe: (blk_start_request+0x0/0x50)</span><br><span class="line">          &lt;idle&gt;-0     [001] dNs. 8125310.330025: myprobe: (blk_start_request+0x0/0x50)</span><br><span class="line">           &lt;...&gt;-51858 [021] d... 8125310.476478: myprobe: (blk_start_request+0x0/0x50)</span><br><span class="line">           &lt;...&gt;-51858 [022] d... 8125310.476750: myprobe: (blk_start_request+0x0/0x50)</span><br><span class="line">           &lt;...&gt;-92844 [001] d... 8125310.476890: myprobe: (blk_start_request+0x0/0x50)</span><br><span class="line">          &lt;idle&gt;-0     [001] dNs. 8125310.476941: myprobe: (blk_start_request+0x0/0x50)</span><br></pre></td></tr></table></figure><h3 id="追踪任意内容"><a href="#追踪任意内容" class="headerlink" title="追踪任意内容"></a>追踪任意内容</h3><p>如果只是看执行的时间点用以上的方法就足够了。但kprobe（还有uprobe）给我们提供了更为强大的机制看到能想象到的所有内容，包括：</p><ul><li>CPU个寄存器的值</li><li>方法各个参数的值</li><li>方法的返回值</li><li>方法内部栈的信息</li><li>如果传入参数为一个数据结构的指针，拿到指针所指对象中某个成员变量的值</li><li>等等</li></ul><p>这些需要你掌握一套定义的语法，先看一下总体的说明：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">p[:[GRP/]EVENT] [MOD:]SYM[+offs]|MEMADDR [FETCHARGS] : Set a probe</span><br><span class="line">r[MAXACTIVE][:[GRP/]EVENT] [MOD:]SYM[+0] [FETCHARGS] : Set a return probe</span><br><span class="line">-:[GRP/]EVENT : Clear a probe</span><br><span class="line"></span><br><span class="line">GRP : Group name. If omitted, use "kprobes" for it.</span><br><span class="line">EVENT : Event name. If omitted, the event name is generated</span><br><span class="line">based on SYM+offs or MEMADDR.</span><br><span class="line">MOD : Module name which has given SYM.</span><br><span class="line">SYM[+offs] : Symbol+offset where the probe is inserted.</span><br><span class="line">MEMADDR : Address where the probe is inserted.</span><br><span class="line">MAXACTIVE : Maximum number of instances of the specified function that</span><br><span class="line">can be probed simultaneously, or 0 for the default value</span><br><span class="line">as defined in Documentation/kprobes.txt section 1.3.1.</span><br><span class="line"></span><br><span class="line">FETCHARGS : Arguments. Each probe can have up to 128 args.</span><br><span class="line"><span class="meta">%</span>REG : Fetch register REG</span><br><span class="line">@ADDR : Fetch memory at ADDR (ADDR should be in kernel)</span><br><span class="line">@SYM[+|-offs] : Fetch memory at SYM +|- offs (SYM should be a data symbol)</span><br><span class="line"><span class="meta">$</span>stackN : Fetch Nth entry of stack (N &gt;= 0)</span><br><span class="line"><span class="meta">$</span>stack : Fetch stack address.</span><br><span class="line"><span class="meta">$</span>argN : Fetch the Nth function argument. (N &gt;= 1) (\*1)</span><br><span class="line"><span class="meta">$</span>retval : Fetch return value.(\*2)</span><br><span class="line"><span class="meta">$</span>comm : Fetch current task comm.</span><br><span class="line">+|-offs(FETCHARG) : Fetch memory at FETCHARG +|- offs address.(\*3)</span><br><span class="line">NAME=FETCHARG : Set NAME as the argument name of FETCHARG.</span><br><span class="line">FETCHARG:TYPE : Set TYPE as the type of FETCHARG. Currently, basic types</span><br><span class="line">(u8/u16/u32/u64/s8/s16/s32/s64), hexadecimal types</span><br><span class="line">(x8/x16/x32/x64), "string" and bitfield are supported.</span><br><span class="line"></span><br><span class="line">(\*1) only for the probe on function entry (offs == 0).</span><br><span class="line">(\*2) only for return probe.</span><br><span class="line">(\*3) this is useful for fetching a field of data structures.</span><br></pre></td></tr></table></figure><p>主要内容是<code>FETCHARGS</code>下面罗列的信息。具体的内容可以在kernel<a href="https://www.kernel.org/doc/html/latest/trace/kprobetrace.html" target="_blank" rel="noopener">官网</a>上查看，我这边主要给出几个应用的实例。</p><p>以<code>blk_account_io_completion</code>为例，它在内核中的原型为：</p><p><code>void blk_account_io_completion(struct request *req, unsigned int bytes);</code></p><p>当我们要看它的参数信息时，从上面能看到取参数的方式，主要可以通过读取寄存器的值来拿到。</p><blockquote><p>上面的文档里确实有直接通过<code>$argN</code>的形式拿到参数的方式，但我感觉这个方法受限于内核版本，当前我用的机器上还没有实现这个方法。</p></blockquote><p>所以去哪找到这两个参数对应的寄存器是哪个呢？</p><p>在kernel源码arch/x86/include/asm/ptrace.h文件中：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * regs_get_kernel_argument() - get Nth function argument in kernel</span></span><br><span class="line"><span class="comment"> * @regs:   pt_regs of that context</span></span><br><span class="line"><span class="comment"> * @n:      function argument number (start from 0)</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * regs_get_argument() returns @n th argument of the function call.</span></span><br><span class="line"><span class="comment"> * Note that this chooses most probably assignment, in some case</span></span><br><span class="line"><span class="comment"> * it can be incorrect.</span></span><br><span class="line"><span class="comment"> * This is expected to be called from kprobes or ftrace with regs</span></span><br><span class="line"><span class="comment"> * where the top of stack is the return address.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="title">regs_get_kernel_argument</span><span class="params">(struct pt_regs *regs,</span></span></span><br><span class="line"><span class="function"><span class="params">                             <span class="keyword">unsigned</span> <span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> argument_offs[] = &#123;</span><br><span class="line">#ifdef __i386__</span><br><span class="line">        offsetof(struct pt_regs, ax),</span><br><span class="line">        offsetof(struct pt_regs, cx),</span><br><span class="line">        offsetof(struct pt_regs, dx),</span><br><span class="line">#define NR_REG_ARGUMENTS <span class="number">3</span></span><br><span class="line">#<span class="keyword">else</span></span><br><span class="line">        offsetof(struct pt_regs, di),</span><br><span class="line">        offsetof(struct pt_regs, si),</span><br><span class="line">        offsetof(struct pt_regs, dx),</span><br><span class="line">        offsetof(struct pt_regs, cx),</span><br><span class="line">        offsetof(struct pt_regs, r8),</span><br><span class="line">        offsetof(struct pt_regs, r9),</span><br><span class="line">#define NR_REG_ARGUMENTS <span class="number">6</span></span><br><span class="line">#endif</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (n &gt;= NR_REG_ARGUMENTS) &#123;</span><br><span class="line">        n -= NR_REG_ARGUMENTS - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">return</span> regs_get_kernel_stack_nth(regs, n);</span><br><span class="line">    &#125; <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> regs_get_register(regs, argument_offs[n]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从这个方法中可以看到在<code>x86_64</code>的机器上，保存内核方法参数的寄存器依次是<code>di</code> <code>si</code> <code>dx</code>…</p><p>所以我们写的指令就是：</p><p><code>echo &#39;p:blkprobe blk_account_io_completion req=%di bytes=%si&#39; &gt; /sys/kernel/debug/tracing/kprobe_events</code></p><p>用同样的方法enable之后就可以看到追踪的信息了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@server-P1 events]# cat ../trace | tail</span><br><span class="line">          &lt;idle&gt;-0     [000] dNs. 8222360.833141: blkprobe: (blk_account_io_completion+0x0/0xb0) req=0xffff8c2028e6f600 bytes=0x0</span><br><span class="line">          &lt;idle&gt;-0     [000] d.s. 8222383.061651: blkprobe: (blk_account_io_completion+0x0/0xb0) req=0xffff8c1f4fb8fc00 bytes=0x1c00</span><br><span class="line">          &lt;idle&gt;-0     [000] dNs. 8222383.076929: blkprobe: (blk_account_io_completion+0x0/0xb0) req=0xffff8c1f4fb8fc00 bytes=0x0</span><br><span class="line">          &lt;idle&gt;-0     [000] d.s. 8222413.140181: blkprobe: (blk_account_io_completion+0x0/0xb0) req=0xffff8c1f4fb8f300 bytes=0x1000</span><br><span class="line">          &lt;idle&gt;-0     [034] d.s. 8222413.141468: blkprobe: (blk_account_io_completion+0x0/0xb0) req=0xffff8c26c6eaf000 bytes=0x400</span><br><span class="line">           &lt;...&gt;-54375 [034] d.s. 8222413.141526: blkprobe: (blk_account_io_completion+0x0/0xb0) req=0xffff8c26c6ead080 bytes=0x2000</span><br><span class="line">          &lt;idle&gt;-0     [034] d.s. 8222413.141565: blkprobe: (blk_account_io_completion+0x0/0xb0) req=0xffff8c26c6eaca80 bytes=0x2000</span><br><span class="line">          &lt;idle&gt;-0     [034] d.s. 8222413.141603: blkprobe: (blk_account_io_completion+0x0/0xb0) req=0xffff8c26c6eac480 bytes=0x1000</span><br><span class="line">          &lt;idle&gt;-0     [034] d.s. 8222413.141679: blkprobe: (blk_account_io_completion+0x0/0xb0) req=0xffff8c26c6eac600 bytes=0x2000</span><br><span class="line">          &lt;idle&gt;-0     [000] dNs. 8222413.174594: blkprobe: (blk_account_io_completion+0x0/0xb0) req=0xffff8c1f4fb8f300 bytes=0x0</span><br></pre></td></tr></table></figure><p>还有一个有意思的地方是<code>blk_account_io_completion</code>这个方法第一个参数是一个类型为<code>strcut request</code>的指针。如果想看到该类型中某一个成员变量的值，可以根据类型定义的偏移量获取地址并追踪，并且支持多次嵌套使用。详细方法可以看这个<a href="https://events.linuxfoundation.org/wp-content/uploads/2017/12/oss-eu-2018-fun-with-dynamic-trace-events_steven-rostedt.pdf" target="_blank" rel="noopener">文档</a>里面对网络函数的实例，我这里就不赘述了。</p><h2 id="产品化"><a href="#产品化" class="headerlink" title="产品化"></a>产品化</h2><p>其实bcc也是利用同样的能力，将一些关键方法预定义为kprobe，通过对原始结果的一些综合，获取对用户的业务是实际意义的信息。比如bcc/tools里面的磁盘操作时延分布、网络收发流量排名等等。</p><p>如果能进一步综合kprobe和uprobe的能力，以及对特定应用场景的预定义，辅以一定的UI、数据可视化和用户交互设计，可以得到很强大的业务性能分析诊断工具。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去15：DPDK VxLAN Inner L4 CSUM OFFLOAD</title>
      <link href="/2019/07/16/test15-dpdk-vxlan-csum-offload/"/>
      <url>/2019/07/16/test15-dpdk-vxlan-csum-offload/</url>
      
        <content type="html"><![CDATA[<h2 id="IXGBE"><a href="#IXGBE" class="headerlink" title="IXGBE"></a>IXGBE</h2><p>以IXGBE驱动为例，看一下如何让把内层报文Checksum的计算Offload给网卡。</p><p>本质上来说，是在DPDK的<code>mbuf</code>结构中，将L2 Header的长度配置为外层VxLAN报文+内层L2 Header的总长度，这样对网卡来说，该<code>mbuf</code>对应的报文就是一个L2 Header长得令人发指的普通非隧道报文，但是这样就可以计算内层L3/L4 Header的Checksum了。<br><a id="more"></a></p><h3 id="ixgbe-tx-offload"><a href="#ixgbe-tx-offload" class="headerlink" title="ixgbe_tx_offload"></a>ixgbe_tx_offload</h3><p>在DPDK的IXGBE驱动代码中有如下结构体：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Offload features */</span></span><br><span class="line"><span class="keyword">union</span> ixgbe_tx_offload &#123;</span><br><span class="line">    <span class="keyword">uint64_t</span> data[<span class="number">2</span>];</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">        <span class="keyword">uint64_t</span> l2_len:<span class="number">7</span>; <span class="comment">/**&lt; L2 (MAC) Header Length. */</span></span><br><span class="line">        <span class="keyword">uint64_t</span> l3_len:<span class="number">9</span>; <span class="comment">/**&lt; L3 (IP) Header Length. */</span></span><br><span class="line">        <span class="keyword">uint64_t</span> l4_len:<span class="number">8</span>; <span class="comment">/**&lt; L4 (TCP/UDP) Header Length. */</span></span><br><span class="line">        <span class="keyword">uint64_t</span> tso_segsz:<span class="number">16</span>; <span class="comment">/**&lt; TCP TSO segment size */</span></span><br><span class="line">        <span class="keyword">uint64_t</span> vlan_tci:<span class="number">16</span>;</span><br><span class="line">        <span class="comment">/**&lt; VLAN Tag Control Identifier (CPU order). */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">/* fields for TX offloading of tunnels */</span></span><br><span class="line">        <span class="keyword">uint64_t</span> outer_l3_len:<span class="number">8</span>; <span class="comment">/**&lt; Outer L3 (IP) Hdr Length. */</span></span><br><span class="line">        <span class="keyword">uint64_t</span> outer_l2_len:<span class="number">8</span>; <span class="comment">/**&lt; Outer L2 (MAC) Hdr Length. */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> RTE_LIBRTE_SECURITY</span></span><br><span class="line">        <span class="comment">/* inline ipsec related*/</span></span><br><span class="line">        <span class="keyword">uint64_t</span> sa_idx:<span class="number">8</span>;  <span class="comment">/**&lt; TX SA database entry index */</span></span><br><span class="line">        <span class="keyword">uint64_t</span> sec_pad_len:<span class="number">4</span>; <span class="comment">/**&lt; padding length */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里面<code>l2_len</code>是占了7个比特位，也就是说你外层报文头长度+内层L2 Header长度不要大于127Byte。</p><p>另外代码中还有一些<code>ol_flag</code>的配置，也需要结合需求一起配置。</p><h2 id="配置方法"><a href="#配置方法" class="headerlink" title="配置方法"></a>配置方法</h2><p>以下内容节选自：<a href="https://doc.dpdk.org/guides/prog_guide/mbuf_lib.html" target="_blank" rel="noopener">https://doc.dpdk.org/guides/prog_guide/mbuf_lib.html</a></p><p>但是我感觉好像没什么人看到过的样子….</p><h3 id="checksum-of-out-ip"><a href="#checksum-of-out-ip" class="headerlink" title="checksum of out_ip:"></a>checksum of out_ip:</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mb-&gt;l2_len = len(out_eth)</span><br><span class="line">mb-&gt;l3_len = len(out_ip)</span><br><span class="line">mb-&gt;ol_flags |= PKT_TX_IPV4 | PKT_TX_IP_CSUM</span><br></pre></td></tr></table></figure><p>set out_ip checksum to 0 in the packet<br>This is supported on hardware advertising DEV_TX_OFFLOAD_IPV4_CKSUM.</p><h3 id="checksum-of-out-ip-and-out-udp"><a href="#checksum-of-out-ip-and-out-udp" class="headerlink" title="checksum of out_ip and out_udp:"></a>checksum of out_ip and out_udp:</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mb-&gt;l2_len = len(out_eth)</span><br><span class="line">mb-&gt;l3_len = len(out_ip)</span><br><span class="line">mb-&gt;ol_flags |= PKT_TX_IPV4 | PKT_TX_IP_CSUM | PKT_TX_UDP_CKSUM</span><br></pre></td></tr></table></figure><p>set out_ip checksum to 0 in the packet<br>set out_udp checksum to pseudo header using rte_ipv4_phdr_cksum()<br>This is supported on hardware advertising DEV_TX_OFFLOAD_IPV4_CKSUM and DEV_TX_OFFLOAD_UDP_CKSUM.</p><h3 id="checksum-of-in-ip"><a href="#checksum-of-in-ip" class="headerlink" title="checksum of in_ip:"></a>checksum of in_ip:</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mb-&gt;l2_len = len(out_eth + out_ip + out_udp + vxlan + in_eth)</span><br><span class="line">mb-&gt;l3_len = len(in_ip)</span><br><span class="line">mb-&gt;ol_flags |= PKT_TX_IPV4 | PKT_TX_IP_CSUM</span><br></pre></td></tr></table></figure><p>set in_ip checksum to 0 in the packet<br>This is similar to case 1), but l2_len is different. It is supported on hardware advertising DEV_TX_OFFLOAD_IPV4_CKSUM. Note that it can only work if outer L4 checksum is 0.</p><h3 id="checksum-of-in-ip-and-in-tcp"><a href="#checksum-of-in-ip-and-in-tcp" class="headerlink" title="checksum of in_ip and in_tcp:"></a>checksum of in_ip and in_tcp:</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mb-&gt;l2_len = len(out_eth + out_ip + out_udp + vxlan + in_eth)</span><br><span class="line">mb-&gt;l3_len = len(in_ip)</span><br><span class="line">mb-&gt;ol_flags |= PKT_TX_IPV4 | PKT_TX_IP_CSUM | PKT_TX_TCP_CKSUM</span><br></pre></td></tr></table></figure><p>set in_ip checksum to 0 in the packet<br>set in_tcp checksum to pseudo header using rte_ipv4_phdr_cksum()<br>This is similar to case 2), but l2_len is different. It is supported on hardware advertising DEV_TX_OFFLOAD_IPV4_CKSUM and DEV_TX_OFFLOAD_TCP_CKSUM. Note that it can only work if outer L4 checksum is 0.</p><h3 id="segment-inner-TCP"><a href="#segment-inner-TCP" class="headerlink" title="segment inner TCP:"></a>segment inner TCP:</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mb-&gt;l2_len = len(out_eth + out_ip + out_udp + vxlan + in_eth)</span><br><span class="line">mb-&gt;l3_len = len(in_ip)</span><br><span class="line">mb-&gt;l4_len = len(in_tcp)</span><br><span class="line">mb-&gt;ol_flags |= PKT_TX_IPV4 | PKT_TX_IP_CKSUM | PKT_TX_TCP_CKSUM |</span><br><span class="line">  PKT_TX_TCP_SEG;</span><br></pre></td></tr></table></figure><p>set in_ip checksum to 0 in the packet<br>set in_tcp checksum to pseudo header without including the IP<br>  payload length using rte_ipv4_phdr_cksum()<br>This is supported on hardware advertising DEV_TX_OFFLOAD_TCP_TSO. Note that it can only work if outer L4 checksum is 0.</p><h3 id="checksum-of-out-ip-in-ip-in-tcp"><a href="#checksum-of-out-ip-in-ip-in-tcp" class="headerlink" title="checksum of out_ip, in_ip, in_tcp:"></a>checksum of out_ip, in_ip, in_tcp:</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mb-&gt;outer_l2_len = len(out_eth)</span><br><span class="line">mb-&gt;outer_l3_len = len(out_ip)</span><br><span class="line">mb-&gt;l2_len = len(out_udp + vxlan + in_eth)</span><br><span class="line">mb-&gt;l3_len = len(in_ip)</span><br><span class="line">mb-&gt;ol_flags |= PKT_TX_OUTER_IPV4 | PKT_TX_OUTER_IP_CKSUM  | \</span><br><span class="line">  PKT_TX_IP_CKSUM |  PKT_TX_TCP_CKSUM;</span><br></pre></td></tr></table></figure><p>set out_ip checksum to 0 in the packet<br>set in_ip checksum to 0 in the packet<br>set in_tcp checksum to pseudo header using rte_ipv4_phdr_cksum()<br>This is supported on hardware advertising DEV_TX_OFFLOAD_IPV4_CKSUM, DEV_TX_OFFLOAD_UDP_CKSUM and DEV_TX_OFFLOAD_OUTER_IPV4_CKSUM.</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> dpdk </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Quickwords31：What Is Inclusive and Exclusive Cache</title>
      <link href="/2019/07/08/quickwords31-inclusive-exclusive-cache/"/>
      <url>/2019/07/08/quickwords31-inclusive-exclusive-cache/</url>
      
        <content type="html"><![CDATA[<h2 id="一般对Cache的认知方式"><a href="#一般对Cache的认知方式" class="headerlink" title="一般对Cache的认知方式"></a>一般对Cache的认知方式</h2><p>我们比较熟悉的对Cache的理解是，首先有3级，L1，L2和L3。这三级依次远离CPU核心，查询数据的速度也依次减慢。当CPU需要一个地址上的数据时，会先去L1查找；当L1没有这个数据的时候，去L2查找；L2也没有的时候，去L3查找。如果还没有，就去内存上去查找。这是我们看待Cache和CPU查询数据时的一般方式。<br><a id="more"></a></p><p>这里面其实没有涉及一个问题，就是L1中包含的数据，L2中是否包含；L2中包含的数据，L3中是否包含。我们可能会习惯性地认为“是包含的”，但实际上这句话只说对了一半，或者一小半吧。当下一级缓存包含上一级缓存的数据时，我们称这种缓存为<code>Inclusive Cache</code>，当下一级缓存不包含上一级缓存的数据的时候，这种缓存就被称为<code>Exclusive Cache</code>。</p><h2 id="Why"><a href="#Why" class="headerlink" title="Why?"></a>Why?</h2><p>那么<code>Exclusive Cache</code>有什么好处呢？首先第一点就是减少了缓存空间的浪费。因为当上级缓存有需要的数据时，CPU是不会查询次级缓存的，所以这部分空间就可以解放出来放别的数据。</p><p>另外一点就是减轻缓存相干性（Cache Coherency）的复杂度。简单来讲，当上一级缓存中的数据需要被踢出时，如果是<code>Inclusive Cache</code>，那么所有下级缓存中都包含该失效的数据，都需要被踢出。同时还需要验证上级缓存中是否也存在需要被提出的数据。在多核系统中，还需要考虑不同CPU核之间的MESI协议的处理，会令情况更加复杂。</p><p>事实上，现在的CPU更多的是<code>Exclusive Cache</code>结构，而非我们（自以为）熟悉的<code>Inclusive Cache</code>结构。但实际上，很多CPU的设计都不是严格的<code>Inclusive/Exclusive Cache</code>结构，而是采用的折衷的<code>NI/NE</code>结构，也就是“既不是严格的Inclusive，也不是严格的Exclusive”，从而在各自针对Cache特性的优先级上获取一定的自由度。</p><h2 id="可能的影响"><a href="#可能的影响" class="headerlink" title="可能的影响"></a>可能的影响</h2><p>在DPDK的应用中，一些原有的DPDK应用在升级了新型号的CPU之后反而出现性能下降（~20%）的问题，这时就需要考虑是否是因为Cache架构变化导致的。例如：</p><p>某些新型的CPU，我就不具体点名了，其L2 Cache和L3 Cache之间，由之前的<code>Inclusive</code>关系变成了<code>Exclusive</code>关系。这也就是说当一个pkt进入某一个CPU核的L2缓存时，其必定不在L3缓存里。当DPDK应用是RTC(Run To Completion)框架时，该pkt的数据只在一个CPU核的L2里处理，还可以取得应有的性能。但当DPDK应用是PipeLine框架时，因为pkt的数据需要在多个核之间传递，每当它进入一个核的L2时，都需要将L3中的数据失效，同时多个核之间又共享L3，所以就增加了pkt在缓存间传递的次数，进而引起应用整体的性能下降。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>应许之日</title>
      <link href="/2019/06/24/promised-date/"/>
      <url>/2019/06/24/promised-date/</url>
      
        <content type="html"><![CDATA[<p>很庆幸自己能活这么久，站在此时此刻的人生节点上，可以闻到更好的时光还在后面。<br><a id="more"></a></p><p>回头看看来时的路，似乎人生的前半程，都是在一片鸿蒙中打滚。不知道自己是谁，不知道自己是个怎样的人，不知道接下来要干什么，不知道明天和今天会有什么不同。也不知道如何去找到自己的位置，如何处理与其他人的关系，如何取得想取得的，留住想留住的，以及摆脱想摆脱的。似乎所有的得失，都只是随机的事件，而我只是被时光推挤着前行，如同被挤入地铁一样身不由己。</p><p>我不喜欢这种感觉，却又无可奈何。自己空有一份力气，却无处去使，只能任由摆布。我不是那种在人生的早期就知道自己这一生要干什么的人，我也不是那种有某一样特别才华的人。但我也有自己的爱好，有自己擅长的东西，最主要的，有想要找到价值的欲望。这股欲望既引领着我，同时也不断折磨着我，直到现在我才渐渐品味到得偿所愿的快乐。</p><p>虽然我的生活看起来还是之前的样子，但我知道我改变了。像青山涳濛之处，仿佛能听到雨后竹笋拔节的声音，又像雷声隐隐之时，将有一场酣畅淋漓解救大地的焦渴。这就是我的应许之日。我知道我是被许诺的，许诺给我这么一天，我此生到世间来的目的就是为了这一天。</p><p>想感谢一下以前的自己，跋涉过漫漫而悠长的岁月，在多少次都以为活不下去的时刻——没有期待和希望——仍然选择等待和忍耐。我没有什么信仰，也不是什么毅力超群的人，我以前并不知道是哪里来的力量为悬崖竖起了一道墙。但现在我想明白了。我要将这股力量归功于我对承诺和约定的看重——我会守约，我一定会守约。也许这反而成为我被伤害的原因，但我心里其实一直相信，有人会和我一样，不顾所有困难地践约。他既然答应给我这么一天，我就知道一定会有这么一天。</p><p>我相信真的能等到这一天，所有的心愿都会达成，所有的过错都被原谅，所有的来不及都可以弥补，所有的无可奈何都可以遗忘。我知道这不是我的一厢情愿，而是我确被许诺的东西，我的应许之日，我所等待的意义和一切等待之所以能称之为等待的原因。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>5分钟经典英文技术演讲3：如何应对信息过载并提高生产效率-Scott Hanselman</title>
      <link href="/2019/06/19/eng-talk3-scaling-yourself/"/>
      <url>/2019/06/19/eng-talk3-scaling-yourself/</url>
      
        <content type="html"><![CDATA[<blockquote><p>一个人的能力上限很大程度上取决于他获取信息的能力。</p><p>而能力增长的速度与获取信息的<strong>质量</strong>正相关。</p><p>不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。</p><p>最新内容将发布于DecodeZ: decodezp.github.io</p><p><a href="https://decodezp.github.io/2018/12/12/eng-talk1-fast-learn/">往期回顾1：如何快速掌握新技术</a><br><a href="https://decodezp.github.io/2018/12/21/eng-talk2-things-matter/">往期回顾2：软件设计真正的精髓</a></p></blockquote><h1 id="GOTO2012-Scaling-Yourself"><a href="#GOTO2012-Scaling-Yourself" class="headerlink" title="GOTO2012: Scaling Yourself"></a>GOTO2012: Scaling Yourself</h1><p><a href="https://www.youtube.com/watch?v=FS1mnISoG7U&amp;list=PL-V4m0AO-7weBsEkJjmF563WGfIsCgk9t&amp;index=16&amp;t=1484s" target="_blank" rel="noopener">原视频</a></p><p><img src="https://www.hanselman.com/blog/content/binary/Windows-Live-Writer/0a3df681baef_C924/97e47e1feb7b591e8220b08a8c83cc9a_28706943-45af-44b8-a280-d15e7cfbc89c.jpg" alt="演讲者：Scott Hanselman"></p><blockquote><p>摘要：信息过载的时代，能否找到一种在信息洪流中独善其身的方法，让我们专注于真正重要事情？当生活/工作的范畴一再扩大，我们也需要延展自身的边界，在充分利用信息的同时，保持持续的生产效率。<br><a id="more"></a></p></blockquote><h2 id="信息的质量已发生变化"><a href="#信息的质量已发生变化" class="headerlink" title="信息的质量已发生变化"></a>信息的质量已发生变化</h2><p>网络时代之前，信息被镌刻在石头和书本之上，经过时间的筛选和检验。而如今的信息，绝大部分就如同你收件箱中好几百封还没来得及打开的邮件一样，廉价而又粗糙。</p><p>即便单单从程序员的角度举例，80和90年代，学习一门语言所要获取的信息，就在下面这两本书中：</p><p><img src="https://s2.ax1x.com/2019/06/19/VO21X9.jpg" alt=""></p><p>而如今每个程序员都在拼命吸收从各个渠道推送过来的“技术”信息，每天工作到很晚才能稍稍打消心中的焦虑感。这是一个危险的信号，实际上这些信息绝大部分都是垃圾，并且根据统计，平均每个工作日，有30%的时间我们都被这些信息占用和打断。</p><h2 id="三类工作"><a href="#三类工作" class="headerlink" title="三类工作"></a>三类工作</h2><p>那么如何应对信息对工作的干扰呢？首先需要对所要执行的工作进行一个分类。</p><p>我们每天需要所做的工作可以分为三个大类：</p><ul><li>提前预知的工作（Pre-defined Work)</li><li>临时出现的工作（Work as it appears)</li><li><strong>定义工作的工作</strong>（Defining Works)</li></ul><p>我们平时会将时间投入到前两种工作之中，而却忽视了最重要的第三种工作——定义工作的工作。有多少次你愿意给自己一段专门的时间，考虑一下什么才是你需要做的工作？</p><p><img src="https://zapier.cachefly.net/storage/photos/3238539f6e1222e19ceb083fc6995ffb.png" alt=""></p><p>考虑这个问题的方法仍然是，老生常谈的，按照重要程度和紧急程度对工作进行分类：</p><ul><li>紧急又重要的工作：马上去做</li><li>重要但不紧急的工作：规划何时去做</li><li>紧急但不重要的工作：交给（对他来说紧急又重要的）别人去做</li><li>不重要也不紧急的工作：不要做</li></ul><p>这个方法相信大家都很熟悉，但实际上，我们很多时间都花在了感觉很紧急，但却一点都不重要的工作之上。我们应当意识到，“感觉紧急”本身就是一件很上瘾的事情，就比如微信上的未读信息以及大部分的邮件一样，每次有新消息的提醒，都会控制不住去点开看看。请不要将此归咎于自己的自制力，这是上帝写在人类PRD里面的内容。但我们依然可以利用有效的方法帮助自己。</p><h2 id="三件事原则"><a href="#三件事原则" class="headerlink" title="三件事原则"></a>三件事原则</h2><p>克服信息洪流对工作的打断效果，可以使用“三件事原则”，方法也很简单：</p><ul><li>写下来这一天你想要完成的三件事是什么</li><li>写下来这一个星期你想要完成的三件事是什么</li><li>写下来这一年你想要完成的三件事是什么</li></ul><p>每个星期周一的时候写下这三件事，等到周五的时候回顾一下：</p><ul><li>是不是都已经完成？</li><li>没有完成的原因是什么？</li><li>如果回到星期一，有哪些可以改善的地方？</li></ul><p>通过这种回顾的形式，可以让你专注于真正重要的事情上。利用这种形式，是为了让工作更加有效，而不仅仅是繁忙。</p><blockquote><p>繁忙是懒惰的一种形式（Being busy is a form of laziness）。</p></blockquote><p>因为你懒于思考应该做什么工作，应该如何采取行动，而仅仅是在接受他人或者环境的<strong>支配</strong>。这种繁忙只会对你产生负面的效果。</p><h2 id="区分你的信息来源"><a href="#区分你的信息来源" class="headerlink" title="区分你的信息来源"></a>区分你的信息来源</h2><p>每一条我们接收的信息，都有它自己的来源。列出你所有的信息来源，然后将它们区分成是”信号”还是“噪声”。区分的标准也很简单，就看是否给你提供了价值。</p><p>比如Scott在这里给了他的分类方式：</p><p><img src="https://s2.ax1x.com/2019/06/19/VO2l6J.jpg" alt=""></p><ul><li><p>信息：</p><ul><li>电话</li><li>来自老板的邮件</li><li>收件人是自己的邮件</li></ul></li><li><p>噪声</p><ul><li>抄送自己的邮件</li><li>Twitter</li><li>Google Reader</li></ul></li></ul><p>有了这些分类之后，可以让我们更好地了解自己有限的精力应该投放在哪里。除此之外的所有那些诱惑着你去读的小红点，加粗字体，图标闪烁……全部简单地标为”已读”，不要害怕错过什么重要的事情，因为如果真正重要，它们一定会通过重要的渠道传达给你。你所要做的，就是不时享受一下这种“没有新信息”所带来的精神上的放松和喘息。</p><h2 id="节省你的键盘敲击次数"><a href="#节省你的键盘敲击次数" class="headerlink" title="节省你的键盘敲击次数"></a>节省你的键盘敲击次数</h2><p><img src="https://zapier.cachefly.net/storage/photos/0e0a681e54cfc93ce1d4790f8288ebb3.png" alt=""></p><p>你一生能敲击键盘的次数是一个有限的数字，你需要节省着用。如果你为了回复某个人的Email或者是微信钉钉这类IM上的问题给出了大段大段的文字去阐述、解释或者辩解，那么你就非常慷慨地将你“不可再生”的敲击次数给了你在Email或IM上对话的人，而你或许根本就不知道他/她有没有认真看了你发的信息。其实我可以保证大多数时候就并没有 )笑。</p><p>所以你应该让你的敲击用在真正可以产生价值的地方。当你要和某人讨论一个技术或是产品问题的时候，你可以把它写到你的博客上，写到公司的产品文档上，然后仅仅给这个人发送相关的链接。每当有人产生了一次浏览，你敲击的价值就又复制了一次，而你并不需要为此多做什么。</p><p>不要在Email或IM上长篇大论，它们除了浪费你的敲击之外，别无他用。</p><h2 id="番茄工作法的正确用法"><a href="#番茄工作法的正确用法" class="headerlink" title="番茄工作法的正确用法"></a>番茄工作法的正确用法</h2><p><img src="https://zapier.cachefly.net/storage/photos/39125d9a9a25f8ce5b2fadb2478c78a6.png" alt=""></p><p>番茄工作法是一个非常有效的提升生产效率的方法。无需赘述，大家对它应当非常熟悉：在一段时间内，专注于一件事情，抵制Multitasking。</p><p>但真实的情况是，在25分钟之内，你并不能做到完全专注。但这非常正常，外界的干扰和输入太多，你不可能永远处于一个无干扰的环境，甚至你自己也会主动“走神”。但每当你被打断的时候，记下来。</p><p>这样做的目标是明确在这一个“番茄时间”之内，你被打断的次数和类型，在每次番茄时间结束的时候回顾一下。明确你被什么东西打断，是一件重要的事情，因为这会让这个数字越来越小，直到你完全不被打断。如此就能释放番茄工作法的全部益处。</p><p>以上就是Scott想在本次演讲中分享给大家的主要内容。</p>]]></content>
      
      
      <categories>
          
          <category> ENG_talk </category>
          
      </categories>
      
      
        <tags>
            
            <tag> English </tag>
            
            <tag> Presentation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Quickwords30：Use Both kprobe and uprobe At The Same Time</title>
      <link href="/2019/06/18/quickwords30-kprobe-uprobe-both/"/>
      <url>/2019/06/18/quickwords30-kprobe-uprobe-both/</url>
      
        <content type="html"><![CDATA[<p>用<code>ftrace</code>可以观察内核方法的调用信息。用<code>uprobe</code>可以观察用户空间二进制可执行文件中方法的调用信息。奇怪的是当你想把两个合在一起用的时候，比如你想看到内核调度器调度到了你关心的用户进程，同时也想知道调度之后，该进程会执行哪个方法的时候，网络上我没有找到任何资料教你如何去做。按说这应该是一个对各类系统问题诊断很有用的能力。</p><p>也许是太简单了？下面用一个示例说明。</p><h2 id="内核版本"><a href="#内核版本" class="headerlink" title="内核版本"></a>内核版本</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uname -r</span><br><span class="line">4.19.6-1.el7.elrepo.x86_64</span><br></pre></td></tr></table></figure><p>有点新，不过不害事。<br><a id="more"></a></p><h2 id="设置uprobe"><a href="#设置uprobe" class="headerlink" title="设置uprobe"></a>设置<code>uprobe</code></h2><p>设置<code>uprobe</code>的方法还是挺多的，我个人建议用<code>perf</code>设置算比较方便。硬核爱好者可以参考这篇：<a href="https://decodezp.github.io/2018/12/04/ftrace-uprobe/">https://decodezp.github.io/2018/12/04/ftrace-uprobe/</a></p><h3 id="看看有哪些能设置的点"><a href="#看看有哪些能设置的点" class="headerlink" title="看看有哪些能设置的点"></a>看看有哪些能设置的点</h3><p><code>perf probe -x /bin/bash -F</code><br>打印出来的是<code>/bin/bash</code>这个二进制文件中可以设置的trace point。</p><h3 id="添加uprobe跟踪点"><a href="#添加uprobe跟踪点" class="headerlink" title="添加uprobe跟踪点"></a>添加<code>uprobe</code>跟踪点</h3><p><code>perf probe -x /bin/bash &#39;readline%return +0($retval):string&#39;</code></p><p><code>readline</code>是上面打印出来的trace point之一，后面的参数是打印该方法的返回值。在这里就是我们在bash中敲入的命令。</p><p>加入之后在<code>cat /sys/kernel/debug/tracing/uprobe_events</code>就能看到这个信息。</p><p>但这里能看到并不说明什么问题。此时会看到在</p><p><code>/sys/kernel/debug/tracing/events/probe_bash</code>会多出一个事件。将这里面的<code>enable</code> echo成1。</p><p>其实这个时候就已经可以从trace中看到用户程序的追踪信息了。（前提是在bash中敲入了一些代码）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon tracing]# cat trace | tail</span><br><span class="line">  kworker/u256:2-3393  [000] d...  4537.944067: sched_stat_runtime: comm=kworker/u256:2 pid=3393 runtime=1557 [ns] vruntime=11510909796 [ns]</span><br><span class="line">  kworker/u256:2-3393  [000] d...  4537.944067: sched_switch: prev_comm=kworker/u256:2 prev_pid=3393 prev_prio=120 prev_state=R+ ==&gt; next_comm=sshd next_pid=1645 next_prio=120</span><br><span class="line">            sshd-1645  [000] d...  4537.944188: sched_stat_runtime: comm=sshd pid=1645 runtime=121420 [ns] vruntime=1187191909 [ns]</span><br><span class="line">            sshd-1645  [000] d...  4537.944191: sched_switch: prev_comm=sshd prev_pid=1645 prev_prio=120 prev_state=D ==&gt; next_comm=swapper/0 next_pid=0 next_prio=120</span><br><span class="line">            bash-1649  [003] d.h.  4537.944987: sched_stat_runtime: comm=bash pid=1649 runtime=991600 [ns] vruntime=9501612170 [ns]</span><br><span class="line">            bash-4920  [001] d...  9557.263762: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="cd .."</span><br><span class="line">            bash-4920  [001] d...  9557.806689: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="ls"</span><br><span class="line">            bash-4920  [001] d...  9558.865593: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="cd .."</span><br><span class="line">            bash-4920  [001] d...  9559.230347: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="ls"</span><br><span class="line">            bash-4920  [001] d...  9562.364085: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="cat trace | tail"</span><br></pre></td></tr></table></figure><h2 id="设置kprobe"><a href="#设置kprobe" class="headerlink" title="设置kprobe"></a>设置<code>kprobe</code></h2><p>这个比较简单，设置一下<code>enable</code>就行。我们这里只打开<code>sched</code>相关的事件。</p><p><code>echo 1 &gt; /sys/kernel/debug/tracing/events/sched/enable</code></p><h2 id="观察trace结果"><a href="#观察trace结果" class="headerlink" title="观察trace结果"></a>观察<code>trace</code>结果</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">cat trace | grep -C 2 readline</span><br><span class="line">kworker/u256:2-3393  [002] d...  4510.436525: sched_switch: prev_comm=kworker/u256:2 prev_pid=3393 prev_prio=120 prev_state=R+ ==&gt; next_comm=swapper/2 next_pid=0 next_prio=120</span><br><span class="line">            bash-1649  [000] d.h.  4510.436528: sched_wakeup: comm=sshd pid=1645 prio=120 target_cpu=000</span><br><span class="line">            bash-1649  [000] d...  4510.436601: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="cat enable "</span><br><span class="line">            bash-1649  [000] d...  4510.436661: sched_stat_runtime: comm=bash pid=1649 runtime=220718 [ns] vruntime=8123222027 [ns]</span><br><span class="line">            bash-1649  [000] ....  4510.436738: sched_process_fork: comm=bash pid=1649 child_comm=bash child_pid=4348</span><br><span class="line">--</span><br><span class="line">            bash-1649  [000] d...  4510.844339: sched_waking: comm=kworker/u256:2 pid=3393 prio=120 target_cpu=000</span><br><span class="line">            bash-1649  [000] d...  4510.844340: sched_wakeup: comm=kworker/u256:2 pid=3393 prio=120 target_cpu=000</span><br><span class="line">            bash-1649  [000] d...  4510.844421: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="ls"</span><br><span class="line">            bash-1649  [000] d...  4510.844476: sched_stat_runtime: comm=bash pid=1649 runtime=148935 [ns] vruntime=8124989109 [ns]</span><br><span class="line">            bash-1649  [000] ....  4510.844549: sched_process_fork: comm=bash pid=1649 child_comm=bash child_pid=4354</span><br><span class="line">--</span><br><span class="line">            bash-1649  [000] d...  4515.309199: sched_waking: comm=kworker/u256:2 pid=3393 prio=120 target_cpu=000</span><br><span class="line">            bash-1649  [000] d...  4515.309200: sched_wakeup: comm=kworker/u256:2 pid=3393 prio=120 target_cpu=000</span><br><span class="line">            bash-1649  [000] d...  4515.309271: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="cd probe_bash/"</span><br><span class="line">            bash-1649  [000] d...  4515.309421: sched_stat_runtime: comm=bash pid=1649 runtime=243557 [ns] vruntime=8128041748 [ns]</span><br><span class="line">            bash-1649  [000] ....  4515.309492: sched_process_fork: comm=bash pid=1649 child_comm=bash child_pid=4361</span><br><span class="line">--</span><br><span class="line">            bash-1649  [000] d...  4515.795429: sched_waking: comm=kworker/u256:2 pid=3393 prio=120 target_cpu=000</span><br><span class="line">            bash-1649  [000] d...  4515.795430: sched_wakeup: comm=kworker/u256:2 pid=3393 prio=120 target_cpu=000</span><br><span class="line">            bash-1649  [000] d...  4515.795500: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="ls"</span><br><span class="line">            bash-1649  [000] d...  4515.795555: sched_stat_runtime: comm=bash pid=1649 runtime=138497 [ns] vruntime=8128576492 [ns]</span><br><span class="line">            bash-1649  [000] ....  4515.795628: sched_process_fork: comm=bash pid=1649 child_comm=bash child_pid=4366</span><br><span class="line">--</span><br><span class="line">  kworker/u256:2-3393  [000] d...  4517.849441: sched_stat_runtime: comm=kworker/u256:2 pid=3393 runtime=1579 [ns] vruntime=11405903803 [ns]</span><br><span class="line">  kworker/u256:2-3393  [000] d...  4517.849441: sched_switch: prev_comm=kworker/u256:2 prev_pid=3393 prev_prio=120 prev_state=R+ ==&gt; next_comm=sshd next_pid=1645 next_prio=120</span><br><span class="line">            bash-1649  [001] d...  4517.849473: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="cat enable "</span><br><span class="line">            bash-1649  [001] d...  4517.849531: sched_stat_runtime: comm=bash pid=1649 runtime=160328 [ns] vruntime=10110004768 [ns]</span><br><span class="line">            sshd-1645  [000] d...  4517.849543: sched_stat_runtime: comm=sshd pid=1645 runtime=101818 [ns] vruntime=1177932308 [ns]</span><br><span class="line">--</span><br><span class="line">  kworker/u256:2-3393  [000] d...  4518.326292: sched_stat_runtime: comm=kworker/u256:2 pid=3393 runtime=1559 [ns] vruntime=11405998988 [ns]</span><br><span class="line">  kworker/u256:2-3393  [000] d...  4518.326293: sched_switch: prev_comm=kworker/u256:2 prev_pid=3393 prev_prio=120 prev_state=R+ ==&gt; next_comm=sshd next_pid=1645 next_prio=120</span><br><span class="line">            bash-1649  [001] d...  4518.326323: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="ls"</span><br><span class="line">            bash-1649  [001] d...  4518.326377: sched_stat_runtime: comm=bash pid=1649 runtime=155566 [ns] vruntime=10126596805 [ns]</span><br><span class="line">            sshd-1645  [000] d...  4518.326390: sched_stat_runtime: comm=sshd pid=1645 runtime=97022 [ns] vruntime=1178607048 [ns]</span><br><span class="line">--</span><br><span class="line">          &lt;idle&gt;-0     [001] d...  4525.694161: sched_switch: prev_comm=swapper/1 prev_pid=0 prev_prio=120 prev_state=S ==&gt; next_comm=bash next_pid=1649 next_prio=120</span><br><span class="line">            bash-1649  [001] d...  4525.694175: sched_waking: comm=kworker/u256:2 pid=3393 prio=120 target_cpu=000</span><br><span class="line">            bash-1649  [001] d...  4525.694257: readline: (0x41e6ea &lt;- 0x48aaf0) arg1="echo "0" &gt; enable"</span><br><span class="line">          &lt;idle&gt;-0     [000] dNh.  4525.694323: sched_wakeup: comm=kworker/u256:2 pid=3393 prio=120 target_cpu=000</span><br><span class="line">            bash-1649  [001] d...  4525.694327: sched_stat_runtime: comm=bash pid=1649 runtime=168870 [ns] vruntime=10131670237 [ns]</span><br></pre></td></tr></table></figure><p>OK，此时就可以同时追踪kproble和uprobe了。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Quickwords29：AMD ZEN 2 Microarchitecture Overview</title>
      <link href="/2019/06/12/quickwords29-amd-zen2-microarch/"/>
      <url>/2019/06/12/quickwords29-amd-zen2-microarch/</url>
      
        <content type="html"><![CDATA[<h2 id="AMD-ZEN-2"><a href="#AMD-ZEN-2" class="headerlink" title="AMD ZEN 2"></a>AMD ZEN 2</h2><p>在消费者和服务器市场AMD推出了全新的基于ZEN 2微架构的处理器，包括Ryzen 3000系列和EPYC系列。在市场宣传方面均给出了高于Intel竞品处理器的性能。我这里还没有拿到实际的产品进行性能测试，但可以先从公开的微架构设计的角度看一看AMD这款新产品的大体思路。</p><h2 id="Microarchitecture-Overview"><a href="#Microarchitecture-Overview" class="headerlink" title="Microarchitecture Overview"></a>Microarchitecture Overview</h2><p><img src="https://images.anandtech.com/doci/14525/Mike_Clark-Next_Horizon_Gaming-CPU_Architecture_06092019-page-003.jpg" alt=""></p><p>上图是ZEN 2产品的微架构示意图。从微架构的“架构”设计上，感觉业界基本上遵从了同一套模式，很难有创新和突破。均是基于以下三个部分：<br><a id="more"></a></p><ul><li>前端，用于取指令和解码</li><li>后端，用于执行</li><li>存储，用于读取缓存和主存中的数据</li></ul><p>和我们之前分析过的Intel Skylake的微架构，或者所有近期以及可预见的未来的CPU的微架构都相类似。</p><p>对微架构的改进基本上只存在于对各类buffer或cache的容量扩充方面。例如图中提到的：</p><ul><li>Micro-Op Cache扩容至4K条，加快解码速度</li><li>更大的L3 Cache</li><li>180个Rename Register，消除False dependency，提高指令并行度</li><li>更多的AGU和指令执行单元</li></ul><p>其他的包括前端4 instructions/cycle的Dercode效率，以及6 ops/cycle的微指令发射效率，和之前介绍的Skylake类似。但也肯定存在指令长度等方面的限制。</p><p>另外在Reservation Station和Re-order buffer方面图中并未给出详细说明，统一合并在了Scheduler中。在Integer部分貌似是多Scheduler的设计，应该是这种设计能够进一步提升指令并行程度，需要进一步资料说明。</p><p>而对AVX指令集的支持当前是有了<code>single-op AVX256</code>的支撑，之前AMD上的AVX指令<strong>据说</strong>是多条指令“模拟”出来的。</p><p><img src="https://images.anandtech.com/doci/14525/Mike_Clark-Next_Horizon_Gaming-CPU_Architecture_06092019-page-004.jpg" alt=""></p><p>这一页仍是对另外一些特性的说明，除了对Cache系统的常规介绍之外，特意提到了处理器安全方面的特性，估计是体现出与最近饱受安全漏洞困扰的Intel产品的“差异性”  笑）。</p><h2 id="处理器的未来发展"><a href="#处理器的未来发展" class="headerlink" title="处理器的未来发展"></a>处理器的未来发展</h2><p>至于AMD的ZEN 2新架构是否真的在一些通用的业务场景中有良好的性能表现，还需要实际业务的检验。但当前处理器的设计真的进入了一个明显的瓶颈期，主要包括以下几点体现：</p><ul><li>主频上不去</li><li>制程挤牙膏</li><li>性能靠猜测</li><li>猜测带来安全漏洞</li><li>缓存相干性(Cache coherence )和内存一致性(Memory consistency)必须遵循</li><li>核间通讯速率仍是瓶颈</li></ul><p>当前的一些应对方法：</p><ul><li>更大的各种缓存</li><li>更多的核</li><li>针对专门业务的指令集</li><li>针对专门业务的专门处理模块</li><li>铲除网络上的负面新闻 笑）</li></ul><p>总之在软件性能上，CPU也就只能帮你到这了，但软件本身其实锁死了很多硬件的性能无法得到释放，后面的优化必须靠精细的软件性能调优。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>拔智齿</title>
      <link href="/2019/06/05/tooth-extraction/"/>
      <url>/2019/06/05/tooth-extraction/</url>
      
        <content type="html"><![CDATA[<p>拔智齿是一个磨人的过程。真正拔的时候其实还好，但决定去拔之前，要做很多心理建设工作。尤其是对牙一直很好的人来说，去拔牙就仿佛承认了之前对牙齿的乐观和与之俱来的优越感都只是一场幻觉。<br><a id="more"></a></p><p>打破自我感觉良好的幻觉，对谁来说都需要一点点时间。</p><p>我这颗智齿其实长了两三年了。最开始冒尖的时候我还挺兴奋，仿佛牙龈中埋藏了一股神秘的身体机能，能带我二次发育。但后来当我意识到它就只能这样一直埋藏了之后，虽然不能说完全没有遗憾，但仍然庆幸至少它没有给我带来疼痛——在两年之内。</p><p>最近它开始疼得厉害，吃饭不敢用它所在的那一边咀嚼。但给人遐想空间的是，有时候它又完全不痛，让我不得不思考，是不是我“牙好”的人设开启了不痛光环。对我来说，牙是不是疼不重要，重要的是人设不能崩。</p><p>但我犯贱的地方就是，越是不疼的时候，越想知道以后是不是也不会疼。所以会在不痛的时候，故意用智齿去咀嚼。在咬合的瞬间，确实有一种赌博的快感。但十赌九输，往往是疼得打一个冷颤，又要接受一次人设崩塌的现实。</p><p>决定去拔牙，是在今年年初。时光无情地让我又长了一岁，以往我总会表现得后知后觉，但这次也不知道哪里来得觉悟，我打算有所改变，打算承认自己的变化，打算不再坚持那些让自己费力坚持却并没有感觉到意义的事情。想通这些之后，马上找了黄牛(aka挂号天使)，约了第二天的号，一共在医院呆了一个小时，散去千元，和一颗不愿离我而去的老友。</p><p>拔完之后，浑身有一种甩掉十斤肥肉的轻松。如果逐渐承认自己的普通是必然要发生的事情，那么我希望能用一种不普通的方式看待它。</p>]]></content>
      
      
      <categories>
          
          <category> life </category>
          
      </categories>
      
      
        <tags>
            
            <tag> life </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Gartner预测误差统计</title>
      <link href="/2019/06/03/gartner-prediction/"/>
      <url>/2019/06/03/gartner-prediction/</url>
      
        <content type="html"><![CDATA[<h2 id="Gartner的预测"><a href="#Gartner的预测" class="headerlink" title="Gartner的预测"></a>Gartner的预测</h2><p>Gartner表面上是一家咨询公司，实际上是一家市场公关公司。不仅通过一些市场工具给厂商打广告，还直接给某样技术打广告，当然也兼做一些资源对接的中介服务。至于Gartner的分析报告，即便每年需要几十万的“咨询费”才能阅读，但我是从来没有完整看完过其中任何一篇，因为他们报告的题目都拟得非常好——非常精炼，也非常准确——所以有时候看完题目就好了。</p><p>每当Gartner新公布了一项市场数字和指标之后，都会被各家媒体和相关厂商疯狂引用，作为论证市场繁荣和增长预期的最有力论据。但年复一年，我们永远盯住的是“下一个丰收的年景”，却不怎么关心当下的市场是否曾被准确勾画。以往知来，我们就以年年火热的云计算市场为例，统计一下Gartner的历史预测准确率。<br><a id="more"></a></p><h2 id="Year-2016"><a href="#Year-2016" class="headerlink" title="Year 2016"></a>Year 2016</h2><p>我曾尝试寻找一个历年实际市场规模统计，但我发现这个数字并不存在。公布的数据，要么没有写明数据来源，要么就是引用的Gartner的数据。所以应该是并没有一个公认的实际的市场规模存在。</p><p>改变一下策略，我们就让Gartner自己的数据和自己对比。在其2013年发布的报告中已经预测了2016年的全球<strong>公有云</strong>市场规模，在其2017年公布的报告中也写明了2016年的全球<strong>公有云</strong>市场规模。分别如下：</p><p><img src="https://s2.ax1x.com/2019/06/03/VJmPu4.jpg" alt="2013年预测报告，来源参考资料[2]"></p><p><img src="https://s2.ax1x.com/2019/06/03/VJmiDJ.jpg" alt="2017年预测报告，来源参考资料[3]"></p><p>可以看出，针对重合的2016年，2013年预测的市场规模为<strong>2100亿</strong>美元，2017年Gartner报告中给出的实际市场规模为<strong>2196亿</strong>美元，二者相差非常小。</p><p>是否可以认为Gartner的预测非常靠谱呢？我们再搜索一下。</p><p>根据中国信息通信研究院2018年8月发布的《云计算发展白皮书（2018年）》中的数据，全球公有云市场规模如下图：</p><p><img src="https://s2.ax1x.com/2019/06/03/VJm8UI.jpg" alt=""></p><p>这里就出现了诡异的情况。在该白皮书中给出的”全球云计算市场规模”中，2016年的数字仅为859亿美元，仅为上面两篇Gartner的报告中数字的<strong>40%</strong>。而更不可理解的是，该图右下角表明数据来源就是Gartner。</p><blockquote><p>补充一下，虽然图注中写的是“全球云计算市场规模及增速”，但从报告上下文来看，其实是“全球<strong>公有云</strong>市场规模及增速”。</p></blockquote><p>信通院报告中的数字我并没有在Gartner的报告中找到，当然也可能是因为我没充会员。但网络上却充斥着引用这两组数据的新闻和所谓市场深度分析，全然罔顾二者相差60%的事实。所以说啊，那些媒体上言之凿凿的市场预测，其实不过是批量生产的未加考证的人云亦云罢了。</p><p>还有一点是，另外一家叫做“前瞻产业研究院”的分析机构也曾对全球公有云市场规模做过统计并给出数据结果，它统计2016年的市场规模仅为<strong>654.83亿</strong>美元，如下图：</p><p><img src="http://upload.idcquan.com/2018/0412/1523526226701.jpg" alt=""></p><p>应当说，对全球云计算市场的定量市场统计和分析工作，当前还处于不靠谱的阶段。市场认的只是品牌效应。虽然此篇分析仅仅针对云计算市场，但有理由怀疑其他市场，特别是新兴市场，也存在类似的现象。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] 中国信息通信研究院 《云计算发展白皮书（2018年）》<a href="http://www.caict.ac.cn/kxyj/qwfb/bps/201808/P020180813540725575770.pdf" target="_blank" rel="noopener">http://www.caict.ac.cn/kxyj/qwfb/bps/201808/P020180813540725575770.pdf</a></p><p>[2]  Forbes “Gartner Predicts Infrastructure Services Will Accelerate Cloud Computing Growth” <a href="https://www.forbes.com/sites/louiscolumbus/2013/02/19/gartner-predicts-infrastructure-services-will-accelerate-cloud-computing-growth/#45be65611938" target="_blank" rel="noopener">https://www.forbes.com/sites/louiscolumbus/2013/02/19/gartner-predicts-infrastructure-services-will-accelerate-cloud-computing-growth/#45be65611938</a></p><p>[3] Enterprise Irregulars “Cloud Computing Market Projected To Reach $411B By 2020” <a href="https://www.enterpriseirregulars.com/120106/cloud-computing-market-projected-reach-411b-2020/" target="_blank" rel="noopener">https://www.enterpriseirregulars.com/120106/cloud-computing-market-projected-reach-411b-2020/</a></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去14：Phoronix tinymembench结果不理想的可能原因</title>
      <link href="/2019/05/28/test14-phoronix-tinymembench/"/>
      <url>/2019/05/28/test14-phoronix-tinymembench/</url>
      
        <content type="html"><![CDATA[<h2 id="Phoronix-tinymembench"><a href="#Phoronix-tinymembench" class="headerlink" title="Phoronix tinymembench"></a>Phoronix tinymembench</h2><p>这个测试经常用来衡量CPU<code>memcpy</code>和<code>memset</code>这两个基本操作的性能。最近在执行针对两款CPU的性能测试中，发现某款相对”高端“的CPU在这两个测试中表现与相对“低端”的CPU相比，存在较大差距。<br><a id="more"></a></p><blockquote><p>当然，高端和低端只是一般印象，具体各个细节参数也需要具体衡量</p></blockquote><p>并且差距不是一般的明显，所以需要调查一下<code>Phoronix tinymembench</code>具体是如何执行测试的。</p><h2 id="Source-code"><a href="#Source-code" class="headerlink" title="Source code"></a>Source code</h2><p>在这里找到了<code>tinymembench</code>的源码：</p><p><a href="https://github.com/ssvb/tinymembench/blob/master/main.c" target="_blank" rel="noopener">https://github.com/ssvb/tinymembench/blob/master/main.c</a></p><p>按照小学语文的一般叙述顺序，我们介绍一下“首先映入眼帘”的：</p><p><code>#define SIZE             (32 * 1024 * 1024)</code></p><p>后面的源码先不用看了，这个是定义了一个32MB的长度，基本上可以认为是执行<code>memcpy</code>和<code>memset</code>的内存大小。</p><p>再看一下执行测试的两块CPU的L3 Cache大小，结果好的那个有64MB，结果不好的那个只有30MB。</p><p>为了验证猜测，把这个指改为<code>16 * 1024 * 1024</code>，原本结果不好的CPU的测试成绩就取得了反超。</p><h2 id="不要灰心"><a href="#不要灰心" class="headerlink" title="不要灰心"></a>不要灰心</h2><p>像这种CPU测试工具，如果测试成绩不好，真的需要深入挖掘一下，也许是这个测试不适用于你CPU的体质。不过如果测试成绩好，那说明确实挺好的 :)</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去13：DPDK i40e X710 FDIR Flexbytes</title>
      <link href="/2019/05/23/test13-dpdk-x710-flexload/"/>
      <url>/2019/05/23/test13-dpdk-x710-flexload/</url>
      
        <content type="html"><![CDATA[<h2 id="Flex-Bytes"><a href="#Flex-Bytes" class="headerlink" title="Flex Bytes"></a>Flex Bytes</h2><p>700系列网卡除了提取包头的字段作为散列的依据之外，还可以截取Payload的特定片段作为散列的依据。</p><p>Flexible payload是可以识别出的L2/L3/L4 Header之后的字节，最多可以截取来自于3个不同偏移（OFFSET）的16字节内容。所有的内容需要来自该报文前480字节内。<br><a id="more"></a></p><blockquote><p>如果是TCP的报文，因为网卡可以识别出L4 Header，则只能针对TCP的Payload进行匹配处理，而不能将TCP Header当作L3或L2的Payload处理。</p></blockquote><h2 id="Testpmd-CMD"><a href="#Testpmd-CMD" class="headerlink" title="Testpmd CMD"></a>Testpmd CMD</h2><p>测试方法可以参考DPDK的官方文档：</p><p><a href="https://doc.dpdk.org/dts/test_plans/generic_flow_api_test_plan.html#test-case-fortville-fdir-for-flexbytes" target="_blank" rel="noopener">https://doc.dpdk.org/dts/test_plans/generic_flow_api_test_plan.html#test-case-fortville-fdir-for-flexbytes</a></p><p>提示一下需要注意的点：</p><ul><li><p>每次设定偏移时，是从前一个偏移结束之后开始计算<code>relative</code>的值，如果前面没有偏移，则从Payload的第一个字节开始计算。</p></li><li><p><code>relative</code>的位置加偏移的长度，是需要匹配的模式（pattern）的具体内容的起始位置</p></li><li><p>在此节最后：</p></li></ul><blockquote><p>check pkt1 to pkt5 are received by queue 1 to queue 5, pkt6 to queue 0, pkt7 to queue6. pkt8 to queue7, pkt8 and pkt9 to queue 0.</p></blockquote><p>这里面似乎最后应该改为<code>pkt9 and pkt10 to queue0</code>。</p><h2 id="Mask"><a href="#Mask" class="headerlink" title="Mask"></a>Mask</h2><p>还有一个问题没有解决，就是Flexbytes如何加Mask。实际上在i40e驱动的<code>i40e_flow.c</code>中提供了设定Mask的接口<code>i40e_flow_store_flex_mask</code>。但直接用该命令会导致报错。具体原因还需要后续挖掘。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> NIC </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>统治者为什么会重复犯同样的错误</title>
      <link href="/2019/05/22/thoughts9-identical-behavior/"/>
      <url>/2019/05/22/thoughts9-identical-behavior/</url>
      
        <content type="html"><![CDATA[<p>史书上对自己作死的亡国之君的描述基本上都是类似的。用查找替换把两个名字换一下，基本不影响阅读体验。</p><p>奇怪的点就在于，从第二个亡国之君开始，为什么明明知道已有“亡国之兆”，却仍然不加收敛？<br><a id="more"></a></p><p>谁都不傻，谁都不想亡国，谁都知道这点事，为啥就控制不住呢？</p><p>如果没有身处统治者的位置，很像理解为什么统治者都会重复犯同样的错误。</p><p>亡国之君之所以犯同样的错误，就在于他清醒地知道自己的权力正在流失。</p><p>权力到底是什么定义，我们不去争论，但“有权力”的表面意思就是可以强迫别人去做自己不愿意做的事情。</p><p>统治者最怕的是他会倒台，所以他需要确认自己还握有权力。并且在权力实际在流失的情况下，为了更能说服自己“权力没有流失”，需要确认的就不仅仅是”原有权力没有失效“，而是权力不但没有流失，反而得到了增长。</p><p>这是统治者对这个世界的预期。他必须保证他对世界的预期，与实际情况保持一致。</p><p>从这一点上讲，大家都没有区别。并且他需要的并非真的是客观上如何如何，而纯粹是自己主观上的感受。</p><p>并非是他们不知道这样会有问题，也不是无法克服对肉体享乐的欲念，而是如果不这样做，他们的问题会更大。预期与实际相一致，是一切人类活动的原动力。</p><p>所以必须强迫更多的人做他们不愿意做的事，不断给自己加强“我的权力仍在增长”的印象。</p><p>同时也在进一步加速权力的流失。</p><p>所以，历史总是会重演，太阳也总是观看重复的桥段。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Quickwords28：Skylake Microarchitecture(11)</title>
      <link href="/2019/05/18/quickwords28-skylake-pipeline-11/"/>
      <url>/2019/05/18/quickwords28-skylake-pipeline-11/</url>
      
        <content type="html"><![CDATA[<h2 id="Store-and-Load-Example"><a href="#Store-and-Load-Example" class="headerlink" title="Store and Load Example"></a>Store and Load Example</h2><p>Given the initialized situation like this:</p><a id="more"></a><p><img src="https://s2.ax1x.com/2019/05/17/ELdlTO.png" alt=""></p><p>At  the start time, several store and load instructions are streamed to <code>Load-Store Queue(LSQ)</code>. And four <code>address-value</code> pairs are stored in the cache.</p><p><img src="https://s2.ax1x.com/2019/05/17/ELdQ0K.png" alt=""></p><p>We start with the first instruction from the <code>LSQ</code>: <code>load from addr 0x3290</code>.</p><p>It will firstly check if there are previous <code>store</code> instruction which stores value at the identical address. As it is the first instruction, there won’t be any <code>store</code> instruction satisfies this requirement.</p><p>Then it looks up to the cache for a hit. In our situation, indeed there is a cache-hit and value <code>42</code> is found and streamed to the corresponding location in the <code>Value</code> Column of the LSQ.</p><p><img src="https://s2.ax1x.com/2019/05/17/ELdMm6.png" alt=""></p><p>Go on with the next <code>store</code> instruction. Assume that the value, 25, of the <code>store</code> instruction has been calculated and it is stored directly into the <code>Value</code> Column of the LSQ. </p><blockquote><p>Note: value will be updated into cache only after the commit phase of <code>store</code> instruction.</p></blockquote><p><img src="https://s2.ax1x.com/2019/05/17/ELduOx.png" alt=""></p><p>Next <code>store</code> instruction shares similar story. Assume the calculated value of the <code>store</code> instruction is -17.</p><p><img src="https://s2.ax1x.com/2019/05/17/ELdn61.png" alt=""></p><p>Next <code>load</code> instruction will, no exception, check if there are previous <code>store</code> instruction stores value at the identical memory address. No <code>store</code> instructions associated with address<code>0x3418</code> so it then come to cache for a hint. Therefore, 1234 stores to the <code>Value</code> Column.</p><p><img src="https://s2.ax1x.com/2019/05/17/ELd8te.png" alt=""></p><p>Next <code>load</code> instruction. And it can find a previous <code>store</code> instruction stores to the identical address, <code>0x3290</code>. It will read the value of the <code>store</code> instruction directly to its <code>Value</code> Column.</p><p>This is a <code>store-forward</code> operation. </p><p><img src="https://s2.ax1x.com/2019/05/17/ELdYpd.png" alt=""></p><p>Next <code>load</code> instruction will also firstly do a search on previous <code>store</code> instructions and obviously, it fails. Then cache will provide with the value <code>1</code> to this <code>load</code>.</p><p><img src="https://s2.ax1x.com/2019/05/17/ELd3kD.png" alt=""></p><p>Next <code>store</code>, 0 is calculated and puts into the <code>Value</code> Column.</p><p><img src="https://s2.ax1x.com/2019/05/17/ELdGfH.png" alt=""></p><p>Next <code>load</code>, a <code>store-forward</code> occurs again. 25 is read out and put into the <code>Value</code> Column.</p><p><img src="https://s2.ax1x.com/2019/05/18/EOa09H.png" alt=""></p><p>For the next <code>load</code> instruction, there will be multiple results return from the search. But it only accept the value returns from the nearest <code>store</code> instruction. Therefore, 0 is put into the <code>Value</code> Column.</p><p><img src="https://s2.ax1x.com/2019/05/18/EOaB3d.png" alt=""></p><p>The last <code>load</code> instruction will read value from cache.</p><p>Then, instruction will be committed.</p><p><img src="https://s2.ax1x.com/2019/05/18/EOdEPe.png" alt=""></p><p>For <code>load</code> instruction, it is just simply dequeue from the LSQ as the value is loaded to the register already at the execution phase.</p><p><img src="https://s2.ax1x.com/2019/05/18/EOdurt.png" alt=""></p><p>For <code>store</code> instruction, the value is updated to cache and then dequeue.</p><p><img src="https://s2.ax1x.com/2019/05/18/EOdexA.png" alt=""></p><p>Next <code>store</code> instruction, similar instruction, value is stored to cache and dequeue.</p><p><img src="https://s2.ax1x.com/2019/05/18/EOdZ2d.png" alt=""></p><p>Next three <code>load</code> instructions, dequeue.</p><p><img src="https://s2.ax1x.com/2019/05/18/EOdV8H.png" alt=""></p><p><code>store</code>, updates cache.</p><p><img src="https://s2.ax1x.com/2019/05/18/EOdnKI.png" alt=""></p><p>Last three <code>load</code> instructions, dequeue.</p><p>The reason why <code>store</code> only updates cache at the commit phase is that if the processor detects a prediction failure in the pipeline and the instructions after the last <code>store</code> instruction need to be flushed, the status of cache is not impacted and instructions at the correct branch can pretend to start with the untouched status.</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去12：DPDK i40e X710 Flow Director Deep Dive(3)</title>
      <link href="/2019/05/14/test12-dpdk-x710-fdir-mask-3/"/>
      <url>/2019/05/14/test12-dpdk-x710-fdir-mask-3/</url>
      
        <content type="html"><![CDATA[<h2 id="多于两个input-set的mask"><a href="#多于两个input-set的mask" class="headerlink" title="多于两个input_set的mask"></a>多于两个<code>input_set</code>的mask</h2><p>先说结论，一个<code>pctype</code>可以设置多个<code>input_set</code>，但是最多仅能给两个<code>input_set</code>设置mask。<br><a id="more"></a></p><p>可以修改代码给三个或多个<code>input_set</code>设置mask，但仅仅前两个mask能生效。同时这应该是比较危险的行为，<em>不要随意尝试</em>。</p><p>提供一下代码的修改方法…..算了….验证了不能用心里也就无憾了….就不再发出来了。</p><p>这里针对710系列的fdir特性总结一下：</p><ul><li>可以针对不同的<code>pctype</code>配置<code>input_set</code></li><li>可以针对不同的<code>pctype</code>配置<code>input_set</code>的mask</li><li>属于针对同一种<code>pctype</code>的fdir规则，共享<code>input_set</code>和mask的配置</li><li>同一个<code>pctype</code>最多给两个<code>input_set</code>配置mask</li></ul><p>可用的配置方式请参见前三节：</p><p><a href="https://decodezp.github.io/2019/05/06/test9-x710-fdir-mask/">测来测去9：DPDK i40e XXV710 Flow Director Mask Configuration</a></p><p><a href="https://decodezp.github.io/2019/05/11/test10-dpdk-x710-fdir-mask-1/">测来测去10：DPDK i40e X710 Flow Director Deep Dive(1)</a></p><p><a href="https://decodezp.github.io/2019/05/13/test11-dpdk-x710-fdir-mask-2/">测来测去11：DPDK i40e X710 Flow Director Deep Dive(2)</a></p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> NIC </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去11：DPDK i40e X710 Flow Director Deep Dive(2)</title>
      <link href="/2019/05/13/test11-dpdk-x710-fdir-mask-2/"/>
      <url>/2019/05/13/test11-dpdk-x710-fdir-mask-2/</url>
      
        <content type="html"><![CDATA[<h2 id="同时添加一个TCP-Flow-Director规则"><a href="#同时添加一个TCP-Flow-Director规则" class="headerlink" title="同时添加一个TCP Flow Director规则"></a>同时添加一个TCP Flow Director规则</h2><p>在<a href="https://decodezp.github.io/2019/05/11/test10-dpdk-x710-fdir-mask-1/">上一篇文章</a>的基础上，添加一个TCP相关的Fdir操作：<br><a id="more"></a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_fdir_filter</span> <span class="title">arg_tcpport</span> = &#123;</span></span><br><span class="line">    .soft_id = <span class="number">3</span>,</span><br><span class="line">    .input   = &#123;</span><br><span class="line">        .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_TCP,</span><br><span class="line">        .flow = &#123;</span><br><span class="line">           .tcp4_flow = &#123;</span><br><span class="line">                .dst_port = <span class="number">0x10</span>, </span><br><span class="line">           &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    .action  = &#123;</span><br><span class="line">        .rx_queue  =  <span class="number">1</span>,</span><br><span class="line">        .behavior  = RTE_ETH_FDIR_ACCEPT,</span><br><span class="line">        .report_status = RTE_ETH_FDIR_REPORT_ID,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>只填写了TCP目的端口匹配4096(0x1000)的一条匹配规则。</p><p>之后按照UDP的操作方法，配置一下先仅仅将TCP目的端口加入<code>input_set</code>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">memset</span>(&amp;info, <span class="number">0</span>, <span class="keyword">sizeof</span>(info));</span><br><span class="line">info.info_type = RTE_ETH_FDIR_FILTER_INPUT_SET_SELECT;</span><br><span class="line">info.info.input_set_conf.flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_TCP;</span><br><span class="line">info.info.input_set_conf.field[<span class="number">0</span>] = RTE_ETH_INPUT_SET_L4_TCP_DST_PORT;</span><br><span class="line">info.info.input_set_conf.inset_size = <span class="number">1</span>;</span><br><span class="line">info.info.input_set_conf.op = RTE_ETH_INPUT_SET_SELECT;</span><br><span class="line"></span><br><span class="line">ret = rte_eth_dev_filter_ctrl(<span class="number">0</span>, RTE_ETH_FILTER_FDIR, </span><br><span class="line">                                                           RTE_ETH_FILTER_SET, &amp;info);</span><br><span class="line">        </span><br><span class="line">ret = rte_eth_dev_filter_ctrl(<span class="number">0</span>, RTE_ETH_FILTER_FDIR,</span><br><span class="line">                                                           RTE_ETH_FILTER_ADD, &amp;arg_tcpport);</span><br></pre></td></tr></table></figure><p>L3fwd跑一下：</p><p><code>./l3fwd -c 0x1ffff -- -p 0x3 -P --config=&quot;(0,0,1),(0,1,2),(0,2,2),(1,0,3),(1,1,4),(1,2,4)&quot;</code></p><p>此时仅有目的端口号为4096的TCP报文可以进入<code>Queue1</code>。</p><p>再给<code>input_set</code>加入一个源端口SRC_PORT：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">memset</span>(&amp;info, <span class="number">0</span>, <span class="keyword">sizeof</span>(info));</span><br><span class="line">info.info_type = RTE_ETH_FDIR_FILTER_INPUT_SET_SELECT;</span><br><span class="line">info.info.input_set_conf.flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_TCP;</span><br><span class="line">info.info.input_set_conf.field[<span class="number">0</span>] = RTE_ETH_INPUT_SET_L4_TCP_DST_PORT;</span><br><span class="line">info.info.input_set_conf.field[<span class="number">1</span>] = RTE_ETH_INPUT_SET_L4_TCP_SRC_PORT;</span><br><span class="line">info.info.input_set_conf.inset_size = <span class="number">2</span>;</span><br><span class="line">info.info.input_set_conf.op = RTE_ETH_INPUT_SET_SELECT;</span><br><span class="line"></span><br><span class="line">ret = rte_eth_dev_filter_ctrl(<span class="number">0</span>, RTE_ETH_FILTER_FDIR, </span><br><span class="line">                                     RTE_ETH_FILTER_SET, &amp;info);</span><br><span class="line">        </span><br><span class="line">ret = rte_eth_dev_filter_ctrl(<span class="number">0</span>, RTE_ETH_FILTER_FDIR,</span><br><span class="line">                                     RTE_ETH_FILTER_ADD, &amp;arg_tcpport);</span><br></pre></td></tr></table></figure><p>因为在<code>arg_tcpport</code>中没有配置具体的源端口号，所以此时只有目的端口是4096，且源端口号为默认值0的TCP报文能够进入Queue1。</p><p>当然也可以加上：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_fdir_filter</span> <span class="title">arg_tcpport</span> = &#123;</span></span><br><span class="line">    .soft_id = <span class="number">3</span>,</span><br><span class="line">    .input   = &#123;</span><br><span class="line">        .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_TCP,</span><br><span class="line">        .flow = &#123;</span><br><span class="line">           .tcp4_flow = &#123;</span><br><span class="line">                .dst_port = <span class="number">0x10</span>, </span><br><span class="line">     .src_port = <span class="number">1234</span>, <span class="comment">//1234=&gt;0x04d2=&gt;0xd204=&gt;53764</span></span><br><span class="line">           &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    .action  = &#123;</span><br><span class="line">        .rx_queue  =  <span class="number">1</span>,</span><br><span class="line">        .behavior  = RTE_ETH_FDIR_ACCEPT,</span><br><span class="line">        .report_status = RTE_ETH_FDIR_REPORT_ID,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><blockquote><p>注意虽然<code>.src_port</code>填写了<code>1234</code>，但匹配的TCP源端口号是53764，具体的推导步骤见注释。</p></blockquote><h2 id="同时配置UDP掩码和TCP掩码"><a href="#同时配置UDP掩码和TCP掩码" class="headerlink" title="同时配置UDP掩码和TCP掩码"></a>同时配置UDP掩码和TCP掩码</h2><p>到此，可以以掩码匹配UDP报文，并且精确匹配TCP报文，那么TCP的Flow Director规则是否也可以添加掩码呢？</p><p>先仿照UDP的方式给TCP的目的端口添加一个掩码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rte_pmd_i40e_inset_get(<span class="number">0</span>, <span class="number">33</span>, &amp;inset, INSET_FDIR); <span class="comment">//tcp</span></span><br><span class="line">inset.mask[<span class="number">0</span>].field_idx = <span class="number">30</span>;</span><br><span class="line">inset.mask[<span class="number">0</span>].mask = <span class="number">0x0fff</span>;</span><br><span class="line">ret = rte_pmd_i40e_inset_set(<span class="number">0</span>, <span class="number">33</span>, &amp;inset, INSET_FDIR);</span><br></pre></td></tr></table></figure><p>此时源端口为53764，目的端口为4096-8191的TCP报文都可以进入Queue1。<br>同时UDP的匹配规则不受影响。</p><p>单独给TCP的源端口加一个掩码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rte_pmd_i40e_inset_get(<span class="number">0</span>, <span class="number">33</span>, &amp;inset, INSET_FDIR); <span class="comment">//tcp</span></span><br><span class="line">inset.mask[<span class="number">0</span>].field_idx = <span class="number">29</span>;</span><br><span class="line">inset.mask[<span class="number">0</span>].mask = <span class="number">0x0fff</span>;</span><br><span class="line">ret = rte_pmd_i40e_inset_set(<span class="number">0</span>, <span class="number">33</span>, &amp;inset, INSET_FDIR);</span><br></pre></td></tr></table></figure><p>当然按照上一篇介绍的规则，<code>arg_tcpport</code>也需要相应修改一下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_fdir_filter</span> <span class="title">arg_tcpport</span> = &#123;</span></span><br><span class="line">    .soft_id = <span class="number">3</span>,</span><br><span class="line">    .input   = &#123;</span><br><span class="line">        .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_TCP,</span><br><span class="line">        .flow = &#123;</span><br><span class="line">           .tcp4_flow = &#123;</span><br><span class="line">                .dst_port = <span class="number">0x10</span>, </span><br><span class="line">     .src_port = <span class="number">0x20</span>,</span><br><span class="line">           &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    .action  = &#123;</span><br><span class="line">        .rx_queue  =  <span class="number">1</span>,</span><br><span class="line">        .behavior  = RTE_ETH_FDIR_ACCEPT,</span><br><span class="line">        .report_status = RTE_ETH_FDIR_REPORT_ID,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>此时源端口为8192-12287，目的端口为4096的TCP报文都可以进入Queue1。且不影响UDP的匹配规则。</p><h2 id="设置两条掩码规则"><a href="#设置两条掩码规则" class="headerlink" title="设置两条掩码规则"></a>设置两条掩码规则</h2><p>给TCP的目标目的端口增加一个掩码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">rte_pmd_i40e_inset_get(<span class="number">0</span>, <span class="number">33</span>, &amp;inset, INSET_FDIR); <span class="comment">//tcp</span></span><br><span class="line">inset.mask[<span class="number">0</span>].field_idx = <span class="number">29</span>;</span><br><span class="line">inset.mask[<span class="number">0</span>].mask = <span class="number">0x0fff</span>;</span><br><span class="line">ret = rte_pmd_i40e_inset_set(<span class="number">0</span>, <span class="number">33</span>, &amp;inset, INSET_FDIR);</span><br><span class="line"></span><br><span class="line">rte_pmd_i40e_inset_get(<span class="number">0</span>, <span class="number">33</span>, &amp;inset, INSET_FDIR); <span class="comment">//tcp</span></span><br><span class="line">inset.mask[<span class="number">1</span>].field_idx = <span class="number">30</span>;</span><br><span class="line">inset.mask[<span class="number">1</span>].mask = <span class="number">0x00ff</span>;</span><br><span class="line">ret = rte_pmd_i40e_inset_set(<span class="number">0</span>, <span class="number">33</span>, &amp;inset, INSET_FDIR);</span><br></pre></td></tr></table></figure><blockquote><p>注意，为了区别UDP的掩码(0x0FFF)，给TCP目的端口使用的是<code>0x00FF</code>。</p></blockquote><p>此时源端口为8192-12287，且目的端口为4096-4351(0x10FF)的TCP报文均可进入Queue1。</p><p>为了验证针对UDP报文的规则不受TCP的Mask影响，发送目的端口为4352的UDP报文，仍可匹配UDP规则。证明不同<code>pctype</code>之间的配置不互相影响。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> NIC </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去10：DPDK i40e X710 Flow Director Deep Dive(1)</title>
      <link href="/2019/05/11/test10-dpdk-x710-fdir-mask-1/"/>
      <url>/2019/05/11/test10-dpdk-x710-fdir-mask-1/</url>
      
        <content type="html"><![CDATA[<p>在<a href="https://decodezp.github.io/2019/05/06/test9-x710-fdir-mask/">这篇文章</a>介绍DPDK i40e X710网卡如何配置Flow director mask的过程中演示了一下如何给UDP流量添加dest Port Mask。首先对当时的配置再做一点细节上的补充：<br><a id="more"></a></p><p>一个是<code>Input Set</code>的配置。这个配置决定了Flow director具体关心UDP的哪些字段。只有在<code>Input set</code>中的字段才有加Mask的必要。在演示的例子中：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_fdir_filter_info</span> <span class="title">info</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">rte_pmd_i40e_inset</span> <span class="title">inset</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">memset</span>(&amp;info, <span class="number">0</span>, <span class="keyword">sizeof</span>(info));</span><br><span class="line">    info.info_type = RTE_ETH_FDIR_FILTER_INPUT_SET_SELECT;</span><br><span class="line">    <span class="comment">//针对Nonfrag-ipv4-udp这种流量类型</span></span><br><span class="line">    info.info.input_set_conf.flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP;</span><br><span class="line">    <span class="comment">//添加UDP-dst-port作为一个`input set`，且仅有这一个</span></span><br><span class="line">    info.info.input_set_conf.field[<span class="number">0</span>] = RTE_ETH_INPUT_SET_L4_UDP_DST_PORT;</span><br><span class="line">    info.info.input_set_conf.inset_size = <span class="number">1</span>;</span><br><span class="line">    info.info.input_set_conf.op = RTE_ETH_INPUT_SET_SELECT;</span><br></pre></td></tr></table></figure><p>通过这种形式配置了Flow director仅关心一个UDP字段，也就是dest Port。其实也可以认为是给src IP/dest IP/src Port设置了通配。</p><p>另外关于配置掩码的规则在这里也说明一下，示例中给的fdir规则dst_port是0x2e06，掩码是0xF000：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_fdir_filter</span> <span class="title">arg_udpport</span> = &#123;</span></span><br><span class="line">    .soft_id = <span class="number">1</span>,</span><br><span class="line">    .input   = &#123;</span><br><span class="line">        .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP,</span><br><span class="line">        .flow = &#123;</span><br><span class="line">           .udp4_flow = &#123;</span><br><span class="line">               .dst_port = <span class="number">0x2e06</span>, <span class="comment">//5678=&gt;0x162e</span></span><br><span class="line">           &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    .action  = &#123;</span><br><span class="line">        .rx_queue  =  <span class="number">2</span>,</span><br><span class="line">        .behavior  = RTE_ETH_FDIR_ACCEPT,</span><br><span class="line">        .report_status = RTE_ETH_FDIR_REPORT_ID,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个配置可以匹配目的端口号为：1582（0x062e）；5678（0x162e）;9774（0x262e）…的端口，即前4个bit为任意数值，后12个bit为0x62e的全部端口号。</p><p>注意此时在fdir规则的配置中，<code>.dst_port</code>只能写0x2e06才可以生效，一是考虑大小端数字的转换，二是需要被Mask的那几位Bit必须写0。另外，对应的Mask(0xF000)中，需要被Mask的Bit位上要写1。</p><p>别问我为什么这么设定，我也不知道，我只管好不好使。</p><h2 id="两条fdir-UDP规则"><a href="#两条fdir-UDP规则" class="headerlink" title="两条fdir UDP规则"></a>两条fdir UDP规则</h2><p>如果你需要配置两条UDP fdir规则，那么之前关于<code>input set</code>和mask的配置是同时应用于这两条UDP规则的。</p><p>比如，所有目的端口号4096（0x1000）-8191的UDP进入队列1，端口号8192（0x2000）-12287（0x2FFF）的进入队列2，可以采取如下配置方式：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_fdir_filter</span> <span class="title">arg_udpport1</span> = &#123;</span></span><br><span class="line">       .soft_id = <span class="number">1</span>,</span><br><span class="line">       .input   = &#123;</span><br><span class="line">           .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP,</span><br><span class="line">           .flow = &#123;</span><br><span class="line">              .udp4_flow = &#123;</span><br><span class="line">                  .dst_port = <span class="number">0x10</span>,</span><br><span class="line">              &#125;,</span><br><span class="line">           &#125;,</span><br><span class="line">       &#125;,</span><br><span class="line">       .action  = &#123;</span><br><span class="line">           .rx_queue  =  <span class="number">1</span>,</span><br><span class="line">           .behavior  = RTE_ETH_FDIR_ACCEPT,</span><br><span class="line">           .report_status = RTE_ETH_FDIR_REPORT_ID,</span><br><span class="line">       &#125;,</span><br><span class="line">   &#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_fdir_filter</span> <span class="title">arg_udpport2</span> = &#123;</span></span><br><span class="line">       .soft_id = <span class="number">2</span>,</span><br><span class="line">       .input   = &#123;</span><br><span class="line">           .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP,</span><br><span class="line">           .flow = &#123;</span><br><span class="line">              .udp4_flow = &#123;</span><br><span class="line">                  .dst_port = <span class="number">0x20</span>,</span><br><span class="line">              &#125;,</span><br><span class="line">           &#125;,</span><br><span class="line">       &#125;,</span><br><span class="line">       .action  = &#123;</span><br><span class="line">           .rx_queue  =  <span class="number">2</span>,</span><br><span class="line">           .behavior  = RTE_ETH_FDIR_ACCEPT,</span><br><span class="line">           .report_status = RTE_ETH_FDIR_REPORT_ID,</span><br><span class="line">       &#125;,</span><br><span class="line">   &#125;;</span><br></pre></td></tr></table></figure><p>此时Mask需要设置为<code>0x0FFF</code>。然后调用示例中的相关接口就可以达到目的。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> NIC </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>命名的力量</title>
      <link href="/2019/05/08/thoughts8-master-of-naming/"/>
      <url>/2019/05/08/thoughts8-master-of-naming/</url>
      
        <content type="html"><![CDATA[<h2 id="一"><a href="#一" class="headerlink" title="一"></a>一</h2><blockquote><p>To Know the Name of a Thing is to Have Power Over It<br>如果我们知道了一件事物的名字，就有了操控它的力量。</p></blockquote><p>常言道，人类最深的恐惧都来自于“未知”。那么，什么是“未知”？<br><a id="more"></a></p><p>未知并不是一片漆黑，也不是一无所知——而是没有名字。</p><p>有了名字并不代表我们就完全了解了一样事物。但奇妙的就是，我们根本不需要去了解，就可以在这个依然满是“未知”的世界里用这个名字去随心所欲地指代。自此，我们才获知事物的坐标；自此，我们才拿到操控的指令；自此，头脑中的万物才真正存在。</p><p>其实细想一下，我们当前也仅仅是对这个世界，以及我们自己，自以为了解。</p><h2 id="二"><a href="#二" class="headerlink" title="二"></a>二</h2><blockquote><p>A thing is a thing, not what is said of that thing<br>大化流行，不拘于形</p></blockquote><p>命名不仅可以让我们拥有改造事物的力量，同时也在操纵我们自己。</p><p>几乎所有的恶习，都来源于此：偏见、歧视、贪婪、愤怒、狂热、嫉妒、自以为是、自欺欺人……如果没有名字构筑的意象，事物本无意义。我们什么都看不到，什么都听不到，所能见能闻的，不过是名字在时间空谷里的涟漪和回音。</p><p>命名为我们架起桥梁，也建好牢笼；我们既接受命名的祝福，也背负命名的诅咒。</p><h2 id="三"><a href="#三" class="headerlink" title="三"></a>三</h2><blockquote><p>A men is what he speaks.<br>至人无己，神人无功，圣人无名</p></blockquote><p>我一直在试图跳出“社会人”的视角，去思考我们到底如何认知周遭的世界。直到我明白，当我只能用这套被偏见熏习浸染的语言去思考时，所有的沉思不过是徒劳无功的挣扎。“为学日益，为道日损”，那就挣扎吧，就是挣扎吧，没什么大不了的，最起码，“挣扎”只是临时给这种心情所起的名字。</p><p>曾试图知道每一样事物的名字，以为就能活得明白。却发现在知道了越来越多的名字之后，自己却成了一个只会用名字敷衍自己的人。这个是XX，那个是YY，所划所指，不过是在重复别人。到头来，发现“张冠李戴”才是一种极高明的生活态度。</p><p>从别人那里继承的名字成为一切构造的原点，包括构造我们自己。在名字罗织的网里，有人游刃有余，也有人自怨自艾，有人如数家珍，也有人忘记了自己的名字。但对我来说，我最理想的职业，就是做一个“命名师”——给所有能见能闻之物，一个最合适的名字。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去9：DPDK i40e XXV710 Flow Director Mask Configuration</title>
      <link href="/2019/05/06/test9-x710-fdir-mask/"/>
      <url>/2019/05/06/test9-x710-fdir-mask/</url>
      
        <content type="html"><![CDATA[<h2 id="Flow-Director"><a href="#Flow-Director" class="headerlink" title="Flow Director"></a>Flow Director</h2><p>最常见的Flow Director使用方式就是将匹配某个五元组的报文送到一个特定的队列里去。但精确匹配有时候并不能满足全部需求，需要给一些特定的字段加Mask。<br><a id="more"></a></p><h2 id="配置方式"><a href="#配置方式" class="headerlink" title="配置方式"></a>配置方式</h2><blockquote><p>修改dpdk-18.05.1/example/l3fwd/main.c</p></blockquote><blockquote><p>目的是给UDP的DST Port添加一个0XF000的掩码。</p></blockquote><p>首先用i40e提供的私有接口加持一下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;rte_pmd_i40e.h&gt;</span></span></span><br></pre></td></tr></table></figure><p>这里面都是偷偷夹带的私货，可以关注一下。</p><p>然后加一个”中规中矩“的FDIR规则：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_conf</span> <span class="title">port_conf</span> = &#123;</span></span><br><span class="line">    .rxmode = &#123;</span><br><span class="line">        .mq_mode = ETH_MQ_RX_RSS,</span><br><span class="line">        .max_rx_pkt_len = ETHER_MAX_LEN,</span><br><span class="line">        .split_hdr_size = <span class="number">0</span>,</span><br><span class="line">        .ignore_offload_bitfield = <span class="number">1</span>,</span><br><span class="line">        .offloads = (DEV_RX_OFFLOAD_CRC_STRIP |</span><br><span class="line">                 DEV_RX_OFFLOAD_CHECKSUM),</span><br><span class="line">    &#125;,</span><br><span class="line">    .rx_adv_conf = &#123;</span><br><span class="line">        .rss_conf = &#123;</span><br><span class="line">            .rss_key = <span class="literal">NULL</span>,</span><br><span class="line">            .rss_hf = ETH_RSS_IP,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    .txmode = &#123;</span><br><span class="line">        .mq_mode = ETH_MQ_TX_NONE,</span><br><span class="line">    &#125;,</span><br><span class="line">    .fdir_conf = &#123;   <span class="comment">//jma fdir</span></span><br><span class="line">        .mode = RTE_FDIR_MODE_PERFECT,</span><br><span class="line">        .pballoc = RTE_FDIR_PBALLOC_64K,</span><br><span class="line">        .status = RTE_FDIR_REPORT_STATUS,</span><br><span class="line">        .drop_queue = <span class="number">127</span>,</span><br><span class="line">        .mask = &#123;</span><br><span class="line">            .vlan_tci_mask = <span class="number">0</span>,</span><br><span class="line">            .ipv4_mask = &#123;</span><br><span class="line">                .src_ip = <span class="number">0xffffffff</span>,</span><br><span class="line">                .dst_ip = <span class="number">0xffffffff</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            .src_port_mask = <span class="number">0xffff</span>,</span><br><span class="line">            <span class="comment">//ori .dst_port_mask = 0xffff,</span></span><br><span class="line">            .dst_port_mask = <span class="number">0xff00</span>,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>不过其实mask不起作用，这里主要做一下错误示范。然后在<code>main</code>函数里加一下配置代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_fdir_filter_info</span> <span class="title">info</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_pmd_i40e_inset</span> <span class="title">inset</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">memset</span>(&amp;info, <span class="number">0</span>, <span class="keyword">sizeof</span>(info));</span><br><span class="line">info.info_type = RTE_ETH_FDIR_FILTER_INPUT_SET_SELECT;</span><br><span class="line">info.info.input_set_conf.flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP;</span><br><span class="line">info.info.input_set_conf.field[<span class="number">0</span>] = RTE_ETH_INPUT_SET_L4_UDP_DST_PORT;</span><br><span class="line">info.info.input_set_conf.inset_size = <span class="number">1</span>;</span><br><span class="line">info.info.input_set_conf.op = RTE_ETH_INPUT_SET_SELECT;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rte_eth_fdir_filter</span> <span class="title">arg_udpport</span> = &#123;</span></span><br><span class="line">    .soft_id = <span class="number">1</span>,</span><br><span class="line">    .input   = &#123;</span><br><span class="line">        .flow_type = RTE_ETH_FLOW_NONFRAG_IPV4_UDP,</span><br><span class="line">        .flow = &#123;</span><br><span class="line">           .udp4_flow = &#123;</span><br><span class="line">               .dst_port = <span class="number">0x2e06</span>, <span class="comment">//5678=&gt;0x162e</span></span><br><span class="line">           &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">    .action  = &#123;</span><br><span class="line">        .rx_queue  =  <span class="number">2</span>,</span><br><span class="line">        .behavior  = RTE_ETH_FDIR_ACCEPT,</span><br><span class="line">        .report_status = RTE_ETH_FDIR_REPORT_ID,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里定义了一个Flow Director规则：”目的端口为5678的UDP报文进入队列2”。</p><p>那么如何加掩码呢？</p><p>在启动转发程序(<code>rte_eal_mp_remote_launch()</code>)之前加上：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ret = rte_eth_dev_filter_ctrl(<span class="number">0</span>,</span><br><span class="line">            RTE_ETH_FILTER_FDIR,RTE_ETH_FILTER_SET,&amp;info);</span><br><span class="line">ret = rte_eth_dev_filter_ctrl(<span class="number">0</span>,</span><br><span class="line">             RTE_ETH_FILTER_FDIR,RTE_ETH_FILTER_ADD, &amp;arg_udpport);</span><br><span class="line">rte_pmd_i40e_inset_get(<span class="number">0</span>, <span class="number">31</span>,&amp;inset, INSET_FDIR); <span class="comment">//udp</span></span><br><span class="line">inset.mask[<span class="number">0</span>].field_idx = <span class="number">30</span>;</span><br><span class="line">inset.mask[<span class="number">0</span>].mask = <span class="number">0xf000</span>;</span><br><span class="line">ret = rte_pmd_i40e_inset_set(<span class="number">0</span>, <span class="number">31</span>,&amp;inset, INSET_FDIR);</span><br></pre></td></tr></table></figure><p>这里面需要关注几个数值，一个是<code>rte_pmd_i40e_inset_get/set</code>参数里的31。这个是<code>pctype</code>的编号。可以查看x710 datasheet的<code>Table 7-5</code>。31号对应的是NonF IPv4, UDP，正好是我们需要的。</p><p>另外一个是<code>inset.mask[0].field_idx</code>给出的30。这个30出自datasheet中的<code>Table 7-12</code>。其中提到<code>29:32</code>这两个word在UDP协议下代表的是<code>First 8 bytes of the UDP header</code>。在UDP header中，前两个Byte是SRC port，对应29；第三第四个Byte是DST port，对应30。这就是30的来历。</p><p>至此就完成了最初的目的。</p><h2 id="Future-Work"><a href="#Future-Work" class="headerlink" title="Future Work"></a>Future Work</h2><p>X710在这方面的配置方法总体来说还是非常隐晦的。在未来还有很多可以验证的工作，比如是否可以针对不同的<code>pctype</code>设置不同的mask，比如mask是否仅限于两个字段等等。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> NIC </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>终端断开任务不中断</title>
      <link href="/2019/04/27/terminal-nohup-screen/"/>
      <url>/2019/04/27/terminal-nohup-screen/</url>
      
        <content type="html"><![CDATA[<p>其实是很常见的需求，但之前一直用<code>nohup command &amp;</code>这种方式。不过有些时候没有充分估计到某些工作的不靠谱性，以为很快能搞定的事，就没用<code>nohup</code>直接执行，当你快要下班了它还遥遥无期。这个时候也可以先<code>ctrl + z</code>从前台挂起，然后<code>bg</code>让它跑到后台去执行，最后再来一个<code>disown -a</code>，这样就可以放心关了终端早点回家了。下次再用其他终端连接上来之后你的工作仍会在持续执行，但是这时候是不能用<code>fg</code>这样的命令让它再回到前台执行的，<code>jobs</code>也不会显示它。</p><p>如果你想持续看到后台进程的输出，以前的办法就是在运行之前就将它重定向到一个文件，后续回来查看文件即可。但如果进程已经开始执行了，再去重定向就稍微费点劲。网上有些用<code>gdb</code>调的方法，我试了试不是太成功，本来打算继续看看，结果发现还是老老实实用<code>screen</code>靠谱一点…<br><a id="more"></a></p><p>其实<code>screen</code>这个命令应该不是什么新鲜玩意了，也有很多人在使用。不过对我来说还是一个挺有新意的发现。我的一般套路：</p><ul><li>新建一个<code>screen</code>并命名为<code>ftp</code>：</li></ul><p><code>screen -S ftp</code></p><ul><li><p>此时会直接进入新的<code>bash</code>，这里搞一些耗时的操作，例如<code>scp</code>等等。</p></li><li><p>从<code>ftp</code>退回：</p></li></ul><p>用快捷键<code>ctrl+a d</code></p><p>这个时候其实就可以关闭当前终端了。</p><p>新打开一个终端</p><ul><li>查看现有<code>screen</code>列表：</li></ul><p><code>screen -ls</code></p><ul><li>看看上传得怎么样了：</li></ul><p><code>screen -r ftp</code></p><p>不但<code>scp</code>的工作没有中断，还可以看到<code>scp</code>当前所有输出，和之前的终端没有关闭一样。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去8：公有云实例性能实际波动情况</title>
      <link href="/2019/04/22/test8-cloud-vm-performance/"/>
      <url>/2019/04/22/test8-cloud-vm-performance/</url>
      
        <content type="html"><![CDATA[<p>公有云作为一种资源打包整合再售卖的商业模式，不可避免地存在多租户共享资源的情况。除了安全问题之外，更多的是需要辨别这种共享对用户各自的性能存在多大的影响。这种影响不仅仅表现在性能的下降，而更多的是表现为性能的不一致：在高峰时段和空闲时段，性能出现较大的波动。<br><a id="more"></a></p><p>这里在某公有云平台购买一台4vCPU/8GB的实例作为DUT，在不同时间执行：</p><p><code>phoronix-test-suite benchmark xsbench</code></p><p>进行CPU处理的性能测试，除此之外该虚拟机上没有任何其他workload，也没有任何其他配置更改，全部采用默认配置。</p><p>以下是不同时段的一组测试数据(lookup/s)：</p><table><thead><tr><th>time</th><th>result</th></tr></thead><tbody><tr><td>11:00</td><td>923024</td></tr><tr><td>14:00</td><td>783030</td></tr><tr><td>16:00</td><td>841485</td></tr><tr><td>17:00</td><td>840289</td></tr><tr><td>18:00</td><td>838885</td></tr></tbody></table><p>可以看出，11：00性能最高，14：00性能最低，16：00-18：00性能稍有波动，最好与最低性能相差15%+。</p><p>针对以上情况的几种可能解释：</p><ul><li><p>虚拟机新创建时(14:00)根据公有云后台调度算法创建到了一台空闲的“物理机”上，以提高物理资源的整体利用率。后续随着新虚拟机的加入导致性能下降。</p></li><li><p>虚拟机新创建时没有特别选择“空闲”物理机，此时物理机中已存在其他虚拟机。但受其他虚拟机各时段业务压力不同影响（14:00为业务压力较大的时间段，16:00-18:00业务压力相对平稳），表现出性能的波动。</p></li><li><p>其他虚拟机压力没有较大波动，但受账号等级、任务优先级等商务或其他因素影响，导致在hypervisor层中为各虚拟机进程分配不同的优先级以及CPU硬件绑定策略，进而影响虚拟机的性能表现。</p></li><li><p>以上原因综合影响。</p></li></ul><p>总之，在公有云上部署应用，如果并没有选购那些资源独占型的产品，就需要充分评估性能波动带来的业务影响。同时，在此一方面做好与云供应商的SLA的制订工作。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> performance </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Quickwords27 Skylake Microarchitecture(10)</title>
      <link href="/2019/04/20/quickwords27-skylake-pipeline-10/"/>
      <url>/2019/04/20/quickwords27-skylake-pipeline-10/</url>
      
        <content type="html"><![CDATA[<h2 id="Load-and-Store-instructions"><a href="#Load-and-Store-instructions" class="headerlink" title="Load and Store instructions"></a>Load and Store instructions</h2><p>In previous chapters we discussed how does ROB and RS as well as RAT work. You may notice that we did not include <code>load</code> and <code>store</code> instruction in the demonstrated examples. This is partly due to simplification reason and partly because of the specialized mechanisms we will introduce in this article.<br><a id="more"></a></p><p>Although we categorize <code>load</code> and <code>store</code> instructions as special from other classes of instructions, all instructions and the design of the pipeline share unified purpose: increase the instruction level parellarmise by eliminating dependencies. By what I am saying:</p><ul><li>Eliminate control dependencies by leveraging branch prediction</li><li>Eliminate false dependencies by leveraging register renaming</li></ul><blockquote><p>Note that register renaming is primarily aimed for registers, not memory.</p></blockquote><p>Is there also dependency existing for memory operations? If yes, what can we do about it? These are the questions we are trying to address.</p><h2 id="Load-and-Store-Are-Different-From-Read-And-Write"><a href="#Load-and-Store-Are-Different-From-Read-And-Write" class="headerlink" title="Load and Store Are Different From Read And Write"></a>Load and Store Are Different From Read And Write</h2><p>Load and store are terms used for memory <em>instructions</em> whereas read and write are used for <em>actions</em> directly operated on memory. Most of the time, these terms are interchangeable. However, in our scope, we must differentiate those in order to avoid misunderstanding in following discussion:</p><p>Stores are instructions and they follow the same procedure described before. Only after the <code>store</code> instruction is committed, memory written happens.</p><p>Loads are also instructions, but memory read action may happen before or after load instruction is committed. That’s mainly because <code>load</code> is able to leverage results of previous stores which store to the same address of the <code>load</code> instruction. Therefore, loads perform in execute stage.</p><h2 id="Registers-and-Memory"><a href="#Registers-and-Memory" class="headerlink" title="Registers and Memory"></a>Registers and Memory</h2><p>Registers and memory share same type of dependences. False dependencies can be eliminated during Out-of-order execution.</p><p>However, there’s one important difference, the address of memory operation known only at runtime, makes memory operation much more difficult to tell if there’s a dependency. For example:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Load r3 = 0[R6]</span><br><span class="line">Add r7 = r3 + r9</span><br><span class="line">Store r4-&gt;0[r7]</span><br><span class="line">Sub r1 = r1 - r2</span><br><span class="line">Load r8 = 0[r1]</span><br></pre></td></tr></table></figure><p>Here, in the third instruction you store value in <code>r4</code> to memory location represented by <code>r7</code>, and then you load value in memory location [r1] to <code>r8</code>. We assume there is a cache hit. If <code>r7</code> is not equals to <code>r1</code>, there’s no problem. Problem arises if <code>r7</code> equals <code>r1</code>, as the store/third instruction has not been committed, the value in cache/read by the last instruction is not the latest/correct. In other word, this is a RAW true dependency. Our trusted friend, compiler, can not help under this circumstance neither.</p><p>This is the root cause of <code>memory aliasing</code>, when two pointers refer to the same memory location, true dependency happens. Although you can give compiler hint to omit memory aliasing, it is up to the unreliable programmer to take care of their spaghetti logic.</p><p>As before, we set an example to make the explanation easier to understand…in next chapter.</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>tar命令速查手册</title>
      <link href="/2019/04/20/tar-cheat-sheet/"/>
      <url>/2019/04/20/tar-cheat-sheet/</url>
      
        <content type="html"><![CDATA[<p>总是会忘记这个命令后面的各种参数对应的压缩格式，每次都要上网重新搜索。可能也是对这种“查一查就能知道”的信息天生缺乏敏感性，但每次都搜索显得实在不太professional，所以…那就在一个地方查吧 ^^<br><a id="more"></a></p><h2 id="tar"><a href="#tar" class="headerlink" title=".tar"></a>.tar</h2><ul><li>解压缩： tar zxvf FileName.tar</li><li>压缩： tar czvf FileName.tar path/to/file</li></ul><h2 id="tar-bz2"><a href="#tar-bz2" class="headerlink" title=".tar.bz2"></a>.tar.bz2</h2><ul><li>解压缩： tar jxvf FileName.tar.bz2</li><li>压缩： tar jcvf FileName.tar.bz2 path/to/file</li></ul><h2 id="tar-bz"><a href="#tar-bz" class="headerlink" title=".tar.bz"></a>.tar.bz</h2><ul><li>解压缩： tar jxvf FileName.tar.bz</li></ul><h2 id="tar-gz-amp-tgz"><a href="#tar-gz-amp-tgz" class="headerlink" title=".tar.gz &amp; .tgz"></a>.tar.gz &amp; .tgz</h2><ul><li>解压缩： tar zxvf FileName.tar.gz</li><li>压缩： tar zcvf FileName.tar.gz path/to/file</li></ul><h2 id="tar-Z"><a href="#tar-Z" class="headerlink" title=".tar.Z"></a>.tar.Z</h2><ul><li>解压缩： tar Zxvf FileName.tar.Z</li><li>压缩： tar Zcvf FileName.tar.Z path/to/file</li></ul>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>如果你到鲁汶来，一定要喝Stella</title>
      <link href="/2019/04/19/thoughts7-leuven-stella/"/>
      <url>/2019/04/19/thoughts7-leuven-stella/</url>
      
        <content type="html"><![CDATA[<blockquote><p>自打那次正式的告别之后，很久都没有再梦见过鲁汶。那几年大部分的时光，都仿佛跌入了时间的黑洞，如今能找到的，只有下面这篇旧文中的只言片语。刚想要深入挖掘一下脑海中的记忆，却又畏葸不前——毕竟清扫记忆这事，如扫落叶，旋扫旋生。<br><a id="more"></a></p></blockquote><p>人生第一次喝到不管不顾，是在2012年1月31日的晚上。那时已是我在鲁汶的最后一年。第二天早上是学校统一安排的论文中期答辩，于是我便知道在今晚，我一定会和K出现在鲁汶一处无所事事的场所。中期答辩这种半娱乐性质的学术活动，对我们来说就像是一场临时起意的火锅，断不能未雨绸缪，更不能胸有成竹：人员、食材、厨具，场所，一定要临渴掘井，倚马援笔，才能在朵颐的餍足之后额外获得一种怪诞的速度感。经验给我们的启示是，只要英语说得足够快，肢体足够挥洒，眼神足够信誓旦旦，就可以弥补学术上的浅尝辄止。于是这天晚上，在Tiensestraat一家新开不久的披萨店，我们坐到了一起。那晚鲁汶没有在准备PPT的学生，可能都在这家披萨店里。</p><p>鲁汶虽小，见面却也需要缘份。作为不是一个系，懒得算计课时费督促自己去上课，中午也很少去吃ALMA的两个人，我和K很少见面。两个人单独活动的次数，其实也屈指可数。双方都在维持一个避免尴尬的微妙距离。这里的每一个人，都会邀请别人到自己的单人Studio／apartment里作客，都会参加由四川人民搞起的各类火锅，但也都会有一些不示人的东西，装在角落那个随着他们漂洋过海的行李箱里。在鲁汶呆了三年，很多事物渐渐地丧失了新鲜感，就连圈子里的八卦，来来回回也总是那些。不再计算欧元的汇率，也不再为法语键盘诡谲的键位苦恼，只有周围的这些人，总能让你感到新的发现。我想，很少和另外一个人联系，也许只是因为并不想在对方身上发现这种“新意”——如果镜子某天被发现了一个裂璺，难免令人恐慌。</p><p>披萨店开在Tiense街，是一个很明智的决断。Tiense街并不是鲁汶的主街，但作为我们到这里之后第一条踏足的街道，它成了我们一切路径规划的起点。这一条街两边的店面，几乎可以满足一个学生的所有需求。沿着这条街，大大小小的街道像血管般交汇铺陈。在这些血管里游走，就像沉入到鲁汶的血液里，被心脏的节律送去每一个总要到达的地方。有些时候是迫不得已地找寻某处地址，有些时候只是自己或他人的兴之所至。哪里是超市，哪里是教堂，哪里新开了一家冰激凌店，就这样不自觉地摸清了每一根血管的秘密。也正是在去哪都轻车熟路之后，才清楚地明白了自己外乡人的身份。却又一边保持着外乡人的执拗，一边从Tiensestraat 154开始，把自己紧紧地编织进一张杂乱又熟稔的网里。</p><p>我跟K说，今天街上的人真少，披萨也很一般。K说，何不去喝杯酒。这是一个很难拒绝的提议。就像很难拒绝在去鲁汶的火车上看到车站旁百威英博的巨大厂房。那上面的Stella Logo初起时引人注目，后来反而会视而不见。毕竟，谁也不会为花萼上开出了一朵花而感到惊奇。比利时数百种啤酒，我只尝过一些最常见的种类。Stella算不上最好喝的，更算不上名气最大的，但在鲁汶，这却是最自然的选项。毕竟两个男人去分吃冰淇淋和华夫饼，还是太需要勇气了。<br>天早就黑了，中心图书馆前的广场上，只有那只甲虫反射着孙燕姿的绿光。鲁汶的纬度据说超过哈尔滨，冬天昼短夜长得像是一杯被人遗忘在角落里的KASTEEL，蕾丝般单薄的泡沫随时会被黑色的酒浆吞没。但这里并不像哈尔滨那般寒冷，北大西洋的暖流从不远的地方流过，海洋和陆地两种不同比热容的东西造就了这里特别的风，像刚刚把开水与冰水混合在一起，在没有达到相互妥协的温度之前，纠结得泾渭分明。</p><p>这种纠结，快要毕业的人感受得最深。那个时候，周围的同学已经开始谋划自己的未来了，至少每个人都是这样以为。献身学术的要继续读博，爱动手解决问题的对工业界早已跃跃欲试，挂科太多的也决心在明年毕业。是走是留，可能每个人都在心里盘算了许久。 我那个时候没什么特别的打算，除了不想继续读博之外，觉得去哪里都好，或者说是，也不清楚要去哪里。如果工作的话 ，希望能找到一个设计嵌入式系统的公司，搞一搞R&amp;D。站在此时此刻的时间纵深上，那个时候的打算都如一场喃喃的梦呓。至少对我来说，现在的生活几乎和那时设想的没有一点关系，但也许现在才是一杯混合好的凉白开的样子。</p><p>但是当我们坐在著名的Professor酒吧里时，自然是不会点一杯凉白开的。以Stella开场，以明早的答辩下酒，两个人似乎都有今晚要发生些什么的预感。桌子上的圆烛越燃越亮，在酒吧街卖花的阿裔大叔凑上来问我们要不要买一支玫瑰，我们三个都笑了。话说得越来越多，酒也喝得越来越快。奇怪的是我现在已经完全想不起来那时说过些什么，只记得啤酒没有了味道，鸡尾酒像一杯果汁，而伏特加因为酒精浓度太高，喝到嘴里不会有任何被水份湿润的感觉。酒精像是一整团粘连的黏液，到达喉咙之后，在胸腔里炸开。</p><p>我和K曾经在同一家中餐馆打工，那还是我们刚到这个国家的时候。不过我们并不是同时在那里，而是一先一后。在靠近法国边境的地方，有一个叫做富豪大酒楼的夫妻店，这也许是我第一次明白了浮夸的含义。老板和老板娘都是浙江青田人，只是老板是二代移民。我去的时候，老板娘已经生了三个儿子，K去了之后，又有了第四个。那个大酒楼是一个纯正的多语言环境，无论是谁的儿子，和老板要说荷兰语，老板和老板娘说青田方言，老板和我说英语，老板娘和我说普通话。传说上帝破坏巴别塔的方法，就是让人说不同的语言。但我想，失败的原因并不是因为无法靠语言交流，而是往昔的环境被打破之后，在新的环境里找不到可以锚定的礁石。个人无法定位，集体也就无法协作。过往经验的全然失效，会生出一种存在与否的焦虑。在这座六个人的巴别塔里，我突然有了这种焦虑。以前并不明白，以为对任何一个问题，都要细加推敲，从长计议，但有些时候，只有迷失时的横冲直撞，才能找到可以靠岸的水港。就像这次在Professor酒吧中所发生的一样。我不记得我们谈话的内容，我甚至怀疑我们有没有说话，我们肯定也不懂古奥的阿拉伯语，但我分明知道我们做了一场酣畅淋漓的交流，也都读懂了那支玫瑰的含义。一杯接一杯，酒保已经放弃投递提醒的眼色，自然也不会有人再考虑明早的答辩，甚至不会去考虑明天。也许酒才是真正意义上的世界语，那么Stella就是鲁汶的方言。</p><p>直到现在，关于鲁汶的记忆已经被严重压缩，甚至在反复加工的过程中失真走样。许多当初习以为常的细节已经如Tiensestraat 154般烟消云散，但我依然记得我们如何在Professor酒吧门口告别——虽然还没有毕业，却像是明天就要各奔东西——揽了揽对方的肩头，并镇定地说着要回去再看一下明天答辩的内容。由此可知，语言的作用并不在交流，而是撒谎。我几乎是一路小跑着跑回了Campus Irena，但还是没来得及在进宿舍之前保持直立行走。手脚并用的从0层爬到了2层，艰难地够到钥匙孔，推开门的瞬间，就给地毯附丽了一幅写意画作。数年以后的同学会，我看到喝多了的J在杭州街头呕吐，泼洒的秽物溅到了我的双脚，竟然有一种熟悉的温热。<br>在鲁汶最后的那段时间里，一度很喜欢Campus Irena的楼顶。夜晚无聊的时候，就会从顶楼的梯子上爬上来，随身带一个高脚杯，和一盒全脂牛奶。周围没有比它更高的建筑，“可以看到整块没有分割的天空”。在这之前，当国内已经是入眠的午夜，我会选择出去闲逛，那些傍晚时的漫步，很多时候都以不知所云，迷途知返收场。楼顶的平台很大，可作闲庭信步，但每当抬起头面对扑面而来的夜空时，就再也不敢迈动一步，失足青年，在那时已逐渐有了暧昧的含义。鲁汶很小，但有些时候却空旷得不知身在何处。只有在离开许久之后，才能在一万两千公里之外看清自己曾经的身影。即便是到了现在，我也无法总结这段时光给我留下了什么，直到2014年的6月，在北京三里屯，我见到了酒吧屋檐下挂出的Stella的酒招。断裂的时光和距离，才在那时重合。<br>第二天，我准时出现在论文答辩的门前，淡定的就像早已胜券在握。我看到K穿着正装，打着领带，从旋转楼梯那边缓缓走来，甚至还丧心病狂地戴着一顶一丝不苟的礼帽。擦肩而过的时候，他问我，昨晚回去吐了吗？</p><p>没有，你吐了？</p><p>没有。</p><p>我们点头致意，心里都默默给对方打了一个8分。下次我们再见，似乎就到了那一年的十月。我虽然没想清楚毕业之后要去哪，但我那个时候就知道，在不远的将来，我们会出现在世界的各个地方。不可免俗的，还是会让一份工作成为我们安身立命的栖身之所。那个时候我们将不能只凭脑力就记住手机通讯录里每一个人的面孔，我们会交换很多名片，会发很多邮件，会参加很多次团建或者林林总总的商务宴请，但却很少再有新的朋友。这很好，可以让我们将感情投入到真正值得的人身上。2012年的1月似乎是我两个时代的分水岭，可惜的是，我那时无知无觉。<br>2012年1月1日的早上，鲁汶oude market广场上满是昨夜跨年时人群遗落的疯狂痕迹。被风推着滚动的杂物以极度亢奋之后的萎靡姿态占领了广场。彼时天空下着小雨，一次性塑料杯中没喝完的啤酒渗透了石头广场的每一个罅隙，整个小城似乎还在宿醉中没有醒来。广场周围的酒吧里还有人停留在2011年的最后一天，随着音乐扭动小脑失效的身体。只是激荡肾上腺的嘈杂音乐一出酒吧的门口就成了强弩之末，唤不醒广场上任何一块酣饮了啤酒的石子。我穿过空气里幽浮起的酒精的气息，想要在如此举世皆醉的清晨看一看2012年第一天的鲁汶，不成想一个醉依在酒吧门口的年轻学生朝我走过来，用无法捋直的舌头对我说，如果你到鲁汶来，一定要喝Stella。</p><p>作者：张攀<br>链接：<a href="https://www.jianshu.com/p/3d065950e73a" target="_blank" rel="noopener">https://www.jianshu.com/p/3d065950e73a</a><br>来源：简书<br>简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>夜色温柔</title>
      <link href="/2019/04/17/thoughts6-tender-is-the-night/"/>
      <url>/2019/04/17/thoughts6-tender-is-the-night/</url>
      
        <content type="html"><![CDATA[<p>好像总是不能沉浸在当下。看着书想着邮件，吃着饭想着项目，看着电影想着停车费，在外面喝酒想着一会回家撸猫。<br><a id="more"></a></p><p>也不是没有专注的时候，但这些时候总像一个美梦，做不多时就会下意识地提醒自己，我是不是在做梦？方醉复醒，梦了无痕。</p><p>今天也是如此。春意浓浓，月色溶溶，酒吧里光影横斜。我端详着酒杯里的泡沫，心思却又不知神游何处。辜负的不止是此时此刻，还有未来那个，终会后悔现在没有更投入一些的自己。</p><p>玩不是玩，工作不是工作，被背景噪音消音，让零碎片段化整为零。不去接收那些廉价的信息，仿佛就是现代最大的罪愆。第一次，我决定好好坐下来，用舌头去听清泡沫在破裂时的轻响；用鼻尖去看清夜风里繁衍的生机；用无缘无故接了一单大活的膀胱，说出心口直通的快乐。</p><p>不愿从众，不想被操控，不接受罗织的罪名。人皆被洪流裹挟，减熵需要额外的输入。而这些输入并不需要你下决心与这个时代分道扬镳，感受被自己遗忘的感官，就是今夜教给我的温柔。</p><p><img src="https://s2.ax1x.com/2019/04/17/Ax6dFU.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>商业供稿3：2019云计算安全5大趋势</title>
      <link href="/2019/04/15/commerical3-2019-cloud-security-trends/"/>
      <url>/2019/04/15/commerical3-2019-cloud-security-trends/</url>
      
        <content type="html"><![CDATA[<p><em>原载于云杉网络 <a href="http://www.yunshan.net" target="_blank" rel="noopener">www.yunshan.net</a> 微信公众号</em></p><h2 id="安全将成为云计算最大的挑战"><a href="#安全将成为云计算最大的挑战" class="headerlink" title="安全将成为云计算最大的挑战"></a>安全将成为云计算最大的挑战</h2><a id="more"></a><p>云计算从诞生之初的“实验性”技术到为IT行业广泛接受，成为新一代社会数字基础设施的核心技术，经历了不同的发展阶段。在“上云”已从一个可选项变成必选项之后，用户对云计算安全的担心将经受现实的真正考验。</p><p>云计算的发展历程自始至终都充满挑战：从灵活性、稳定性、性能、成本等技术挑战到用户教育等市场挑战，云计算已在这些方面取得长足进步，并通过应对这些挑战变得更加成熟。而用户也将在解决了迁移、高可用和成本控制等多种难题之后，逐渐采取以“安全”为第一出发点的上云和演进策略。这不仅要求云服务厂商具备相应的安全技术和产品支撑，也需要用户转变观念和部门文化，适应云计算环境带来的技能变化。根据调查，安全仍是用户最大的疑虑，并将随着云计算市场规模的持续增长成为云计算面临的最大挑战。</p><h2 id="容器和Serverless的普及将催生新的安全攻防形态"><a href="#容器和Serverless的普及将催生新的安全攻防形态" class="headerlink" title="容器和Serverless的普及将催生新的安全攻防形态"></a>容器和Serverless的普及将催生新的安全攻防形态</h2><p>容器是一种新的虚拟化形态，因其轻量、高效的特点正受到热烈追捧。但同传统的虚拟机不同，多个容器或不同租户间的容器都共享同一个系统内核，而不是像虚拟机一样各自拥有独立的内核。这为恶意攻击者提供了更大的攻击面。一项调查表明，60%的组织机构在2018年都遭遇过容器安全事件。</p><p>2019年，容器和Serverless的发展必将持续，同时基于这两项技术的DevOps等技术最佳实践方式也将进一步获得普及。针对容器技术特点的安全攻击和防范方法将会各自提升到一个新的阶段。当前的云计算用户对针对容器的攻击方式和防范方法仍缺少意识和规范的制度，此前在Docker Hub中发现的几十个恶意Docker镜像至今仍存在于某些用户的生产环境中，未加以任何审核和监控。但随着容器和Serverless的普及和进一步应用，此过程中必将有更多的用户意识到“容器安全”在整个基础设施体系中的重要位置，并成为整个云计算生态的重要一环。进而催生出DevSecOps等新技术最佳实践。</p><h2 id="云安全事件将波及社会基础服务设施"><a href="#云安全事件将波及社会基础服务设施" class="headerlink" title="云安全事件将波及社会基础服务设施"></a>云安全事件将波及社会基础服务设施</h2><p>在云计算发展之初，一度打出的口号是成为“IT行业的水和电”。云计算也确实在践行这一目标，并取得了IT基础设施的中心地位。有意思的是，和当初设想的略有不同，传统的社会基础设施，比如云计算的目标“水和电”，也已经开始和云计算互相融合。传统行业和社会基础服务设施也已开始数字化转型和网络化改造。《世界城市报告》指出，未来20年全球发展中国家的城市，每年都会新增近7500万人口，满足这些人口的需求，自然就需要对现有的社会服务基础设施进行改造。</p><p>金融支付、智慧交通、智慧城市、智慧油田、智慧电网、智慧农业等等都是新兴的基于云计算的社会基础服务设施改造工程。这些改造在享受云计算带来的种种便捷，提升社会整体效率的同时，也将传统社会服务基础设施和数字基础设施相互耦合，物理世界与数字世界的边界将进一步模糊。此时数字基础设施所遭受的安全风险将不仅仅局限于数字世界内部，而将进一步传导至日常社会生活的方方面面。针对此类风险的安全监管和防护规范必将成为相关工作的重点。</p><h2 id="云计算服务商将加强与安全生态的合作"><a href="#云计算服务商将加强与安全生态的合作" class="headerlink" title="云计算服务商将加强与安全生态的合作"></a>云计算服务商将加强与安全生态的合作</h2><p>云计算把涉及IT基础设施的方方面面都高度集成并统一开放给用户，计算、存储、网络、应用都划归于统一的资源池，成为一套完整的体系。并且各个不同云计算服务商之间也将涉及混合云业务和多云互联等业务。云计算安全防护的考虑，也必须针对每一个可能涉及的环节。Gartner也有报告指出，云计算服务商将最终向着“安全服务提供商”转变。</p><p>计算、存储、网络每一项都是一个专门的安全研究领域，单凭任何一家企业或组织都不可能构建一个涵盖全部细节的安全体系。云计算服务商现在多是采取与用户”责任分担”的安全策略，但并不能从根本上解决安全问题。好消息是，传统的安全公司也在向虚拟化和云原生转型，提供多种适合云计算环境的安全防护产品，并在某一特定领域有多年的沉淀和积累。云计算服务商、用户、安全生态合作伙伴将在这种合作模式中各取所需，一同打造完整的云计算安全体系。</p><h2 id="使用云内流量可视化构筑微分段安全策略"><a href="#使用云内流量可视化构筑微分段安全策略" class="headerlink" title="使用云内流量可视化构筑微分段安全策略"></a>使用云内流量可视化构筑微分段安全策略</h2><p>微分段（Microsegmentation）是当前确保云内安全的一种有效的实践方式。通过隔离不同属性的工作负载并单独加以防护，使网络具备细粒度防护的能力，同时安全规则可以随着工作负载在云内的迁移而迁移。确保不因云环境的灵活性特点而产生额外的安全策略维护负担。</p><p>针对工作负载的可视化，比如应用流量，性能，访问拓扑关系等信息，可以让用户快速构建适宜的微分段策略，并实现安全策略的自动化下发和处理。通过云内流量可视化的手段，对虚拟机和容器基于应用、审计合规需求、数据敏感性等特征分组并划分为不同的工作负载，将会极大减轻规则维护开销，并提供适应于云环境特点的细粒度的防护能力。这将是未来确保云内网络安全的主流方式。</p>]]></content>
      
      
      <categories>
          
          <category> commerical </category>
          
      </categories>
      
      
        <tags>
            
            <tag> commerical </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Quickwords 26 Linux Perf Under The Hood</title>
      <link href="/2019/04/13/quickwords26-linux-perf-under-the-hood/"/>
      <url>/2019/04/13/quickwords26-linux-perf-under-the-hood/</url>
      
        <content type="html"><![CDATA[<p>Too many <code>perf</code> usage articles exist on the Internet yet few talks about its source code, mechanism and architecture under the hood. For anyone who’s not satisfied with a black box, this article tries to address this.</p><h2 id="Hardware-Background-Knowledge"><a href="#Hardware-Background-Knowledge" class="headerlink" title="Hardware Background Knowledge"></a>Hardware Background Knowledge</h2><p>You probably know that <code>perf</code> retrieves CPU hardware PMU counter value at some regular sampling frequency to make everything happen. The path through the hardware value is called <code>MSR(Model-Specific Register)</code> operations. Note that <code>MSR</code> is a general designation for various kinds of registers and PMU is just a small portion of it. To be more specific, we are mainly talking about the Performance Event Select Registers and the Performance Monitoring Counters(PMC) which make up the PMU together. By interacting with the Performance Event Select Register at the software side, value of performance events is streaming out via PMC.<br><a id="more"></a></p><p>The Performance Event Select Register has quite a lot of control flags to let you specify which and how a performance event you’d like to monitor. This article does not try to cover this topic, one can refer to the Intel Software Developer Manual for detail.</p><p>The PMC value can be proactively counted as well as reactively sampled. In this article we narrow our scope to the proactive manner only as we would like to concentrate more on the “big picture”.</p><h2 id="How-perf-Works"><a href="#How-perf-Works" class="headerlink" title="How perf Works"></a>How <code>perf</code> Works</h2><p>In order to understand how <code>perf</code> works we need to answer the following questions:</p><ul><li>How to read PMC</li><li>How does <code>perf</code> obtain PMC value via file operation</li></ul><p>These are basically the core functionalities of <code>perf</code> and every its fancy feature is based on this. </p><h3 id="How-To-Read-PMU"><a href="#How-To-Read-PMU" class="headerlink" title="How To Read PMU"></a>How To Read PMU</h3><p><code>MSR</code> is relatively difficult to interact when compare to stuffs like <code>rdtsc</code>. You need a whole software schema to build up the APIs even though they share similar names(<code>rdpmc</code>).</p><p>Regarding the underlying implementation, one can find in the <code>struct pmu</code> data struct(<code>/include/linux/perf_event.h</code>) which consists of a branch of operation function pointers. Implementations pointed by these pointers are the real workers for PMU tasks.</p><p>In case of x86, the implementations are located in file <code>/arch/x86/events/intel/core.c</code>. Address of worker functions are assigned to corresponding function pointers in <code>struct x86_pmu</code>(/anch/x86/events/core.c).</p><p>Set <code>x86_pmu_read</code> which reads the <code>PMU</code> of a particular kind of event as an example, this function finally invokes <code>x86_perf_event_update()</code>(/arch/x86/events/core.c) to obtain PMC value via <code>rdpmcl</code> which involves with the ultimate assembly instruction, in a compare and swap manner.</p><h3 id="How-Does-perf-Obtain-PMC-Value-via-File-Operation"><a href="#How-Does-perf-Obtain-PMC-Value-via-File-Operation" class="headerlink" title="How Does perf Obtain PMC Value via File Operation"></a>How Does <code>perf</code> Obtain PMC Value via File Operation</h3><p>A complete <code>perf_event</code> consists of the value of PMC, the critical part, and a handful of linked list, status and statistics elements. The definition is <code>struct perf_event</code> in /include/linux/perf_event.h.</p><p><code>perf_event</code> exposes as a file descriptor to the user space applications(<code>stat</code>, <code>top</code>, <code>record</code> etc). These applications interact with <code>perf_event</code>, as well as PMU, by invoking normal file operations on corresponding file descriptors.</p><p>It appears that application just calls <code>read</code> on a file operations, actually, the <code>read</code> action has already been replaced by actions of <code>static const struct file_operations perf_fops</code>  in /kernel/events/core.c. The real <code>read</code> function invoked is <code>perf_read</code>. This function will finally call <code>pmu-&gt;read</code> to stream out the PMC value.</p><p>The initialization process of <code>perf_event</code> and file descriptor is <code>sys_perf_event_open</code> in /kernel/events/core.c. The new file descriptor will be returned when success.</p><p>In real application, <code>buildtin-stat.c</code> for instance, <code>__run_perf_stat</code> consequently calls <code>process_interval()</code>, <code>read_counters()</code>, <code>read_counter()</code>, <code>perf_evsel__read_counter()</code>, <code>perf_evsel__read_one()</code>, <code>perf_evsel__read()</code>, and <code>readn()</code>.</p><p>Multiple file descriptors/counters can be polled as same as the normal <code>poll()</code> operation from application’s perspective. The only difference is invoking fd’s customized poll() function.</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> perf </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚25：Skylake微架构(Microarchitecture)剖析(9)</title>
      <link href="/2019/04/08/quickwords25-skylake-pipeline-9/"/>
      <url>/2019/04/08/quickwords25-skylake-pipeline-9/</url>
      
        <content type="html"><![CDATA[<p>接<a href="https://decodezp.github.io/2019/04/06/quickwords24-skylake-pipeline-8/">上期</a>。</p><h2 id="第六个cycle之后"><a href="#第六个cycle之后" class="headerlink" title="第六个cycle之后"></a>第六个cycle之后</h2><p>看一下第六个cycle时会发生什么。<br><a id="more"></a></p><p><img src="https://s2.ax1x.com/2019/04/06/AW0xf0.png" alt=""></p><p>仍然分为两个阶段。第一个阶段<code>cycle 6’</code>里，第六条<code>ADD</code>指令指令可以进入ROB以及RS。</p><p>在RS中，<code>D-tag</code>填写该指令所在的ROB条目<code>ROB6</code>，两个操作数通过读取<code>RAT</code>获得，<code>R4</code>和<code>R2</code>对应的分别是<code>ROB5</code>和<code>ROB1</code>。</p><p><code>RAT</code>中<code>R1</code>所对应的最新值修改为<code>ROB6</code>。</p><p><img src="https://s2.ax1x.com/2019/04/06/AWBCXF.png" alt=""></p><p>在第二个阶段，注意到此时第二条指令也在<code>cycle 6</code>执行完毕，因此它将执行的结果(8)写入到其所在的ROB条目<code>ROB2</code>，并在同时将执行的结果广播给RS中的指令。</p><p>此时RS中的<code>MUL</code>指令正在等待<code>ROB2</code>的值，此时将其对应的<code>Value1</code>中写入计算的结果(8)。</p><p><img src="https://s2.ax1x.com/2019/04/06/AWBplT.png" alt=""></p><p>在第七个周期，注意到第五条指令也该执行完成，其所执行所得到的结果(-1)，也需要写回到<code>ROB5</code>并广播给RS中的指令。但此时没有等待该值的指令。所以对其他状态暂时没有影响。</p><p>但如果此时有新的指令需要<code>R4</code>，<code>ROB5</code>此时的值可以直接传递给该指令。</p><p><img src="https://s2.ax1x.com/2019/04/06/AWBSpV.png" alt=""></p><p>在第7个指令之后，CPU进入一个尴尬的时期。没有新的指令执行完毕，RS中的指令也没有<code>Ready</code>的，观察一下时刻表，下一个时刻有新的指令执行完毕是<code>cycle 12</code>的事。</p><p>在<code>cycle 12</code>中第一条<code>DIV</code>指令执行完毕，结果写入<code>ROB1</code>，广播结果给RS中的指令，正好两个都需要<code>ROB1</code>，并且拿到这个结果之后都进入<code>Ready</code>状态，可以在下一个cycle执行。</p><p>更新一下第四条和第六条指令的时刻表，执行都是在第13个cycle，完成将分别在第16和14个cycle。</p><p>此时还发生了一件事，就是ROB中的第一条指令的<code>DONE</code>标志位标成了<code>Y</code>。ROB之前我们介绍是一个先入先出的FIFO结构，只有第一条指令完成之后，才能按顺序开始commit。</p><p><img src="https://s2.ax1x.com/2019/04/06/AWB96U.png" alt=""></p><p>所以在<code>cycle 13</code>，第一条指令历史性的commit了。Commit的意思就是把结果写入到<code>ARF</code>，因此<code>R2</code>在ARF中改为了4。同时删除该ROB条目，为后续的指令腾出资源。当然<code>RAT</code>中也不再需要rename到<code>ROB1</code>，最新的值已经在<code>ARF</code>中。</p><p><img src="https://s2.ax1x.com/2019/04/06/AWBim4.png" alt=""></p><p>在<code>cycle 14</code>中，ROB中的当前在队列头部的指令，也就是第二条指令也可以commit了，按之前的操作，<code>R1</code>的值也改成了最新的值(8)。</p><p>同时，第六条指令也执行完毕，计算的结果写入<code>ROB6</code>。当然这条指令还不能commit，因为commit需要按指令顺序。</p><p><img src="https://s2.ax1x.com/2019/04/06/AWBF0J.png" alt=""></p><p>第15个cycle，除了commit第三条指令之外没什么好做的。和以前的操作类似。</p><p><img src="https://s2.ax1x.com/2019/04/06/AWBVt1.png" alt=""></p><p>第16个指令，第4条指令执行完毕，结果写入<code>ROB4</code>，同时它也是当前ROB中在队列头部的指令，可以在下一个cycle commit。</p><p><img src="https://s2.ax1x.com/2019/04/06/AWBEkR.png" alt=""></p><p>那就commit呗。</p><p><img src="https://s2.ax1x.com/2019/04/06/AWBk79.png" alt=""></p><p>剩下的第18,19 cycle想必你也知道该干什么了：把最后的两条指令commit掉。</p><p><img src="https://s2.ax1x.com/2019/04/06/AWBZfx.png" alt=""></p><p>OK，当指令时刻表都完成之后，这6条指令正式执行完毕。</p><h2 id="关于这几个组件"><a href="#关于这几个组件" class="headerlink" title="关于这几个组件"></a>关于这几个组件</h2><p>全部目的都在于通过一个示例解释<code>RAT</code>, <code>ROB</code>和<code>RS</code>这三个组件的组成、特性和功能。在熟悉了这个例子的基础上可以再去寻找那些传统的“教科书”去印证理解那些大段大段的文字描述。</p><p>这个例子其实还缺少一些类似分支转跳，尤其是分支预测失败之后如何操作的说明。但足矣描述清楚CPU的乱序执行和顺序commit到底是怎么回事。</p><p>关于CPU微架构，前端和后端的内容基本上介绍的差不多了，后面会开始最后一个部分，也就是内存操作相关的组件的介绍。兴许会再添加一个后端执行的示例也说不定，看心情。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚24：Skylake微架构(Microarchitecture)剖析(8)</title>
      <link href="/2019/04/06/quickwords24-skylake-pipeline-8/"/>
      <url>/2019/04/06/quickwords24-skylake-pipeline-8/</url>
      
        <content type="html"><![CDATA[<h2 id="一个示例介绍Reorder-Buffer-ROB-和Register-Alias-Table-RAT-和Reservation-Station-RS"><a href="#一个示例介绍Reorder-Buffer-ROB-和Register-Alias-Table-RAT-和Reservation-Station-RS" class="headerlink" title="一个示例介绍Reorder Buffer(ROB)和Register Alias Table(RAT)和Reservation Station(RS)"></a>一个示例介绍Reorder Buffer(ROB)和Register Alias Table(RAT)和Reservation Station(RS)</h2><p>理解乱序执行（Out-of-Order）的核心其实就是把ROB，RAT和RS这三个组件搞透。<br><a id="more"></a></p><p>如果要单独讲，很容易成为一大锅概念和专有名词的杂烩。所以这次把这几个紧密相关的组件放到一起，先用例子说明，仅描述自然行为，同时也避免出现太多概念。</p><p><img src="https://s2.ax1x.com/2019/04/06/AW0jkn.png" alt=""></p><p>上图是在一个起始时刻<code>CYCLE 0</code>时CPU后端各组件的状态。它即将执行<code>Instructions</code>表格里的6条指令。不同种类指令所需要消耗的执行时间如<code>Cycle Consumption</code>所示。</p><p><code>ARF</code>是<code>Architectural Register File</code>，里面保存有当前时刻<code>architectural register</code>中的值；<code>RAT</code>就是<a href="https://decodezp.github.io/2019/04/03/quickwords23-skylake-pipeline-7/">前面</a>介绍过的<code>Register Alias Table</code>，主要用作对<code>architectural register</code>的Rename。</p><p><code>Reservation Station(RS)</code>根据所连接的执行不同类型指令的Port而分成两类，一类保存<code>ADD/SUB</code>相关的指令，一类保存<code>MUL/DIV</code>相关的指令。里面的指令在两个Value都<code>Ready</code>的时候将发送到执行单元执行。</p><p> <code>Re Order Buffer</code>旁边的表格是这6条指令从<code>Issue</code>到<code>Execute</code>, <code>Write</code>最后再到<code>Commit</code>这几个状态的cycle时刻表。</p><p>OK，那么下面进入第一个cycle。</p><p><img src="https://s2.ax1x.com/2019/04/06/AW0HOg.png" alt=""></p><p>第一条指令<code>DIV R2, R3, R4</code>按照先进先出的原则首先进入<code>ROB1</code>。</p><p>在ROB中，<code>Dst</code>填该指令的目的<code>architectural register</code>，也就是R2；<code>Value</code>是该指令执行完计算出来的结果，显然现在还不得而知，表示是否执行完的<code>Done</code>标志位也是N的状态。</p><p>同时针对<code>DIV</code>指令的RS中也有空闲资源，因此该指令也会在同一cycle进入RS。目的tag<code>D-tag</code>填写指令对应的<code>ROB</code>条目(ROB1)；<code>Tag1</code>和<code>Tag2</code>通过查阅<code>RAT</code>中<code>R3</code>和<code>R4</code>的状态，如果有Rename的情况，则填写对应的ROB条目，如果没有，则直接读取<code>ARF</code>中的值，作为<code>Value</code>填入。</p><p>因此，<code>D-tag</code>是<code>ROB1</code>，<code>Tag1</code>和<code>Tag2</code>因为<code>R3</code>和<code>R4</code>没有Rename所以不填，直接读取<code>ARF</code>中的值，20和5，放入<code>Value1</code>和<code>Value2</code>中。</p><p>之后，在<code>RAT</code>中，R2被Rename成了<code>ROB1</code>，即表示后续指令欲读取R2的值的话，都应该去读取<code>ROB1</code>中<code>value</code>的值。</p><p>此时该<code>DIV</code>指令所需要的操作数都已经<code>Ready</code>，那么就可以在下一个cycle时从RS中<code>发射</code>到执行单元去执行。</p><p>下面进入第二个cycle。</p><p><img src="https://s2.ax1x.com/2019/04/06/AW0qmQ.png" alt=""></p><p>在第二个cycle中，第一条<code>DIV</code>指令开始执行，根据<code>DIV</code>的执行周期，那么我们知道它将在第<code>2 + 10 = 12</code>个cycle中执行完成。同时ROB中还有空闲，我们可以<code>issue</code>第二条<code>MUL</code>指令。</p><p>在RS中，上一条<code>DIV</code>指令已经清出，也有空闲资源，所以<code>MUL</code>指令也可以进入到RS中。另外几个选项也如<code>DIV</code>指令的判断方式，因此<code>D-tag</code>为<code>ROB2</code>，两个<code>value</code>为4和2。此时<code>MUL</code>指令也已经<code>Ready</code>，可以在下一个cycle开始执行。</p><p>同时<code>RAT</code>中将<code>R1</code>rename到<code>ROB2</code>。因为后续最新的<code>R1</code>的值将等于<code>ROB2</code>中的<code>value</code>。</p><p><img src="https://s2.ax1x.com/2019/04/06/AW0Lwj.png" alt=""></p><p>在第三个cycle中，<code>MUL</code>指令开始执行，根据<code>MUL</code>的执行周期，它将在第<code>3 + 3 = 6</code>个cycle中执行完成。因ROB中 还有空闲，此时可以<code>issue</code>第三条<code>ADD</code>指令。</p><p>RS里面，<code>ADD</code>指令需要放到存放<code>ADD/SUB</code>指令的RS中，除此之外，各字段的填写方式与之前的指令没有区别。<code>R7</code>和<code>R8</code>也可以直接从<code>ARF</code>中获取数值，因此该<code>ADD</code>指令也已经<code>Ready</code>，可以在下一个cycle开始执行。</p><p>之后，<code>RAT</code>中将<code>R3</code>rename到<code>ROB3</code>。</p><p><img src="https://s2.ax1x.com/2019/04/06/AW076S.png" alt=""></p><p>那么在第四个cycle中，第四条<code>MUL</code>指令可以进入<code>ROB</code>和<code>RS</code>之中。在RS中，<code>D-tag</code>填入该指令对应的<code>ROB</code>条目，即<code>ROB4</code>。而它的第一个操作数<code>R1</code>通过<code>RAT</code>读取（参见cycle 3中的<code>RAT</code>情况。），rename到了<code>ROB2</code>，因此<code>tag1</code>需要填<code>ROB2</code>。<code>Tag2</code>同理，填<code>ROB1</code>。</p><p>之后，<code>RAT</code>中的<code>R1</code>需要rename到<code>ROB4</code>，以保持最新的状态。</p><p>RS中，因为该条指令两个操作数的<code>value</code>还没有Ready，不能在下一个cycle开始执行，因此还暂存在RS之中。</p><p><img src="https://s2.ax1x.com/2019/04/06/AW0OTs.png" alt=""></p><p>在第五个cycle中，拆成两个阶段来看。第一个阶段，也即<code>cycle 5`</code>，第五条<code>SUB</code>指令进入<code>ROB</code>和<code>RS</code>，各字段的填写方式与之前相同。</p><p><img src="https://s2.ax1x.com/2019/04/06/AW0vYq.png" alt=""></p><p>在cycle 5的第二个阶段中，注意到指令时刻表中，第三条在指令将在cycle 5完成执行，并进入<code>Write</code>阶段。</p><p>于是此时第三条指令在<code>ROB</code>中对应的<code>ROB3</code>的<code>Value</code>中将填入该指令执行的结果，也就是3，同时设置标志位<code>DONE</code>为Y。</p><p>在执行完成之后，在同一个cycle中，CPU还将进行一个操作，就是将该结果广播给RS中现存的指令，如果有等待<code>ROB3</code>执行结果的指令，将接收该结果并更新状态。</p><p>在当前<code>RS(Adder)</code>中，<code>SUB</code>指令正在等待<code>ROB3</code>的结果（参见<code>cycle5`</code>），于是其不再等待<code>Tag1</code>，并在<code>Value1</code>中填入结果3。此时该<code>SUB</code>指令也已经Ready，并将在下一个cycle中执行，根据其执行开销，将在第<code>6 + 1 = 7</code>cycle时执行完成。</p><p>后面的下期再继续。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚23：Skylake微架构(Microarchitecture)剖析(7)</title>
      <link href="/2019/04/03/quickwords23-skylake-pipeline-7/"/>
      <url>/2019/04/03/quickwords23-skylake-pipeline-7/</url>
      
        <content type="html"><![CDATA[<h2 id="接前Register-Rename"><a href="#接前Register-Rename" class="headerlink" title="接前Register Rename"></a>接前Register Rename</h2><p>这次得用Markdown画表格了，想来想去用<code>markdown</code>这么久还是第一次。<br><a id="more"></a></p><p>如前所述，<code>physical register</code>的数量远多于<code>architectural register</code>的数量。其实<code>architectural register</code>仅仅是一个“代号”，并不是真正存放数据的位置。用这种方式，可以消除<code>WAW</code>和<code>WAR</code>这两种数据依赖进而增加程序整体的并行性。</p><p>那么到底怎么操作呢？其实本质上也就是建立一个“映射表”，一个从“代号”到存储位置的映射表。</p><p>E.g.</p><p>现有5个<code>architectural register</code>寄存器：r1, r2, r3, r4, r5；9个<code>physical register</code>寄存器：p1, p2, …, p9。</p><p>指令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Add r1, r2, r3 ;r1 = r2 + r3</span><br><span class="line">Sub r2, r1, r2 ;r2 = r1 - r2</span><br><span class="line">Add  r1, r4, r5 ;r1 = r4 + r5</span><br></pre></td></tr></table></figure><p>最开始是一个简单的映射关系：</p><table><thead><tr><th>r1</th><th>r2</th><th>r3</th><th>r4</th><th>r5</th></tr></thead><tbody><tr><td>p1</td><td>p2</td><td>p3</td><td>p4</td><td>p5</td></tr></tbody></table><p>在这张表里面还有一个<code>FreeList</code>，用来保存还没有被占用的<code>physical register</code>。</p><table><thead><tr><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>p6</td><td>p7</td><td>p8</td><td>p9</td></tr></tbody></table><p>OK，首先考虑不使用<code>Register Rename</code>的情景。第二条指令是必须等待第一条指令执行完成之后才能执行，因为<code>r1</code>有<code>RAW</code>型依赖。这个其实<code>Register Rename</code>也没有办法。但是第三条指令也不能在第二条指令之前执行，因为写入<code>r1</code>可能会影响第二条指令的结果（r2）。</p><p>为了增加指令的并行性，让第三条指令能与第一条指令并行，同时消除<code>WAW</code>和<code>WAR</code>型依赖，看一下<code>Register Rename</code>是怎么做的。</p><p>第一条指令就用原始对应的寄存器，此时还没有Register Rename。对应的“映射表”<code>Rename Table</code>如下：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>r1</td><td>p1</td></tr><tr><td>r2</td><td>p2</td></tr><tr><td>r3</td><td>p3</td></tr><tr><td>r4</td><td>p4</td></tr><tr><td>r5</td><td>p5</td></tr></tbody></table><p>第二条指令中，<code>r2</code>针对第一条指令有<code>WAR</code>型依赖，可以将写入<code>r2</code>的结果放在另外一个寄存器里。从<code>FreeList</code>中选取下一个空闲的<code>physical register</code>，即<code>p6</code>。</p><p>所以这条指令实际上就变成了<code>Sub r6, r1, r2; r6 = r1 - r2</code>。</p><p><code>Rename Table</code>如下：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>r1</td><td>p1</td></tr><tr><td>r2</td><td><strong>p6</strong></td></tr><tr><td>r3</td><td>p3</td></tr><tr><td>r4</td><td>p4</td></tr><tr><td>r5</td><td>p5</td></tr></tbody></table><p>即告之后续指令<code>r2</code>最终的结果保存在<code>p6</code>里面。</p><p>第三条指令，<code>r1</code>针对第一条指令有<code>WAW</code>型依赖，可以将写入<code>r1</code>的结果放到另外一个寄存器里。从<code>FreeList</code>中选取下一个空闲的<code>physical register</code>，即<code>p7</code>。</p><p>所以这条指令实际上就变成了<code>Add p7, p4, p5 ; p7 = p4 + p5</code></p><p><code>Rename Table</code>如下：</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>r1</td><td><strong>p7</strong></td></tr><tr><td>r2</td><td>p6</td></tr><tr><td>r3</td><td>p3</td></tr><tr><td>r4</td><td>p4</td></tr><tr><td>r5</td><td>p5</td></tr></tbody></table><p>即告之<code>r1</code>最终的结果保存在<code>p7</code>里面。</p><blockquote><p>所有指令对<code>architectural register</code>的读取都先通过<code>Rename Table</code>获得确切地址。</p></blockquote><p>回到最初提到的问题，因为第一条指令和第三条指令实际写入的寄存器（分别是p1和p7）并不冲突，且第二条指令仅在<code>p1</code>中读取数据，因此这两条指令可以并行执行。</p><p>现代CPU的<code>Rename Table</code>一般是在<code>ROB</code>里的<code>RAT(Rename Alias Table)</code>。同时<code>physical register</code>也会被<code>ROB entry</code>取代。</p><p>其实现在对<code>Register Rename</code>的理解更多的是建立一个概念，在整个微架构中，这一步不是一个孤立的组件，所有组件之间都需要紧密配合。</p><p>后续会对后端的执行进行示例介绍。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>雨中冒险2 Risk Of Rain 2</title>
      <link href="/2019/04/03/games-risk-of-rain-2/"/>
      <url>/2019/04/03/games-risk-of-rain-2/</url>
      
        <content type="html"><![CDATA[<p>《雨中冒险》是我买的第一款Steam游戏。</p><p>6年前，刚刚毕业，手边只有一台上学时陪伴着我的笔记本电脑，我知道它只能带得动这种简陋的像素风游戏。<br><a id="more"></a></p><p>好在这游戏可玩性很好，在2013年这个难过的年份里带给我很多慰藉。那时的我刚刚处于毕业后的迷茫期，各种失望，看不清也不想看什么所谓的未来。每天晚上下班在合租的房子里玩一会这个游戏，就是一天里最快乐的一段时间。</p><p>《雨中冒险》当时也小火了一阵。我会在网上看看别人的视频和评价，有一次无意中看到了游戏开发者发的一篇博客。我大概记着他在博客里说这款游戏最初只是一个学生项目，谢谢大家的支持，他没有想到可以走这么远。</p><p>传统的一些套话。我真正记住的是他后面说的：</p><blockquote><p>我想看看还能走多远。</p></blockquote><p>后来，我自己买了房子，摆了一台可以碾压市面上所有游戏的台式机，可以在Steam上不再关注什么打折促销信息，什么火买什么。简单地说，就是实现了“Steam自由”。</p><p>但很多最初期待颇高的游戏大作，我都是进入游戏看看，就再也没打开过。</p><p>唯一例外的是，我总会想起《雨中冒险》，虽然我距离上一次打开它已经有了三四年的时间。</p><p>人们会相信一些东西，往往只是因为那是人们心里想要相信的东西；人们也会记住一些东西，却并不是因为记忆力有多么好，而只是因为那是心里想要记住的。对我来说，我还一直记得《雨中冒险》，只是因为想要明确那个当初说“想看看还能走多远”的人，到底走了多远。</p><p>虽然我和这游戏的作者素不相识，但我那时仿佛单方面和他立了一个约定。</p><p>所以当我得知《雨中冒险》出了续作之后，一点也不吃惊；当我得知《雨中冒险2》是3D画面的时候，一点也不吃惊；当我购买了游戏结束了一盘战斗的时候，我觉得这游戏就应该是这个样子，我仿佛看到了我过去6年的足迹。</p><p>给五星，没有什么好说的。</p>]]></content>
      
      
      <categories>
          
          <category> game </category>
          
      </categories>
      
      
        <tags>
            
            <tag> game </tag>
            
            <tag> life </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚22：什么是AF_XDP Socket</title>
      <link href="/2019/03/26/quickwords22-af-xdp/"/>
      <url>/2019/03/26/quickwords22-af-xdp/</url>
      
        <content type="html"><![CDATA[<h2 id="AF-XDP"><a href="#AF-XDP" class="headerlink" title="AF_XDP"></a>AF_XDP</h2><p>默认读者已经了解XDP(eXpress Data Path)的概念。<br><a id="more"></a></p><p>基于Kernel提供的BPF能力，XDP可以提供高性能的数据面处理能力。</p><p>所谓<code>AF_XDP</code>，和<code>AF_INET</code>一样，也是<code>address family</code>的一种，用于规定socket通讯的类型。相当于socket底层通讯方式的不同实现（多态）。一般的，<code>AF_INET</code>可以用于IPv4类型地址的通讯，在实际通讯中应用自己的那套具体实现（TCP/IP协议栈等），<code>AF_XDP</code>就是一套基于XDP的通讯的实现。</p><p>还有支持IPX的<code>AF_IPX</code>，支持蓝牙的<code>AF_BLUETOOTH</code>等等Address Family。</p><h2 id="Main-Idea"><a href="#Main-Idea" class="headerlink" title="Main Idea"></a>Main Idea</h2><p><img src="https://s2.ax1x.com/2019/03/26/ANONQS.jpg" alt=""></p><p>XDP程序在Kernel提供的网卡驱动中直接取得网卡收到的数据帧，然后直接送到用户态应用程序。应用程序利用<code>AF_XDP</code>类型的socket接收数据。</p><p>用虚拟化领域的完全虚拟化和半虚拟化概念类比，如果DPDK是”完全Kernel bypass”，那么AF_XDP就是“半Kernel bypass”。</p><p>XDP程序会把数据帧送到一个在用户态可以读写的队列Memory Buffer中，叫做<code>UMEM</code>。用户态应用在<code>UMEM</code>中完成数据帧的读取和写入。当然了，整个过程都是零拷贝（Zero Copy）的。</p><h2 id="AF-XDP-Socket和它的小伙伴们"><a href="#AF-XDP-Socket和它的小伙伴们" class="headerlink" title="AF_XDP Socket和它的小伙伴们"></a>AF_XDP Socket和它的小伙伴们</h2><p><img src="https://s2.ax1x.com/2019/03/26/AUoFzQ.png" alt=""></p><p><code>AF_XDP</code>Socket的创建过程可以使用在网络编程中常见的<code>socket()</code>系统调用，就是参数需要特别配置一下。在创建之后，每个socket都各自分配了一个RX ring和TX ring。这两个ring保存的都是descriptor，里面有指向<code>UMEM</code>中真正保存帧的地址。</p><p><code>UMEM</code>也有两个队列，一个叫<code>FILL ring</code>，一个叫<code>COMPLETION ring</code>。其实就和传统网络IO过程中给DMA填写的接收和发送环形队列很类似。在RX过程中，用户应用程序在<code>FILL ring</code>中填入接收数据包的地址，XDP程序会将接收到的数据包放入该地址中，并在socket的RX ring中填入对应的descriptor。</p><p>但<code>COMPLETION ring</code>中保存的并非用户应用程序“将要”发送的帧的地址，而是已经完成发送的帧的地址。这些帧可以用来被再次发送或者接收。“将要”发送的帧的地址是在socket的TX ring中，同样由用户应用填入。</p><p>RX/TX ring和FILL/COMPLETION ring之间是多对一（n:1）的关系。也就是说可以有多个socket和它们的RX/TX ring共享一个<code>UMEN</code>和它的FILL/COMPLETION ring。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>后凉龙骧将军吕邈教你如何一本正经胡说八道</title>
      <link href="/2019/03/24/history3-lvmiao/"/>
      <url>/2019/03/24/history3-lvmiao/</url>
      
        <content type="html"><![CDATA[<p>胡说八道容易，看起来一本正经也不难，但那都是从你自己的眼光出发。</p><p>让别人看起来同样一本正经就非常有挑战了，即便你真的是在一本正经。</p><a id="more"></a><p>历史上很多著名的说服案例，其实都有一个“成功核心”。因此，那些有名的谋臣说客不用上沃顿商学院的谈判课也能够纵横捭阖。</p><p>和秦仪良平比起来，后凉龙骧将军吕邈只是一个小角色，但他也有属于自己的高光时刻。这个时刻就是那一次他胡说八道的时候。</p><p>吕邈也算是后凉的皇亲贵胄，虽然这个政权只有17年的历史，但这并不妨碍在这里上演那些百年王朝的保留节目——夺嫡。</p><p>后凉太祖吕光，是所有人的爸爸。但参与夺嫡的不仅有自己的儿子，还有自己的侄子。这场宫廷戏有三位主角：庶长子吕纂，侄子吕超，以及吕光嫡出的吕纬。而我们的主人公吕邈，是吕超的弟弟。</p><p><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTtDnH9tB62d1KhX6_fd1OYGYLIWL2fSFiyU6WhzU2I0I6mPmB5" alt="吕光"></p><p>其实还有一位太子吕绍，在吕光崩后很快就被吕纂逼死。</p><p>吕纂继位不到一年，本来朝内就众心不安，几个兄弟又各自为政，本应多加优抚，延揽人心，却又不知道哪根筋搭错，对吕超开起了“不听话就把你杀掉”的玩笑。吕超自然当了真，也不得不当真。在一起喝了场大酒之后趁机将吕纂贯胸刺死。</p><p>吕超虽说杀了吕纂，但还不能自己继承大统，因为按继承人的顺位，前面还有吕光的嫡子吕纬。</p><p>当时就有人劝吕纬：</p><blockquote><p>超为逆乱，公以介弟之亲，仗大义而讨之。姜纪、焦辨在南城，杨桓、田诚在东苑，皆吾党也，何患不济！</p></blockquote><p>倘若能兴“义师”击超，或许真能一战。但吕纬自然知道，成王败寇，这一仗如果不能保证取胜，那么自己只会万劫不复。面对“举事已成，据武库，拥精兵”的吕超，吕纬心里还是打鼓的。</p><p>这种时候，谁都需要有一个人能信任。而之所以信任他，并不是“这个人”多么值得信任，而是“这个人”能告诉你，你自己是多么值得信任。</p><p>这就是那些纵横家赖以肆其志的关键，但在具体的操作手法上还有讲究。</p><p>于是我们的主人公登场。吕超的弟弟吕邈当时“有宠于绍”，进言曰：</p><blockquote><p>纂贼杀兄弟，隆、超顺人心而讨之，正欲尊立明公耳。方今明公先帝之长子，当主社稷，人无异望，夫复何疑！</p></blockquote><p>在我们这些“外人”看来，这根本就是吕超派来的卧底在跳反：用这些华而不实的理由麻痹吕邈，给吕超以可乘之机。</p><p>吕超杀了吕纂，是为了给吕绍你清除障碍，现在大家都等着你去当老板，吕超根本就没想和你抢——这不是胡说八道是什么？</p><p>吕绍绝非昏聩之人，又在吕家历练多年，既知道宫廷斗争的六亲不认，也知道吕邈和吕超的关系。他说的话，能信吗？</p><blockquote><p>纬信之，乃与隆、超结盟，单马入城；超执而杀之。</p></blockquote><p>他彻头彻尾地信了，于是彻头彻尾地输了。</p><p>吕邈这段话为什么能在吕纬这里取得“一本正经”的效果，主要有以下几个原因：</p><ul><li><p>吕纬愿意相信。当时的形势，吕纬如果不兴师任由吕超发展，那么自己肯定是下一个被除掉；如果兴师讨伐，心里却没底，甚至他可能已经肯定自己在军事上不是吕超的对手。两者都是死，但他同时也认定一点，就是自己在“伦理”上占有嫡出的优势，这是他唯一的“卖点”。所以他愿意相信吕邈说的，这是第一个原因。</p></li><li><p>吕邈说出了吕纬对现实的设定。“先帝长子，当主社稷”，这应该是吕纬无数次对自己说过的话。人在世上，只受一件事的驱动，那就是让自己的想法与现实实际保持一致。但这件事有一个特点，如果是自己考虑，会对“现实究竟是不是我想的这样”保持怀疑，但如果由别人说（特别是自己从来没有向别人提起过），那么就很容易轻信。因为这份“认同”是现实能向我们罗织的最温柔的陷阱。这是第二个原因。</p></li><li><p>吕邈描绘了一幅图景。这是这套一本正经胡说八道心法的具体招式。“正欲尊立明公耳”，让人仿佛看到了吕超将王位拱手让人，北面称臣的样子，吕邈可能还给自己添了些黄袍加身、山呼万岁的戏份。在前两点的前提下，如果再能将具体的景象描绘出来，激发出对方的瑰丽想象，那么你的胡说八道就成了发自肺腑的金玉良言。</p></li></ul><hr><p>庄子《大宗师》开篇有云：</p><blockquote><p>知天之所为，知人之所为者，至矣。</p></blockquote><p>老天究竟是什么意思，我摸不明白，但人都在想什么，庶几可以窥测。特记于书侧：</p><blockquote><p>此非纬昏闇轻信，固邈之所言，如纬自言，邈之所劝，如纬自劝；言而能验，事与意合，此即人之所为。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> history </category>
          
      </categories>
      
      
        <tags>
            
            <tag> history </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>商业供稿2：网络可视化如何抵御数字化转型风险</title>
      <link href="/2019/03/23/commerical2-visibility-digital-transform/"/>
      <url>/2019/03/23/commerical2-visibility-digital-transform/</url>
      
        <content type="html"><![CDATA[<p><em>原载于云杉网络 <a href="http://www.yunshan.net" target="_blank" rel="noopener">www.yunshan.net</a> 微信公众号</em></p><p>当前，“数字化转型”已成为企业或组织绕不过去的一个话题。诚然，并非所有(云杉网络的)客户都会直接声称“我们正在数字化转型”或者“我们正在做一个数字化转型的项目”，但对IT基础设施进行敏捷性改造，提升业务灵活性和效率，已是各行各业的一致追求。<br><a id="more"></a></p><p>数字化转型不是一蹴而就，对希望能“快速转型”的企业CIO和IT Leader来说，除了关注转型的战略制定和执行之外，还需要特别注意转型过程的风险。这些风险不仅会延长数字化转型的周期，还会降低IT基础设施的整体可用性。有没有可以显著降低转型风险的手段呢？近期一份研究机构推出的数字化转型关键观点报告表明：可视化是解决转型风险的关键(ASSET VISIBILITY IS KEY TO MITIGATING RISK)。</p><p>分析报告中提到了CIO与IT Leader在数字化转型中最为顾虑的几个问题：</p><p>关注最多的三个问题都与可视化直接相关。</p><p>IT基础设施中的盲点：在虚拟化已成为必选配置之后，容器、微服务、混合云、多云、云+边缘等最新趋势也将进一步加剧IT基础设施的复杂度，盲点也自然随之而生。“心里没底“是很多客户在面对复杂度呈指数级增长的IT基础设施时的共同心态。与其在半夜三更爬起来处理紧急网络故障，不如未雨绸缪，建立一套可以消除盲点的监控体系。<br>各类监控工具自然是早已有之，但能适应IT基础设施最新发展的现代监控体系必须能“整合“进基础设施本身之中，换句话说，监控工具也应具有虚拟化或云原生的基因。所有支撑数字化转型的IT基础设施所具备的特点，也应同样适用于监控方案。唯有如此，监控才能伴随基础设施一同发展，并深入到日益复杂的基础设施的方方面面，才能看到传统监控工具看不到的“盲点”。<br>在认识到基础设施复杂性的同时，也应意识到不同组件间的普遍关联性。如果仍将基础设施“分门别类”并分别加以监控，将只会在不同的部门之间树立一个个独立的“烟筒”，既令监控方案与基础设施方凿圆枘，无法发挥已有监控工具的能力，也无法通过统一的数据分析纳管消除盲点。</p><p>扩展监控的能力：IT基础设施在变得日益复杂的同时带来了一个简单粗暴的问题：如此大规模的数据采集和处理监控工具能不能扛得住？曾有报道提到Google每周启动40亿个容器，Uber的监控系统每秒钟采集5亿条指标。这些事件产生的是海量的需要处理的数据。即便很多企业或组织达不到这种互联网巨头的体量，但物理机、虚拟机、容器和网络规模的大幅度增长也是数字化转型过程中必然可以预见的事情。当量变产生质变，之前的工具和手段是否仍然行之有效，或者说，当前的监控方案为IT基础设施的增长预留了多大的成长空间，自然成为CIO和IT Leader关心的事情。相应的，现代监控系统也应具备这种伸缩能力以及深度优化的数据处理性能，才能持续为数字化转型保驾护航。这不仅要求该方案具有极高的技术含量，同时也需要深厚的产品哲学和数据理念。</p><p>成熟的IT运维流程：数字化转型享有的一大优势就是能以敏捷的方式应对业务和客户的需求，从而对市场做出快速反应。这一方面需要IT基础设施提供生产资料保证，另一方面，生产资料能创造多大的生产力，仍然取决于它握在谁的手里。传统的IT运维团队往往以各种形式划分为独立的小团队，团队之间会一般性地存在信息壁垒。这些壁垒导致运维流程只能不断迁就人为的限制，造成效率方面的损失，已不能适应数字化转型之后的IT基础设施的发展。<br>为了应对数字化转型带来的挑战，CIO和IT Leader需要考虑为DevOps团队打造更加成熟的流程。一支训练有素的DevOps团队将是提高企业生产力的最核心要素。高效的团队一定有成熟的流程保证，但流程的制定是建立在信息透明，全局可控的基础之上。不同职能的个人可以在一个统一的可视化监控平台中交换信息，形成合力，逐步完善运维、扩容和安全流程。这也应是监控体系在数字化转型中提供的能力。</p><p>当企业或组织的CIO和IT Leader在评估IT基础设施中的监控方案时，需要着意上述提到的数字化转型过程中的风险以及它们的应对方法。</p>]]></content>
      
      
      <categories>
          
          <category> commerical </category>
          
      </categories>
      
      
        <tags>
            
            <tag> commerical </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>生小猫啦</title>
      <link href="/2019/03/20/hello-kitty/"/>
      <url>/2019/03/20/hello-kitty/</url>
      
        <content type="html"><![CDATA[<p>去年夏天的时候家里从地铁站门口迎来了两位新成员，蓝猫derder和他的媳妇葡萄。</p><p>我其实本意并不想养宠物的，毕竟从小到大除了养过两只乌龟之外，从来也没和动物有过什么亲密接触。养猫基本上都是张老师的主意，她从小就是养鸡小能手，还养过狗啊鱼啊刺猬啊这些，所以一直想在家里恢复一下她的童年记忆。<br><a id="more"></a></p><p>对此我嘴上说太麻烦，但其实心里多少也有一些期待。所以当某一天张老师告诉我地铁站门口在卖猫的时候，我也就直接答应了下来。</p><p>后来张老师跟我说，她一眼相中derder的原因就是因为他那张大脸，在一群猫中显得卓尔不群：</p><p><img src="https://s2.ax1x.com/2019/03/20/AK9XCQ.jpg" alt="可以拿来当枕头用的脸"></p><p>刚到家里的时候两只猫并没有这么放浪形骸，躲在前主人送的猫厕所里不敢出来。我们也完全是新晋猫奴，还曾担心过他们会不会因为思念过往得上抑郁症。后来证明完全是多余的，derder完全就是一只毫无气节奴颜媚骨的弄臣，几天的时间就把我们讨好得心甘情愿给他和他媳妇铲屎。</p><p><img src="https://s2.ax1x.com/2019/03/20/AKCdVf.jpg" alt="手机里第一张derder的照片，走出厕所，变节叛变"></p><p>而和derder相比，葡萄就显得太过孤僻了。不敢和我们靠近，经常自己躲在一个小角落里向外观望，一旦家里有什么风吹草动就瑟缩在一个自认为安全的角落里。虽然颜值很高，但还是能看出心里总是有戒备，总是一副生气的表情，所以在家里完全失宠，作为derder的一个“附庸”存在，成为了“愤怒的葡萄”。</p><p><img src="https://s2.ax1x.com/2019/03/20/AKPPsI.jpg" alt="葡萄第一次从厕所出来，离得我们远远的"></p><p><img src="https://s2.ax1x.com/2019/03/20/AKPTk8.jpg" alt="很长一段时间是处于只露出一直爪子的阶段"></p><p>自从有了猫，我感觉家里的快递就没停过。猫粮、猫砂、猫罐头、猫薄荷、亮毛膏就一股脑地往家里运，还有猫抓板、猫别墅、饮水器、逗猫棒、摄像头、各种小玩具、小衣服等等不一而足。一直没仔细算过养两只猫一个月得有多少成本，但我觉得这个市场规模可能比我从事的云计算规模还大。</p><p><img src="https://s2.ax1x.com/2019/03/20/AKiBcj.jpg" alt="打上领结也还是一只傻猫"></p><p>Derder很快就和我们混熟了，我觉得最重要的一点原因就是他从来不惮于表达他对我们的喜爱。晚上在门口迎接，跟着你到处跑，你坐下的时候就爬到你身上，不停地蹭你，拱你，用小肉垫拍拍你，喉咙里还经常呼噜呼噜的，让你觉得不用手撸他就是一种毫无人性的犯罪。我们也很吃这套，张老师每天都会把derder抱在怀里治愈自己。</p><p><img src="https://s2.ax1x.com/2019/03/20/AKFhIf.md.jpg" alt="黏人的derder"></p><p>这期间我换了份工作，张老师也取得了一些进步，所以有时候我们会把derder看成是家里的一个吉祥物，能够为我们带来好运气。我当初在derder来家里不久就把我的微信头像换成了他，当时很大一部分是出于讨好张老师的原因，后来我却是真的想用这个头像了。另外，为了祝贺我跳槽成功，张老师也送了我一个特别的礼物，叫做<code>Der CUP</code>。</p><p><img src="https://s2.ax1x.com/2019/03/20/AKF2qI.jpg" alt="摆在我办公桌上的Der CUP"></p><p>张老师养猫的决策发挥了很大的积极作用，当然，在这个过程里我觉得我也做了两条关键的决策。第一是没有一上来就给derder绝育，而是等到葡萄怀孕之后。虽然不绝育有发情期的各种问题，但能体验到新生命降临的幸福感，这绝对是我的功劳。第二是没让张老师把葡萄送人，葡萄当时一直是一只孤僻胆小的小母猫，跟谁也不亲近，骨瘦如柴，还经常”保持愤怒“。但我还是不想放弃她，相信她最终能融入到我们家，因为我们家就有这种包容的气质。</p><p>后来证明我是对的，葡萄慢慢对我们放下了戒备，也慢慢有了些许的互动，甚至体重也上升了。我觉得虽然是我坚持没有放弃葡萄，但葡萄能产生这种转变应该主要归功于张老师。她天生就有这种母性的光辉和气质，能融化一切冰冷。</p><p><img src="https://s2.ax1x.com/2019/03/20/AKFfdP.jpg" alt="双猫傍地走"></p><p>作为一个从前从未养过宠物的人，我从derder他们身上得到的最大的惊喜就是”陪伴“。以前我在电脑上搞个什么东西的时候，从来都是一个人，在我的意识里，其实就没有“有人陪着你”的概念。但是当derder开始在我弄这些东西的时候趴在我旁边，虽然他可能仅仅是想让我挠他，但这让我开始意识到生活中很多事情可以不必一个人完成。这对我来说，是很大的突破了。</p><p><img src="https://s2.ax1x.com/2019/03/20/AKkSWF.jpg" alt="在电脑前陪伴我的derder"></p><p><img src="https://s2.ax1x.com/2019/03/20/AKF5i8.jpg" alt="早晨四点陪我起来弄资料的derder"></p><p>转眼就到了圣诞节，derder和葡萄也在相互打闹和撕咬中成为了我们家里自然而然的一部分。每天早晨铲屎、吸地、铺猫砂、添水加粮都成了平日寻常，晚上也会在下班回到家的时候看到derder在门口贱贱的样子。张老师喜欢让两只猫当模特摆拍，然后修图发朋友圈。也不知道她是炫耀她的猫还是炫耀她对家的匠心。我非常希望看到她发这些照片，因为这让我感觉自己真的是一个“成功人士”。</p><p><img src="https://s2.ax1x.com/2019/03/20/AKFHMj.jpg" alt="张老师总会在家里搭配出合适的颜色"></p><p><img src="https://s2.ax1x.com/2019/03/20/AKFbss.jpg" alt="圣诞驯猫，其实主要是测试一下新买的Mate20 Pro的照相能力"></p><p>刚进入2019年，葡萄就发情了，有那么几天会在家里叫一整夜。和张老师不同，我对葡萄非常宽容，因为我睡着了什么也听不见。葡萄就是那个时候怀孕的，怀孕之后的葡萄完全褪去了之前的“愤怒”和戒备，让我愈发觉得自己之前的决策简直英明神武。</p><p><img src="https://s2.ax1x.com/2019/03/20/AKFxiT.jpg" alt="学会了放松自己的葡萄"></p><p><img src="https://s2.ax1x.com/2019/03/20/AKFWZt.jpg" alt="学会了放飞自己的葡萄"></p><p><img src="https://s2.ax1x.com/2019/03/20/AKFoRg.jpg" alt="和葡萄一样越来越会找地方躺着的derder"></p><p>随着葡萄的腰身越来越粗，我们也意识到葡萄要生了。既然我说了要为葡萄接生，我还是在网上搜了搜相关资料的。不过都太复杂了，所以我没怎么仔细看。我还是比较相信动物的本能和生存能力，真要出了问题，与其说是考验我的姿势水平，不如说是考验我的心理素质。这个我可以确保没有问题。另外有可能她生的时候我不在家或者是晚上在睡觉，所以看了也没用，日子就这么得过且过了。</p><p><img src="https://s2.ax1x.com/2019/03/20/AKFjoV.jpg" alt="腰围暴涨的葡萄"></p><p>直到前天下午我回到家，听到了不一样的叫声。我当时就意识到是葡萄生了。到阳台一看，除了有些血迹之外，葡萄看起来没有什么困难，4只新出生的小猫浑身湿哒哒的，有3只像derder一样的蓝猫，和一只像葡萄的蓝白。简单清理了一下现场，戴着手套把一只跑到产房外面嗷嗷待哺的小derder放回了准备好的产房里。上手一拿之下，才吃惊于小猫的重量，比看起来重多了。</p><p>我赶紧通知了张老师，和她分享了这份欣喜。我也感觉自己再次走了狗屎运，没有遇到难产这一类的特殊事件，葡萄自己就在我们没在家的时候把事都办了。另外我觉得最淡定的是derder，他好像什么事也没有发生一样。</p><p><img src="https://s2.ax1x.com/2019/03/20/AKFOZq.jpg" alt="成功瘦身的老母亲"></p><p>到这里这篇文章就该结束了。没有什么总结，就是流水账一样的记述。每年过的节，要记得日子越来越多，让人习惯了过一段时间就总结点什么，其实没这个必要，上班开的会还不够多吗？也没有什么对未来的展望啊，规划啊这类内容，文章可以是流水账，但不能是PPT。</p><p>最后，这篇文章，献给张老师。</p><p><em>2019/3/20</em></p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>OVS-DPDK 82599 VF初始化失败诊断方法一例</title>
      <link href="/2019/03/19/82599-vf-err-debug/"/>
      <url>/2019/03/19/82599-vf-err-debug/</url>
      
        <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>在82599上创建了两个VF之后，各自绑定到vfio，启动DPDK时出现错误：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PMD: eth_ixgbevf_dev_init(): VF Initialization Failure: -15</span><br><span class="line">EAL: Error - exiting with code: 1</span><br><span class="line">    Cause: Requested device 0000:01:10.0 cannot be used</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="诊断"><a href="#诊断" class="headerlink" title="诊断"></a>诊断</h2><p>其实第一眼也看不出个什么来，但报错信息提供了两个线索：</p><ul><li>错误是<code>eth_ixgbevf_dev_init</code>报的</li><li>错误代码是<code>-15</code></li></ul><p>剩下后面的看起来也直接提供了error code和错误的root cause，其实什么也没说。</p><p>所以从<code>eth_ixgbevf_dev_init</code>入手吧。</p><p>先找到这个方法在哪：</p><p><code>grep -r “eth_ixgbevf_dev_init” ./</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./ixgbe_ethdev.c:static int eth_ixgbevf_dev_init(struct rte_eth_dev *eth_dev);</span><br><span class="line">./ixgbe_ethdev.c:eth_ixgbevf_dev_init(struct rte_eth_dev *eth_dev)</span><br><span class="line">./ixgbe_ethdev.c:sizeof(struct ixgbe_adapter), eth_ixgbevf_dev_init);</span><br><span class="line">./ixgbe_ethdev.c: * is mapped to VFIO vector 0 in eth_ixgbevf_dev_init( ).</span><br><span class="line">./ixgbe_ethdev.c: * If previous VFIO interrupt mapping setting in eth_ixgbevf_dev_init( )</span><br><span class="line">./ixgbe_ethdev.c:ret = eth_ixgbevf_dev_init(dev);</span><br></pre></td></tr></table></figure><p>是在<code>ixgbe_ethdev.c</code>这个文件里没跑了。</p><p>打开看一下，是在：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if ((diag != IXGBE_SUCCESS) &amp;&amp; (diag != IXGBE_ERR_INVALID_MAC_ADDR)) &#123;</span><br><span class="line">              PMD_INIT_LOG(ERR, "VF Initialization Failure: %d", diag);</span><br><span class="line">              /*</span><br><span class="line">               * This error code will be propagated to the app by</span><br><span class="line">               * rte_eth_dev_reset, so use a public error code rather than</span><br><span class="line">               * the internal-only IXGBE_ERR_RESET_FAILED</span><br><span class="line">               */</span><br><span class="line">              return -EAGAIN;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个位置，但实际上打印的是一个变量<code>diag</code>的值。在上面<code>diag</code>的赋值方法是：</p><p><code>diag = hw-&gt;mac.ops.reset_hw(hw)</code></p><p>这个看起来就是个抽象层封装了一堆ops函数指针的形式。要马上找到具体调用的是哪个实现还不是太容易的事情。但看到上面定义的<code>IXGBE_ERR_INVALID_MAC_ADDR</code>的宏就应该能猜到相关的error信息应该都在一起。</p><p>通过<code>Ctags</code>转跳<code>IXGBE_ERR_INVALID_MAC_ADDR</code>的定义，果然找到了我们要找的<code>-15</code>是什么错误：</p><p><code>#define IXGBE_ERR_RESET_FAILED                                    -15</code></p><p>OK，下面只要看一下这个错误在什么地方返回：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@Server-N3 ixgbe]# grep -r "IXGBE_ERR_RESET_FAILED" ./</span><br><span class="line">./base/ixgbe_82598.c:status = IXGBE_ERR_RESET_FAILED;</span><br><span class="line">./base/ixgbe_vf.c:return IXGBE_ERR_RESET_FAILED;</span><br><span class="line">./base/ixgbe_x540.c:status = IXGBE_ERR_RESET_FAILED;</span><br><span class="line">./base/ixgbe_82599.c:status = IXGBE_ERR_RESET_FAILED;</span><br><span class="line">./base/ixgbe_82599.c:ret_val = IXGBE_ERR_RESET_FAILED;</span><br><span class="line">./base/ixgbe_phy.c:status = IXGBE_ERR_RESET_FAILED;</span><br><span class="line">./base/ixgbe_type.h:#define IXGBE_ERR_RESET_FAILED-15</span><br><span class="line">./base/ixgbe_x550.c:status = IXGBE_ERR_RESET_FAILED;</span><br><span class="line">./ixgbe_ethdev.c: * the internal-only IXGBE_ERR_RESET_FAILED</span><br></pre></td></tr></table></figure><p>对我们的VF初始化场景来说，肯定就是在<code>./base/ixgbe_vf.c</code>这个文件里返回的前述的错误。打开看一下返回这个错误的逻辑是什么：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/* we cannot reset while the RSTI / RSTD bits are asserted */</span><br><span class="line">      while (!mbx-&gt;ops.check_for_rst(hw, 0) &amp;&amp; timeout) &#123;</span><br><span class="line">              timeout--;</span><br><span class="line">              usec_delay(5);</span><br><span class="line">      &#125;</span><br><span class="line">  </span><br><span class="line">      if (!timeout)</span><br><span class="line">              return IXGBE_ERR_RESET_FAILED;</span><br></pre></td></tr></table></figure><p>基本就是在一定时间段内检测一个寄存器有没有被设置正确，如果没有就返回这个错误。</p><p>好在代码注释中提到了检测的是RSTI/RSTD这两个标志位。</p><p>那就查查这两个标志位是什么意思呗，打开82599祖传的datasheet：</p><p><img src="https://s2.ax1x.com/2019/03/19/AupJN4.jpg" alt=""></p><p>在PDF里搜索一下就能看到，这个标志位其实就是表示PF的reset过程有没有完成。</p><p>那么reset如果完成了..应该PF至少会UP起来吧…检查了一下果然PF没有UP，UP之后问题解决。</p><h2 id="主要是"><a href="#主要是" class="headerlink" title="主要是"></a>主要是</h2><p>主要并不是想说这个具体的问题应该怎么解决，而是如何在不死扣细节的情况下快速找到线索，快速解决问题。从最直接的表象入手，熟稔一套猜测的直觉，保持对复杂问题的简单看法。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> dpdk </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚21：Skylake微架构(Microarchitecture)剖析(6)</title>
      <link href="/2019/03/10/quickwords21-skylake-pipeline-6/"/>
      <url>/2019/03/10/quickwords21-skylake-pipeline-6/</url>
      
        <content type="html"><![CDATA[<h2 id="OOO-Once-More"><a href="#OOO-Once-More" class="headerlink" title="OOO Once More"></a>OOO Once More</h2><p>这里对OOO(Out-Of-Order)乱序执行再简单讲两句。深入乱序执行的难点不在于“不按指令顺序执行”，而是如何做到“按指令顺序退出”。</p><p>这里面的关键是，所有执行过的指令都先被“缓存”起来，并不把执行之后的结果真正写到寄存器或者内存里。从用户角度看，这个指令其实并没有被“执行”，因为它没有引起任何数据方面的变化。等到它可以确定是需要被执行的指令，并且它前面的指令都已经把结果写入(commit)之后，它再去Commit。这样从用户角度看来，程序就是按照指令顺序执行了。<br><a id="more"></a></p><blockquote><p>在很多文档里，Commit和Retire是两个可以互换(interchangable)的词。</p></blockquote><p>说实话，研究这块东西，最烦的就是同一个概念有N个名字。</p><p><img src="https://s2.ax1x.com/2019/03/10/ApUYNT.png" alt=""></p><p>再来总结一下OOO的Big Picture:</p><ul><li>左边<code>Fetch&amp;Decode</code>是之前讲的前端（Front-End）相关的内容。此时指令还是有序的。</li><li>Decode成微指令（uop）之后，这些微指令进入一个指令池（Instruction Pool），这里面能够被执行的指令，就直接被执行。“能够被执行”是指满足以下两个条件：<ul><li>已有指令需要的数据</li><li>执行单元有空闲</li></ul></li><li>当指令被执行之后<ul><li>通知所有对该指令有依赖的指令（们），它们所需要的数据已经准备好。</li><li>注意这里说的是“执行”，不是上面说的“Retire”或“Commit”</li><li>为实现这一功能，CPU中还必须要对微指令的操作数（数据）有Bookkeeping的能力</li></ul></li><li>Commit指令<ul><li>只有当前指令的前序（指令顺序）指令都Commit之后，才能Commit当前指令</li><li>Commit也可以并行进行，前提是满足上面一条的条件，同时并行Commit的指令间没有依赖</li></ul></li></ul><h2 id="False-Dependency"><a href="#False-Dependency" class="headerlink" title="False Dependency"></a>False Dependency</h2><p>乱序执行的一大前置条件就是指令数据间没有相互依赖。下面就着重分析一下依赖。</p><p>用下面的指令过程作一个示例：</p><p><img src="https://s2.ax1x.com/2019/03/10/Apw3DA.png" alt=""></p><p>简单分析一下：</p><ul><li>Read After Write(RAW)型依赖<br>(2)指令需要读取r1的值，而r1的值需要(1)指令执行之后给出。所以(2)指令对(1)指令有RAW依赖。RAW依赖也被称作<code>true dependency</code>或者<code>flow dependency</code>。</li><li>Write After Read(WAR)型依赖<br>(3)指令需要更新r8的值，但在此之前(2)指令需要读取r8的值参与计算。所以(3)指令对(2)指令有WAR依赖。WAR依赖也被称作<code>anti-dependencies</code>。</li><li>Write After Write(WAW)型依赖<br>(4)指令需要在(2)指令写入r3之后再写入r3。所以(4)指令对(2)指令有WAW依赖。WAW依赖也可以被叫做<code>output dependencies</code></li></ul><p>按照以上的分析，这几条指令几乎没有可以并行执行的余地。不过，我想你也已经看出了一些“转机”：针对WAR和WAW，是可以被Register Rename这种方法破解的。这两种依赖都被称为<code>false dependency</code>。</p><h2 id="Register-Rename"><a href="#Register-Rename" class="headerlink" title="Register Rename"></a>Register Rename</h2><p>当需要写入r1的指令在读取r1的指令之后，写入的r1的新值可以首先保存在另外一个寄存器r1’里。读取r1的指令仍然读取原r1寄存器中的值，这样WAR指令就可以并行执行。当所有需要读取r1原值的指令都执行完毕，r1就可以用新值代替。</p><blockquote><p>Register Rename其实就是利用CPU提供的大量的物理寄存器，为寄存器制作“分身”或者，Alias，提供能够增加程序并行性的便利。</p></blockquote><p>上面的例子里，r1是<code>architectural register</code>，r1’是内部的<code>physical register</code>。Rigster Rename就是在制作这两种寄存器间的映射关系。当然，这一切对用户来说都是透明的。</p><p>其他内容留待后面介绍。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>在控制台水平滚动</title>
      <link href="/2019/03/07/terminal-horizontal-scrolling/"/>
      <url>/2019/03/07/terminal-horizontal-scrolling/</url>
      
        <content type="html"><![CDATA[<p>在CLI下操作，很多时候会因为屏幕尺寸的原因导致格式化输出的字符变成一副惨不忍睹的样子。比如你在有很多CPU核的环境下打印<code>cat /proc/interrupts</code>的时候。</p><p>当然你可能有很多方式能够处理这种情形，比如使用<code>awk</code>或者重定向到某个文件再打开。<br><a id="more"></a></p><p>但要始终相信Linux总有更好的办法，不可能在如此常见的场景中留下没有人看管的尾巴。</p><p>经过一番尝试和搜索，终于发现一个最简单的方法：</p><p><code>cat /proc/interrupts | less -S</code></p><p>使用<code>Arrow</code>键水平移动就可以了。</p><p>信念帮助了我们！</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>商业供稿1：消除虚拟化环境网络盲点</title>
      <link href="/2019/03/05/commerical1-eliminate-vnet-blind-spot/"/>
      <url>/2019/03/05/commerical1-eliminate-vnet-blind-spot/</url>
      
        <content type="html"><![CDATA[<p><em>原载于云杉网络 <a href="http://www.yunshan.net" target="_blank" rel="noopener">www.yunshan.net</a> 微信公众号</em></p><p>网络盲点是引起虚拟化环境中业务中断、服务质量下降以及遭受安全威胁的最主要原因。当公司或组织缺乏网络可见性，无法完全掌握其虚拟化环境中业务的网络运行情况时，将必然面临频繁的业务中断、客户投诉以及恶意攻击带来的损失。据Gartner预测，到2019年，实现适当的网络可见性和控制工具的60%的企业将减少三分之一的安全故障。</p><p>随着业务规模的扩大，公司和组织对网络可见性的投入亦将会持续增加。但除了购买增强网络可见性的产品和服务之外，还应针对虚拟化环境中的业务特点，从以下几个导致网络盲点的原因出发，构建完善的网络监控和安全体系。<br><a id="more"></a></p><ul><li>缺乏虚拟网络监控手段<br>Gartner报告声称80%的虚拟化数据中心流量将是虚拟机或容器之间的东西向流量。这些流量可能永远不会到达ToR交换机，而仅仅发生在服务器内部。随着东西向流量规模的进一步增长，以及未来微服务和Serverless架构的盛行，对虚拟环境网络及流量的监控将成为决定业务健康的重头戏。据某金融行业资深专家反馈，当前大部分公司或组织仍依靠传统的从ToR交换机上获取镜像流量的采集方式或是采用功能薄弱，性能不完善的虚拟网络监控工具，将使自身在虚拟网络和云时代中身处盲人摸象的尴尬境地。</li><li>采集丢包<br>传统的流量采集方法多使用“采样”的方式采集大规模网络流量，这些信息一般会通过NetFlow/IPFIX等协议形式生成汇总信息。在采样的过程中将会不可避免地产生失真。这种失真虽然是一种折衷和妥协的产物，但却使得精细化的网络管理不再可行。在传统网络时代，采样的方式仍可以产生一定作用，但在虚拟网络时代，业务流量具有短连接多、并发与突发流量密集、转发路径复杂、虚拟机/容器E2E端点变化频繁等特点，使得原始的采样方法在构建真正能转化成生产力的网络全景视图方面显得力不从心，甚至因采样这种方式的天然缺点，可能会对网络运维人员产生误导。很多一线的网络运维人员反映，现有的工具无法满足他们在虚拟网络和云时代运维决策的制定需求。<br>除此之外，在应对激增的东西向流量时，只有经过精心调校的采集软件可以在不影响服务器生产业务效率的条件下全量采集流量。除此之外的产品都将会因为过载而产生丢包，使得产品能力无法得到充分发挥。随着10G/25G/100G网卡在数据中心的普及，性能将成为一项关键指标。</li><li>虚拟机/容器变动<br>虚拟化环境的特点就是可以针对不同的应用场景，从计算、存储和网络资源中灵活抽象出虚拟机/容器示例。当抽象的规模达到一定程度之后，将会逐渐失去对资源的掌控。在某金融企业1000台服务器规模的数据中心中，因回收不及时而闲置的虚拟机有将近100台的规模。另外，因一再删除添加的防火墙/安全组规则而产生的安全漏洞，以及在复杂的抽象层中丢失或延迟到达的网络流量，都将成为制约资源集约化利用，提供业务安全保障的网络盲点。</li><li>工具集关联<br>在大规模企业和组织中，都存在多种网络工具共存的情形。将不同的工具可以提供不同的互补的能力，但往往需要事先配置不同的工具使能方式。如有些工具需要网元提供NetFlow信息，有些需要配置ERSPAN，有些需要In-band串联等等。这种后台工具各自不一的使能方式在增加网络复杂度的同时，也进一步提升了工具的使用成本。据分析机构报告显示，企业将持续增加IT预算，并达到5%以上的年增长率，IT工具会持续增多。因工具获取信息“源”各不相同，无法对各自的分析结果进行有效综合，也就无法形成工具间的优势互补，进而导致本应可以实现的能力没有实现，损害企业投资。若能从单一信息源处获取网络信息，将产生1+1&gt;2的规模优势。</li><li>工具操作复杂<br>新的工具本身会很复杂，而让使用人员完全掌握新工具的特点，摸清它的“脾气”会是更复杂的事情。如何能最大效率地利用工具，为企业或组织带来最大的投资回报率并非是一件显然的事情。虚拟化环境以及云上环境本身正在变得越来越复杂，而针对它的工具也有同样的趋势。Gartner的报告显示，每增加25%的工具功能，将会提升100%的工具复杂度。而工具本身的复杂将从“工具盲点”最终传导为网络盲点。清晰、简明、强大的工具本身就是从最终用户的层面消除网络盲点的一种手段。</li></ul><p>网络中的盲点将最终成为业务问题。其所波及的并不仅仅是网络组件，而是所有身处这一网络之中的虚拟化以及物理组件。消除网络盲点的方式就是提高网络，特别是虚拟网络的可见性。</p>]]></content>
      
      
      <categories>
          
          <category> commerical </category>
          
      </categories>
      
      
        <tags>
            
            <tag> commerical </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚20：eBPF的机制</title>
      <link href="/2019/03/01/quickwords20-ebpf-intro/"/>
      <url>/2019/03/01/quickwords20-ebpf-intro/</url>
      
        <content type="html"><![CDATA[<h2 id="怎么出来的eBPF"><a href="#怎么出来的eBPF" class="headerlink" title="怎么出来的eBPF"></a>怎么出来的eBPF</h2><p>用Linux Kernel Module来做一个类比说明eBPF诞生的目的。<br><a id="more"></a></p><p>Kernel Module的主要目的就是让用户可以通过这种机制，实现对内核的“赋能”，动态添加一些内核本身不支持的功能，比如硬件的驱动能力，新的文件系统或是系统调用。当然也可以融合到现有的内核处理流程中，比如在netfilter的某个hook点中添加包处理方法等。</p><p>Kernel Module的优点：</p><ul><li>动态添加/删除，无需重新编译内核</li><li>减小内核体积</li></ul><p>缺点：</p><ul><li>一旦出现BUG可能导致内核直接崩溃</li><li>增加内核攻击面，影响内核安全</li></ul><p>eBPF要做的事情也非常类似，但它想要克服Kernel Module的缺点，即确保执行的代码绝对安全。</p><h2 id="eBPF的使用方式"><a href="#eBPF的使用方式" class="headerlink" title="eBPF的使用方式"></a>eBPF的使用方式</h2><p>为了达到这一目的，eBPF在内核中实现了一个虚拟机执行用户的指令。与Kernel Module直接在真实的物理硬件上执行用户的指令不同，eBPF提供给用户一个虚拟的RISC处理器，以及一组相关的指令。用户可以直接用这组指令编写程序。同时，程序在下发到该虚拟机之前也会经过eBPF的检查，比如会不会进入无限循环，会不会访问不合法的内存地址等等。只有在通过检查之后才可以进入执行的环节。</p><p>同时eBPF生态链中也有将高级语言转换成虚拟处理器指令的工具，这个主要靠LLVM提供。</p><h2 id="eBPF的架构"><a href="#eBPF的架构" class="headerlink" title="eBPF的架构"></a>eBPF的架构</h2><p><img src="https://478h5m1yrfsa3bbe262u7muv-wpengine.netdna-ssl.com/wp-content/uploads/2019/02/ebpf-architecture-1.png" alt=""></p><p>对eBPF来说，和Kernle Module一样，也是通过特定的Hook点监听内核中的特定事件，进而执行用户定义的处理。这些Hook点包括：</p><ul><li>静态tracepoint</li><li>动态内核态探针(Dynamic Kernel probes)</li><li>动态用户态探针(Dynamic User Probes)</li><li><a href="https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md#events--arguments" target="_blank" rel="noopener">其他hook点</a></li></ul><p>针对主要是监控、跟踪使用的eBPF应用来说，主要通过这种方式取得内核运行时的一些参数和统计信息。例如，系统调用的参数值、返回值，通过eBPF map将得到的信息送给用户态程序，进而在用户态完成后处理流程。</p><p>另外一类应用则直接在一些内核处理流程中加入自己的处理逻辑，例如<a href="https://www.iovisor.org/technology/xdp" target="_blank" rel="noopener">XDP</a>，就是在网卡驱动和内核协议栈之间插入了eBPF扩展的网包过滤、转发功能。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚19：描述性能优化成果的正确姿势</title>
      <link href="/2019/02/24/quickwords19-desc-perf-improvement/"/>
      <url>/2019/02/24/quickwords19-desc-perf-improvement/</url>
      
        <content type="html"><![CDATA[<h2 id="从10秒到1秒"><a href="#从10秒到1秒" class="headerlink" title="从10秒到1秒"></a>从10秒到1秒</h2><p>周末了说点不硬的技术。<br><a id="more"></a></p><p>自从摩尔定律不那么好使了之后，人们才真正开始关注软件性能。各类开源或者商业产品也经常以性能提升XXX作为卖点宣传。如果在搜索引擎以“性能提升[9, 8, 7, 6]0%”为关键字搜索一下，能看到连篇累牍的精确匹配的信息。但这些信息本身却并不“精确”，甚至都不正确。</p><p>经常能看到的一个错误与下面这个简化的例子相似：</p><blockquote><p>一辆汽车以前行驶100米需要10秒钟，新型号推出后，仅需要1秒钟。</p></blockquote><p>你会看到很多产品信息将这种提升描述为“性能提升90%”。</p><p>我猜测90%的计算方式是：</p><p><code>(10 - 1) / 10 = 90%</code></p><p>但实际上这完全错误。</p><h2 id="性能的表达"><a href="#性能的表达" class="headerlink" title="性能的表达"></a>性能的表达</h2><p>所有的性能都可以表达为：</p><p><code>性能 = 工作量 / 单位时间</code></p><p>其实就是单位时间内能完成的工作量。</p><p>在上面的例子中，工作量是移动距离（m），单位时间（s），性能其实就是m/s，也就是“速度”。</p><p>我们有很多常用的指标已经直接是这种形式，例如QPS、PPS、BPS等。</p><h2 id="性能优化的表达方式"><a href="#性能优化的表达方式" class="headerlink" title="性能优化的表达方式"></a>性能优化的表达方式</h2><p>那前后两次的速度是多少呢？分别是<code>10m/s</code>和<code>100m/s</code>。那性能提升就是<code>100m/s / 10m/s = 10x</code>。</p><p>所以上面的例子中，你可以说：</p><ul><li>性能（速度）10倍提升</li><li>快了10倍/1000%</li></ul><p>但不能说：</p><ul><li>性能提升90%</li><li>快了90%</li></ul><p>一定要用到90%的话，那就是：</p><ul><li>移动耗时减少90%</li></ul><p>如果真正按性能提升90%来计算，那么速度之前是10m/s，之后是<code>10 * ( 1 + 90% ) = 19m/s</code>，也就是1.9倍。</p><p>这个问题在英语世界里也很常见。例如经常会看到一些<code>Get something done 90% faster</code>的宣传，其实都应该改成<code>Get something done 10 times faster</code>。当然也有故意利用这部分认知漏洞，让人误以为性能提升了10倍的。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚18：PCIE带宽单位GT/s到Gbps转换方法</title>
      <link href="/2019/02/22/quickwords18-pcie-gtps-gbps/"/>
      <url>/2019/02/22/quickwords18-pcie-gtps-gbps/</url>
      
        <content type="html"><![CDATA[<h2 id="PCIE的表达方式"><a href="#PCIE的表达方式" class="headerlink" title="PCIE的表达方式"></a>PCIE的表达方式</h2><p>PCIE使用GT/s这个单位表达自己的带宽，这并不是为了标新立异，而是为了更好（直接）地表达PCIE的工作方式。<br><a id="more"></a></p><p>原始的数据在采用PCIE总线传输的时候，需要重新编码。因为PCIE是一种串行总线所以总线时钟要嵌入在串行的数据里。为了保证数据接收方能够正确地还原出时钟，需要提供足够多的信号电位变化（Level Transitions），电位的高低其实代表的就是传输的比特（0或者1）。所以对PCIE来说，它的传输效率并非在于传输了多少有效的数据，而是电位变化的频率。</p><p>GT/s其实就是GigaTransfers per second。而重新编码的电位变化频率也会高于原始数据的比特变化频率，从而导致PCIE传输对带宽有一些因为编码产生的Overhead。</p><p>一次电位变化从数据角度说就相当于传输了一个Bit。所以在下面的计算里GT/s可以等同于Gbps，不过这是编码后的数据。</p><h2 id="PCIE-Gen2-Gen3的区别"><a href="#PCIE-Gen2-Gen3的区别" class="headerlink" title="PCIE Gen2/Gen3的区别"></a>PCIE Gen2/Gen3的区别</h2><p>按上面介绍的原理，为了提高传输速率，一是提高最大可用电位变化频率，而是提高编码效率。</p><h3 id="变化频率"><a href="#变化频率" class="headerlink" title="变化频率"></a>变化频率</h3><ul><li>Gen2最大支持5GT/s</li><li>Gen3最大支持8GT/s</li></ul><h3 id="编码效率"><a href="#编码效率" class="headerlink" title="编码效率"></a>编码效率</h3><ul><li>Gen2编码8Bit原始数据需要10Bit的数据量</li><li>Gen3编码128Bit原始数据需要130Bit的数据量</li></ul><h2 id="GT-s到Gbps的转换"><a href="#GT-s到Gbps的转换" class="headerlink" title="GT/s到Gbps的转换"></a>GT/s到Gbps的转换</h2><ul><li>Gen2</li></ul><p>Gen2最大支持5GT/s/lane。相当于5Gbps的编码后的数据，乘以编码效率<br><code>5Gbps * (8/10) = 4Gbps = 500MBps</code>未编码的原始数据。</p><ul><li>Gen3</li></ul><p>Gen3最大支持8GT/s/lane。按上述算法：</p><p><code>8Gbps * (128/130) = 7876Gbps = 984.6MBps</code></p><p>如果是PCIE Gen3 x8那就是984.6MBps x 8</p><h2 id="速查表格"><a href="#速查表格" class="headerlink" title="速查表格"></a>速查表格</h2><p><img src="https://s2.ax1x.com/2019/02/22/kfycbq.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚17：用Makefile.am和configure.ac构建一个专业的Hello World</title>
      <link href="/2019/02/21/quickwords17-makefileam-configureac/"/>
      <url>/2019/02/21/quickwords17-makefileam-configureac/</url>
      
        <content type="html"><![CDATA[<p>首先感谢GUN的良好<a href="https://www.gnu.org/software/automake/manual/html_node/Creating-amhello.html" target="_blank" rel="noopener">教程</a>，这里主要是做一点点加工。</p><h2 id="GNU-Autotool"><a href="#GNU-Autotool" class="headerlink" title="GNU Autotool"></a>GNU Autotool</h2><p>现在写开源项目，如果只提供一个Makefile可能会令别人怀疑你项目的专业程度:D虽然其实并没有什么关系，但看着别的项目目录下面的<code>configure</code>, <code>configure.ac</code>, <code>Makefile.in</code>, <code>Makefile.am</code>, <code>aclocal.m4</code>等文件还是会觉得有必要也用这些东西“装点”一下。<br><a id="more"></a></p><p>这些文件其实都是由GNU Autotools生成的。Autotools的功能当然不止是装点一下，但我们不在这里深究这个问题，下面通过一个最简单的Hello World示例来解释一下Autotools的使用方法。</p><h2 id="构建必要的文件"><a href="#构建必要的文件" class="headerlink" title="构建必要的文件"></a>构建必要的文件</h2><h3 id="src-main-c"><a href="#src-main-c" class="headerlink" title="src/main.c"></a>src/main.c</h3><p>在项目根目录下新建一个<code>src</code>文件夹，放Hello World的<code>main.c</code></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;config.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">main (<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">puts</span> (<span class="string">"Hello World!"</span>);</span><br><span class="line">  <span class="built_in">puts</span> (<span class="string">"This is "</span> PACKAGE_STRING <span class="string">"."</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>特别注意一下与”传统”Hello World不同的是include了一个<code>config.h</code>，所以才会有<code>PACKAGE_STRING</code>这一变量。</p><p>不直接在根目录创建main.c是因为后续Autotools会自动创建一些额外的作为一个”专业”项目所需要的文件夹，例如<code>man/</code>和<code>data/</code>等等。</p><h3 id="README"><a href="#README" class="headerlink" title="README"></a>README</h3><p>这个直接放根目录就行了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">This is a demonstration package for GNU Automake.</span><br><span class="line">Type 'info Automake' to read the Automake manual.</span><br></pre></td></tr></table></figure><h3 id="根目录下的Makefile-am"><a href="#根目录下的Makefile-am" class="headerlink" title="根目录下的Makefile.am"></a>根目录下的Makefile.am</h3><p>这个这么写：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SUBDIRS = src</span><br><span class="line">dist_doc_DATA = README</span><br></pre></td></tr></table></figure><h3 id="src目录下的Makefile-am"><a href="#src目录下的Makefile-am" class="headerlink" title="src目录下的Makefile.am"></a>src目录下的Makefile.am</h3><p>是的，确实需要写两个Makefile.am：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin_PROGRAMS = hello</span><br><span class="line">hello_SOURCES = main.c</span><br></pre></td></tr></table></figure><h3 id="configure-ac"><a href="#configure-ac" class="headerlink" title="configure.ac"></a>configure.ac</h3><p>下面就可以写最后的<code>configure.ac</code>文件了，这个放在根目录下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">AC_INIT([amhello], [1.0], [bug-automake@gnu.org])</span><br><span class="line">AM_INIT_AUTOMAKE([-Wall -Werror foreign])</span><br><span class="line">AC_PROG_CC</span><br><span class="line">AC_CONFIG_HEADERS([config.h])</span><br><span class="line">AC_CONFIG_FILES([</span><br><span class="line"> Makefile</span><br><span class="line"> src/Makefile</span><br><span class="line">])</span><br><span class="line">AC_OUTPUT</span><br></pre></td></tr></table></figure><p>AC_INIT等等Autotools预定义的宏，看一下括号里的东西大概就能明白是什么意思了吧：D当然，除了这几个之外还有很多其他功能强大的操作，可以自行查找相关信息。</p><h2 id="实例化构建系统"><a href="#实例化构建系统" class="headerlink" title="实例化构建系统"></a>实例化构建系统</h2><p>运行<code>autoreconf</code>命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">autoreconf --install</span><br><span class="line">configure.ac: installing './install-sh'</span><br><span class="line">configure.ac: installing './missing'</span><br><span class="line">configure.ac: installing './compile'</span><br><span class="line">src/Makefile.am: installing './depcomp'</span><br></pre></td></tr></table></figure><p>这个时候你就可以看到你的目录下面多出了<code>configrure</code>, <code>config.h.in</code>, <code>Makefile.in</code>以及<code>src/Makefile.in</code>这几个文件。但<code>autoreconf</code>的目的不仅仅是创建这几个文件，而是为了在你的系统里创建GNU Build System。</p><h2 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h2><p>下面你就可以用平时你在开源项目里用到的操作手法编译生成安装了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">./configure</span><br><span class="line">checking for a BSD-compatible install... /usr/bin/install -c</span><br><span class="line">checking whether build environment is sane... yes</span><br><span class="line">checking for gawk... no</span><br><span class="line">checking for mawk... mawk</span><br><span class="line">checking whether make sets $(MAKE)... yes</span><br><span class="line">checking for gcc... gcc</span><br><span class="line">checking for C compiler default output file name... a.out</span><br><span class="line">checking whether the C compiler works... yes</span><br><span class="line">checking whether we are cross compiling... no</span><br><span class="line">checking for suffix of executables...</span><br><span class="line">checking for suffix of object files... o</span><br><span class="line">checking whether we are using the GNU C compiler... yes</span><br><span class="line">checking whether gcc accepts -g... yes</span><br><span class="line">checking for gcc option to accept ISO C89... none needed</span><br><span class="line">checking for style of include used by make... GNU</span><br><span class="line">checking dependency style of gcc... gcc3</span><br><span class="line">configure: creating ./config.status</span><br><span class="line">config.status: creating Makefile</span><br><span class="line">config.status: creating src/Makefile</span><br><span class="line">config.status: creating config.h</span><br><span class="line">config.status: executing depfiles commands</span><br></pre></td></tr></table></figure><p>用了<code>configure</code>之后就可以看到<code>Makefile</code>和<code>src/Makefile</code>以及<code>config.h</code>了。下面直接<code>make</code>就好。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">make</span><br><span class="line">…</span><br><span class="line">src/hello</span><br><span class="line">Hello World!</span><br><span class="line">This is amhello 1.0.</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> program </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚16：如何构建零干扰CPU Benchmark环境</title>
      <link href="/2019/02/20/quickwords16-noisy-free-benchmark-env/"/>
      <url>/2019/02/20/quickwords16-noisy-free-benchmark-env/</url>
      
        <content type="html"><![CDATA[<h2 id="CPU性能测试对环境的要求"><a href="#CPU性能测试对环境的要求" class="headerlink" title="CPU性能测试对环境的要求"></a>CPU性能测试对环境的要求</h2><p>即便是硬件配置完全一样，操作系统相同，工作负载也相同的硬件平台，性能测试的结果也可能会因为各项配置的不同出现较大出入。<br><a id="more"></a></p><p>除了硬件的Hyper Thread/Turbo等特性之外，OS对进程的调度、中断等等也可能会产生影响。当然如果你要测试的工作负载还要和网络、存储交互的话，那么就还需要把他们放在一起综合考虑。</p><p>这里的讨论只限于Linux系统。</p><h2 id="几种手段"><a href="#几种手段" class="headerlink" title="几种手段"></a>几种手段</h2><h3 id="识别系统架构"><a href="#识别系统架构" class="headerlink" title="识别系统架构"></a>识别系统架构</h3><p>先看一下系统NUMA的情况，以及与要测试的工作负载相关的硬件资源分布情况。选用合理的测试配置（e.g. CPU核与网卡在同一个NUMA节点上）。</p><h3 id="配置scaling-governor"><a href="#配置scaling-governor" class="headerlink" title="配置scaling_governor"></a>配置<code>scaling_governor</code></h3><p>将<code>scaling_governor</code>配成<code>performance</code>是一个比较常用的手段。</p><p><code>echo performance &gt; /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</code></p><p>可以仅配置参与测试的CPU核(cpu*)，也可以全部配置。另有<code>cpupower</code>工具可以协助完成，相关资料可以自行<code>man cpupower</code>。</p><h3 id="关闭Hyper-Thread"><a href="#关闭Hyper-Thread" class="headerlink" title="关闭Hyper Thread"></a>关闭Hyper Thread</h3><p>Intel的CPU如果打开Hyper Thread，同一个CPU核中有很多流水线资源是两个Thread共享的。详情可以参见<code>Skylake微架构剖析</code>系列文章。如果能操作BIOS，最好就是直接关闭Hyper Thread。如果不方便操作BIOS或者只想关闭与测试有关的CPU核的Hyper Thread也可以用：</p><p>查看该CPU核的siblings列表：</p><p><code>/sys/devices/system/cpu/cpuN/topology/thread_siblings_list</code></p><p>看到另外那个CPU X之后：</p><p><code>echo 0 &gt; /sys/devices/system/cpu/cpuX/online</code></p><h3 id="关闭Turbo"><a href="#关闭Turbo" class="headerlink" title="关闭Turbo"></a>关闭Turbo</h3><p>并不是说Turbo不好，其实Trubo能比较显著地提高性能，但我们这里追求的是一个”纯净”的测试环境，需要尽量排除Trubo在频率升降过程中产生的误差干扰。</p><p><code>echo 1 &gt; /sys/devices/system/cpu/intel_pstate/no_turbo</code></p><h3 id="屏蔽内核干扰"><a href="#屏蔽内核干扰" class="headerlink" title="屏蔽内核干扰"></a>屏蔽内核干扰</h3><p>内核有些时候也会对测试结果产生干扰，比如用户/内核线程到参与测试的CPU核，或者给CPU分配网卡等设备的中断等等。这些都有相应的内核参数可以配置，在这里推荐一个简单点的工具：</p><p><a href="https://github.com/lpechacek/cpuset" target="_blank" rel="noopener">cpuset</a>:<a href="https://github.com/lpechacek/cpuset" target="_blank" rel="noopener">https://github.com/lpechacek/cpuset</a> </p><p>那么预留出参与测试的CPU核就比较简单了：</p><p><code>cset shield -c N1,N2 -k on</code></p><p>N1,N2就是CPU的编号。</p><p>查看和分配中断的方法可以参考<a href="https://decodezp.github.io/2019/01/22/test5-linux-network-performance-optimization/">这篇</a></p><p>执行要测试的负载可以用<code>taskset</code>也可以继续使用<code>cset</code> e.g.</p><p><code>cset shield --exec -- perf stat -r 10 &lt;cmd&gt;</code></p><h3 id="关闭ASLR"><a href="#关闭ASLR" class="headerlink" title="关闭ASLR"></a>关闭ASLR</h3><p>ASLR(Address Space Layout Randomization)是一种安全机制，但可能会引入性能下降。我本人没有太深入研究具体原因，但可以参考一些现有的资料e.g.<a href="https://benpfaff.org/papers/asrandom.pdf" target="_blank" rel="noopener">On the Effectiveness of Address-Space Randomization</a>。</p><blockquote><p>Implementations of WX on CPUs whose memory-management units lack a per-page execute bit, for example, current x86 chips, incur a significant performance penalty.</p></blockquote><p>关闭的方法：</p><p><code>echo 0 &gt; /proc/sys/kernel/randomize_va_space</code></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去7：筛法求素数Loop Unrolling性能优化实例</title>
      <link href="/2019/02/19/test7-prime-opt/"/>
      <url>/2019/02/19/test7-prime-opt/</url>
      
        <content type="html"><![CDATA[<h2 id="筛法求素数"><a href="#筛法求素数" class="headerlink" title="筛法求素数"></a>筛法求素数</h2><p>最近拿到一段筛法求素数的代码，希望能够在不改变原有算法的基础上提高性能。<br><a id="more"></a></p><p>关于筛法求素数的算法，网络上有很多介绍。算法之间的效率存在差异，但我们的重点不在这里，而是如何在不改动现有算法的前提下提升性能。</p><blockquote><p>关于不同筛法算法可以参见<a href="https://www.cnblogs.com/grubbyskyer/p/3852421.html" target="_blank" rel="noopener">这里</a>，这段程序里使用的是埃拉托斯特尼筛法。</p></blockquote><p>核心代码段：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">count = <span class="number">0</span>; </span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">2</span>; i &lt;= <span class="number">8192</span>; i++) &#123;</span><br><span class="line">    flags[i] = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">2</span>; i &lt;= <span class="number">8192</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (flags[i]) &#123;</span><br><span class="line">               <span class="comment">/* remove all multiples of prime: i */</span></span><br><span class="line"><span class="keyword">for</span> (k=i+i; k &lt;= <span class="number">8192</span>; k+=i) &#123;</span><br><span class="line">    flags[k] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">count++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完整代码在：</p><p><code>wget https://raw.githubusercontent.com/llvm-mirror/test-suite/master/SingleSource/Benchmarks/Shootout/sieve.c</code></p><p>其实是<code>LLVM</code>编译器的性能测试代码。</p><h2 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CPU: Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHz</span><br><span class="line">Hyper-thread:OFF</span><br><span class="line">Power-governor: Performance</span><br><span class="line">GCC: 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC)</span><br><span class="line">GCC option: -O3</span><br></pre></td></tr></table></figure><h2 id="诊断"><a href="#诊断" class="headerlink" title="诊断"></a>诊断</h2><p>先运行一下原有代码看看时间：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gcc sieve.c -O3 -o sieve</span><br><span class="line">time -p ./sieve</span><br><span class="line"></span><br><span class="line">Count: 1028</span><br><span class="line">real 3.34</span><br><span class="line">user 3.34</span><br><span class="line">sys 0.00</span><br></pre></td></tr></table></figure><p>简单想象一下代码流程：</p><ul><li>处理的数据是8K Byte(char flags[])，相对于32K的L1缓存不算什么数据量，所以数据缓存似乎问题不大</li><li>生成的二进制文件也不大，指令缓存也没太大压力</li><li>前端这边处理的主要是带分支的循环，内层循环就算还好吧…但外层循环中有个if分支判断</li><li>涉及到这个判断，因为素数的出现/分布没太大规律，所以对CPU来说，这个分支判断结果相当于是随机的，有可能会影响前端流水线的性能</li></ul><p>然后用我们之前介绍的<a href="https://decodezp.github.io/2019/02/14/quickwords15-toplev/">Top-down方法和toplev工具</a>看看实际测试的情况：</p><p><code>./toplev.py -v --no-desc  -l1 /root/perfcontest/sieve</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Using level 1.</span><br><span class="line"><span class="meta">#</span> 3.4-full on Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHz</span><br><span class="line">perf stat -x\; --no-merge -e '&#123;cpu/event=0xc2,umask=0x2/,cpu/event=0xe,umask=0x1/,cpu/event=0xd,umask=0x3,cmask=1/,cpu/event=0x9c,umask=0x1/,cycles&#125;' /root/perfcontest/sieve</span><br><span class="line">Count: 1028</span><br><span class="line">FE             Frontend_Bound:          38.45 +-     0.00 % Slots       &lt;==</span><br><span class="line">BAD            Bad_Speculation:         16.45 +-     0.00 % Slots      </span><br><span class="line">BE             Backend_Bound:            8.92 +-     0.00 % Slots below</span><br><span class="line">RET            Retiring:                36.19 +-     0.00 % Slots below</span><br><span class="line">               MUX:                    100.00 +-     0.00 %</span><br></pre></td></tr></table></figure><p>基本上可以看到是前端Bound了，同时分支预测里出现了比较多的<code>Bad_Speculation</code>。</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>OK，先用个简单的方法处理一下分支：</p><p>结合业务的话，素数越到后面分布是越稀松的，所以外层循环中的那个判断应该大部分时间是false。所以，先套个likely/unlikely。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> likely(x)       __builtin_expect((x),1)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> unlikely(x)     __builtin_expect((x),0)</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i])) &#123;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>编译之后看一下时间：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">time -p ./sieve</span><br><span class="line">Count: 1028</span><br><span class="line">real 3.08</span><br><span class="line">user 3.08</span><br><span class="line">sys 0.00</span><br></pre></td></tr></table></figure><p>有些许提升，不过不太明显。如果此时再用<code>toplev</code>测试一下，可以发现分支预测的改善并不可观。</p><p>那么如何改善分支预测呢？最好的办法就是不要有分支；或者，如果完全没有不可能的话，就让分支出现规律性；如果这样也不行的话，就减少分支；如果减少也不可能的话，就搞大乱序并发。</p><p>对于我们这个算法来说，判断每个数字的标志位并做后续的置位是算法的要求。提升规律性的话，也没有什么特别好的办法（至少我没想出来）， 那就只能用最后一种办法了…</p><p>把循环展开，提升流水线并行性。</p><p>展开16级还不算那么激进吧…同时内层循环也可以适当展开…</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i=<span class="number">2</span>; i &lt;= <span class="number">8191</span>; i = i + <span class="number">16</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i; k &lt;= <span class="number">4096</span>; k+=(<span class="number">7</span> * i)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">        flags[k + i] = <span class="number">0</span>;</span><br><span class="line">        flags[k + (<span class="number">2</span> * i)] = <span class="number">0</span>;</span><br><span class="line">        flags[k + (<span class="number">3</span> * i)] = <span class="number">0</span>;</span><br><span class="line">        flags[k + (<span class="number">4</span> * i)] = <span class="number">0</span>;</span><br><span class="line">        flags[k + (<span class="number">5</span> * i)] = <span class="number">0</span>;</span><br><span class="line">        flags[k + (<span class="number">6</span> * i)] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count0++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">1</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">2</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">1</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count1++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">2</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">4</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">2</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count2++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">3</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">6</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">3</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count3++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">4</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i+<span class="number">8</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">4</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count4++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">5</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">10</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">5</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count5++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">6</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">12</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">6</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count6++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">7</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">14</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">7</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count7++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">8</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i+<span class="number">16</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">8</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count8++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">9</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">18</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">9</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count9++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">10</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">20</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">10</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count10++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">11</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">22</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">11</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count11++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">12</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i+<span class="number">24</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">12</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count12++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">13</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">26</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">13</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count13++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">14</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">28</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">14</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count14++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unlikely(flags[i + <span class="number">15</span>])) &#123;</span><br><span class="line">    <span class="keyword">for</span> (k=i+i + <span class="number">30</span>; k &lt;= <span class="number">8191</span>; k+=(i + <span class="number">15</span>)) &#123;</span><br><span class="line">        flags[k] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">count15++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">"Count: %d\n"</span>, count0 + count1 + count2 + \</span><br><span class="line">                         count3 + count4 + count5 + \</span><br><span class="line">                         count6 + count7 + count8 + \</span><br><span class="line">                         count9 + count10 + count11 + \</span><br><span class="line">                         count12 + count13 + count14 + \</span><br><span class="line">                         count15);</span><br></pre></td></tr></table></figure><p>先直接刷一下时间：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">time -p ./sieve</span><br><span class="line">Count: 1028</span><br><span class="line">real 1.56</span><br><span class="line">user 1.56</span><br><span class="line">sys 0.00</span><br></pre></td></tr></table></figure><p>提升了120%</p><p>再用<code>toplev</code>看一下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">./toplev.py -v --no-desc  -l1 /root/perfcontest/sieve</span><br><span class="line">Using level 1.</span><br><span class="line"><span class="meta">#</span> 3.4-full on Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHz</span><br><span class="line">perf stat -x\; --no-merge -e '&#123;cpu/event=0xc2,umask=0x2/,cpu/event=0xe,umask=0x1/,cpu/event=0xd,umask=0x3,cmask=1/,cpu/event=0x9c,umask=0x1/,cycles&#125;' /root/perfcontest/opt1</span><br><span class="line">Count: 1028</span><br><span class="line">FE             Frontend_Bound:          11.60 +-     0.00 % Slots below</span><br><span class="line">BAD            Bad_Speculation:          3.30 +-     0.00 % Slots below</span><br><span class="line">BE             Backend_Bound:            8.43 +-     0.00 % Slots below</span><br><span class="line">RET            Retiring:                76.68 +-     0.00 % Slots       &lt;==</span><br><span class="line">               MUX:                    100.00 +-     0.00 %</span><br></pre></td></tr></table></figure><p>瓶颈已经不在分支预测上了。</p><p>用<code>perf stat</code>看一下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@server-P1 perfcontest]# perf stat ./sieve</span><br><span class="line">Count: 1028</span><br><span class="line"></span><br><span class="line"> Performance counter stats for './opt1':</span><br><span class="line"></span><br><span class="line">       2334.081187      task-clock (msec)         #    1.000 CPUs utilized          </span><br><span class="line">                 7      context-switches          #    0.003 K/sec                  </span><br><span class="line">                 0      cpu-migrations            #    0.000 K/sec                  </span><br><span class="line">               141      page-faults               #    0.060 K/sec                  </span><br><span class="line">     5,355,895,762      cycles                    #    2.295 GHz                    </span><br><span class="line">    19,038,809,322      instructions              #    3.55  insn per cycle         </span><br><span class="line">     4,209,500,410      branches                  # 1803.494 M/sec                  </span><br><span class="line">        10,114,763      branch-misses             #    0.24% of all branches        </span><br><span class="line"></span><br><span class="line">       2.334590616 seconds time elapsed</span><br></pre></td></tr></table></figure><p>branch-misses占比很小，同时IPC也在3.55，已经接近理论最大值(4)。</p><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>仅仅调了一个小时，应该还有继续优化的空间，比如利用PGO和SIMD指令。这个留在后续尝试。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> CPU </tag>
            
            <tag> performance </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>《居家男人》</title>
      <link href="/2019/02/15/thoughts5-family-man/"/>
      <url>/2019/02/15/thoughts5-family-man/</url>
      
        <content type="html"><![CDATA[<p>大约在2010年左右的时候，我会经常在PPS这种视频流软件上面看尼古拉斯凯奇的电影。他早期的一些作品还是令人印象深刻。相较于那些有名的动作片，《居家男人》应该只是一部家庭剧小品，但却成了我这些年重复播放最多的他的片子。<br><a id="more"></a></p><p>故事很普通，两个原本相爱的大学生在毕业时各奔前程，十几年后，一个成了家住曼哈顿上东区的金融巨子，一个是某律所的女合伙人，事业上都很成功，却都没有组建家庭。在圣诞这天，凯奇有了一次体验家庭生活的机会——如果毕业时他没有登上去往伦敦的飞机在巴克莱实习，而是选择与女主厮守，那么十几年后他们的家庭生活将会是什么样子。</p><p>当然有纽约一般中产的琐碎和烦恼，以及一儿一女等种种家庭生活的幸福。电影还是在宣扬“家庭幸福比世俗成功更重要”的主题，让人们认清什么是真正珍贵的东西。我对这种类似“说教”的信息并不反感，但这绝不至于让我把这部片子反复观看，甚至我个人认为，这应该是比《真爱至上》更好的圣诞电影。</p><p>之所以能这样认为，纯粹是因为观看这部影片时的私人体验。这种体验并不在于电影的镜头、布景、台词这些评判一部电影的“指标”，而仅仅在于片中场景的似曾相识，以及晏殊赋予”似曾相识“的另外一重意境——无可奈何。</p><p>面对生活中的各种取舍的时候，我们似乎有一个默认的“优先级”。这里面，个人的发展似乎是不言自明的第一位。因为逻辑是非常清晰的：你爱我，那么你会希望我好，你支持我追求我的发展，自然就是对我好。至于是否会为此失去其他，那倒不重要了。一旦有一方亮出这张牌，其他所有的理由都要退避三舍。这张牌往往还有一些别的登场方式，比如”这是为了我们共同的未来”、“这是我的梦想”等等。</p><p>影片的设定也是如此。凯奇为了追求自己的金融”梦”义无反顾地与女主在机场分道扬镳。登机前他向女主也基本上讲了一遍上面的逻辑，最后他说：</p><blockquote><p>在伦敦的一年并不会改变什么。</p></blockquote><p>正是这句话让我有了一种无可奈何的情状。一是因为世事难料，一是因为你无法指责别人的健忘。而更重要的是，即便你做了万全的计划，即便你为此舍弃了你自认为需要舍弃的东西，但最终真正能实现计划的人，却并没有多少。这和你的能力，你的决心以及外界的环境都没有关系。</p><p>因为一定要舍弃什么重要的东西才能实现的计划，要么是舍弃的东西并不那么重要，要么是这个计划并不值得实现。舍弃不重要的东西，不需要用这么”宏大“的计划作为说辞；而一旦没有了真正重要的东西，也很难“身残志坚”地应对挑战。这很像你打算爬上珠峰，却要先砍断一条腿一样。身处其中的人往往很难看清这一点，但拉开一段时间的距离，很快就能看清楚。</p><p>而所谓”为了我好”的逻辑，只不过是没有根据的臆想。往往在做这种幻梦的时候，我们还不够成熟，却喝了太多夹杂了催熟添加剂的鸡汤。归根到底，是没有真正地认识生活——生活的途径，永远不止一条。</p><p>不过还好，我虽然也有自己的安排，但似乎没有这种权衡和取舍，反而得到了所有想要的。理智给出的方案在很多时候确实是最优解，但首先要确保的是理智处在最优的状态。我从来不做难做的选择题，我宁愿在这种问题上交白卷，因为我知道“割舍”这个词其实就是“自戕”的另外一种写法，而你永远不会知道这张卷子后面哪里能找到一个加分题。</p><p>影片中凯奇得偿所愿，自己住在全球最贵的豪华公寓内俯瞰芸芸众生。我很喜欢当夜幕降临，他穿着条内裤独自躺在床上的片段，此时他的卧室因为刻意的灯光调整显得狭小而逼仄，我也曾经以同样的dress code，同样的姿势，躺在这样的房间里。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚15：Top-Down性能分析方法资料及Toplev使用</title>
      <link href="/2019/02/14/quickwords15-toplev/"/>
      <url>/2019/02/14/quickwords15-toplev/</url>
      
        <content type="html"><![CDATA[<h2 id="Top-down-Microarchitecture-Analysis-Method-TMAM-资料"><a href="#Top-down-Microarchitecture-Analysis-Method-TMAM-资料" class="headerlink" title="Top-down Microarchitecture Analysis Method(TMAM)资料"></a>Top-down Microarchitecture Analysis Method(TMAM)资料</h2><p>之前介绍过TMAM的具体内容，在这里对网络上相关的信息和资料做一个汇总：</p><p><a href="https://software.intel.com/en-us/vtune-amplifier-help-tuning-applications-using-a-top-down-microarchitecture-analysis-method" target="_blank" rel="noopener">Tuning Applications Using a Top-down Microarchitecture Analysis Method</a><br><a id="more"></a></p><p><a href="http://www.cs.technion.ac.il/~erangi/TMA_using_Linux_perf__Ahmad_Yasin.pdf" target="_blank" rel="noopener">Top-down Microarchitecture Analysis through Linux perf and toplev tools</a></p><p><a href="https://ieeexplore.ieee.org/document/6844459/metrics#metrics" target="_blank" rel="noopener">A Top-Down method for performance analysis and counters architecture</a></p><p><a href="https://doc.itc.rwth-aachen.de/download/attachments/28344675/08.Performance_Analysis_in_a_Nutshell.pdf?version=1&amp;modificationDate=1480665136000&amp;api=v2" target="_blank" rel="noopener">Performance_Analysis_in_a_Nutshell</a></p><p><a href="https://indico.cern.ch/event/280897/contributions/1628888/attachments/515367/711139/Top_Down_for_CERN_2nd_workshop_-_Ahmad_Yasin.pdf" target="_blank" rel="noopener">Top Down Analysis Never lost with Xeon® perf. counters</a></p><p><a href="https://dyninst.github.io/scalable_tools_workshop/petascale2018/assets/slides/TMA%20addressing%20challenges%20in%20Icelake%20-%20Ahmad%20Yasin.pdf" target="_blank" rel="noopener">How TMA* Addresses Challenges in Modern Servers and Enhancements Coming in IceLake</a></p><p>当然还有一些其他的相关信息，不过上面几个都可以覆盖（其实已经有点过量了）。</p><h2 id="Toplev使用"><a href="#Toplev使用" class="headerlink" title="Toplev使用"></a>Toplev使用</h2><p><code>toplev</code>是一个基于<code>perf</code>和TMAM方法的应用性能分析工具。从之前的<a href="https://decodezp.github.io/2019/01/27/quickwords13-tma/">介绍文章</a>中可以了解到TMAM本质上是对CPU Performance Counter的整理和加工。取得Performance Counter的读数需要<code>perf</code>来协助，对读数的计算进而明确是Frondend bound还是Backend bound等等。</p><p>在最终计算之前，你大概需要做三件事：</p><ul><li>明确CPU型号，因为不同的CPU，对应的PMU也不一样</li><li>读取TMAM需要的<code>perf event</code>读数</li><li>按TMAM规定的算法计算，具体算法在这个<a href="https://share.weiyun.com/5jNsb6o" target="_blank" rel="noopener">Excel表格</a>里</li></ul><p>这三步可以自动化地由程序来做。本质上<code>toplev</code>就是在做这件事。</p><p><code>toplev</code>的<a href="https://github.com/andikleen/pmu-tools" target="_blank" rel="noopener">Github地址</a>：<a href="https://github.com/andikleen/pmu-tools" target="_blank" rel="noopener">https://github.com/andikleen/pmu-tools</a></p><p>另外补充一下，TMAM作为一种<code>Top-down</code>方法，它一定是分级的。通过上一级的结果下钻，最终定位性能瓶颈。那么<code>toplev</code>在执行的时候，也一定是包含这个“等级”概念的。</p><p>下面是<code>toplev</code>使用方法的资料：</p><p><a href="https://github.com/andikleen/pmu-tools/wiki/toplev-manual" target="_blank" rel="noopener">toplev manual</a></p><p><a href="http://halobates.de/blog/p/262" target="_blank" rel="noopener">pmu-tools, part II: toplev</a></p><p>基本上都是由<code>toplev</code>的开发者自己写的，可以作为一个Quick Start Guide。</p><blockquote><p><code>toplev</code>仅针对系统瓶颈是CPU的场景，除此之外仍需要使用其他方法，如<code>pcm</code> tool。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚14：Skylake微架构(Microarchitecture)剖析(5)</title>
      <link href="/2019/02/03/quickwords14-skylake-pipeline-5/"/>
      <url>/2019/02/03/quickwords14-skylake-pipeline-5/</url>
      
        <content type="html"><![CDATA[<h2 id="Instruction-Decode-Queue-IDQ"><a href="#Instruction-Decode-Queue-IDQ" class="headerlink" title="Instruction Decode Queue(IDQ)"></a>Instruction Decode Queue(IDQ)</h2><p>IDQ也叫Allocation Queue(AQ)，也有时候会写成是Decode Queue。解码完成的uops在进入后端之前需要先在IDQ中做一下缓冲。作为一个”缓冲队列”，主要作用是将前端解码可能引入的流水线”气泡(bubbles)“消化掉，为后端提供稳定的uops供应(目标是6uop/cycle)。<br><a id="more"></a></p><p>Skylake的IDQ最大可以存放64个uops/thread，比Broadwell的28个多一倍还多。这些uop在IDQ中除了排一下队之外，还会被Loop Stream Detector(LSD)扫描一遍，用来发现这些uop是不是来自于一个循环。</p><h3 id="Loop-Stream-Detector-LSD"><a href="#Loop-Stream-Detector-LSD" class="headerlink" title="Loop Stream Detector(LSD)"></a>Loop Stream Detector(LSD)</h3><p>如果在IDQ中能被发现存在循环体uop，那么在下一次循环的时候，就不需要去重新解码这些循环体生成的uop，而是直接由LSD提供uops。这便可以省去指令fetch、解码、读uop cache、分支预测等所有之前的步骤，并且能进一步减少缓存占用。当然，当LSD起作用的时候，整个前端都是处于Disabled的状态。</p><p>Skylake的LSD需要在IDQ的长度（64uop）内发现循环，所以，循环体还是尽量紧凑一点吧:D</p><h2 id="后端（Backend）"><a href="#后端（Backend）" class="headerlink" title="后端（Backend）"></a>后端（Backend）</h2><p><img src="https://en.wikichip.org/w/images/thumb/6/64/skylake_rob.svg/450px-skylake_rob.svg.png" alt=""></p><p>还是首先介绍一下这个部分是否有别的名字。在有些文档里后端又直接被称为<code>Execution Engine</code>。后端的主要任务当然就是执行前端解码出来的这些uop。但后端和前端的设计都在围绕着“如何提高指令的并行性”来设计和优化。</p><p>在Skylake架构中，IDQ以最大6uop/cycle的速度将uop送入Re-order Buffer，后端的处理在Re-order Buffer中正式开始。</p><h2 id="Out-of-order-OOO-Execution-Engine"><a href="#Out-of-order-OOO-Execution-Engine" class="headerlink" title="Out-of-order(OOO)Execution/Engine"></a>Out-of-order(OOO)Execution/Engine</h2><p>先讲一下OOO（乱序）以便对后端的执行有一个整体的把握。</p><p>我们的程序虽然是按顺序编写的指令，但CPU并不（一定）会按相同的方式执行。为了提升整体效率，CPU采用的是乱序执行的方式。从一个“窗口”范围内选取可以执行的指令执行，并且这些操作对用户透明，在程序编写者的角度看来仍是在按他编写的指令顺序执行。</p><blockquote><p>从根本上来讲，OOO是用”数据流（Data flow）”的角度来看待程序，而非程序员的“指令流”视角。</p></blockquote><p>指令的目的就是以一种特定的方式操纵存在于内存/缓存中的数据，引起数据的变化，其实这就是我们通常所说的“写程序”。只不过这是人类习惯的逻辑方式，在机器看来并不一定高效。</p><p><img src="https://s2.ax1x.com/2019/02/03/kGeQiV.jpg" alt="截图出自Computer Architecture 2011 – out-of-order execution (lec 7) 1 Computer Architecture Out-of-order execution By Dan Tsafrir, 11/4/2011 Presentation"></p><p>在上图例子中，需要执行左上角的六个计算指令。<code>In-order execution</code>是假设完全按照程序顺序执行这六个指令的耗时。下面的`In-order(superscalar3)是合并了一些可以并行执行的指令的耗时。</p><p>因为指令(2)中的<code>r1</code>要依赖指令(1)的结果，所以指令(2)只能等(1)执行结束再执行。而本来可以并行执行的(3)(4)也因为要保证In-order顺序而只能一同放在(1)之后执行。</p><p>但从左下角的<code>Data flow</code>的角度来看，其实我们并不需要按照指令顺序运行程序：指令(2)完全可以放在后面执行，并重新安排并行计算顺序。这样就又节省了执行所需的时间。</p><p>OOO选择可执行指令的依据是：</p><ul><li>不依赖未执行指令操纵的数据</li><li>有可用的执行资源</li></ul><p>为了尽可能让进入后端的指令满足这两个条件，OOO采用了一系列的组件和技术。在后面的章节中将会进行介绍。</p><p><img src="http://hpca23.cse.tamu.edu/taco/utsa-www/cs5513-fall07/basic-concept.gif" alt=""></p><p>上图是一个OOO的概念示意图。前端输出给后端的都是顺序指令流，后端在一个窗口范围中选择可以执行的指令进行乱序执行。这里面没有强调的是，最终指令退出(retire)的顺序仍是按照程序的顺序。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序员学英语的几点实用经验</title>
      <link href="/2019/01/31/how-to-learn-english/"/>
      <url>/2019/01/31/how-to-learn-english/</url>
      
        <content type="html"><![CDATA[<p>学习英语当然要靠不断的练习，但同样的练习时间往往效果却大相径庭。以下是我结合自己的经历总结的一些经验和方法，希望能帮助大家提高学习英语的效率。</p><h2 id="Rubbish-in-rubbish-out"><a href="#Rubbish-in-rubbish-out" class="headerlink" title="Rubbish in, rubbish out"></a>Rubbish in, rubbish out</h2><p>把自己想象成一个处理英文的黑盒，输入就是听读，输出就是说写。和人工智能训练模型需要优质的标签数据一样，学习英语也需要优质的输入才能达到良好的学习效果。</p><p>在程序员的领域，最直接的优质的英文材料就是经典的英文原版技术书籍。编写这些书籍的大师不但是技术领域的巨擘，同时也是操纵语言的大师，他们的书籍往往最是简洁明快，逻辑清晰。<br><a id="more"></a></p><h2 id="复写"><a href="#复写" class="headerlink" title="复写"></a>复写</h2><p>但如果你是刚开始决定提高自己的英文水平，看这些书籍其实很容易产生挫败感。我的建议是，找自己这个领域最著名的开源项目，一般这种项目都会有很好的文档(教程)支持。这个项目的教程就是你英文的入门材料。</p><p>但不是说能看着教程，自己找了台电脑跟着操作了一遍就算学会了。在有了实际操作经验之后，你其实已经知道这一节教程内容是要告诉你什么了，这个时候把教程的窗口最小化，打开你最喜欢的文字编辑器，将刚刚教程的内容复写一遍。</p><p>就是要有那种“明明知道要表达什么，但就是忘了刚才教程里是怎么写的了”的焦灼感。</p><p>这种时候先用自己的“初中英语”硬把坑填上。等这一节都复写完成之后，把教程的窗口重新最大化，再看一遍，看看刚刚自己胡说八道的地方教程都是怎么写的，默默记下来，然后重新把窗口最小化，修改刚刚自己复写的内容。</p><p>别指望看了第二遍就能全部记住，重复这个过程，直到完全一致。注意单复数，be动词时态，以及a/an/the定冠词的用法。</p><p>慢慢你就会发现英语的表达，尤其是在技术领域，就那么几个套路。</p><h2 id="利用Google"><a href="#利用Google" class="headerlink" title="利用Google"></a>利用Google</h2><p>在练习了一段时间的复写之后，在工作中遇到开发或技术上的问题，不要用百D或是中文搜索，而是在Google上用英文搜索(bing也不行，只建议用Google)。</p><p>搜索栏里填什么关键词随便你，但最开始很可能找不到你要搜索的问题的答案。</p><p>尝试不断更换关键词，多往后翻几页，直到找到那个你认为你最需要的页面。这个时候不要Ctrl+C/V把页面里的代码一复制再来个git commit就完了，重新回到Google，重新调整你的关键词，用最短，最少的关键字让这个页面出现在搜索结果的第一页第一行。</p><p>能让自己的表达逐渐精确，就是语言能力的提升。</p><h2 id="建立全面的信息关联"><a href="#建立全面的信息关联" class="headerlink" title="建立全面的信息关联"></a>建立全面的信息关联</h2><p>两个人面对面说话，所传达的全部信息，纯粹语言的内容只能占30%。剩下的信息是由肢体语言、表情、语调语速传递的。</p><p>为什么很多人学了半天仍然觉得语言实际应用能力提高不大，就是因为只冲着那30%去的，实际能传达出要传达的20%就算不错了。</p><p>关键就是在于，没有将一句话放到实际中去关联场景，而大脑关联学习或关联记忆的效率是最高的。</p><p>在教程和搜索上小有成就了之后，你需要学习真正的语言。将语言划分为“听说读写”四项没有错，但如果你练习听力就只塞一个耳机那是效率很低的学习方法。</p><p>打开一个经典的技术视频，或者你感兴趣的TED演讲，不要关注演讲者说的你是不是都能听懂，而是关注演讲本身，关注他的肢体语言、关注观众的反馈、关注他如何使用他的PPT，关注他是如何表达，语言本身只是这一切的副产品。你的大脑会自己将这些都分门别类罗缕纪存。</p><p>之后自己尽最大的努力将要点复述(用嘴说)一遍，回想当时的场景，回想演讲者的动作和表情，回想他的语调和语速，回想当时的摄像机的角度和PPT的内容。然后把你能想到整场演讲的逻辑和每一环节的中心思想写下来。返回视频，和复写一样，对照修改，直到自己满意。</p><h2 id="输出的时候放空大脑"><a href="#输出的时候放空大脑" class="headerlink" title="输出的时候放空大脑"></a>输出的时候放空大脑</h2><p>最后一点想说的是，无论是说还是写，很多人遇到的问题是，英文输出的过程多了”翻译”这个步骤。先想中文的意思，再将这个意思翻译成英文，再转换为文字或者口语。而对听和读，也是要翻译一遍，大脑再去处理中文的意思。</p><p>这是很没效率的事情，就像Linux收发包要对数据报文做多次拷贝一样，很有可能成为你整个系统的瓶颈。这里放空大脑的意思和”零拷贝”技术十分类似，就是不要有任何翻译的过程。在练习的时候，不要用中文去想你要表达什么，不要让大脑中出现任何中文的”声音”，不要给你对面的哥们做同声传译。最开始可能不容易做到，但要不断强调这个意识。</p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>几句话说清楚13：什么是Top-Down性能分析方法</title>
      <link href="/2019/01/27/quickwords13-tma/"/>
      <url>/2019/01/27/quickwords13-tma/</url>
      
        <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>前几篇连续介绍了一些Skylake微架构的内容（还没有结束，还会继续填坑），主要目的并不是要对读者开启名词或者概念的Flood攻击，而是为了方便读者以后可以“有理有据”地进行软件的性能优化。<br><a id="more"></a></p><p>但不能否认的是，CPU微架构的学习还是有比较陡峭的曲线的。是不是一定要非常精通微架构之后，才能进行软件的性能优化呢？从我自己的经验来说，并非如此。</p><p>性能优化虽然是一门专业的技术，但它和其他所有技术一样，也有自己的整体思想和方法论。首先对其方法论有一个大概的认识之后，再去精研细节，在我看来是一个比较有效率的学习方法。</p><p>《三国志》诸葛亮传中曾载：</p><blockquote><p>亮在荆州，以建安初与颍川石广元、徐元直、汝南孟公威等俱游学。三人务于精熟，而亮独观其大略。</p></blockquote><p>先贤轨物范世在前，古今一辙，今日正当观其荦荦大端者。</p><h2 id="Top-down-Microarchitecture-Analysis-TMA"><a href="#Top-down-Microarchitecture-Analysis-TMA" class="headerlink" title="Top-down Microarchitecture Analysis(TMA)"></a>Top-down Microarchitecture Analysis(TMA)</h2><p>Top-down可以翻译成“自顶向下”，经常做一些有可有无的PPT架构设计的同学应该对这类词汇比较熟悉。当然也有一些“分析方法”喜欢用这个词。</p><p>TMA就是一套基于CPU微架构的“自顶向下”分析的方法。我对这个词的理解倒和具体的方位无关，而是紧紧抓住目标的一种思维方式。</p><p>这里就不得不提一下我的初中物理老师，她教给我们的一种解题方法似乎就可以概括为“自顶向下”，简单在这里介绍一下，希望这一类比能在后面叙述时帮助理解。</p><p>比如有一道很复杂的题目，题干很长，但最终的问题就是求密度。那么前面的东西可以先忽略，仅仅针对“密度”来说，那么就需要知道质量和体积。假设体积是已知的，那么问题“转化”为如何知道质量。质量等于匀速运动时的滑动摩擦力除以滑动摩擦系数。在题干中找出这些条件，或继续进行类似的推导。虽然最终在列公式时需要“反向”求得最终的密度，但思考方式是先从密度开始的。</p><p>基本上就是这个道理。同如何“求得密度”类似，TMA解决的问题就是如何“求得瓶颈”。</p><p>那么为了求得瓶颈，其实就是首先看CPU流水线总体上有多少时间没有真正在处理计算任务（aka流水线利用率）。继而，观察没有处理计算任务，是因为各方面没有协调好导致流水线空转(Stalled)还是虽然没有空转(Non-stalled)但却没有进行实际的计算（e.g.分支预测失败aka指令没有最终retired）。</p><p><img src="https://software.intel.com/sites/default/files/did_feeds_images/6E3B86B7-8072-4E6A-9E27-0CD21446ACB1/6E3B86B7-8072-4E6A-9E27-0CD21446ACB1-imageId=9681762B-D017-4429-B60E-E66D0E98B6AB.gif" alt=""></p><p>然后针对空转，看看是前端的原因还是后端的原因。然后再具体看是前/后端哪一个具体项目导致的空转，进而定位系统瓶颈。当然最终还是依赖PMU counter提供的基础数据。</p><h2 id="Pipeline-slots"><a href="#Pipeline-slots" class="headerlink" title="Pipeline slots"></a>Pipeline slots</h2><p>Pipeline slots是一个经常出现的概念。它是流水线利用率的一种抽象表达，并没有实际的硬件或软件对应于这一概念。这里尝试解释一下：想象一条组装汽车的流水线，一开始时，很多汽车外壳被“挂”在了一个钩子上面，这个钩子其实就可以类比为一个Pipeline slots，只不过这个slot里装的是一条指令，uop，确切地说。</p><p>这些汽车壳子在以一个均匀的速度往前走，进而在不同的流水线阶段完成不同的工作，最后组装成一台完整的汽车。向前走的速度可以类比为CPU的Clock cycle，最终下线出厂就是指令retired。只不过有可能这些slot有些挂上了汽车外壳，有些还是空的（指令没取到），有些挂的，是没有用的废品壳子（分支预测失败）。</p><p>在上图中，<code>Uop allocate</code>其实就是说Uop有没有挂到Pipeline slot中的意思。</p><h2 id="分析指标（Metric）"><a href="#分析指标（Metric）" class="headerlink" title="分析指标（Metric）"></a>分析指标（Metric）</h2><p>OK，有了总体的方法之后，下面的工作就是如何再量化一下了。比如如何确定流水线的利用率，如何确定是前端Stall还是后端Stall，判断的依据和计算方法，设定的阈值等等。这些不是本文的重点，但在后续介绍完Skylake微架构后详细介绍。心急的同学可以先下载Intel总结好的<a href="https://share.weiyun.com/5jNsb6o" target="_blank" rel="noopener">Excel表格</a>。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去6：Linux网络性能调优方法（补遗）</title>
      <link href="/2019/01/24/test6-linux-network-performance-optimization-2/"/>
      <url>/2019/01/24/test6-linux-network-performance-optimization-2/</url>
      
        <content type="html"><![CDATA[<h2 id="没提到的"><a href="#没提到的" class="headerlink" title="没提到的"></a>没提到的</h2><p><a href="https://decodezp.github.io/2019/01/22/test5-linux-network-performance-optimization/">上一篇</a>内容中介绍了一些Linux网络协议栈的调优方法，但遗漏了一些可以发挥重要作用的方法，在这一篇中补充一下。<br><a id="more"></a></p><h2 id="net-rx-action-budget"><a href="#net-rx-action-budget" class="headerlink" title="net_rx_action budget"></a><code>net_rx_action</code> budget</h2><p>这个参数可以决定NAPI可以占用多少CPU的处理能力，可以调到900</p><p><code>sysctl -w net.core.netdev_budget=900</code></p><h2 id="netdev-max-backlog"><a href="#netdev-max-backlog" class="headerlink" title="netdev_max_backlog"></a><code>netdev_max_backlog</code></h2><p><code>sysctl -w net.core.netdev_max_backlog=65535</code></p><h2 id="dev-weight"><a href="#dev-weight" class="headerlink" title="dev_weight"></a><code>dev_weight</code></h2><p><code>sysctl -w net.core.dev_weight=1024</code><br>这个参数在实际测试中影响也比较大</p><h2 id="ip-early-demux"><a href="#ip-early-demux" class="headerlink" title="ip_early_demux"></a><code>ip_early_demux</code></h2><p><code>sysctl -w net.ipv4.ip_early_demux=0</code><br>这个参数根据实际测试结果调整。改为0或1。</p><h2 id="关于RPS"><a href="#关于RPS" class="headerlink" title="关于RPS"></a>关于RPS</h2><p>在前面提到需要关闭RPS功能，但在实际测试中发现设定相应的CPU Mask还是能对性能有比较大的提升，具体原因在进一步挖掘的过程中，当前需要实际测试找出最适合的配置方法。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> network </tag>
            
            <tag> performance </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去5：Linux网络性能调优方法</title>
      <link href="/2019/01/22/test5-linux-network-performance-optimization/"/>
      <url>/2019/01/22/test5-linux-network-performance-optimization/</url>
      
        <content type="html"><![CDATA[<h2 id="换换口味"><a href="#换换口味" class="headerlink" title="换换口味"></a>换换口味</h2><p>老搞DPDK的人有一个毛病就是怎么也看不上内核网络，又是中断又是拷贝的，实在没有一脚地板油CPU直接100%炸街来得爽快。另外作为一个软件性能优化的“硬核”玩家，是很看不上内核这种改改参数，调调设置的玩法的。不过…既然自己主动跳了个大坑，该调内核性能的时候还是要调的…所以今天就换换口味，看看在Linux下通过配置调优网络性能怎么搞。</p><a id="more"></a><h2 id="了解你的设备"><a href="#了解你的设备" class="headerlink" title="了解你的设备"></a>了解你的设备</h2><p>性能调优只有一个任务，就是充分发挥现有资源的能力。因此，了解自己的设备，就成了一切的前提。</p><p>硬件软件的细节难以遍数，若从细处着手…傻子才从细处着手吧。在网络方面，需要从全局上搞清楚这样几个问题：</p><ul><li>网卡什么型号</li><li>网卡有几个口</li><li>每个口有几个队列</li><li>有什么硬件offloading的功能</li><li>CPU什么型号</li><li>CPU有几个核心</li><li>CPU有什么能调高主频的方法</li><li>CPU有什么指令集</li><li>有没有NUMA</li></ul><p>其他至于内存、存储的可以先放一边。搞清楚系统配置之后需要准备几样工具。</p><h2 id="几样工具"><a href="#几样工具" class="headerlink" title="几样工具"></a>几样工具</h2><ul><li>htop<br>和top相比确实更直观一些，没有的话用<code>top</code>凑活一下也行。难就难在有些自己裁剪的Linux系统（比如OpenWRT）里虽然有<code>top</code>，但和我们用的不是一个<code>top</code>….</li><li>ethtool<br>非常非常非常值得深度挖掘的工具，最近一个星期最后悔的事就是自己编译OpenWRT时没有勾上它。导致配代理配了个一六八开才把OpenWRT盒子挂上外网用<code>opkg</code>装上。</li><li>sysctl<br>主要用来修改内核参数。</li><li>perf<br>其实在这里用处不大，但一个系统里没装perf就会感觉少点什么。</li><li>常规工具<br><code>cat</code>、<code>echo</code>、<code>ifconfig</code>等基础自带的工具。</li></ul><h2 id="搞一搞"><a href="#搞一搞" class="headerlink" title="搞一搞"></a>搞一搞</h2><h3 id="测试拓扑及相关"><a href="#测试拓扑及相关" class="headerlink" title="测试拓扑及相关"></a>测试拓扑及相关</h3><p>拓扑如下：</p><p><img src="https://www.strongswan.org/testing/testresults/images/a-m-w-s-b.png" alt=""></p><p>其中Gateway Moon就是需要调优性能的OpenWRT盒子。Gateway Moon和Gateway Sun之间建立了IPsec加密隧道。进行Client Alice和Client Bob之间的路由转发。</p><p>在两个Client上分别运行<code>iperf3</code> server和client，来进行带宽（也即IPSec隧道的转发性能）测试。</p><p>目前除了Gateway Moon之外所有服务器都是用的高端服务器，所以瓶颈肯定在这片可怜的阿童木小盒子上。</p><p>IPsec相关的详细配置可以参考<a href="https://www.strongswan.org/testing/testresults/ikev2/net2net-psk/" target="_blank" rel="noopener">这里</a>。</p><blockquote><p>如果只是单纯测试转发速率完全不用这么复杂，两个盒子直连就可以。我这里只是最近需要搞IPsec隧道。</p></blockquote><h3 id="打开网卡多队列"><a href="#打开网卡多队列" class="headerlink" title="打开网卡多队列"></a>打开网卡多队列</h3><p>先看看你的网卡支持多少个队列：</p><p><code>ethtool -l eth3</code></p><p>这里面<code>RX</code>和<code>TX</code>等于0是说仅仅能用作接收或发送的队列个数为0，而下方<code>combined</code>是指既可以作为发送队列也可以作为接收队列的个数，一般看这个数字就知道可以有多少个接收队列和多少个发送队列了。</p><p>而<code>other</code>是指用作link interrupt或SR-IOV协调的队列，在我们这个场景下并没有什么卵用。</p><p>打开多队列：</p><p><code>ethtool -L eth3 combined 2</code></p><p>这样你就有了两个接收队列，以及两个发送队列。</p><p>这个时候看一下<code>cat /proc/interrupts</code>应该能看到eth3-rx-0/1的中断号。</p><h3 id="打开能打开的网卡Offloading"><a href="#打开能打开的网卡Offloading" class="headerlink" title="打开能打开的网卡Offloading"></a>打开能打开的网卡Offloading</h3><p>首先看一下你都有哪些offloading能力：</p><p><code>ethtool -k eth3</code></p><p>带<code>[fixed]</code>标识的就别多想了。如果有想打开的offloading能力，比如RX checksum：</p><p><code>ethtool -K eth3 rx on</code></p><blockquote><p>全部能力和操作方法参考<code>man ethtool</code>。</p></blockquote><h3 id="网卡队列深度"><a href="#网卡队列深度" class="headerlink" title="网卡队列深度"></a>网卡队列深度</h3><p>看一下最大支持深度和现在的配置情况：</p><p><code>ethtool -g eth3</code></p><p>将接收队列深度改为4096</p><p><code>ethtool -G eth3 rx 4096</code></p><h3 id="RSS队列配置"><a href="#RSS队列配置" class="headerlink" title="RSS队列配置"></a>RSS队列配置</h3><p>开了多队列最好配置一下RSS，先看一下RSS现在的配置：</p><p><code>ethtool -x eth3</code></p><p>能看到RSS indirection table和RSS hash key以及RSS hash function。</p><p>具体RSS是什么就不在这里讲解了，如果想比较均匀地让报文散列到前两个RX队列上：</p><p><code>ethtool -X eth3 equal 2</code></p><p>再看一下RSS indirection table，也许会有不一样的地方，当然也许没有 :D</p><p>如果想让某条RX队列收取更多的报文，可以配置报文的权重：</p><p><code>ethtool -X eth3 weight 6 2</code></p><p>这样RX queue 0的权重是6，会比RX queue 1收取更多的报文(一般情况下)。在需要更细粒度优化的情况下可以使用。</p><h3 id="RSS-Hash配置"><a href="#RSS-Hash配置" class="headerlink" title="RSS Hash配置"></a>RSS Hash配置</h3><p>这里可以决定针对不同的流量（IPv4-tcp, IPv4-udp, IPv6-tcp, Ethernet…)采用报文的哪些字段进行RSS Hash。</p><p>有没有体验过UDP流量换了端口号还是始终进入同一条队列的恐惧？</p><p>那是因为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@OpenWrt:~# ethtool -n eth0 rx-flow-hash udp4</span><br><span class="line">UDP over IPV4 flows use these fields for computing Hash flow key:</span><br><span class="line">IP SA</span><br><span class="line">IP DA</span><br></pre></td></tr></table></figure><p>针对UDP流量只用Src IP和dst IP做哈希…如果这两个字段没变化那么就只能进入同一条队列…</p><p>想添加上src和dst port一同作为RSS的字段：</p><p><code>ethtool -N eth3 rx-flow-hash udp4 sdfn</code></p><p>查看一下<code>man ethtool</code>可以明白<code>sdfn</code>的意义：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">m   Hash on the Layer 2 destination address of the rx packet.</span><br><span class="line">v   Hash on the VLAN tag of the rx packet.</span><br><span class="line">t   Hash on the Layer 3 protocol field of the rx packet.</span><br><span class="line">s   Hash on the IP source address of the rx packet.</span><br><span class="line">d   Hash on the IP destination address of the rx packet.</span><br><span class="line">f   Hash on bytes 0 and 1 of the Layer 4 header of the rx packet.</span><br><span class="line">n   Hash on bytes 2 and 3 of the Layer 4 header of the rx packet.</span><br><span class="line">r   Discard all packets of this flow type. When  this  option  is</span><br><span class="line">    set, all other options are ignored.</span><br></pre></td></tr></table></figure><blockquote><p>另外注意如果你搭建的是IPsec隧道，即便你加解密之前/后可能是UDP/TCP流量，但经过加密之后都是<code>esp4</code>类型的流量。</p></blockquote><h3 id="N-tuple-filters配置"><a href="#N-tuple-filters配置" class="headerlink" title="N-tuple filters配置"></a>N-tuple filters配置</h3><p>这个需要考虑自己的实际应用场景，比如在一个web服务器中将处理http流量的进程绑定在CPU1，同时将RX queue-1的中断都放在CPU1，这时如果将所有dst port是80的http流量都导入Rx queue-1将会在进程切换和缓存命中方面提供好处。</p><p>首先查看一下网卡是不是支持：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ethtool -k eth3</span><br><span class="line">...</span><br><span class="line">ntuple-filters: off</span><br></pre></td></tr></table></figure><p>打开：</p><p><code>ethtool -K eth3 ntuple on</code></p><p>配一条过滤规则：</p><p><code>ethtool -U eth3 flow-type tcp4 dst-port 80 action 1</code></p><p>具体流量的命中情况可以通过</p><p><code>ethtool -S eth3</code></p><p>中的<code>fdir_match</code>和<code>fdir_miss</code>查看。</p><h3 id="中断分布"><a href="#中断分布" class="headerlink" title="中断分布"></a>中断分布</h3><p>内核收包的一大瓶颈就是中断处理。一个常见的技巧就是让这些中断由所有CPU核共同分担。最优的配置就是一个NUMA节点中有多少个CPU核，该节点上的网卡就有多少个收包队列。当然我这里用的这个盒子是不敢奢望什么NUMA了….</p><p>先看一下都挂了哪些中断：<br><code>cat /proc/interrupts</code></p><p>然后把某个收包队列对应的中断号绑定到对应的CPU核上：</p><p><code>echo mask &gt; /proc/irq/$IRQ/smp_affinity</code></p><p>其中<code>mask</code>就是允许发送中断的CPU的bit位。mask=1就是CPU0, mask=2就是CPU1, mask=3就是CPU0和1.</p><blockquote><p>在自己手动设置中断分布之前，先检查一下系统里是不是已经在运行<code>irqbalance</code>守护进程。如果有先把它关掉。</p></blockquote><p>贴一个网上应用比较广泛的脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> setting up irq affinity according to /proc/interrupts</span><br><span class="line"><span class="meta">#</span> 2008-11-25 Robert Olsson</span><br><span class="line"><span class="meta">#</span> 2009-02-19 updated by Jesse Brandeburg</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> &gt; Dave Miller:</span><br><span class="line"><span class="meta">#</span> (To get consistent naming in /proc/interrups)</span><br><span class="line"><span class="meta">#</span> I would suggest that people use something like:</span><br><span class="line"><span class="meta">#</span>             char buf[IFNAMSIZ+6];</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>             sprintf(buf, "%s-%s-%d",</span><br><span class="line"><span class="meta">#</span>                 netdev-&gt;name,</span><br><span class="line"><span class="meta">#</span>                            (RX_INTERRUPT ? "rx" : "tx"),</span><br><span class="line"><span class="meta">#</span>                            queue-&gt;index);</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>  Assuming a device with two RX and TX queues.</span><br><span class="line"><span class="meta">#</span>  This script will assign:</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>             eth0-rx-0  CPU0</span><br><span class="line"><span class="meta">#</span>             eth0-rx-1  CPU1</span><br><span class="line"><span class="meta">#</span>             eth0-tx-0  CPU0</span><br><span class="line"><span class="meta">#</span>             eth0-tx-1  CPU1</span><br><span class="line"><span class="meta">#</span></span><br><span class="line">set_affinity()</span><br><span class="line">&#123;</span><br><span class="line">MASK=$((1&lt;&lt;$VEC))</span><br><span class="line">printf "%s mask=%X for /proc/irq/%d/smp_affinity\n" $DEV $MASK $IRQ</span><br><span class="line">printf "%X" $MASK &gt; /proc/irq/$IRQ/smp_affinity</span><br><span class="line">echo $DEV mask=$MASK for /proc/irq/$IRQ/smp_affinity</span><br><span class="line">echo $MASK &gt; /proc/irq/$IRQ/smp_affinity</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">if [ "$1" = "" ] ; then</span><br><span class="line">    echo "Description:"</span><br><span class="line">    echo "This script attempts to bind each queue of a multi-queue NIC"</span><br><span class="line">    echo "to the same numbered core, ie tx0|rx0 --&gt; cpu0, tx1|rx1 --&gt; cpu1"</span><br><span class="line">    echo "usage:"</span><br><span class="line">    echo "$0 eth0 [eth1 eth2 eth3]"</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> Set up the desired devices.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"> </span><br><span class="line">for DEV in $*</span><br><span class="line">do</span><br><span class="line">  for DIR in  rx tx</span><br><span class="line">  do</span><br><span class="line"> MAX=`grep $DEV-$DIR /proc/interrupts | wc -l`</span><br><span class="line"> if [ "$MAX" == "0" ] ; then</span><br><span class="line">   MAX=`egrep -i "$DEV:.*$DIR" /proc/interrupts | wc -l`</span><br><span class="line"> fi</span><br><span class="line"> if [ "$MAX" == "0" ] ; then</span><br><span class="line">   echo no vectors found on $DEV</span><br><span class="line">   exit 1</span><br><span class="line"> fi</span><br><span class="line"> for VEC in `seq 0 1 $MAX`</span><br><span class="line"> do</span><br><span class="line">    IRQ=`cat /proc/interrupts | grep -i $DEV-$DIR-$VEC"$"  \</span><br><span class="line">| cut  -d:  -f1 | sed "s/ //g"`</span><br><span class="line">    if [ -n  "$IRQ" ]; then</span><br><span class="line">          set_affinity</span><br><span class="line">    else</span><br><span class="line">           IRQ=`cat /proc/interrupts | egrep -i $DEV:v$VEC-$DIR"$"  \</span><br><span class="line">| cut  -d:  -f1 | sed "s/ //g"`</span><br><span class="line">           if [ -n  "$IRQ" ]; then</span><br><span class="line">             set_affinity</span><br><span class="line">           fi</span><br><span class="line">    fi</span><br><span class="line"> done</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="内核网络相关参数"><a href="#内核网络相关参数" class="headerlink" title="内核网络相关参数"></a>内核网络相关参数</h3><p>这一部分没太多好说的，下面给一个<code>/etc/sysctl.conf</code>的配置内容，可以参考，若是觉得有些数字还不够激进，可以自己再改大一点，最后别忘了用<code>sysctl -p</code>生效。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>## GENERAL NETWORK SECURITY OPTIONS ###</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Number of times SYNACKs for passive TCP connection.</span><br><span class="line">net.ipv4.tcp_synack_retries = 2</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Allowed local port range</span><br><span class="line">net.ipv4.ip_local_port_range = 2000 65535</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Protect Against TCP Time-Wait</span><br><span class="line">net.ipv4.tcp_rfc1337 = 1</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Control Syncookies</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Decrease the time default value for tcp_fin_timeout connection</span><br><span class="line">net.ipv4.tcp_fin_timeout = 15</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Decrease the time default value for connections to keep alive</span><br><span class="line">net.ipv4.tcp_keepalive_time = 300</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 5</span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 15</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span>## TUNING NETWORK PERFORMANCE ###</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Default Socket Receive Buffer</span><br><span class="line">net.core.rmem_default = 31457280</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Maximum Socket Receive Buffer</span><br><span class="line">net.core.rmem_max = 67108864</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Default Socket Send Buffer</span><br><span class="line">net.core.wmem_default = 31457280</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Maximum Socket Send Buffer</span><br><span class="line">net.core.wmem_max = 33554432</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase number of incoming connections</span><br><span class="line">net.core.somaxconn = 65535</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase number of incoming connections backlog</span><br><span class="line">net.core.netdev_max_backlog = 65536</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase the maximum amount of option memory buffers</span><br><span class="line">net.core.optmem_max = 25165824</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase the maximum total buffer-space allocatable</span><br><span class="line"><span class="meta">#</span> This is measured in units of pages (4096 bytes)</span><br><span class="line">net.ipv4.tcp_mem = 786432 1048576 26777216</span><br><span class="line">net.ipv4.udp_mem = 192576 256768 385152</span><br><span class="line"><span class="meta">#</span> Increase the read-buffer space allocatable</span><br><span class="line">net.ipv4.tcp_rmem = 8192 87380 33554432</span><br><span class="line">net.ipv4.udp_rmem_min = 131072</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase the write-buffer-space allocatable</span><br><span class="line">net.ipv4.tcp_wmem = 8192 65536 33554432</span><br><span class="line">net.ipv4.udp_wmem_min = 131072</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Increase the tcp-time-wait buckets pool size to prevent simple DOS attacks</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 1440000</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br></pre></td></tr></table></figure><h3 id="Interrupt-Coalescing"><a href="#Interrupt-Coalescing" class="headerlink" title="Interrupt Coalescing"></a>Interrupt Coalescing</h3><p>在大流量情况下需要考虑对NIC发送的中断进行一些“批量处理”，合并一些中断请求，从而减少CPU的压力。</p><p>看一下当前网卡的Interrupt Coalescing的配置情况：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@server-P1 ~]# ethtool -c eno3</span><br><span class="line">Coalesce parameters for eno3:</span><br><span class="line">Adaptive RX: off  TX: off</span><br><span class="line">stats-block-usecs: 0</span><br><span class="line">sample-interval: 0</span><br><span class="line">pkt-rate-low: 0</span><br><span class="line">pkt-rate-high: 0</span><br><span class="line"></span><br><span class="line">rx-usecs: 1</span><br><span class="line">rx-frames: 0</span><br><span class="line">rx-usecs-irq: 0</span><br><span class="line">rx-frames-irq: 0</span><br><span class="line"></span><br><span class="line">tx-usecs: 0</span><br><span class="line">tx-frames: 0</span><br><span class="line">tx-usecs-irq: 0</span><br><span class="line">tx-frames-irq: 0</span><br><span class="line"></span><br><span class="line">rx-usecs-low: 0</span><br><span class="line">rx-frame-low: 0</span><br><span class="line">tx-usecs-low: 0</span><br><span class="line">tx-frame-low: 0</span><br><span class="line"></span><br><span class="line">rx-usecs-high: 0</span><br><span class="line">rx-frame-high: 0</span><br><span class="line">tx-usecs-high: 0</span><br><span class="line">tx-frame-high: 0</span><br></pre></td></tr></table></figure><p>改动这些配置需要网卡硬件和驱动的支持。如果可以改动的话，比较简单的就是改成自适应模式：</p><p><code>ethtool -C eth3 adaptive-rx on</code></p><p>自适应模式就是自动在网络压力小或者大的时候调整参数，从而达到最小延迟/最大吞吐。</p><p>其他的参数的含义如下：</p><ul><li><code>rx-usecs</code>：从收到报文到发送中断delay的usec</li><li><code>rx-frames</code>：发送中断前最大收取的报文数量</li><li><code>rx-usecs-irq</code>：再次发送中断的delay的usec<br>等等…</li></ul><h3 id="Receive-Packet-Steering-RPS"><a href="#Receive-Packet-Steering-RPS" class="headerlink" title="Receive Packet Steering(RPS)"></a>Receive Packet Steering(RPS)</h3><p>RPS是一种软件实现的RSS。在多队列网卡系统上，这个东西是非常多余的…所以前面的中断和RSS都配置得没问题得话，一定要记得关闭RPS：</p><p><code>echo 0 &gt; /sys/class/net/&lt;dev&gt;/queues/rx-&lt;n&gt;/rps_cpus</code></p><p>关于RPS具体的说明，以及为什么它是多余的，可以参看<a href="https://github.com/torvalds/linux/blob/v3.13/Documentation/networking/scaling.txt#L138-L164" target="_blank" rel="noopener">这里</a>。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> network </tag>
            
            <tag> performance </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚12：Skylake微架构(Microarchitecture)剖析(4)</title>
      <link href="/2019/01/20/quickwords12-skylake-pipeline-4/"/>
      <url>/2019/01/20/quickwords12-skylake-pipeline-4/</url>
      
        <content type="html"><![CDATA[<h2 id="MSROM"><a href="#MSROM" class="headerlink" title="MSROM"></a>MSROM</h2><p><img src="https://en.wikichip.org/w/images/thumb/5/5e/skylake_decode.svg/425px-skylake_decode.svg.png" alt=""></p><p>MSROM(Micro-code sequencer ROM)就是在<a href="https://decodezp.github.io/2019/01/12/quickwords11-skylake-pipeline-3/">上一篇连载</a>中提到的专门处理输出大于4个uop的那块类似缓存的ROM。很多文档里面也直接将其称为<code>MS</code>，具体叫什么多需要结合上下文语境，知道是一回事就好了。</p><blockquote><p>我个人其实推荐读者在编写自己的文档时能注意这些名称上的“一致性”，同编写程序时给变量或函数命名时的一致性一样，这些看似没什么“技术含量”的工作，却能够极大地提高信息传达的效率，也就是提高文档或代码的可读性和可维护性。</p></blockquote><a id="more"></a><p>在Instruction Decoder收到一个输出要大于4个uop的指令之后，它就会将请求转发给MSROM。MSROM虽然是专门解码/查询大于4个uop的指令的组件，但它最大的传输效率是4uop/cycle。同时在它工作的时候，所有的Instruction Decoder都要处于Disable的状态。因此虽然它的工作不太需要“动脑子”，但却仍要尽量避免。</p><h2 id="Stack-Engine"><a href="#Stack-Engine" class="headerlink" title="Stack Engine"></a>Stack Engine</h2><p>Stack Engine是专门处理栈操作指令的专用组件。类似<code>PUSH</code>、<code>POP</code>、<code>CALL</code>、<code>RET</code>这样的指令都算栈操作指令。Stack Engine不算什么新鲜的黑科技，自从Pentium M时代起就已经出现在Intel的CPU中。它的主要目的是避免栈操作指令对后端资源的占用，从而为其他计算任务提供出更多的资源。为此，Stack Engine提供栈操作指令专用的加法器和其他所需的逻辑完成这一任务。</p><p>Stack Engine在Instruction Decoder之后，监控所有流出的uop，并且从中提取出栈操作指令，进而直接执行，从而减轻栈操作指令对后端资源的占用。</p><p>这也可能是为什么有些时候<code>inline</code>的函数性能还不如不<code>inline</code>的原因吧:D（不负责任猜测）</p><h2 id="Decoded-Stream-Buffer-DSB"><a href="#Decoded-Stream-Buffer-DSB" class="headerlink" title="Decoded Stream Buffer(DSB)"></a>Decoded Stream Buffer(DSB)</h2><p><img src="https://en.wikichip.org/w/images/thumb/5/58/skylake_ucache.svg/400px-skylake_ucache.svg.png" alt=""></p><h3 id="别名"><a href="#别名" class="headerlink" title="别名"></a>别名</h3><p>像DSB这种组件，首先要说明的就是它也叫uop cache或decoded icache。</p><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>无论是用Instruction Decoder还是用MSROM，终究还是要做一次“解码”的操作。但同所有Cache加速的原理一样，如果能把解码之后的结果(uop)存下来，下次再出现的时候直接使用，那么就可以显著提高解码速度，DSB就是这个目的。</p><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><p>DSB的组织形式是32个set，每个set有8条cache line，每条cache line最多保存6个uop。</p><p>每次cache hit可以传输最大6个uop/cycle，这6个uop最大可以对应到64 byte的前端fetch window size，并且完全不需要任何Instruction decoder参与，也没有繁琐的解码过程。在实际应用中，DSB的cache hit rate在80%或以上。</p><h3 id="与icache的关系"><a href="#与icache的关系" class="headerlink" title="与icache的关系"></a>与icache的关系</h3><p>CPU的icache一般存储的是最原始的从内存里读进来的程序的汇编指令(marco instruction)。而DSB或者uop cache虽然也是存instruction的cache，但如前所述，它存的是已经解码好的uop，所以这玩意有时候又被称为“decoded icache”。当然了，这些uop都是CPU的icache中的指令解码之后得到的。</p><h3 id="与MSROM的关系"><a href="#与MSROM的关系" class="headerlink" title="与MSROM的关系"></a>与MSROM的关系</h3><p>输出大于4个uop的指令依然只能由MSROM解码。DSB保存的也是那些小于等于4个uop指令的uop。</p><h2 id="MITE-Path和DSB-Path"><a href="#MITE-Path和DSB-Path" class="headerlink" title="MITE Path和DSB Path"></a>MITE Path和DSB Path</h2><p>这两个概念主要用于区分最终需要执行的uop是通过什么方式来的。在上一节<code>Decoded Stream Buffer</code>之前的所有内容，都算是MITE Path。MITE是(Micro-instruction Translation Engine)的缩写，同时它在有些文档里也被称作legacy decode pipeline或legacy path。这条线路上过来的uop都是从marco instruction一步一步解码来的。</p><p>DSB path就是直接从DSB那条道上过来的uop。当CPU需要在MITE Path、DSB Path以及MSROM之间切换(switch)以便取得所需的uop时，需要花费一定的CPU cycle完成这一工作。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>有时做梦</title>
      <link href="/2019/01/19/thoughts4-dream/"/>
      <url>/2019/01/19/thoughts4-dream/</url>
      
        <content type="html"><![CDATA[<p>活得年头多起来之后，很难再明确地忆起某件事发生在哪一年。时间变得不再激烈，但往事却在交织纠缠，许多不可能的事还以为理所当然，而那些早已发生的事实却总需要确认再三。</p><a id="more"></a><p>这些事往往都发生在梦里。纵使过了做梦的年纪，也依然会有美梦，有噩梦，有能轻易按照弗洛伊德按图索骥的梦，还有一些不知所云得让人拍案叫绝的梦。但与年少时的最大区别，是有越来越多明知是梦的梦。在这些梦里，有不曾实现的愿望，有毋须弥补的过错，有仇恨背后的和解，有始终羞于开口的依赖，还有离开了却又回来的人，他们在梦里，有一场亲切的重逢。</p><p>人们总是倾向于相信自己愿意相信的事，而不是真真正正的现实。所以这种梦做多了并不好，容易把梦境与现实混淆。同时，越多这样的梦，下次就会越早意识到自己是在做梦。</p><p>可能每个人始终在梦中反复出现的都是那几件同样的事。</p><p>当意识到自己是在做梦之后，以前会一下就惊醒，现在反而会摆摆手继续做下去，甚至闭着眼都能看到自己蜷缩在枕头里自嘲的笑容。既然又梦到这里，就这样吧。</p><p>更多时候，就只是“昼有所思，夜有所梦”，或者说，是那些起床之后蹲在马桶上能想起来搜索一下的梦。所有这些梦，在“周公解梦”里都能找出来好几个解释，有些能相互印证，有些凶吉完全相反。但不管怎样，看来大家除了明知是梦的梦之外，梦到过的东西都一样。在给解梦类网站带来几个点击之后，这些梦都在早高峰的时候统统被忘掉。</p><p>做梦同Sex一样，也是一项夜晚（或早晨:D）的福利。我想我应该不会听从那些“每天只睡4小时”的成功学鸡汤而把这样的大礼买椟还珠。每个白天，从马桶上站起来之后就是战斗状态。要并线、要抢道、要甩锅、要争功、要倾轧、要离间、要摆脱已经发生的事，却又总要等待还没发生的事…最后的结果就是，梦可以明知是梦，而生活却不知是否一定要是这样的生活。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>在OpenWRT中添加perf工具</title>
      <link href="/2019/01/15/openwrt-perf/"/>
      <url>/2019/01/15/openwrt-perf/</url>
      
        <content type="html"><![CDATA[<h2 id="OpenWRT性能调优的必要"><a href="#OpenWRT性能调优的必要" class="headerlink" title="OpenWRT性能调优的必要"></a>OpenWRT性能调优的必要</h2><p>如果仅仅是家庭网关，确实没太大必要，毕竟网络的瓶颈主要在运营商的出口那。OpenWRT之所以开始关注极致的性能，是由于OpenWRT的应用场景出现了变化。从SD-WAN和边缘计算概念，到混合云与智能网关，都催生出了在边缘接入侧uCPE或其他类似的小盒子中部署基于OpenWRT系统的必要。不同于满足家庭接入的需求，这些小盒子往往对应一间Office或公司分支的网络需求。增长的网络带宽和对安全性、QoS等能力的要求都对OpenWRT的性能提出了更高的要求。</p><a id="more"></a><h2 id="没有perf"><a href="#没有perf" class="headerlink" title="没有perf"></a>没有<code>perf</code></h2><p>按照官网的教程，在<code>make menuconfig</code>之后就可以选择要一起编译到系统里的工具了。首先查找一下perf在哪：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/perf</span><br></pre></td></tr></table></figure><p>显示在Development这个分类下面：</p><p><img src="https://s2.ax1x.com/2019/01/15/FzIp5V.png" alt=""></p><p>OK，在Development这个分类下面自然是找不到的，不然也没必要写这篇博客了。</p><h2 id="搞一搞"><a href="#搞一搞" class="headerlink" title="搞一搞"></a>搞一搞</h2><p>那么怎么把它搞出来呢？</p><p>首先进入<code>Global build settings</code>选项卡，然后找到<code>Kernel build options</code>，然后选上<code>Compile the kernel with performance events and counters</code>和<code>Compile the kernel with profiling enabled</code>，如下图：</p><p><img src="https://s2.ax1x.com/2019/01/15/FzIYVI.png" alt=""></p><p>再回到Development这里就可以看到perf了：</p><p><img src="https://s2.ax1x.com/2019/01/15/FzIP8U.png" alt=""></p><p>天下的知识分两类，一类是从这里学会了，在别处也能用的；一类是在一个地方学会了就只能在一个地方用的。本文中介绍的内容其实属于后者。但诡吊的是，掌握第二类知识往往更加费时费力。所以记录这一类的内容，主要出于节省他人时间的目的。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> openwrt </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>王朝兴亡周期律的本因</title>
      <link href="/2019/01/13/thoughts3-zhouqilv/"/>
      <url>/2019/01/13/thoughts3-zhouqilv/</url>
      
        <content type="html"><![CDATA[<h2 id="王朝兴亡周期律"><a href="#王朝兴亡周期律" class="headerlink" title="王朝兴亡周期律"></a>王朝兴亡周期律</h2><blockquote><p>六位参政员将要回重庆时，毛泽东问黄炎培有什么感想，黄炎培坦率地说：“我生六十多年，耳闻的不说，所亲眼看到的，真所谓‘其兴也勃焉’，‘其亡也忽焉’，一人，一家，一团体，一地方，乃至一国，不少单位都没有跳出这周期率的支配力。大凡初时聚精会神，没有一事不用心，没有一人不卖力，也许那时艰难困苦，只有从万死中觅取一生。既而环境渐渐好转了，精神也就渐渐放下了。有的因为历史长久，自然地惰性发作，由少数演变为多数，到风气养成，虽有大力，无法扭转，并且无法补救。也有为了区域一步步扩大，它的扩大，有的出于自然发展，有的为功业欲所驱使，强求发展，到干部人才渐见竭蹶、艰于应付的时候，环境倒越加复杂起来了，控制力不免趋于薄弱了。一部历史‘政怠宦成’的也有，‘人亡政息’的也有，‘求荣取辱’的也有。总之没有能跳出这周期率。中共诸君从过去到现在，我略略了解的了。就是希望找出一条新路，来跳出这周期率的支配。”</p></blockquote><a id="more"></a><p>不仅仅中国有此周期规律，任何国家，任何民族，任何团体，乃至任何个人，都有此周期规律。</p><p>这其实不是什么新鲜概念，我们的语言体系里早就有各种玄之又玄的词汇可以给出模棱两可的总结：物极必反、物壮则老，以及所有和消、息、盈、冲，相关的词汇。但既然人们早已总结出这样的规律，为何在事到临头之时，却都无法避免被裹挟而去的命运？这一“兴亡律”当真是万世不易的铁律吗？</p><h2 id="人与物质世界的根本矛盾"><a href="#人与物质世界的根本矛盾" class="headerlink" title="人与物质世界的根本矛盾"></a>人与物质世界的根本矛盾</h2><p>人是自然的造物，却也在永不停歇地与自然斗争。这种斗争从最初的生存之争，到现如今的索取与利用，再到以后可能的自然律改造，看似人在逐步认知物质世界，并取得了和谐共处的权利甚至一定程度的相对优势，但人与物质世界的根本矛盾仍然存在，并依旧支配着人类的所有活动。</p><h3 id="人对物质的认知"><a href="#人对物质的认知" class="headerlink" title="人对物质的认知"></a>人对物质的认知</h3><p>人类所认知的物质世界，从某种意义上讲，全部都是人类自己的臆造。</p><p>但这并非等同于物质不存在，或者是“缸中之脑”这种科幻玩笑。物质真实存在，人类也可以因为与物质的相互作用产生出对物质的认知，但这种认知仅仅是对真实物质世界的狭隘偏见。</p><p>这种偏见的产生由两方面原因造成：</p><ol><li>人类感官的局限</li><li>人类描述语言的局限</li></ol><p>感官的局限很好理解，如同可见光光谱仅仅占据电磁波谱很细小的一部分一样，即便我们可以自己发明现代仪器帮助我们一定程度地突破人类肉体的感官局限，但只要最终的信号仍需要由人类的肉体来接收，那么感官的局限就无法完全突破。</p><p>同样，人类的语言也无法描述真实的物质世界，因为无论是哪种自然语言，符号（形式）语言或者由人类技术衍生出的智能人造物的语言，都不可能描述出从来没见过的东西。</p><p>已有的认知在我们自己的体系里是自洽的，虽然这体系仅仅是真实的一个狭小的侧面，但也足够用了——这反倒成为我们应该感谢自身局限的理由。人类虽然一直在努力排除这种局限，我也相信我们在这条路上会继续打开局面，但同样的，随着认知越来越多，会越来越发觉我们的认知是如此之少。</p><h3 id="人类活动的根本目的"><a href="#人类活动的根本目的" class="headerlink" title="人类活动的根本目的"></a>人类活动的根本目的</h3><p>那么“认知”这件事本身是为了什么？我们大可以如同岩石那样安然接受周遭的一切，毕竟了解万万万万分之一和全然不了解，似乎也没什么差别。但人不会接受这样的安排。也许是出自动物的本能，也许是造物者的旨意，我们在这里不探究原因，只讨论这给我们带来什么。</p><blockquote><p>我们所做的一切活动，都是为了能让真实世界与我们认知的世界一致。</p></blockquote><p>这是我们内心中最原始也是最底层的驱动力。无论是群聚生产、巫术卜筮、屯田开荒、君权天授、两相攻伐、望气观星、揭竿而起、六艺俱佳、推导公式、狂敲代码，都是为了这一件事——即便我们并没有生活在“三体运动”的混乱之中，我们也一定要用那些最聪明的头脑来研究混乱的轨迹。</p><p>因为这种“一致”，为我们带来最基本的两点对物质世界的诉求：</p><ul><li>可控</li><li>可预期</li></ul><p>我可以接受我的农田远离河流，但我不能接受我开渠引水之后粮产依旧；我可以接受今年因为干旱导致赤地千里，但我不能接受风调雨顺时仍然欠收。这对任何拥有智能的生物都至关重要。</p><p>为了让感知的物质世界与认知的物质世界保持一致，人类必须一直处于与物质世界交互的状态。这种交互中的活动，要么是对物质世界进行改造，使其至少感知起来，与认知的情况一致；要么是调整自身对物质世界的认知（一般是进一步加深认知），继而达到更高层次的一致。</p><p>这便是所有人类活动的根本原因和内在驱动力，或者也可以说，即便你现在悲观厌世只想了此残生，你也同其他所有人一样，一直走在理想的路上。</p><h3 id="人类不能停止的心理摆动"><a href="#人类不能停止的心理摆动" class="headerlink" title="人类不能停止的心理摆动"></a>人类不能停止的心理摆动</h3><p>是否达成一致之后，人类就不再继续活动了呢？</p><p>这种静态的一致永远不可能达到。我想也不必用科学上的不断进步来举例说明。造成没有静态一致的原因，正是因为追求静态一致的原因：我们自身的认知有限。</p><p>因为认知有限，所以我们要追求一致，在追求一致的过程中，又总会有超出现有认知的发现，因此又要继续追求一致。如此，既可以类比于西西弗斯的意象，又可以从逻辑上解释叔本华对人生犹如钟摆的描述。</p><h2 id="王朝兴亡周期律的本因"><a href="#王朝兴亡周期律的本因" class="headerlink" title="王朝兴亡周期律的本因"></a>王朝兴亡周期律的本因</h2><p>王朝的兴亡，只不过是人类“追求一致”的一个产物。只不过它看起来宏大又神秘，所以被拿出来单说。</p><p>如开篇中黄炎培的引言中所述：大凡“聚精会神，用心卖力”，多是因为心中有一理想世界，却与现今的世界大不相同。因此人人可知，欲求得“一致”，非尽心竭力不可。而一旦达成目标，又会激发人心思寻新的“一致”——对这“理想世界”更多的可控与可预期的“理想”，这便是黄炎培所言之“惰性发作”，其实和科学探索并无本质区别。至于后续“环境愈加复杂”，乃是因为人人各有探索，因此也各有理想，人人都寻求各自的一致，而再无统一的一致。</p><p>如此社会又回到了需要建立一个“理想世界”的状态。所谓“理想世界”，就是指与大多数人的认知相一致的世界。而此时人的认知，因为前面所述不断发展的原因，已与建立上一个“理想世界”时大不相同，上一个“理想世界”自然也就“人亡政息”了。</p><p>从某一个王朝角度出发，这似乎是一个由盛而衰的过程，但从宏观上讲，这其实是一个再正常不过的自然发展的过程。所谓“盛极则衰”，背后的原因也是因为不同的人（多是不同阶级）所要求的“一致”出现了分裂和不可弥合的矛盾。</p><p>因此，跳出“周期律”的方式也非常简单，就是平衡这些人对“一致”的诉求。可以简单称之为“平衡各方利益，表达不同阶层人民诉求”，但这需要王朝实现自我革新，这并不是一个仅仅需要决心就能完成的事情。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚11：Skylake微架构(Microarchitecture)剖析(3)</title>
      <link href="/2019/01/12/quickwords11-skylake-pipeline-3/"/>
      <url>/2019/01/12/quickwords11-skylake-pipeline-3/</url>
      
        <content type="html"><![CDATA[<h2 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h2><p><img src="https://en.wikichip.org/w/images/thumb/5/5e/skylake_decode.svg/425px-skylake_decode.svg.png" alt=""></p><p>在拿到了经过“预解码”的<code>macro-ops</code>之后，开始正式进入解码过程。<code>marco-ops</code>进入Instruction Decode组件解码，最终的输出为定长的<code>micro-ops</code>。</p><p>Insturction Decode组件也有入口带宽限制，每个Cycle最多取3个unfused指令+2个fused指令，或者5个unfused指令（这里指macro ops）。所以说fused多了也不好，一个cycle最多取两个。同时如果开了Hyper Thread，则两个Thread按Cycle交替使用Instruction Decode。</p><a id="more"></a><p>在Instruction Decode组件里面的就是各个具体的Decoder。Decoder类型可以分类两类，一类是Simple Decoder，一类是Complex Decoder，感觉这句是在说废话。</p><p>顾名思义，Simple Decoder处理的是解码之后的输出为1个<code>fused-uop</code>的指令；Complex Decoder处理的是解码之后的输出为1个至4个<code>fused-uop</code>的指令。</p><h2 id="Fused-uop"><a href="#Fused-uop" class="headerlink" title="Fused-uop"></a>Fused-uop</h2><p>注意这里说的是fused-<code>uop</code>，不是fused-<code>marco</code>。在这里所有输出的<code>uop</code>都是做过<code>fused</code>处理的，目的是减少后续资源的占用。</p><blockquote><p>但这里有一个比较容易混淆的概念，就是<code>fused-uop</code>并非专指那些两个uop合并之后生成的“合并uop”，而是指所有经过了uop fusion处理的uop：有些指令可能两个uop变一个，但也有一些是一个还是一个，即便如此，输出的那一个也叫<code>fused-uop</code>。</p></blockquote><p>为了进一步澄清这个概念，我们稍微需要涉及一点后端的概念。在前端这里，生成<code>fused-uop</code>的部分还属于CPU流水线中的<code>uops fused domain</code>，而在后端需要将指令发射到执行单元去的时候，是不能执行<code>fused uop</code>的，所以<code>fused uop</code>还需要再分解为<code>unfused uop</code>才可以执行，这一部分就属于CPU流水线中的<code>uops unfused domain</code>。</p><p>有了这些概念之后，我们可以看一下<a href="https://www.agner.org/optimize/instruction_tables.pdf" target="_blank" rel="noopener">Instruction Tables.pdf</a>这份文档。</p><p>在P244中有对skylake指令的说明，上面有对一些概念的解释，下面是一张表格：<br><img src="https://s2.ax1x.com/2019/01/12/FjnbCV.png" alt=""></p><p>在这张表格里是最常见的<code>mov</code>命令的说明。但因为操作<br>数(operands)的不同在真正执行的时候也会有细节上的差别。第一行中的<code>mov</code>的两个操作数一个是register，另外一个是一个立即数。在<code>uops fused domain</code>和<code>uops unfused domain</code>两栏中的计数都是1。</p><p>这种指令也算在<code>uops fused domain</code>经过了fusion处理。只不过其实前后没什么区别。</p><p>但如果我们看一下所有在<code>uops unfused domain</code>里计数为2的<code>mov</code>指令，它们在<code>uops fused domain</code>中的计数都是1。这种<code>mov</code>指令就是真正做过2条uop合并的<code>mov</code>指令。</p><p>这份表格还有很多有趣的内容，推荐有时间的时候随手翻翻。</p><p>Skylake有4个Simple Decoder和1个Complex Decoder。但从表里我们可以看到<code>uops fused domain</code>计数为1，也就是可以被Simple Decoder处理的指令在所有指令中所占的比例似乎并没有达到4/5那么高。</p><p>这里需要说明的是，输出大于4个uop的指令，既不由Simple Decoder处理，也不由Complex Decoder处理，而是直接去查<code>Microcode Sequencer(MS)</code>，这是一块类似于缓存的ROM。</p><p>Complex Decoder的数量始终为1的原因是Complex Decoder解码出来的uop都很难在执行时进行并行化处理，同时Complex Decoder每多解码一个uop，就要有一个Simple Decoder处于不能工作的状态。</p><p>对CPU来说，它最希望的就是它要做的工作，它需要的数据，它要执行的指令，都已经在一块缓存里准备就绪了。这是CPU上班摸鱼的主要方法，但摸出了风格，摸出了水平。下一部分介绍一下在指令解码方面的缓存内容。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚10：Skylake微架构(Microarchitecture)剖析(2)</title>
      <link href="/2019/01/10/quickwords10-skylake-pipeline-2/"/>
      <url>/2019/01/10/quickwords10-skylake-pipeline-2/</url>
      
        <content type="html"><![CDATA[<h2 id="前端"><a href="#前端" class="headerlink" title="前端"></a>前端</h2><p>处理器在前端这一部分的时候还是顺序(in-order)处理的，主要是也确实没什么乱序的空间。虽然说是顺序，但前端因为贴近业务，所以受人写的代码的影响也比较大。如果仅仅只是“取指令-&gt;解码”，恐怕需要写程序的人是个非常聪明的程序员。前端很多组件的工作其实都是在填程序员的坑，这也是我比较心疼前端的地方。</p><a id="more"></a><h2 id="Fetch"><a href="#Fetch" class="headerlink" title="Fetch"></a>Fetch</h2><p><img src="https://en.wikichip.org/w/images/thumb/7/79/skylake_fetch.svg/300px-skylake_fetch.svg.png" alt=""></p><p>前端的任务，首先是从内存中取得指令。同读取数据类似，CPU通过查询页表获得指令所在的内存地址，同时把指令塞到CPU的L1指令缓存里。</p><p>具体要把哪个地址上的指令数据送到L1I$里，这是分支预测器(Branch predictor)的工作。作为CPU的核心技术，Intel并没有透露太多信息，我们这里也只好一笔带过。不过它的细节也许很复杂，但它的脾气很好掌握：和我们很多人不喜欢自己的工作一样，它的工作就是处理分支，但它最不喜欢分支。</p><p>在Skylake架构里，L1I$大小为32KB，组织形式为8-way set associative(关于CPU缓存组织形式的讲解可以参照<a href="https://decodezp.github.io/2018/11/25/quickwords2-cacheassociativity/">这篇</a>)，每个Cycle可以取16Byte长度(fetch window)的指令。如果你开了Hyper-thread，那么同一个物理核上的两个逻辑核均分这个fetch window，每个Cycle各占用一次。</p><blockquote><p>所以没事别开Hyper-thread，不过我这么说没有任何技术依据，单纯是帮Intel多卖几个核。</p></blockquote><p>在L1I$里的指令还都是变长的x86 <code>macro-ops</code>，也就是我们看到的那些编译之后的汇编指令。如果熟悉这些指令的话，就会知道这些指令的长度（就是那些二进制数字）都不一样，同时一条指令有时可以由好几个操作组成。</p><p>这种指令对CPU的执行单元来说是很不友好的，同时如果想要通过乱序执行提高指令的并行度，减小指令的粒度也是必须的步骤。因此需要把这些<code>marco-ops</code>“解码”为“micro-ops”。</p><p>当然具体的解码工作还在后面。从L1I$中取得指令数据后，首先要进入“预解码”阶段，在这里需要识别出在一个fetch window中取得的这16个Byte的数据里面有多少个指令。除此之外，还需要对一些特殊指令，比如分支转跳打上一些标记。</p><p>但因为指令变长的原因，16个Byte往往并不对应固定的指令数，还有可能最后一个指令有一半在这16Byte里，另一边还在后面。另外就是pre-decode在一个Cycle最多识别出6个指令，或者这16Byte的数据都解析完。如果你这16个Byte里包含有7个指令，那么第一个Cycle识别出前6个之后，还需要第二个Cycle识别最后一个，然后才能再读取后面16Byte。</p><p>那么pre-decode的效率就变成了3.5 instruction / cycle，比最理想的情况6 instruction / cycle降低了41%，现实就是这么残酷。</p><p>经过pre-decode之后，才真正从16Byte的二进制数据中识别出了指令，这些指令下一步要被塞到一个队列里(Instruction Queue)看看有没有什么能被优化的地方。一个最常见的优化方式就是<code>macro-op fusion</code>，就是把两个相邻的，且能被一个指令表示的指令，用那一个指令替换掉。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmp eax, [mem]</span><br><span class="line">jne loop</span><br></pre></td></tr></table></figure><p>直接换成<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmpjne eax, [mem], loop</span><br></pre></td></tr></table></figure></p><p>当然既然决定这么替换，新指令对流水线的开销肯定小于被替换的两个指令之和。如此可以减轻一部分后端执行单元的工作负荷和资源开销。</p><p>OK, 在取得了指令数据，识别出了数据中的指令，并对指令做了一些优化合并之后，就该开始正儿八经地解码了，这部分在后面的文章中介绍。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚9：Skylake微架构(Microarchitecture)剖析(1)</title>
      <link href="/2019/01/07/quickwords9-skylake-pipeline-1/"/>
      <url>/2019/01/07/quickwords9-skylake-pipeline-1/</url>
      
        <content type="html"><![CDATA[<h2 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h2><p>了解CPU的微架构是基于其开发“硬核”软件的必需步骤。由于一些历史遗留问题，现存的技术资料往往存在一些概念混淆、重复命名甚至自相矛盾之处。本文一来梳理Skylake微架构(主要是流水线)的组成和特性，二来试图厘清一些含混的概念用以帮助后来者。</p><p>另外在介绍完微架构之后，会继续结合<code>Perf</code>中的<code>Performance Event</code>来对照说明互为印证。</p><a id="more"></a><blockquote><p>需要强调的是，本文的重点是Skylake的流水线(pipeline)架构，core间的连接和架构方式不作重点说明。</p></blockquote><h2 id="Skylake简介"><a href="#Skylake简介" class="headerlink" title="Skylake简介"></a>Skylake简介</h2><p>Skylake是由Intel以色列研发中心于2015年发布的14nm CPU架构。作为Broadwell的继任者，Skylake在原有架构的基础上，对一些关键特性和组件做出了相当幅度的优化：</p><p><img src="https://en.wikichip.org/w/images/thumb/0/0d/skylake_buff_window.png/350px-skylake_buff_window.png" alt=""></p><p>上图简单列举了一些量化指标，现在不求甚解就好。</p><p>在指令集方面，引入了<code>AVX-512</code>、<code>CLFLUSHOPT</code>、<code>CLWB</code>等新的指令集，不过本文不打算介绍这些东西，写到这里只是觉得如果只用上一段话结束这一小节有些太突兀了。</p><h2 id="流水线总览"><a href="#流水线总览" class="headerlink" title="流水线总览"></a>流水线总览</h2><p><img src="https://en.wikichip.org/w/images/thumb/8/80/intel_common_arch_post_ucache.svg/428px-intel_common_arch_post_ucache.svg.png" alt=""></p><p>引用上面这张图是为了举一个反例，说明一下本文要解决的问题。这张图可以被当做是一张流水线的架构抽象，我可以指着每一个组件讲讲它们都是干嘛的，但这里的问题就是某一个相同的组件在不同的文档、资料、甚至语境下可能有两个甚至更多个名字。</p><p>比如蓝色方块最下面的<code>Allocation Queue</code>，它就还有一个名字叫做<code>Instruction Decode Queue</code>，同时它还有可能被叫做<code>IDQ</code>或<code>AQ</code>。而关于<code>Decoded Instruction Queue</code>、<code>Micro Instruction Sequencer</code>、<code>Re-order buffer</code>、<code>Scheduler</code>、<code>Reservation Station</code>等概念的辨析也是…需要下一番功夫。</p><p>本文将以全网最清晰的方式讲清楚这些概念。</p><p>从high-level的层面来讲，Skylake的流水线架构与Broadwell和Haswell没有太大出入。还是可以分为两个阶段：</p><h3 id="前端-Front-End"><a href="#前端-Front-End" class="headerlink" title="前端(Front-End)"></a>前端(Front-End)</h3><p>上图中蓝色部分就代表流水线的前端。它的主要作用就是获取指令、解码(Decode)指令。</p><p>为了最大限度的发挥CPU的能力，前端就需要尽可能高效率地把程序指令输送给后端。这里就面临两个挑战：</p><ol><li>如何更快更准确地取得要执行的指令</li><li>如何将取得的指令更快地解码为微指令(micro-ops/uops)</li></ol><p>有了更多的微指令输送给后端（执行单元），后端的工作量才能饱和。而前端的所有组件和机制，都是围绕这两个挑战进行的。</p><h3 id="后端-Back-End"><a href="#后端-Back-End" class="headerlink" title="后端(Back-End)"></a>后端(Back-End)</h3><p>上图中红色的部分就代表流水线的后端。一般来讲绿色的部分是存储子系统，虽然与后端交互，但严格讲不算在后端里面。</p><p>后端的主要任务就是执行前端送过来的指令。和前端类似，后端除了“来料加工”之外，也有它自己需要面对的挑战：</p><ol><li>如何提高指令的并行程度</li><li>如何充分利用已有的CPU能力</li></ol><p>如果将CPU比作一家餐厅，跑在上面的应用就是来餐厅就餐的食客。前端类似餐厅的服务生，需要接受客人的下单，同时将订单送到后厨。而后厨就类似后端，负责做出客人需要的菜品。</p><p>但如何能让上菜速度更快？前端是否可以在客人排位时就让其提前下单？后厨是否能够提前准备好本店热门的特色菜，或者一并煮好一大锅面条，根据需要浇上不同的浇头？</p><p>CPU说是高科技，其实干得也就是这些事情。</p><p>在下一篇文章中将详细介绍一下前端。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>汉光文帝教你如何提出领导无法拒绝的方案</title>
      <link href="/2019/01/05/history2-liuyuan/"/>
      <url>/2019/01/05/history2-liuyuan/</url>
      
        <content type="html"><![CDATA[<h2 id="在成为领导之前"><a href="#在成为领导之前" class="headerlink" title="在成为领导之前"></a>在成为领导之前</h2><p>只有开国皇帝的孙子生下来就是皇帝，开国皇帝往往都给别人打过工。</p><p>别人给老板打工，不高兴了可以换个老板，而开国皇帝给老板打工，不想干了还必须得干掉老板。<br><a id="more"></a></p><p>这次要说的就是汉赵的开国之君汉光文帝刘渊。当然在成为开国之君之前，刘渊也曾有过一位叫司马颖的老板。</p><p>司马颖是司马家“八王之乱”中的一乱。在还没有乱起来的时候，匈奴贵族出身的刘渊就被送到晋朝作质子(人质)。</p><p>说到做人质，这是一个投资收益比两极分化严重的工作。史书上出现过的人质，要么潜龙入海回归故国做了一番大事，要么就是成为第一个祭旗的祭品。</p><p>同样的问题也摆在了刘渊面前。在司马颖还没登上历史舞台的时候，司马家内部就有声音要除掉刘渊，以防其“非我族类其心必异”。虽然由于贵人的保荐逃过一劫，但刘渊一定不喜欢自己的命运捏在别人手上的滋味。</p><p>等到司马家的兄弟们相斫之时，刘渊和他的匈奴族人终于等来了机会——趁中原板荡，他要回到匈奴。</p><p>但司马颖不会不明白这么基本的道理。他一方面要利用刘渊领兵打仗的能力襄助自己，一方面也更不可能纵虎归山。</p><p>刘渊需要提出一个能让司马颖心甘情愿让他回到匈奴族人那里去的方案。</p><h2 id="还是要考虑历史的进程"><a href="#还是要考虑历史的进程" class="headerlink" title="还是要考虑历史的进程"></a>还是要考虑历史的进程</h2><p>如果司马颖一手平定了内乱成为了晋朝的中兴之主，那肯定也就没刘渊什么事了。</p><p>但司马颖此时正在遭受外部敌人的猛烈攻击。刘渊自然会利用这一时机，提出回部请匈奴部众救援的提议。</p><p>但司马颖必然还是会担心，所以他首先提出一个方案：</p><blockquote><p>颖曰：“五部之众，果可发否？就能发之，鲜卑、乌桓，未易当也。吾欲奉乘舆还洛阳以避其锋，徐传檄天下，以逆顺制之，君意何如？”——《资治通鉴》</p></blockquote><p>基本思想就是，你的方案我没太大把握(对你没什么信心)，即便可行，也不见得打得过敌人。我先带着皇帝回洛阳躲避一下锋芒，然后再挟天子慢慢想办法。</p><p>这个时候，切忌就领导的方案展开细节上的辩论。比如说一些什么“我一定能动员我的族人过来帮你”、“鲜卑乌桓，一帮乌合之众而已”，“皇帝早就不能号令天下了”等等。</p><p>那应该说什么？看一下刘渊怎么说的：</p><blockquote><p>渊曰：“殿下武皇帝之子，有大勋于王室，威恩远著，四海之内，孰不愿为殿下尽死力者！何难发之！王浚竖子，东嬴疏属，岂能与殿下争衡邪！殿下一发鄴宫，示弱于人，洛阳不可得而至；虽至洛阳，威权不复在殿下也。愿殿下抚勉士众，靖以镇之，渊请为殿下以二部摧东嬴，三部枭王浚，二竖之首，可指日而悬也。”——《资治通鉴》</p></blockquote><p>这段话可以分为三个部分：</p><h3 id="为什么这么做可行"><a href="#为什么这么做可行" class="headerlink" title="为什么这么做可行"></a>为什么这么做可行</h3><p>刘渊在陈述这一句的时候，并没有以“我”为主语。他没有说“我”在我的族人里多么有威信，“我”有哪些神奇的手段可以确保可行等等。而是将“你”，也就是领导作为了最主要的原因。</p><p>此时即便你说的是最没有逻辑的理由，在领导那里也是有逻辑的。因为领导首先是个人，而不是一架逻辑的机器。</p><p>当你将领导认为最能体现出他的特点和价值的东西拿出来说服他，如果你还说服不了他，那只能证明他已经神经错乱了，比八王之乱还要乱。</p><p>证明可行要用“正”，证明为什么要这么做要用“奇”，也就是从反面来论述。</p><h3 id="为什么要这么做"><a href="#为什么要这么做" class="headerlink" title="为什么要这么做"></a>为什么要这么做</h3><p>从反面来论述，就是假设你不这么做，会有什么危害。</p><p>会有什么危害呢？必须是失去其最看重的东西。</p><blockquote><p>虽至洛阳，威权不复在殿下也。</p></blockquote><p>也许能逃得性命，也许手里还能有“皇帝”这样一枚棋子，但在现在的世道，谁拳头大谁就是权威。你自己就是这么上来的，当然明白权威的价值。如果别人一吓唬就逃跑了，那别人就是新的权威。</p><p>你没有了权威，其他的一切还有什么意义？你要不这么做，还闹啥闹？</p><h3 id="具体怎么做"><a href="#具体怎么做" class="headerlink" title="具体怎么做"></a>具体怎么做</h3><p>关于这一部分，刘渊只用了最短的篇幅，却把所有需要说明的要素都覆盖了：</p><blockquote><p>渊请为殿下以二部摧东嬴，三部枭王浚，二竖之首，可指日而悬也。</p></blockquote><p>作为一个办公室里的白领，你一定听别人说过“要用SMART法则给领导提方案”。</p><p>那么我们就套用一下SMART法则的框架分析一下刘渊的这句话：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SMART法则</span><br><span class="line"></span><br><span class="line">*Specific:“二竖之首”</span><br><span class="line">*Measurable:“悬”</span><br><span class="line">*Achievable:“以二部摧东嬴，三部枭王浚”</span><br><span class="line">*Relevant: “渊请为殿下”</span><br><span class="line">*Time-bound:“指日”</span><br></pre></td></tr></table></figure><p>这TM简直是古典与现代的完美结合。</p><p>司马颖在听后终于放下了他对刘渊的芥蒂。不是因为他真的不再怀疑刘渊，而是刘渊的提议毫无破绽。</p><p>而刘渊也终于凭借这个提议回到了他的北方，在接下来的历史里开创了属于自己的时代。</p>]]></content>
      
      
      <categories>
          
          <category> history </category>
          
      </categories>
      
      
        <tags>
            
            <tag> history </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去4：82599在DPDK下使用fdir</title>
      <link href="/2019/01/04/test4-82599-fdir/"/>
      <url>/2019/01/04/test4-82599-fdir/</url>
      
        <content type="html"><![CDATA[<h2 id="文档过期"><a href="#文档过期" class="headerlink" title="文档过期"></a>文档过期</h2><p>近期有客户反馈82599的fdir(flow director)功能在DPDK环境下不生效，本想丢一个DPDK官网上的82599 fdir测试资料过去，但幸好我仔细看了一下测试流程，发现这个<a href="https://doc.dpdk.org/dts/test_plans/fdir_test_plan.html" target="_blank" rel="noopener">官方文档</a>里使用的<code>testpmd</code>命令已经过期了(时间戳：Jan 3rd, 2019)….所以…我自己写一个吧。</p><a id="more"></a><h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DPDK Version: 17.11</span><br><span class="line">NIC: 82599</span><br><span class="line">DUT: test-pmd</span><br><span class="line">Traffic Generator: scapy</span><br></pre></td></tr></table></figure><p>其中DUT与Traffic Generator 10G接口直连。</p><h2 id="Test-Cases"><a href="#Test-Cases" class="headerlink" title="Test Cases"></a>Test Cases</h2><h3 id="首先测试对ipv4-tcp报文的支持"><a href="#首先测试对ipv4-tcp报文的支持" class="headerlink" title="首先测试对ipv4-tcp报文的支持"></a>首先测试对<code>ipv4-tcp</code>报文的支持</h3><h4 id="perfect-mode"><a href="#perfect-mode" class="headerlink" title="perfect mode"></a>perfect mode</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=perfect --nb-ports=1</span><br><span class="line">set verbose 1</span><br><span class="line">set fwd rxonly</span><br><span class="line"></span><br><span class="line">flow_director_filter 0 mode IP add flow ipv4-tcp src 172.16.182.82 20 dst 2.2.2.3 80 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1</span><br><span class="line"></span><br><span class="line">start</span><br></pre></td></tr></table></figure><p>在Traffic Generator侧构造一个匹配的报文并发送：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p1=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.182.82", dst="2.2.2.3")/TCP(sport=20, dport=80)</span><br><span class="line">sendp(p1, iface="ens785f0")</span><br></pre></td></tr></table></figure><p>应该可以看到<code>testpmd</code>将该报文收到了Queue 1。</p><h4 id="signature-mode"><a href="#signature-mode" class="headerlink" title="signature mode"></a>signature mode</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=signature --nb-ports=1</span><br></pre></td></tr></table></figure><p>除在上面的命令行中<code>--pkt-filter-mode=signature</code>之外与前一个测试例完全一致。</p><blockquote><p>对<code>ipv4-udp</code>的测试也基本类似，不再赘述。</p></blockquote><h3 id="测试对ipv6-tcp报文的支持"><a href="#测试对ipv6-tcp报文的支持" class="headerlink" title="测试对ipv6-tcp报文的支持"></a>测试对<code>ipv6-tcp</code>报文的支持</h3><h4 id="Signature-mode"><a href="#Signature-mode" class="headerlink" title="Signature mode"></a>Signature mode</h4><blockquote><p>82599 DPDK ixgbe驱动不支持IPv6报文flow director的<code>perfect mode</code>，所以只能用<code>signature mode</code>。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=signature --nb-ports=1</span><br><span class="line">set verbose 1</span><br><span class="line">set fwd rxonly</span><br><span class="line"></span><br><span class="line">flow_director_filter 0 mode IP add flow ipv6-tcp src fcbd:dc01:1:222:0:0:0:3 8000 dst fcbd:dc01:1:222:0:0:0:12 1029 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1</span><br><span class="line"></span><br><span class="line">start</span><br></pre></td></tr></table></figure><p>在Traffic Generator侧构造一个匹配的报文并发送：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p1=Ether(src=get_if_hwaddr("ens785f0"))/IPv6(src="fcbd:dc01:1:222:0:0:0:3",dst="fcbd:dc01:1:222:0:0:0:12")/TCP(sport=8000,dport=1029)</span><br><span class="line">sendp(p1, iface="ens785f0")</span><br></pre></td></tr></table></figure><p>应该可以看到<code>testpmd</code>将该报文收到了Queue 1。</p><blockquote><p><code>ipv6-udp</code>报文的支持也基本类似。</p></blockquote><h3 id="添加Mask"><a href="#添加Mask" class="headerlink" title="添加Mask"></a>添加Mask</h3><p>问题主要在对Mask的支持上，首先用<code>ipv4-tcp</code>举个栗子：</p><h4 id="如果想mask掉-通配-全部的src-ip"><a href="#如果想mask掉-通配-全部的src-ip" class="headerlink" title="如果想mask掉(通配)全部的src ip"></a>如果想mask掉(通配)全部的<code>src ip</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./testpmd -c 1ffff -w 02:00.0 -w 02:00.1 -n 4 -- -i --nb-cores=8 --rxq=4 --txq=4 --disable-rss --pkt-filter-mode=signature --nb-ports=1</span><br><span class="line">set verbose 1</span><br><span class="line">set fwd rxonly</span><br><span class="line">port stop 0</span><br><span class="line">flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFF dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFF</span><br><span class="line">port start 0</span><br></pre></td></tr></table></figure><p>这个配mask的命令长得令人发指，同时必须要先stop port 0。通配的方式就是src_mask后写<code>0.0.0.0</code>。<br>这时如果你希望所有源端口号是20，目的IP是2.2.2.3，目的端口号是80的报文都进入Queue 1，那么flow director的命令必须写成：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">flow_director_filter 0 mode IP add flow ipv4-tcp src 0.0.0.0 20 dst 2.2.2.3 80 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1</span><br><span class="line">start</span><br></pre></td></tr></table></figure></p><p>一般人的理解，设置了通配mask之后，<code>src IP</code>写成什么都无所谓了，但这里必须要写成<code>0.0.0.0</code>，不然匹配不到。</p><p>Traffic Generator侧构造任意<code>src IP</code>的且满足其他匹配条件的报文，并发送：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">p1=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.182.82", dst="2.2.2.3")/TCP(sport=20, dport=80)</span><br><span class="line">p2=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.182.8", dst="2.2.2.3")/TCP(sport=20, dport=80)</span><br><span class="line">p3=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.18.82", dst="2.2.2.3")/TCP(sport=20, dport=80)</span><br><span class="line"></span><br><span class="line">sendp(p1, iface="ens785f0")</span><br><span class="line">sendp(p2, iface="ens785f0")</span><br><span class="line">sendp(p3, iface="ens785f0")</span><br></pre></td></tr></table></figure></p><p>可以在<code>testpmd</code>中看到三个报文均进入了Queue 1。</p><h4 id="如果想mask掉-通配-全部的src-ip与scr-port"><a href="#如果想mask掉-通配-全部的src-ip与scr-port" class="headerlink" title="如果想mask掉(通配)全部的src ip与scr port"></a>如果想mask掉(通配)全部的<code>src ip</code>与<code>scr port</code></h4><p>与上一个类似，设置mask和fdir规则的命令分别为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0x0 dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFF</span><br><span class="line"></span><br><span class="line">flow_director_filter 0 mode IP add flow ipv4-tcp src 0.0.0.0 0 dst 2.2.2.3 80 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1</span><br></pre></td></tr></table></figure><p>与之前一样，fdir规则中，<code>src</code>后面必须写<code>0.0.0.0 0</code>才能达到预期效果。</p><p>此时仅由目的IP和目的端口号决定报文的去向。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">p1=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.182.82", dst="2.2.2.3")/TCP(sport=19, dport=80)</span><br><span class="line">p2=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.182.8", dst="2.2.2.3")/TCP(sport=2, dport=80)</span><br><span class="line">p3=Ether(src=get_if_hwaddr("ens785f0"))/IP(src="172.16.18.82", dst="2.2.2.3")/TCP(sport=21, dport=80)</span><br><span class="line"></span><br><span class="line">sendp(p1, iface="ens785f0")</span><br><span class="line">sendp(p2, iface="ens785f0")</span><br><span class="line">sendp(p3, iface="ens785f0")</span><br></pre></td></tr></table></figure><p>可以在<code>testpmd</code>中看到三个报文均进入了Queue 1。</p><h4 id="IPv6的情况"><a href="#IPv6的情况" class="headerlink" title="IPv6的情况"></a>IPv6的情况</h4><p>如果想mask掉IPv6报文的<code>src ip</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">port stop 0</span><br><span class="line">flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 0:0:0:0:0:0:0:0 0x0 dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0xFFFF</span><br><span class="line">port start 0</span><br></pre></td></tr></table></figure><p>同理，fdir规则中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flow_director_filter 0 mode IP add flow ipv6-tcp src 0:0:0:0:0:0:0:0 0 dst fcbd:dc01:1:222:0:0:0:12 1029 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 1</span><br></pre></td></tr></table></figure><p><code>ipv6-tcp src</code>后必须写<code>0:0:0:0:0:0:0:0 0</code>以配合mask的设置。</p><blockquote><p>关键就是如果mask中某字段中某bit为0，那么fdir规则中该字段对应的bit位也必须为0，82599网卡才能按预期的方式工作。</p></blockquote><p>再举一个栗子，如果想将dst port的mask设置为0x00F0，对应的mask和fdir规则为：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flow_director_mask 0 mode IP vlan 0x0 src_mask 0.0.0.0 0:0:0:0:0:0:0:0 0x0 dst_mask 255.255.255.255 FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF 0x00F0</span><br><span class="line"></span><br><span class="line">flow_director_filter 0 mode IP add flow ipv6-tcp src 0:0:0:0:0:0:0:0 0 dst fcbd:dc01:1:222:0:0:0:12 240 tos 0 ttl 0 vlan 0x0 flexbytes () fwd pf queue 1 fd_id 2</span><br></pre></td></tr></table></figure></p><p>此时再发送目的端口号为240或241…的IPv6报文都可以匹配该fdir规则。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> dpdk </tag>
            
            <tag> network </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>唯识与C语言指针</title>
      <link href="/2018/12/31/thoughts2-weishi-c-pointer/"/>
      <url>/2018/12/31/thoughts2-weishi-c-pointer/</url>
      
        <content type="html"><![CDATA[<blockquote><p>旧文虽无殊胜处却最解少年意，重发于此，乃自喜其披坚执锐行而无返之气。</p></blockquote><h1 id="作者按"><a href="#作者按" class="headerlink" title="作者按"></a>作者按</h1><p>丙申孟春，始得熊君十力之微言宏旨，于《新唯识论》中得窥心外无物，体用不二，翕辟成变之理。数年兵、道、史、释之学，终为一脉贯通，于世间纷杂，万相罗织，始有定见。乃身蹈统摄之道，心得自在清凉，不免情动于衷，喜不自胜。</p><p>熊君为阐唯识之旨，于书中多举譬喻。举“海水与众沤”喻，“绳索与大麻”喻种种；更尝作图形，以穷其本旨，表其胜义，苦口婆心，令人动容，非沐手开卷不能彰其功，焚香斋戒不能铭其德。吾观乎此学，虽能以物物强为譬喻，然万物浩汤，皆为大化，果有以大化喻大化之理乎？终须另觅一人造之物，探幽寻明，见微知著，庶几可得于大化矣。今请试以指针喻之。</p><p>下面开始正常说话。<br><a id="more"></a></p><h1 id="这是要干什么？"><a href="#这是要干什么？" class="headerlink" title="这是要干什么？"></a>这是要干什么？</h1><p>没有人会对“世界到底是什么？”这个问题不感兴趣。科学、哲学、艺术，宗教都在以种种的方式诠释这个问题的答案。作为人生不可逃避的问题之一，每个人或多或少，也都会有自己或明朗或隐约的勾画。</p><p>但是在这个问题上，一直存在诸多的争论。且不说唯心唯物之争，在以确定性立身的科学领域，在人们得窥量子的堂奥之后，也观察到了诸如“二相性”、“测不准”，“非定域”等等的现象，虽然有各个理论都在尝试自圆其说，但不可否认的一点是，随着人类的进步，世界不是变得越来越简单，而是变得越来越复杂了。</p><p>而这恰恰是符合逻辑的。外物确为实有，却不曾脱离心而存在。人类的进步，自然伴随心智的成长，自然就会见到以前“视而不见”的东西。并非有新物凭空而生，而是原物之一“相”得显于成长了的心智。这一新“相”又成为心智继续成长的养料，从而使人认识到更多。这一过程永无休止，方生方死，方死方生。这不是简单的唯物或唯心，而是要结合两者各自的主张。</p><p>唯识论就是在做这一尝试。为表明物与心的关系，亦即如何认识世界的问题，熊君在其论述中做了种种譬喻。惜哉熊君，英才天纵，所举例证却仅限于瓶、罐、桌，绳之间，虽可强为譬喻，但恐有志于学者，不能于此中得其全旨。</p><p>计算机是人类创造的一个世界，人通过编程语言与这个世界发生相互作用。正可成为我们用以阐明世界本旨的绝佳实例。简单类比，计算机里的三极管，是真实存在的“物”，三极管的开关，是其呈现出的“相”，而对这些开关如何认识，就是我们的“心”。唯识精深，非我所能穷究，仅在此以C语言另作一譬喻，以望有启于同侪，足慰心愿。</p><h1 id="如何从C语言中领悟心外无物"><a href="#如何从C语言中领悟心外无物" class="headerlink" title="如何从C语言中领悟心外无物"></a>如何从C语言中领悟心外无物</h1><p>在Linux上编写的C语言是相对底层的语言，原因有很多，但可以直接操作允许范围内的系统内存一定是原因之一。内存的操作除了分配、释放和更改之外，还需要更加频繁地标记和指向，这便引入了指针的概念。一个指针也只是一个普通的变量，只是它的值是一个内存的地址，如此便“指向”了该内存。这些基础的知识，无需再赘言。本文所强调的，是指针、内存、程序之间的种种变换。</p><p>有如下基础代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*object struct*/</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"></span><br><span class="line">    element_type element;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*void pointer*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span>*ptr=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object</span> <span class="title">obj</span>;</span></span><br><span class="line"></span><br><span class="line">obj.element=element_value1;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*point to obj, cast to type struct object*/</span></span><br><span class="line"></span><br><span class="line">(struct object*)ptr=&amp;obj;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*modify obj's member value through pointer*/</span></span><br><span class="line"></span><br><span class="line">*ptr.element=element_value2;</span><br></pre></td></tr></table></figure><p>Line1-6 声明<code>object</code>结构体</p><p>Line 8 定义了一个指针，类型为<code>void*</code>,并指向NULL</p><p>Line 9 定义了<code>objecti</code>结构体对象<code>obji</code>，系统为其分配一片内存</p><p>Line 10 为i<code>obj</code>中的<code>elementi</code>成员赋值为<code>element_value1</code></p><p>Line 12 将对象i<code>obji</code>所在的内存首地址存入i<code>ptri</code>指针中，并将指针类型转换为<code>struct object *</code></p><p>Line 14 解析<code>ptri</code>指针，更改i<code>element</code>对应内存的内容，并赋值为i<code>element_value2</code></p><p>定义对象obj，系统在栈内存上划出了一片内存空间，其长度为obj的长度。但在完成这一步之后，这一部分内存并没有因此产生任何变化。内存里的每一个比特，并没有带上任何“这是obj的内存”的标记。从内存本身来看与没有obj时没有分别。内存作为载体，是一切变动的肇始，不增不减，不净不垢，是真实存在的。</p><h2 id="物是实有的"><a href="#物是实有的" class="headerlink" title="物是实有的"></a>物是实有的</h2><p>到这里，分配给obj的这片内存是有实体存在，却是没有任何“相”可言的。</p><p>在Line10中，我们为<code>elementi</code>赋值，相应的，会引起内存的变化。变化的内存的位置，程序可于<code>struct objecti</code>的定义中得知（计算element_type的offest，）。在赋值之后，这片内存有了第一个“相”，我们可以将这个“相”笼统称为“element的值为element_value1”的obj，就如同我们称呼一个“蓝色带横条纹的“皮球一样。这个值，可以为任何一个允许的值，于是obj就可以显现出任何一个对应的“相”。</p><h2 id="相是变动不居的"><a href="#相是变动不居的" class="headerlink" title="相是变动不居的"></a>相是变动不居的</h2><p>接下来是对指针的的操作。指针是什么？前面虽然已有技术上的说明，但还没有点出本文想阐明的主旨。指针可以让程序连接到相应的数据内存上，如果将程序本身比作自身的意识，内存比作实有的物质世界，那么指针就是我们用以认识世界的感官，是“眼耳鼻舌身意”，它将决定我们接触（看、听、嗅，触摸等等）到哪个实有的物质（指向内存），以及意识中对物质的“相”如何认识（依何种struct定义去解析内存）。</p><p>真正的关键，是指针类型的转换。只有将指针的类型转换为<code>struct object *i</code>，后续的代码才有意义。类型转换并没有改变指针本身，它所在的内存地址，它的长度，它的作用域等等并没有任何变化，但程序（意识）却懂得了，它所接触到的那片内存（实体），是一个<code>struct object</code>的区域（相），并且可以以此认识和改造obj此时显现出来的“相”。这便是常说的“相由心生”之意。</p><h2 id="人通过感官与物质的相发生作用"><a href="#人通过感官与物质的相发生作用" class="headerlink" title="人通过感官与物质的相发生作用"></a>人通过感官与物质的相发生作用</h2><p>就像我们的眼睛、口鼻，手足（指针本身）始终没有什么变化，但我们却可以将某一物质识为瓶瓶罐罐，桌子麻绳，皆是因为我们的意识通过感官注意于其上（Line12），并依照指针的类型给出了对此“相”解释。依照对“相”的理解，我们可以作用于物质，令起变为另外一种“相”(Line14)。</p><p>如果我们不能通过感官去注意(动宾用法，下同)此物，或对此物视而不见（即不能有相关的struct去解释此物，”视而不见”不等同于”看不到”），那么虽然该物是真实存在的，但其“相”在我们的心里是不存在的。此柏拉图洞穴壁影所喻之意，亦为王阳明“与花同归于寂，同起于明”之意。就像虽然内存中的数据是一直都有的，但如果我们没有指针类型的转换，甚至没有struct object的定义，那对程序（意识）来说，任何obj的“相”都是不存在的。唯其二者（指针与struct）皆备于心（意识），才可得obj之“相”。此所谓“心外无物”之意。</p><h1 id="如何从C语言中领悟翕辟成变"><a href="#如何从C语言中领悟翕辟成变" class="headerlink" title="如何从C语言中领悟翕辟成变"></a>如何从C语言中领悟翕辟成变</h1><p>一个某一类型的指针，只要该类型(struct)存在于程序（意识）中，就可以内存（实有的物质）作出相应的解析（物质的相）。通过对“相”的认识（struct中成员的定义），就可以使意识与物质发生作用，但所能改变的，及其改变后的形态，却始终不出“相”的范畴。若上述明了，可稍悟叔本华“意志与表象”之旨。</p><p>但我们需注意的是，指针的类型可以变为任意类型。如从i<code>void*</code>变为i<code>struct object*i</code>，其指向的内存并没有变化，内存本身也没有变化，但程序（意识）对这片内存的解释发生了变化。同一物质，转换成了另外的相，这便是熊君所述，物质转为心上之相的翕的势用。</p><p>如指针从<code>struct object*</code>类型转为<code>void*i</code>类型，则对程序而言，该处内存所显现出的相尽皆消失，只是一片混沌虚静，原有的“相”复返归于大化，此熊君所述，心上之相转为物质的辟的势用。翕辟两者结合，便是老子所谓“无为而无不为”之意。</p><p>从中亦说明一个道理，同一个物质，可计现万相。即同一片内存，可以接受任何类型的指针，其所显现的“相”，亦因指针类型的不同而可显为一组群相。而某一时刻我们所见得的一种”相“，只是此实在之物的“诈现”之相。“相”终是变动不居的，此即《心经》所述“一切有为法，皆如梦幻泡影，如电亦如露”之意。</p><h2 id="于万相中取其一相"><a href="#于万相中取其一相" class="headerlink" title="于万相中取其一相"></a>于万相中取其一相</h2><p>有如下基本代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object1</span>&#123;</span>intobject1_num;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object2</span>&#123;</span>intobject2_num;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span>*ptr=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">object1</span> <span class="title">obj</span>;</span></span><br><span class="line"></span><br><span class="line">(struct object1*)ptr=&amp;obj;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*assign random_value to the first sizeof(int) bytes*/</span></span><br><span class="line"></span><br><span class="line">*ptr.object1_num=random_value;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*cast pointer type to struct object* and do the same thing*/</span></span><br><span class="line"></span><br><span class="line">*(struct object2*)ptr.object2_num=randome_value;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*cast pointer type to int* and do the same thing*/</span></span><br><span class="line"></span><br><span class="line">*(<span class="keyword">int</span>*)ptr=random_value;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*cast pointer type to char* and do the same thing*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> i=<span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(--i)&#123;</span><br><span class="line"></span><br><span class="line">*(<span class="keyword">char</span>*)(ptr+i)=random_value&amp;(<span class="number">0xFF000000</span>&gt;&gt;(i*<span class="number">8</span>));</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上的代码，从Line12开始，都是在对同一块内存进行相同的赋值操作。不同的指针类型，使程序对同一块内存的解释也不尽相同。struct可以从i<code>object1</code>至<code>object2</code>乃至于无穷，所有的struct皆可为&amp;obj处内存所诈现的任一之相。这也解释了，为什么同一事物，有人识得，却有人不识，或两人皆识得，却有不同的态度和看法。</p><p>人的一生，始终都在填充自己的头文件库。有了新的阅历，即是添加了新的struct；对事物有了新的认识，即是在原有的struct中添加了新的成员变量。意识将这些从感官搜集来的struct再重新注意于感官（指针类型转换）之上，便得出了我们所见的世界。</p><p>如果我们所见到的事物，只是真实本体诈现的一相，我们是否有可能穷尽事物所有的相？答案是不能。因为我们的感官无法无限拓展。虽然我们如今有了红外探测仪，X光机等等设备辅助我们的眼睛，声呐、雷达等设备辅助我们的耳朵，但即便是集合所有的外来辅助，甚至是未来所有的外来辅助，所能见到的也只是物质本体的一部分“相”。如一个红色的气球，在可见光范围内，红色是其一相，在红外线范围内，又呈另外一相，既有物质波的相，也有引力波的相，未来还会有新的相。这个过程，便是人对物质的逐步深入认识，即寻找出本体所呈现出的更多的相。但这永远不会止步，就如同struct的定义没有限制一样。所能得知的，就是在指针类型的转换中，在一翕一辟中，在对struct不断地添加调整修改中，形成了我们现在所身处的此在世界。就如同指针不能指向地址长度之外的内存一样，有些相，是我们永远也看不见的。但这些看不见的东西，离我们并不遥远，它是与我们能见到的“相”同时存在的，都是实有的物质本身。如同引力波是物质都具有的一个“相”，但在之前我们都不曾有所体认一样。我们始终在认识“相”的路上，而成就了一切“相”却又不是“相”的，是实有的物质。此即老子所谓“万物恃之以生而不辞，功成不名有，衣养万物而不为主”之谓。</p><h1 id="再论人生之意义"><a href="#再论人生之意义" class="headerlink" title="再论人生之意义"></a>再论人生之意义</h1><p>如果我们无法完全识却世界之本体万相，那我们岂非是活在自欺欺人之中。此言大谬。须知当指针指向一片内存的时候，程序便已可接触内存的每一位比特。易言之，当感官接收到某一实体显现的“相”时，意识已经注意到了实体本身。套用不同的struct会让同一片内存显为不同的“相”，但并不妨碍程序在此“相”中对内存的操作和功用。人生的意义，须在这里求得。</p><p>每一段程序，都有其特别的作用，即便是运行在同一台机器上，运行在同一片内存上（不同时刻），也都有其所特有的对内存的理解和操作。为完成程序自身的任务，体现其意义与价值，每段程序都要对内存有其自身的理解与互动。我们见不到实体全部的“相”，并不是对我们的一种限制，恰恰是对我们的一种褒奖。让我们可以于万相纷杂中取其一，并专注于此，完善自己的心智，完成自己的任务。</p><p>而人生的意义，不在于求得对实体的全部理解，因为那可能是别人的人生，是一种向外的追寻；真正的意义在于求得自身的圆满，而这一切都需要向内去寻求。写好自己的头文件，磨练自己的API，若能将自己这段“程序”补充完整，让它完成自己要去做的任务，吾不知复有何求矣。</p><p>2016.4.22</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>吃牛排的技术</title>
      <link href="/2018/12/28/steak/"/>
      <url>/2018/12/28/steak/</url>
      
        <content type="html"><![CDATA[<p>虽然不知道背后是什么原理，但烤出好吃的牛排一定是一门重要的技术。</p><p>因为重要的技术，门槛一般都很高。它的高不仅体现在如何掌握这门技术，还体现在如何使用这门技术。<br><a id="more"></a></p><p>作为一个普通的食客，一个“烤牛排”这门技术的用户，你首先得学会实例化牛的各个部位。必须要准确给出Rib Eye、T-Bone、Filet的名字，大小写敏感，但也许其实你根本不知道这具体是牛身上的哪个部分。</p><p>然后要学会在不同场景下调用一分熟、五分熟、九分熟和rare、medium、well-done这种多态接口，以及不要设置“十分熟”这种非法参数。</p><p>对于高级用户自然还会有cru、à point、bien cuit来丰富抽象接口的实现；同时还会用一杯Pinot Noir或者Sauvignon Blac作为必不可少的语法糖点缀。</p><p>但当品尝了食客、厨师、还有牛都付出了如此努力才端上来的珍馐之后，你很难在第二天回味起它是什么味道——仿佛残留在唇齿间的始终是当时在餐桌上没说的心思。</p><p>见过一个人吃火锅，但我始终没见过一个人吃牛排。似乎“技术”可以用来掩盖目的，越是高深的技术，掩盖得越不动声色，掩盖得越托物言志。</p><p>我也从来不自己一个人来这家店。周五的中午，没有太多项目和进度报表，没有轻描淡写的握手和佶屈聱牙的名片，更没有迷离的夜色温柔；我所仰仗的“技术”，不过是打开APP找一找团购的套餐，然后在咬上一口汁液四溢时捂住嘴，和对面的人说上一句含混不清的：</p><p>“新年快乐”   emmmm..</p><p><img src="https://s1.ax1x.com/2018/12/28/FWrgiV.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去3：抽象层直接调用实例方法性能提高百分之20</title>
      <link href="/2018/12/27/test3-indirectcall/"/>
      <url>/2018/12/27/test3-indirectcall/</url>
      
        <content type="html"><![CDATA[<blockquote><p>首先吐槽一下hexo标题不能以%结尾 -_-||</p></blockquote><h2 id="抽象层"><a href="#抽象层" class="headerlink" title="抽象层"></a>抽象层</h2><p>经常，我们会在相对比较成熟的软件中见到这样一类结构体：<br><a id="more"></a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">void</span> <span class="params">(*func)</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">abstraction_layer</span> &#123;</span></span><br><span class="line">    func f;</span><br><span class="line">    …</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>内部的成员变量，多以函数指针为主。</p><p>这种结构体主要作用是实现一个”抽象层”，用来解耦上层的业务需求和具体的实现。在操作系统、设备驱动等各种场合有很广泛的应用。</p><p>采用这种抽象形式，虽然增加了程序的灵活性和拓展性(其实就是OOP中多态的实现方式)，但最大的问题就是当真正需要调用某一实例的方法时，只能通过抽象层的函数指针间接调用(indirect call)，而这种调用是伤害性能的。</p><p>有没有在性能上更好的方式呢？</p><h2 id="测试对象"><a href="#测试对象" class="headerlink" title="测试对象"></a>测试对象</h2><p>我们构造这样一个抽象层和一组具体的实现：</p><p>抽象层<code>struct op</code>需要实现六个操作接口：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FUNC_RETURN_TYPE void</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FUNC_PARAMETER void</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OPS \</span></span><br><span class="line">    _(open) \</span><br><span class="line">    _(close) \</span><br><span class="line">    _(write) \</span><br><span class="line">    _(read) \</span><br><span class="line">    _(add) \</span><br><span class="line">    _(<span class="keyword">delete</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _(op) typedef FUNC_RETURN_TYPE (*op)(FUNC_PARAMETER);</span></span><br><span class="line">OPS <span class="comment">// typdef void (*open)(void) and so on...</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> _</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _(op) op op##_fp;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">op</span> &#123;</span></span><br><span class="line">    OPS <span class="comment">// open open_fp; and so on...</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> _</span></span><br></pre></td></tr></table></figure><p>而具体实现这些结构体的实例我们用不同的“颜色”表示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> LIST \</span></span><br><span class="line">    _(red) \</span><br><span class="line">    _(blue)\</span><br><span class="line">    _(yellow)\</span><br><span class="line">    _(black)\</span><br><span class="line">    _(white)</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FUNC_BODY &#123;int i=0; i++;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _(color) FUNC_RETURN_TYPE open_##color(FUNC_PARAMETER) FUNC_BODY \</span></span><br><span class="line">    FUNC_RETURN_TYPE close_#<span class="meta">#color(FUNC_PARAMETER) FUNC_BODY \</span></span><br><span class="line">    FUNC_RETURN_TYPE write_#<span class="meta">#color(FUNC_PARAMETER) FUNC_BODY \</span></span><br><span class="line">    FUNC_RETURN_TYPE read_#<span class="meta">#color(FUNC_PARAMETER) FUNC_BODY \</span></span><br><span class="line">    FUNC_RETURN_TYPE add_#<span class="meta">#color(FUNC_PARAMETER) FUNC_BODY \</span></span><br><span class="line">    FUNC_RETURN_TYPE delete_#<span class="meta">#color(FUNC_PARAMETER) FUNC_BODY</span></span><br><span class="line"></span><br><span class="line">LIST <span class="comment">// void open_red(void) &#123;int i=0; i++&#125; and so on...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> _</span></span><br></pre></td></tr></table></figure><p>然后我们分别把这几个“颜色”的具体实现与抽象层挂钩：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OP_TYPE_NUM 5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> types &#123;</span><br><span class="line">    red,</span><br><span class="line">    blue,</span><br><span class="line">    yellow,</span><br><span class="line">    black,</span><br><span class="line">    white</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">op</span> <span class="title">ops</span>[<span class="title">OP_TYPE_NUM</span>];</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _(color) ops[color].open_fp = &amp;open_##color; \</span></span><br><span class="line">    ops[color].close_fp = &amp;close_##color; \</span><br><span class="line">    ops[color].write_fp = &amp;write_##color; \</span><br><span class="line">    ops[color].read_fp = &amp;read_##color; \</span><br><span class="line">    ops[color].add_fp = &amp;add_##color; \</span><br><span class="line">    ops[color].delete_fp = &amp;delete_##color;</span><br><span class="line"></span><br><span class="line">LIST <span class="comment">// ops[red].open_fp = &amp;open_red; and so no...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> _</span></span><br></pre></td></tr></table></figure><p>准备好了被测对象之后，下面就是对比测试了。</p><h2 id="直接调用"><a href="#直接调用" class="headerlink" title="直接调用"></a>直接调用</h2><p>对每种实例中的方法，有两种调用方式：</p><ul><li>间接调用：</li></ul><p>以调用每个实例的<code>open</code>接口为例：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ops[idx].open_fp();</span><br></pre></td></tr></table></figure><p>这种是最常见的调用方式。因为需要先获取指针，再根据指针去调用，所以称为间接调用。</p><ul><li>直接调用：</li></ul><p>仍是以调用实例的<code>open</code>接口为例：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span>(idx) &#123;</span><br><span class="line"> <span class="meta">#<span class="meta-keyword">define</span> _(color) case color: open_##color(); break;</span></span><br><span class="line"> LIST <span class="comment">// case red: open_red(); break; and so on...</span></span><br><span class="line"> <span class="meta">#<span class="meta-keyword">undef</span> _</span></span><br><span class="line">     <span class="keyword">default</span>: open_red(); <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用一个<code>switch</code>结构先判断该欲调用的方法属于哪个实例，然后直接调用该方法。</p><p>看起来直接调用的方式不如间接调用“优雅”，但直接调用是否能带来性能提升呢？</p><h2 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CPU： Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHz</span><br><span class="line">OS：3.10.0-514.21.1.el7.x86_64</span><br><span class="line">GCC：4.8.5</span><br><span class="line"></span><br><span class="line">====RANDOM IDX -O0</span><br><span class="line">call_ops()                                  :  7936.000 cycles per input word (best)  8279.895 cycles per input word (avg)</span><br><span class="line">call_ops_directly()                         :  6287.000 cycles per input word (best)  6858.248 cycles per input word (avg)</span><br><span class="line">====FIX IDX -O0</span><br><span class="line">call_ops()                                  :  7862.000 cycles per input word (best)  8035.686 cycles per input word (avg)</span><br><span class="line">call_ops_directly()                         :  6713.000 cycles per input word (best)  7234.337 cycles per input word (avg)</span><br></pre></td></tr></table></figure><p>在两种不同的调用方式下（一种是随机选取实例调用，一种是固定调用一个实例），直接调用的方式都比间接调用快(消耗的cycle数少)，在随机调用模式下有接近20%((8279-6858)/8279)的性能提升。</p><p>完整代码已传到Github：<a href="https://github.com/PanZhangg/x86perf/blob/master/indirectcall.c" target="_blank" rel="noopener">https://github.com/PanZhangg/x86perf/blob/master/indirectcall.c</a></p><p>至于为什么会出现这个结果，会在后续的系列文章中探究。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> performance </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚8：Intel 700系列网卡内部结构概览</title>
      <link href="/2018/12/25/quickwords8-700-nic-arch/"/>
      <url>/2018/12/25/quickwords8-700-nic-arch/</url>
      
        <content type="html"><![CDATA[<p>一不小心这个系列写到了第8期，原本打算写些别的东西，不过看到8这个数字就想到了Intel将要推出的800系列网卡…的小弟——命途多舛的700系列网卡。从目前市场(主要是云计算、互联网公司和数据中心)的情况看，700系列有逐渐推广的趋势，那么这一期就介绍一下700系列网卡的基本技术架构和特点吧。<br><a id="more"></a></p><h2 id="Intel-700系列网卡的内部架构"><a href="#Intel-700系列网卡的内部架构" class="headerlink" title="Intel 700系列网卡的内部架构"></a>Intel 700系列网卡的内部架构</h2><p>在处理完物理层的事情之后，数据包会进入网卡内部的处理流水线。</p><p>对于网络中的事情，所有参与者基本上就在做一个事情：分类-&gt;转发。大到核心路由器，小到iptables都是一样。只不过有些按IP地址的前缀分类，有些按报文的协议类型分类，有些按某些header字段分类罢了。</p><p>所以对Intel 700系列网卡来说，在物理层接收到帧之后，首先要做的就是”解析“一下，这个帧到底属于哪一类。</p><p><img src="https://software.intel.com/sites/default/files/managed/f3/d2/Intel-Ethernet-Controller-700-series-Hash-and-Flow-Filters-fig01.png" alt="700系列网卡简易架构图"></p><p>因此Parser解析器就是流水线的第一环。它会根据帧本身的特点，以及自己的识别解析能力，给每个包都打上一个标签(PTYPE和PCTYPE)。</p><p>而根据这些标签，会抽取帧中相应的字段(一般是标签所代表的协议中比较关键的字段)存入<code>Field Vector</code>，以备后用。</p><p>后面的<code>Switch</code>主要就是用<code>Field Vector</code>中的数据，包括<code>DMAC</code> <code>VLAN ID</code>等等，来决定该帧是应该进入PF还是VF。</p><h2 id="流分类-RSS和fdir"><a href="#流分类-RSS和fdir" class="headerlink" title="流分类(RSS和fdir)"></a>流分类(RSS和fdir)</h2><p>在确定了进入哪一个PF或VF之后，就可以对帧进行RSS或者fdir的操作，来决定根据预设的配置，这个帧最终进入哪个队列，进而被哪些上层进程所消费。</p><p><code>Field Vector</code>中的数据在这个时候就会被拿过来做Hash或者过滤，来计算出最终的结果。</p><p>而上面提到的<code>PCTYPE</code>，其为”Packet Classifier Type”的缩写。其实是每一种<code>PCTYPE</code>对应后面一套预设的处理过滤规则(Classifier)。比如<code>IPV4 TCP</code>和<code>IPV6 TPC</code>就分别是两种<code>PCTYPE</code>，那么对于这两种报文的处理就可以分别设定规则。e.g. <code>IPV4 TCP</code>的报文进入Queue2, <code>IPV6 TCP</code>的报文进入Queue3。</p><p>700系列网卡所谓的“灵活性”和“可编程性”也主要基于此。</p><p>最大支持64种<code>PCTYPE</code>，但网卡默认支持的只有…呃..几种。但可以通过DDP动态添加。可以参考前一篇关于DDP的说明<a href="https://decodezp.github.io/2018/12/18/quickwords6-ddp/">文章</a>。</p><h2 id="收包流程"><a href="#收包流程" class="headerlink" title="收包流程"></a>收包流程</h2><p>再简单总结一下700系列网卡的收包流程。</p><p>二层帧到达之后，首先进入<code>Parser</code>解析器。解析器根据协议类型，给二层帧打上<code>PTYPE</code>和<code>PCTYPE</code>的“标签”。</p><p>同时，根据这些标签，提取标签规定的字段，存入到<code>Field Vector</code>中。<code>Field Vector</code>相当于该二层帧的一个meta data，一直跟随到从某一端口或队列发送出去。</p><p>然后在<code>Switch</code>阶段，网卡会根据该二层帧<code>Field Vector</code>中的某些字段判断该帧进入哪个PF或VF。</p><p>在进入PF和VF之后，会根据帧各自的<code>PCTYPE</code>，从<code>Field Vector</code>取数据(其实也就是各协议的关键字段e.g. 目的IP地址，VNI等等)参与计算或过滤规则匹配。最后按照规则转发或丢弃。</p><p>严格来说，是先经过fdir，再去RSS。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚7：DPDK不同CPU平台交叉编译指令不支持的问题</title>
      <link href="/2018/12/24/quickwords7-dpdk-cross-compile/"/>
      <url>/2018/12/24/quickwords7-dpdk-cross-compile/</url>
      
        <content type="html"><![CDATA[<h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>在比较高级的CPU平台(比如skylake)编译DPDK，会在编译的目标文件中加入一些高级指令集中的指令，比如AVX512。</p><p>如果运行最终可执行文件的机器的CPU架构(比如broadwell)不支持编译机器中的指令，则会在执行时报类似这种错误：<br><a id="more"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">174146:Dec 21 10:56:30 n10-023-013 kernel: [57619.700220] traps: obj-name[861199] trap invalid opcode ip:501c31 sp:7fff9782d090 error:0</span><br></pre></td></tr></table></figure><p>其实就是在0x501c31(ip是instruction pointer)这个位置上的指令不支持(invalid)。</p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>那么如何查看具体是哪条指令呢? </p><p>用<code>objdump -D obj-name</code>查看一下目标文件的汇编代码，找到该位置上的指令。</p><p>我这里的例子中，这个指令是<code>vmovdqa64</code>，简单搜索一下可以知道这是个<code>AVX512f</code>的指令。</p><blockquote><p>其他详细内容可以查看Intel SDM(Software Development Manual)<a href="https://software.intel.com/en-us/articles/intel-sdm" target="_blank" rel="noopener">下载链接</a></p></blockquote><p>而这个指令在<code>skylake</code>上支持，<code>broadwell</code>上不支持。</p><p>可以通过在两个机器上执行<code>cat /proc/cpuinfo | grep flags</code>查看支持的指令集。或者执行<code>gcc -march=native -Q --help=target</code>查看。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>在编译机器(skylake)DPDK的/mk/machine/native/rte.vars.mk中，设置<code>MACHINE_CFLAGS= -march=native</code>为<code>-march=broadwell</code>就可以了。</p><p>当然还有一些详细的交叉编译方法，可以参考这篇<a href="http://syswift.com/355.html" target="_blank" rel="noopener">文章</a>。</p><p>另外还有一点要提醒的是，如果你是在编译某些基于DPDK的应用，比如DPVS，要一并修改应用中的编译配置，例如DPVS就是在<code>./src/dpdk.mk</code>中，需要修改<code>CFLAGS += -march=broadwell</code>。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> dpdk </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>5分钟经典英文技术演讲2：软件设计真正的精髓-Scott Meyer</title>
      <link href="/2018/12/21/eng-talk2-things-matter/"/>
      <url>/2018/12/21/eng-talk2-things-matter/</url>
      
        <content type="html"><![CDATA[<blockquote><p>一个人的能力上限很大程度上取决于他获取信息的能力。</p><p>而能力增长的速度与获取信息的_质量_正相关。</p><p>不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。</p><p>最新内容将发布于<a href="https://decodezp.github.io">DecodeZ</a>: <a href="https://decodezp.github.io">https://decodezp.github.io</a></p><p><a href="https://decodezp.github.io/2018/12/12/eng-talk1-fast-learn/">往期回顾：如何快速掌握新技术</a></p></blockquote><h1 id="DConf2017：软件设计真正的精髓"><a href="#DConf2017：软件设计真正的精髓" class="headerlink" title="DConf2017：软件设计真正的精髓"></a>DConf2017：软件设计真正的精髓</h1><p><a href="https://www.youtube.com/watch?v=RT46MpK39rQ" target="_blank" rel="noopener">原视频</a></p><p><a href="http://dconf.org/2017/talks/meyers.pptx" target="_blank" rel="noopener">PPT/Slides下载</a></p><p>演讲者：Scott Meyer</p><p>上一张演讲者的照片，硬撸过C++的应该都很熟悉他:</p><p><img src="https://s1.ax1x.com/2018/12/21/FsMA2R.jpg" alt="Scott Meyer"></p><blockquote><p>摘要：成功的软件产品都有其共性。在Scott Meyer看来，这些共性由几个要素组成。在你的作品中考虑这些要素，将帮助你掌握软件设计真正的精髓。<br><a id="more"></a></p></blockquote><h2 id="效率-速度-Efficiency-Speed"><a href="#效率-速度-Efficiency-Speed" class="headerlink" title="效率/速度(Efficiency/Speed)"></a>效率/速度(Efficiency/Speed)</h2><p>效率高(所需要执行的指令数少)的软件在大多数情况下等于速度快性能高的软件。</p><p>在硬件性能普遍过剩的2C和移动市场，对软件效率的追求也可以带来更广泛的平台配适性和更好的功耗表现。</p><p>而在每增加100毫秒延时，年收入就掉几个百分点的电商、在线广告和高频交易领域，对服务器软件效率的追求没有止境。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsM5W9.jpg" alt=""></p><p>追求软件的高性能肯定没错，但大家一定都熟悉一句话：</p><blockquote><p>“过早优化是万恶之源”(Pre-mature optimization is the root of all evil)。</p></blockquote><p>很多人将这句话作为“先不忙优化，最后再说”的理由。但有多少人知道这句话的出处和上下文?</p><p>这句话出自Donald Knuth的一篇叫做”Structured Programming with go to Statements”的论文。而这句话的前面一句话和它连起来是：</p><blockquote><p>如果你不能确定在哪里可以优化，就先不要优化。过早优化是万恶之源。</p></blockquote><p>而在这篇总长度41页的论文的同一页，Donald写道：</p><blockquote><p>可以简单获得(easily obtained)的性能提升，并非无足轻重。</p></blockquote><p><img src="https://s1.ax1x.com/2018/12/21/FsMhi4.jpg" alt=""></p><p>当软件已届完成时再考虑性能优化，将是艰难甚至不可能的任务，例如单线程程序改为多线程，有锁替换为无锁结构等等。</p><p>所谓”过早优化“(我还是更喜欢将其直译为”不成熟的优化“)，并不是指“从软件的设计阶段就考虑性能”，而是指你还并不知道哪里能优化就一通乱搞的时候。</p><p>而能看出系统性能的瓶颈，可以给出“成熟的优化”方案，是需要长期的学习和实践积累的。</p><blockquote><p>Side Note: 对软件性能优化，特别是结合CPU内存等硬件特性感兴趣的读者可以自行搜索一下笔者在青涩时期挖了还没填上的大坑: <a href="https://www.baidu.com/s?wd=x86%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B%E7%AC%BA%E6%B3%A8&amp;rsv_spt=1&amp;rsv_iqid=0xe6a969f800013a74&amp;issp=1&amp;f=8&amp;rsv_bp=0&amp;rsv_idx=2&amp;ie=utf-8&amp;tn=baiduhome_pg&amp;rsv_enter=1&amp;rsv_sug3=34&amp;rsv_sug1=2&amp;rsv_sug7=100&amp;rsv_sug2=0&amp;inputT=6753&amp;rsv_sug4=6958" target="_blank" rel="noopener">x86高性能编程笺注</a></p></blockquote><h2 id="可移植性-Portability"><a href="#可移植性-Portability" class="headerlink" title="可移植性(Portability)"></a>可移植性(Portability)</h2><p>可移植性的出发点，是市场和客户。</p><p>Scott举出了一个他供职过的公司的例子：有自己的硬件平台、编译器、和操作系统。他们的产品跑在自己高度定制化的平台上，各方面的优化已臻完美，一切都很美好。</p><p>相形之下，那些跑在“拼凑”出来的平台上的竞品，就像一个拙劣的玩笑。</p><p>这一切都随着“通用硬件”性价比突飞猛进而结束，竞品提出的策略是：提供该公司80%的产品性能，但只需要20%的价格。</p><p>而这样的故事，在Scott二十余年的从业经历中重复发生着。</p><p>当你真的认真在考虑一个严肃的软件产品时，请通过可移植性给予它更多的市场适应能力，而不至于因为产品之外的因素影响产品本身的生命周期。</p><p>同时可移植性也可以帮助你在推出了一款成功的产品并在当前平台下达到市场饱和之后，开拓出更多的市场增长空间。有增长才有后续的融资嘛 :)</p><p>而做好产品的可移植性设计，其难度不亚于上一节提到的性能优化。有太多硬件的和软件的细节需要考虑，不但要做好不同平台之间的抽象，还要考虑如何充分利用不同平台的独有特性。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsMWoF.jpg" alt=""></p><p>而这一切都将是你不断学习的内容。</p><h2 id="修补性-Toolability"><a href="#修补性-Toolability" class="headerlink" title="修补性(Toolability)"></a>修补性(Toolability)</h2><p>字典中出给的翻译是“修补性”，但我觉得这是一个不贴切的翻译。<code>Toolability</code>在这里的意思是，当你创造出某种产品的时候，需要考虑能够简单地让别人围绕它开发出工具(Tool-able)。</p><p>我个人的理解就是，预留出构建生态的能力。</p><p>如果把编程语言看作是一种产品，那么某种语言的重构工具就是它整个生态中重要的一环。</p><p>重构工具的一项基本功能，就是在一个项目工程中替换某一个函数的名字。在Java中我们有Intellij，有Eclipse，在对C++来说，我们还没有一个特别好使的重构工具。</p><p>因为在C++中，一个简单的<code>f(x)</code>可能是：</p><ul><li>一个函数</li><li>一个函数指针</li><li>一个重载操作符</li><li>一个模板</li><li>一个宏</li><li>等等等等</li></ul><p>这样的复杂度，让实现C++的重构工具变得几乎不可能。<code>Comments: 现在确实出现了一些C++的重构工具，但相比于其他语言，晚了十余年。</code></p><p>但我们想强调的并不是C++如何重构，而是当没有这些工具，没有产品生态的时候，你的产品能发挥出多大作用，完全受限于使用者本身的能力。而如果他人能够迅速构建出一套工具，将会帮助你提升产品能力的下限。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsM4JJ.jpg" alt=""></p><p>简单来说就是，只靠产品一个人打天下不行，需要有组件团队的能力。同时当别人想加入你的团队时，最好不要有太多障碍。</p><h2 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性(Consistency)"></a>一致性(Consistency)</h2><p>一致性是用户体验提升的核心，这里的用户既包括产品最终的消费者，同时也包括开发者。</p><p>所谓用户体验，是能够轻易的与以往的经验做类比。保持一致并不是处女座强迫症作祟，而是在软件设计领域有重要意义——带来有效的抽象和类比。一致性本质上是在为我们的大脑创造一种”模式“，既然是模式，就需要有保持一致的东西。</p><p>看一个iOS10上的例子：<br><img src="https://s1.ax1x.com/2018/12/21/FsMRdU.jpg" alt=""></p><p>删除按钮的图标都是一致的，但位置和颜色并没有保持一致。</p><p>试想，如果一系列相关的函数调用，它的相同类型的参数位置都不一样，如下面这个C语言的例子：<br><img src="https://s1.ax1x.com/2018/12/21/FsMTQ1.jpg" alt=""></p><p>即便是编写了数十年C程序的程序员，每次也都需要查表才能确定自己把参数放对了位置。</p><p>又如Java中求得某个数据类型的长度的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array.length</span><br><span class="line">string.length()</span><br><span class="line">List.size()</span><br></pre></td></tr></table></figure><p>这种体验需要开发者针对每种不同的数据类型分别记忆不同的方法，而不能构建一个一致性的抽象。</p><p>现在当然有智能化的IDE可以帮助我们摆放好参数或者使用正确的方法，但我们想探究的正是，为什么IDE会加入这个功能——因为不一致的参数位置和方法名实在太恼人了。</p><p>而用户体验的核心，并非是扁平化设计，而是追求一致：产品本身性能一致，稳定性一致；用起来的时候，能把我以前的经验带到这里来，并且我一看就知道，这个产品如何操作。</p><h2 id="接口-Interfaces"><a href="#接口-Interfaces" class="headerlink" title="接口(Interfaces)"></a>接口(Interfaces)</h2><p>设计接口，既要考虑如何容易用对，同时也考虑如何很难用得不对。</p><p>而上一节提到的一致性，就是一个很好的指导原则。</p><p>毕竟会调用你接口的人，都是聪明人，都是有软件经验的人，同时他们也希望你实现的接口能够帮助他们自己，所以也愿意去读一点文档。</p><p>如果即便如此他们还是不能正确使用你的接口，那一定是你自己的问题。</p><p>而真正优秀的接口，是调用者凭借你提供的一致性，凭直觉就能使用的接口——“我也不知道为什么，但这个接口就是工作了”。</p><p>而一个设计不靠谱接口的开发人员的典型口头禅就是：他们会搞明白的。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsMIzR.jpg" alt=""></p><p>这可能正是你的产品变得混乱不堪的开始。</p><p>以上就是Scott Meyer想要在本次演讲中传达给我们的内容。</p>]]></content>
      
      
      <categories>
          
          <category> ENG_talk </category>
          
      </categories>
      
      
        <tags>
            
            <tag> English </tag>
            
            <tag> Presentation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚6：什么是DDP(Dynamic Device Personalization)</title>
      <link href="/2018/12/18/quickwords6-ddp/"/>
      <url>/2018/12/18/quickwords6-ddp/</url>
      
        <content type="html"><![CDATA[<h2 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h2><p>通过网卡的多队列和RSS将网包根据一些关键字段散列(hash)到不同的队列已成为一种主流的在x86平台开发信通以及云计算领域产品的方式。</p><p>在整体产品架构规划中，不同的网卡队列(Rx/Tx Queues)往往对应/绑定着不同的CPU核(Worker)，以利用资源隔离的方式提高性能。</p><p>传统的RSS，往往是依据header的五元组来做散列。通常，网卡可以识别出的报文类型包括<code>ipv4-tcp|ipv4-udp|ipv4-other|ipv6-tcp|l2-payload</code>等等，然后根据能识别出的类型进行关键字段的提取。</p><p>但现在如此简单的识别能力已经不能满足业务的需求。在复杂的协议和隧道通讯场景下，往往还需要识别隧道内层header甚至私有字段才能实现业务能力的最优化。<br><a id="more"></a></p><p>所以对RSS/Fdir来说，首先需要能“识别”出特定的协议报文，才能找到关键的字段进行散列操作。</p><p>在网卡出厂的时候，是可以预置一些协议类型的，但还是最好能有自定义的动态调整的能力。</p><h2 id="DDP-Dynamic-Device-Personalization"><a href="#DDP-Dynamic-Device-Personalization" class="headerlink" title="DDP(Dynamic Device Personalization)"></a>DDP(Dynamic Device Personalization)</h2><p>名字起得很“大”，不过就是上面说的定制化的技能——动态地赋予网卡识别新协议的能力。</p><p>具有这种能力之后，就可以把任意协议的网包按用户意愿提取出关键字段(Key)，然后散列到网卡各个Rx队列里。比如VxLAN协议中的内层DIP等等。</p><p>下图是一个赋予网卡<code>GTP-U</code>协议(好吧，我并不知道这是什么…)识别能力，并可以依据<code>TEID</code>字段的值进行RSS计算的示例：</p><p><img src="https://s1.ax1x.com/2018/12/18/FBJ5q0.png" alt="绿色的可以被用来RSS的字段增多"></p><p>现在已经能被识别出的包括L2TPv3\QUIC\PPPOE\SRv6\RoE\MQTT-SNoUDP等等，还有一些大客户做了自己私有协议的定制。</p><p>总得来说就是，可以把这部分classification的活儿offload到硬件上，减轻后续CPU处理/分发时的压力，同时均衡一下负载，提升整体性能。</p><h2 id="DDP的需求："><a href="#DDP的需求：" class="headerlink" title="DDP的需求："></a>DDP的需求：</h2><ul><li>Intel 700系列网卡以上</li><li>固件版本6.01以上</li><li>一个由Intel官方出品的特定协议识别的binary package file(需要到官网下载)</li><li>DPDK提供的配置接口</li></ul><p>具体在DPDK上怎么搞后续会有文章说明。</p><h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><blockquote><p>Q:如何自己制作binary package file?<br>A:目前不支持自己制作，只能由Intel提供。</p><p>Q:一张网卡最多支持载入多少个binary package file(profile)?<br>A:最多支持16个，但不推荐这么做，推荐同时只载入一个。</p><p>Q:载入之前需要首先关闭网卡设备吗？<br>A:不需要，支持运行时直接载入，但会引起一些丢包</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>谁不是在像CPU一样活着</title>
      <link href="/2018/12/16/cpulized-life/"/>
      <url>/2018/12/16/cpulized-life/</url>
      
        <content type="html"><![CDATA[<p>上一次兴奋到浑身发热，还是把赛扬300A超频到450兆赫的时候。身体如摩尔定律般长高，觉得距离1GHz只差一罐液氮，心里装着只有一心一意才能装下的事情。</p><p>记得那时看到一篇报道，英特尔说“到2011年的时候，我们都能用上10GHz的电脑”。十几岁的你笑这家美国公司野心不大，现在你说出这件事，只是想给大家讲个笑话。<br><a id="more"></a></p><p>2018年，没等来10GHz的电脑，也再也没有一心一意的机会。学会了MMX、SSE、AVX，TSX和AEX等十八般武艺，领导说你是“业务中坚”，其实你知道你只是个挣扎着适应环境的执行人员。</p><p>好在熟稔让你变得老练，打点好前端后端的各种关系，再低的IPC也可以不动声色。毫无指摘地把锅甩给温吞的硬盘，你想你可能明白了什么是sophisticated，就是心里只寻思自己那点14nm的柴米。</p><p>但越是老练越让你厌恶风险，你给自己加了iCache、dCache、iTLB、dTLB，IOTLB等各种保险，但每次分支预测失败还是要彻底打乱你的流水线。即便凭借经验已能做到99%的正确，却能又让你掉入Spectre的窠臼。</p><p>真是怕什么来什么，左右为难的时候，自己的窘样又让心里有一点点好笑，能用一罐液氮解决的事情，偏要搞这么复杂。</p><p>突然有些怀念那个为450兆赫兴奋的自己，当时你只想完成这一件事。但此刻你心里不再只住着你自己，每个人都同时在跑好几个角色，你号称你是3GHz还能hyperthread，其实你知道你早已没了章法，所有的事情都不过是水来土掩的乱序执行。</p><p>但好在还有一块L3缓存，和你那些sophisticated的L1缓存相比，这里虽然慢，慢得就像曾经的赛扬300A，但却有一心一意的完整。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚5：影响服务器内存性能的硬件知识</title>
      <link href="/2018/12/13/quickwords5-server-memory/"/>
      <url>/2018/12/13/quickwords5-server-memory/</url>
      
        <content type="html"><![CDATA[<h2 id="发挥内存条理财的最大收益率"><a href="#发挥内存条理财的最大收益率" class="headerlink" title="发挥内存条理财的最大收益率"></a>发挥内存条理财的最大收益率</h2><p>内存条作为年度最佳理财产品除了能躺着赚钱之外，使用得好还可以一条当两条用。</p><p>在计算机系统中，内存的价值就体现在快速提供数据给CPU处理。当CPU需要的数据没有在缓存里时，CPU内部的<code>Memory Controller</code>就需要去内存中读取内容。<br><a id="more"></a></p><p>而<code>Memory Controller</code>为了尽快完成CPU交代的任务，用了<code>多通道</code>的方式增大内存存取带宽。</p><p><code>多通道</code>这个概念很好理解，和多条车道是一个意思。比如CPU需要1MB大小的数据，单通道的话数据就只能在一条通道上老老实实排队；双通道就可以并行两个512KB的读取；四通道就是并行四个256KB的读取。</p><p>我知道你要问什么，这1MB大小的数据已经被<code>Memory Controller</code>通过一种叫做<code>Interleave(交织)</code>的技术“打散”在了两个通道或者四个通道对应的物理内存上。<code>Interleave</code>由硬件实现，细节不在这里深究，我们想说明的是发挥这些硬件组件的最大能力需要外界条件配合。</p><p>内存在硬件方面的性能优化，就围绕这个主题。</p><h2 id="内存相关概念"><a href="#内存相关概念" class="headerlink" title="内存相关概念"></a>内存相关概念</h2><p>现在主流Intel E5 CPU的配置是一颗CPU上两个<code>Memory Controller</code>，每个Controller有两个通道，每个通道对应主板上三个内存插槽(DIMM)。</p><p><img src="http://1.bp.blogspot.com/-Iaf9qQgC-zM/VdDIBPzscoI/AAAAAAAAABs/AU-vcOrCSck/s1600/6101_48_supermicro_x9dr7_tf_intel_c602j_server_motherboard_review.jpg" alt="内存插槽"></p><p><code>Interleave</code>首先发生在通道层面，进而发生在通道的DIMM层面（使用的DIMM越多，交织得越充分）</p><p>同时每根内存条还有一个<code>Rank</code>的概念。这个概念可以理解为更进一步的<code>Interleave</code>，多<code>Rank</code>的内存条可以再进行一次<code>Interleave</code>。</p><p><img src="https://cdn3.bigcommerce.com/s-3jjekk/product_images/uploaded_images/memory-rank.png?t=1518214379&amp;_ga=2.27767868.1254827790.1518192896-72491761.1493653618" alt="看序列号读取内存信息"></p><h2 id="充分平衡"><a href="#充分平衡" class="headerlink" title="充分平衡"></a>充分平衡</h2><p>满足最优的内存配置就是四个字：充分平衡。</p><p>-充分：并不是要你插满所有插槽，而是充分利用每个<code>Memory Controller</code>和每条通道<br>-平衡：每个<code>Memory Controller</code>和通道上的内存配置(Size, Rank和频率)都相同。</p><p>在实际应用中，首先绘制一个内存拓扑，如下图：<br><img src="https://s1.ax1x.com/2018/12/13/FNdSBT.png" alt="充分平衡"></p><blockquote><p>如何检查是否充分？看一下每个<code>Memory Controller</code>中的每个通道是否都有内存条<br>如何检查是否平衡？将拓扑图从中垂线对折一次，检查图像是否能重合；再从水平中位线对折一次，检查是否能重合。如果两次回答都是yes，就平衡了。</p></blockquote><h3 id="实例1"><a href="#实例1" class="headerlink" title="实例1"></a>实例1</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNwPqf.png" alt="平衡不充分"></p><h3 id="实例2"><a href="#实例2" class="headerlink" title="实例2"></a>实例2</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNazuV.png" alt="充分不平衡"></p><h3 id="实例3"><a href="#实例3" class="headerlink" title="实例3"></a>实例3</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNajcq.png" alt="不充分不平衡"></p><h3 id="实例4"><a href="#实例4" class="headerlink" title="实例4"></a>实例4</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNavj0.png" alt="充分平衡"></p><h2 id="软件检查工具"><a href="#软件检查工具" class="headerlink" title="软件检查工具"></a>软件检查工具</h2><p>为了不让每次内存检测都需要打开机箱…有一个开源工具可以通过读取<code>dmidecode</code>的信息自动化做检验：<a href="https://github.com/PanZhangg/DPDKick" target="_blank" rel="noopener">DPDKick</a></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> performance </tag>
            
            <tag> memory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>5分钟经典英文技术演讲1：如何快速掌握新技术 - Kathy Sierra</title>
      <link href="/2018/12/12/eng-talk1-fast-learn/"/>
      <url>/2018/12/12/eng-talk1-fast-learn/</url>
      
        <content type="html"><![CDATA[<blockquote><p>一个人的能力上限很大程度上取决于他获取信息的能力。</p><p>而能力增长的速度与获取信息的质量正相关。</p><p>不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。</p><p>最新内容将发布于DecodeZ: decodezp.github.io</p></blockquote><h2 id="Fluent-如何快速掌握新技术"><a href="#Fluent-如何快速掌握新技术" class="headerlink" title="Fluent: 如何快速掌握新技术"></a>Fluent: 如何快速掌握新技术</h2><p><a href="https://www.youtube.com/watch?v=FKTxC9pl-WM" target="_blank" rel="noopener">原视频</a><br>演讲者: Kathy Sierra</p><blockquote><p>摘要：无论是谁，以有限的精力来面对层出不穷的新技术挑战都是不够的。你需要学会一套方法论来帮助你快速习得新的技能。而快速学习的秘诀却还不止这些…<br><a id="more"></a></p></blockquote><h2 id="每个程序员都面临的挑战"><a href="#每个程序员都面临的挑战" class="headerlink" title="每个程序员都面临的挑战"></a>每个程序员都面临的挑战</h2><p>为了成为一名“合格”的程序员，你认为你需要掌握哪些技术？</p><p>这将是一个长长长长长的名单，更可怕的是，每个人列出的内容都将各不相同。</p><p>所以这么提问并没有太大意义，更好的问题是：</p><p>我如何快速掌握新的技术？</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0sqf.jpg" alt=""></p><h2 id="认知资源"><a href="#认知资源" class="headerlink" title="认知资源"></a>认知资源</h2><p>我们习得新的技能，需要依赖我们自己的认知资源（Cognitive resources）。</p><p>但作为一个正常的“人类”，我们的认知资源易耗且稀缺。</p><p>到底有多容易消耗？Kathy提到了一个大学里的实验：实验人员要求一半实验参与者记忆一个两位的数字，而另外一半参与者记忆一个七位的数字。</p><p>等确保每个人都记住了自己的数字之后，实验人员随即宣布实验结束，并邀请所有参与者去取用一些零食——蛋糕，或水果。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0rsP.jpg" alt=""></p><p>而实验结果也能猜到，仅仅是5位数字的差别，就让记忆七位数的实验者选取蛋糕的比例比记忆两位数的参与者高出一半。</p><p>你是否有想认真掌握一门新技能，但一拿起各类技术书籍、文档，很快就放弃的经历？你又是否在做一些让别人“选择蛋糕”的事情？比如让别人阅读你自己编写的项目文档。</p><p>当你想要快速掌握一项技能的时候，你需要学会管理自己的认知资源。<br><img src="https://s1.ax1x.com/2018/12/12/Ft0cdS.jpg" alt=""></p><h2 id="学习方法"><a href="#学习方法" class="headerlink" title="学习方法"></a>学习方法</h2><p>将你现在的技能分为三类：</p><ul><li>A还没有掌握，但需要掌握的</li><li>B经过一定努力可以掌握的</li><li>C已经掌握的</li></ul><p><img src="https://s1.ax1x.com/2018/12/12/Ft0DMt.jpg" alt=""></p><p>我们的目标其实是如何将AB的技能快速移动到C。在这个过程中我们会遇到两类典型问题：</p><ul><li>没有进步</li><li>耗时太久</li></ul><h3 id="没有进步"><a href="#没有进步" class="headerlink" title="没有进步"></a>没有进步</h3><p>第一类问题的根本原因在于你的认知资源不足以支撑技能的学习需求。我们不能要求自己有无限的认知资源，在资源极度有限的情况下，仍有两种解决策略：</p><p>第一种，将更多的需要掌握的技能放在A，将精力集中于少量的B类技能。但在日常工作中，需要掌握哪些技能，解决哪些问题，都不是自己可以安排的。对此，我们还有第二种策略。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0gIg.jpg" alt=""><br>第二种策略，就是将B中的技能分解为更小的粒度。这种策略，在有限的认知资源的情况下效果等同于一个需要处理多任务并发的CPU，上面运行的程序都采用了更加细粒度的锁机制，带来了程序性能的提升。<br><img src="https://s1.ax1x.com/2018/12/12/Ft06Z8.jpg" alt=""></p><p>那么如何界定分解之后的技能足够“细”？Kathy给出了一个她的评判标准：</p><blockquote><p>从完全不会到十分熟练，最多经过3次练习，每次45-90分钟。</p></blockquote><p>能满足上面的标准就可以认为分解到了合理的粒度。</p><h3 id="耗时太久"><a href="#耗时太久" class="headerlink" title="耗时太久"></a>耗时太久</h3><p>程序员不但要学习很多技能，还需要快速学习。所以从A开始，我们最好能够绕过B直接到C。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0fRs.jpg" alt=""><br>怎么可能从完全不懂，到突然就明白了？</p><p>Kathy给出了一个“极端”的例子：学习给分辨雏鸡的性别。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0RiQ.jpg" alt=""><br>从视觉上，这是一件不可能的事，但日本却有一些非常擅长分别雏鸡性别的人。</p><p>人们希望这些“性别分辨大师”能够将他们的方法教授给别人，但这些人并不能讲出什么明确的“规则”。</p><p>这就是这件真正神奇的地方，我们的大脑能够在潜意识中处理一些信息，但却讲不出来为什么。</p><p>所以学习雏鸡性别分辨的人最开始只是随机判断雏鸡的性别，而这些“专家”则告诉他们结果是不是正确。</p><p>一段时间以后，这些学习分辨性别的人正确率越来越高，最终达到了专家的水平。</p><p>这些学习的人并没有记忆任何具体的“规则”，却能够不断提升自己的技能水平。这里产生核心影响的是：高质量的例子。</p><blockquote><p>这非常类似机器学习的过程，模型的质量取决于训练这些模型的数据的质量。</p></blockquote><h2 id="关键的缺失——高质量的例子"><a href="#关键的缺失——高质量的例子" class="headerlink" title="关键的缺失——高质量的例子"></a>关键的缺失——高质量的例子</h2><p>当要学习某样特殊技术的时候，你是找官方的、正式的、长而无味的文档，还是去找一个精悍的例子？</p><p>当你能找到一个精确的示例来演示如何使用这样技术的时候，你几乎可以“瞬间”掌握这项技术。</p><p>你需要这些示例来让大脑自动地，潜意识地识别其中的模式。但现在的问题是，所有技术里又臭又长的文档很多，但短小精悍的示例很少。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0WGj.jpg" alt=""><br>所以是否可以利用社区的力量，将这些文档转换成一系列高质量的示例库呢？</p><p>以上就是在本次演讲中，Kathy想要传达给我们的内容。</p><h2 id="引申"><a href="#引申" class="headerlink" title="引申"></a>引申</h2><p>《庄子》中有这样一个故事：</p><blockquote><p>桓公读书于堂上，轮扁斫轮于堂下，释椎凿而上，问桓公曰：“敢问：“公之所读者，何言邪？”<br>公曰：“圣人之言也。”<br>曰：“圣人在乎？”<br>公曰：“已死矣。”<br>曰：“然则君之所读者，古人之糟粕已夫！”<br>桓公曰：“寡人读书，轮人安得议乎！有说则可，无说则死！”<br>轮扁曰：“臣也以臣之事观之。斫轮，徐则甘而不固，疾则苦而不入，不徐不疾，得之于手而应于心，口不能言，有数存焉于其间。臣不能以喻臣之子，臣之子亦不能受之于臣，是以行年七十而老斫轮。古之人与其不可传也死矣，然则君之所读者，古人之糟粕已夫。“</p></blockquote><p>真正的精髓，都在手上，而不在文档里。</p>]]></content>
      
      
      <categories>
          
          <category> ENG_talk </category>
          
      </categories>
      
      
        <tags>
            
            <tag> English </tag>
            
            <tag> Presentation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚4：什么是Pointer Aliasing</title>
      <link href="/2018/12/11/quickwords4-pointer-aliasing/"/>
      <url>/2018/12/11/quickwords4-pointer-aliasing/</url>
      
        <content type="html"><![CDATA[<h2 id="指向同一地址的两个相同类型的指针"><a href="#指向同一地址的两个相同类型的指针" class="headerlink" title="指向同一地址的两个相同类型的指针"></a>指向同一地址的两个相同类型的指针</h2><p><code>aliasing</code>本身是一个信号处理方面的概念。是指在信号采样过程中，不同的信号不再能相互区分的现象。</p><p>如下图所示的波纹现象，相对于拍摄的采样频率（横纵像素分辨率），墙砖缝隙变化的频率要大于采样频率。或者换句话说，多条墙砖缝隙需要挤在一个像素里面。<br><img src="https://svi.nl/wikiimg/StFargeaux_kasteel_buiten1_aliased.jpg" alt=""></p><a id="more"></a><p>同样的现象也会出现在程序员穿着“高密度”的格子衬衫接受电视采访时。</p><p>墙砖缝隙出现<code>aliasing</code>后无法再行区分，从字面意义来说，<code>Pointer Aliasing</code>就是不同的指针也无法区分。</p><p>指针无法区分，只有一种情况，就是指针的类型和指向的地址都是相同的，这就是<code>Pointer Aliasing</code>。</p><h2 id="为什么会有性能影响"><a href="#为什么会有性能影响" class="headerlink" title="为什么会有性能影响"></a>为什么会有性能影响</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> *<span class="built_in">array</span>, <span class="keyword">int</span> *size, <span class="keyword">int</span> *value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; *size; ++i) &#123;</span><br><span class="line">        <span class="built_in">array</span>[i] = <span class="number">2</span> * *value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果让我们自己“优化”一下这段代码，我们可能会首先将<code>value</code>指向的值存入一个临时变量里，然后将临时变量在循环中直接赋值给<code>array</code>。</p><p>我们假设个<code>array</code>的初始状态：<code>[0, 1, 2, 3, 4]</code></p><p>如果<code>value</code>指向的值等于3，那么按我们优化的方式，<code>array</code>最终的状态是：<code>[6, 6, 6, 6, 6]</code></p><p>但这里存在一个问题，如果<code>value</code>指向<code>array[3]</code>，那么<code>array</code>最终的状态就是：<code>[6, 6, 6, 12, 24]</code></p><p><code>value</code>和<code>array[3]</code>就是指向相同地址类型相同的指针。</p><p>编译器为了得到最终正确的结果，就不得不取消我们之前提到的”优化”方式。</p><h2 id="预防方法"><a href="#预防方法" class="headerlink" title="预防方法"></a>预防方法</h2><p>使用<code>__restrict</code>关键字：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> * __restrict <span class="built_in">array</span>, <span class="keyword">int</span> *__restrict size, <span class="keyword">int</span> *__restrict value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; *size; ++i) &#123;</span><br><span class="line">        <span class="built_in">array</span>[i] = <span class="number">2</span> * *value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然，前提是自己可以确定代码逻辑中不会引入<code>aliasing</code>。</p><h2 id="怎么使用"><a href="#怎么使用" class="headerlink" title="怎么使用"></a>怎么使用</h2><p>首先明确一点，不是加上了<code>__restrict</code>性能就会提升。</p><blockquote><p><code>Pointer aliasing</code>对性能根本的伤害不是需要每次重新去某个地址取值，而是因为引入了潜在的数据依赖关系，从而关闭了很多编译器优化代码的能力。</p></blockquote><p>上面两段代码，在<code>-O0</code>优化时生成的汇编代码(<code>gcc 4.8.5</code>)完全相同。不同的地方在于，第一段代码在<code>-O2</code>和<code>-O3</code>时生成的汇编代码仍然相同；而第二段做了<code>__restrict</code>处理的代码则会在<code>-O3</code>时加入大量循环展开等优化方式。</p><p>在线查看汇编代码：<a href="https://godbolt.org/z/2nXlNa" target="_blank" rel="noopener">链接</a></p><p>所以<code>__restrict</code>需要在打开较高等级的编译器优化的情况下使用才会有效果。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> CPU </tag>
            
            <tag> performance </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>产品观察1：华为FabricInsight产品简要分析</title>
      <link href="/2018/12/08/product1-huawei-fabricinsight/"/>
      <url>/2018/12/08/product1-huawei-fabricinsight/</url>
      
        <content type="html"><![CDATA[<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">最近机缘巧合之下接触到了华为FabricInsight这款产品，简要谈谈看法。</span><br><span class="line">只针对2018年8月份左右发布的版本。</span><br><span class="line">另外注意，在Google搜索相关资料的时候，记得要把Fabric Insight这两个单词合并在一起搜索，中间不要加空格，别问我怎么知道的。</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="信息采集"><a href="#信息采集" class="headerlink" title="信息采集"></a>信息采集</h3><h4 id="SNMP"><a href="#SNMP" class="headerlink" title="SNMP"></a>SNMP</h4><p>在使用FabricInsight之前需要配置华为设备的SNMP协议，主要作用为获取设备的MIB信息，<br>并进行其他管理操作。</p><h4 id="LLDP"><a href="#LLDP" class="headerlink" title="LLDP"></a>LLDP</h4><p>使能各设备的LLDP功能，以便FabricInsight据此（以及通过SNMP上送的MIB信息）绘制硬<br>件连接拓扑图。</p><h4 id="NetConf"><a href="#NetConf" class="headerlink" title="NetConf"></a>NetConf</h4><p>使能各设备的NetConf配置，以便FabricInsight能通过NetConf协议配置各设备的ERSPAN功<br>能。</p><h4 id="ERSPAN"><a href="#ERSPAN" class="headerlink" title="ERSPAN"></a>ERSPAN</h4><p>配置ERSPAN功能，destination IP配置为FabricInsight collector的地址。底层实现为：通过<br>GRE隧道的方式将远程设备的流量路由/镜像至分析节点，以实现对流量可视化分析。<br>ERSPAN可配置筛选特定的流量，并非全量镜像。从华为对交换机的配置： </p><pre><code class="shell">[~Device] observe-port 1​ destination-ip 10.10.10.20​ source-ip 10.1.1.1 [*Device] traffic-mirroring vxlan tag-format none tcp-flag fin syn rst observe-port 1 inbound [*Device] traffic-mirroring tcp-flag fin syn rst observe-port 1 inbound [*Device] commit</code></pre><p>通过ERSPAN镜像给FabricInsight的流量包括带有FIN/SYN/RST等TCP flag的网包。对应其<br>产品中对TCP事件的可视化能力。<br><em>注*：据此可以看出FabricInsight没有全量流量镜像&amp;分析能力</em><br><em>注*：命令中的vxlan可能是将流量通过vxlan封装，做三层转发，而非镜像全部vxlan流量</em></p><h4 id="Telemetry"><a href="#Telemetry" class="headerlink" title="Telemetry"></a>Telemetry</h4><p>华为的Telemetry指设备主动、以固定周期上报的一些设备信息，包括CPU\MEM\QUEUE等信<br>息。 </p><h4 id="手动录入"><a href="#手动录入" class="headerlink" title="手动录入"></a>手动录入</h4><p>主要为用户业务信息，每一个业务的定义为一组IP和某一固定端口号的集合，需要用户手工录<br>入。</p><p><img src="https://i.ytimg.com/vi/uVcXxn30qqY/maxresdefault.jpg" alt=""></p><h3 id="功能分类"><a href="#功能分类" class="headerlink" title="功能分类"></a>功能分类</h3><h4 id="Underlay拓扑可视化"><a href="#Underlay拓扑可视化" class="headerlink" title="Underlay拓扑可视化"></a>Underlay拓扑可视化</h4><p>依据LLDP生成及SNMP上报的信息，可生成Underlay设备间的拓扑信息。<br>流量事件统计<br>依据ERSPAN镜像的含有SYN\FIN\RST等flag的TCP网包，可统计一条流（五元组）中的事件<br>发生次数、时间及类型。并可据此进行简单的SYN重传、建立连接RTT、建连成功率分析。但<br>缺少对网流完整过程（e.g.流量传输数据总量、pps、整体平均时延等）的统计和分析。 </p><h4 id="设备信息统计"><a href="#设备信息统计" class="headerlink" title="设备信息统计"></a>设备信息统计</h4><p>根据Telemetry信息给出CPU\MEM等设备运行状态统计信息，以及对各网络端口IN/OUT总<br>量、drop、error数量等的统计信息。 </p><h4 id="应用流量分类过滤"><a href="#应用流量分类过滤" class="headerlink" title="应用流量分类过滤"></a>应用流量分类过滤</h4><p>其应用功能，本质为手动设置IP+端口号过滤规则，通过过滤的流量即为一个应用。应用间的<br>流量状态展现，即为在流量事件统计数据库中分别为起止两端的流量配置两个应用的过滤规则<br>，筛选出的流量即可作为应用间的流量状态展示。 </p><h2 id="FabricInsight特点"><a href="#FabricInsight特点" class="headerlink" title="FabricInsight特点"></a>FabricInsight特点</h2><h3 id="强绑定性"><a href="#强绑定性" class="headerlink" title="强绑定性"></a>强绑定性</h3><p>只能用于华为的硬件设备。并且后期会形成双向绑定，如若依赖FabricInsight，扩容时只能继<br>续采购华为设备。 </p><h3 id="基于流量事件"><a href="#基于流量事件" class="headerlink" title="基于流量事件"></a>基于流量事件</h3><p>对于流的分析仅涉及五元组和TCP流量事件。可依据SYN、FIN、RST等TCP流量事件完成<br>TCP SYN重传、RST等事件的侦测，并作为报警依据。 </p><h3 id="无流量全量分析"><a href="#无流量全量分析" class="headerlink" title="无流量全量分析"></a>无流量全量分析</h3><p>当前观察，仅有TCP流量的事件信息，对UDP、ICMP、ARP等网络流量无采集分析能力。仅<br>针对TCP流量，亦无流量全量分析能力，无法获取诸如流量总字节数、总包数、pps、平均时<br>延、最大时延等信息。</p><h3 id="Overlay能力暂无"><a href="#Overlay能力暂无" class="headerlink" title="Overlay能力暂无"></a>Overlay能力暂无</h3><p>当前FabricInsight宣称的可分析虚拟网络是指，手工指定某一虚拟网元（Virtual NE）IP地址<br>，手工指定其角色（e.g. FW\LB\Router）其与外界通讯的流量可以以与Underlay网络相同的<br>方式采集。<br>未发现针对虚拟网络VM间的采集分析能力。从其官方手册中针对ERSPAN的配置来看，可能<br>或未来会具有一定的VXLAN隧道解封装及关联对应能力。但即便如此，在大规模网络流量的<br>情况下，对全部VXLAN流量分析亦将为设备带来压力。<br>另外，主机内的虚拟网络流量，FabricInsight以现在的形式是绝对无法取得的。 </p><h2 id="FabricInsight未来演进趋势推测"><a href="#FabricInsight未来演进趋势推测" class="headerlink" title="FabricInsight未来演进趋势推测"></a>FabricInsight未来演进趋势推测</h2><h3 id="In-band-Telemetry"><a href="#In-band-Telemetry" class="headerlink" title="In-band Telemetry"></a>In-band Telemetry</h3><p>FabricInsight的数据采集能力全部来自于设备提供的能力。在设备/芯片领域的发展趋势是提<br>供更加精细化的In-band Telemetry遥测能力。从Cisco/Barefoot等厂商近期对P4芯片的动态来<br>看，华为跟风也是早晚的事。In-band Telemetry可以提供诸如per packet的全生命周期、匹配<br>的具体转发规则、更加精细的时间戳等能力。但如若采用新的芯片组提供In-band Telemetry<br>，则会仅支持新款产品。<br>除此之外，也将不仅仅将流量分析的范畴局限于TCP流量。 </p><h3 id="虚拟网络"><a href="#虚拟网络" class="headerlink" title="虚拟网络"></a>虚拟网络</h3><p>虚拟网络是行业演进的趋势，但需要考虑华为对FabricInsight这款产品本身的定位。如果添加<br>虚拟网络能力，则其品牌名称、目标人群都将会有较大调整。但华为整体上缺乏虚拟网络可视<br>化的产品和能力，因此推断会先对接华为自己的云平台FusionCloud，计算节点绑定探针。但<br>先期仍会仅采用TCP流量事件的分析模式，不会全量采集和分析。 </p><h3 id="AIops"><a href="#AIops" class="headerlink" title="AIops"></a>AIops</h3><p>AI的概念在当前版本的FabricInsight中已有所体现，但当前仅是一些标准差方差的统计计算。<br>演进的方式将是对网络中断和延迟的诊断以及自调优的赋能。但这种分析首先要求用户能够输<br>入一定的专家经验作为数据训练的标记，同时对分析节点的部署要求较高（支持大数据分布式<br>计算和存储）。 </p><h3 id="安全防御"><a href="#安全防御" class="headerlink" title="安全防御"></a>安全防御</h3><p>这是当前看起来最有实际效能的功能。其本身具有的TCP事件分析能力完全可以用来完成<br>DDoS攻击的侦测和防御。 </p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> product </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>可以预测交通路况的 APP</title>
      <link href="/2018/12/06/life-traffic-prediction/"/>
      <url>/2018/12/06/life-traffic-prediction/</url>
      
        <content type="html"><![CDATA[<blockquote><p>能不能有这样一款应用<br><a id="more"></a></p><p>或者地图 APP 实现这样一个功能</p><p>能通过历史路况大数据分析</p><p>告诉我今天晚上几点出发上路</p><p>东北四环不堵</p><p>把什么机器学习人工智能数字孪生</p><p>能加的都给它加上</p><p>感觉又是一个割 VC 韭菜的杀手应用</p><p>只要有人搭出来这个框架</p><p>我愿意帮忙实现所有的业务代码</p><p>因为只需要一句</p><p><code>return &quot;您期望的时间不存在&quot;</code></p></blockquote><p><em><em>2018.12.6</em></em></p>]]></content>
      
      
      <categories>
          
          <category> life </category>
          
      </categories>
      
      
        <tags>
            
            <tag> life </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去2：CPU缓存读入策略</title>
      <link href="/2018/12/06/test2-cache-line-alignment/"/>
      <url>/2018/12/06/test2-cache-line-alignment/</url>
      
        <content type="html"><![CDATA[<h2 id="到底哪些数据写入了CPU缓存"><a href="#到底哪些数据写入了CPU缓存" class="headerlink" title="到底哪些数据写入了CPU缓存"></a>到底哪些数据写入了CPU缓存</h2><p>我们知道CPU会在要读写某个数据时，先将数据写入缓存。</p><p>我们也知道这个操作一般以Cache Line为操作粒度，并且Cache Line的长度一般为64Byte。<br><a id="more"></a></p><p>那么这个Cache Line包含的数据到底是哪64Byte呢？</p><p>如果要读写的数据的地址正好以64Byte对齐，那么肯定是这个数据和它之后的<code>（64 - sizeof(数据)）</code>Byte存在于这个缓存行里。</p><p>但是如果要读写的这个数据地址不以64Byte对齐，而是在两个64Byte对齐的地址中间的某个位置，CPU写入Cache Line里的数据还是它和它之后的64Byte吗？CPU会“向前”对64取整作为Cache Line中的数据吗？</p><h2 id="用False-Sharing证明"><a href="#用False-Sharing证明" class="headerlink" title="用False Sharing证明"></a>用False Sharing证明</h2><p>根据之前介绍False Sharing的原理<a href="https://decodezp.github.io/2018/11/27/quickwords3-falsesharing/">链接</a>，通过判断是否发生False Sharing可以判断某两个数据是否存在于同一条Cache Line里。</p><p>构造如下结构体：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> front_padding[<span class="number">15</span>];</span><br><span class="line">    <span class="keyword">uint32_t</span> c1;</span><br><span class="line">    <span class="comment">/* 64 bytes */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> c2;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中<code>c1</code>和<code>c2</code>是分别被两个CPU core写入的变量。</p><p>在构造counter_t的实例时，利用<code>GCC attribute</code>确保其起始地址与64Byte对齐：</p><p><code>struct counter_t counter __attribute__((aligned(64)));</code></p><p>在两个CPU核分别开始操作<code>c1</code>和<code>c2</code>之前利用<code>clflush</code>指令清除所有相关缓存：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span></span><br><span class="line">clflush(<span class="keyword">volatile</span> <span class="keyword">void</span> *p)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span> <span class="params">(<span class="string">"clflush (%0)"</span> :: <span class="string">"r"</span>(p))</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>如果发生了False Sharing，则说明这两个变量在一个Cache Line里，则证明CPU是取欲读写变量及其之后64Byte数据写入缓存<br>如果没有发生False Sharing，则说明这两个变量不在一个Cache Line里，则证明CPU是取欲读写变量向前64取整地址上的数据写入缓存</p></blockquote><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>结果当然是没有发生False Sharing。</p><p>不然还搞什么n-way set associative :)</p><p>代码：<a href="https://github.com/PanZhangg/x86perf/blob/master/cache_line_alignment.c" target="_blank" rel="noopener">https://github.com/PanZhangg/x86perf/blob/master/cache_line_alignment.c</a></p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>魏孝文帝教你提proposal</title>
      <link href="/2018/12/05/history-tuobahong/"/>
      <url>/2018/12/05/history-tuobahong/</url>
      
        <content type="html"><![CDATA[<h2 id="艰难的Proposal"><a href="#艰难的Proposal" class="headerlink" title="艰难的Proposal"></a>艰难的Proposal</h2><p>每个人都有独自一人面对全世界的时候，即便你是魏孝文帝拓跋宏。</p><p>北魏太和十七年，承平日久的北魏都城里正在酝酿一件大事——迁都。<br><a id="more"></a></p><p>自天兴元年拓跋圭定都平城起，北魏在此地经营了九十余年。此时的平城，早已是北魏王公贵族富商巨贾的乐土。</p><p>而拓跋宏却不想在这呆了，对这位一心思慕华夏风仪的少数民族首领来说，城狭地偏的平城终究不是久居之地。</p><p>迁都，迁往洛阳，只有住在这座每块城砖上都写满了厚重的城邑的中心，才是北漂买房落户的那一刻。</p><p>但除了拓跋宏，没有人愿意当拆迁户，被连根拔起。拓跋宏自己也知道这一点。晓以大义？没用的，天底下最难的事，就是劝说别人放弃眼前的利益，去追求什么万世之业；</p><p>以皇帝的权威一意孤行？没有问题，但人心不齐，效果打折扣，既损威严，又于事无益。</p><p>那么迁都这个Proposal，到底怎么提呢？</p><h2 id="魏孝文帝的方式"><a href="#魏孝文帝的方式" class="headerlink" title="魏孝文帝的方式"></a>魏孝文帝的方式</h2><p>拓跋宏并没有在一开始就透露自己的意图，而是提出了一个更加”不得人心”的Proposal——亲自带队，攻打南朝。</p><p>如果说迁都不得人心，那么发动战争就更加让改革的主要阻力——深居平城的皇亲贵胄们如坐针毡。</p><p>因为迁都或许还可以讨论讨论，但南下伐齐“一统中国”那是北魏政权不容辩驳的“正统思想”，是政治正确，有拓跋氏列祖列宗的加持，以及冯太后的附魔。</p><p>这一年的八月，拓跋宏亲率三军开拔南下。</p><p>当然，皇帝都出去打仗了，除了太子监国以外，平日里的文武百官哪有在家呆着的道理，一起走吧！</p><p>从山西大同往南，大军在秋雨连绵的泥泞中走了整整一个月，终于到达了宿命的重点——洛阳。</p><p>这个时候所有人都不想再走了。一路的狼狈或可忍受，但后面还有与齐国的恶战。而拓跋宏依然兴致不减，号令即刻开拔，继续南进。</p><p>这下文武百官们可都要“犯颜进谏”了，纷纷叩头不止，甚至不惜死谏以请求拓跋宏停止南征。</p><p>这个时候拓跋宏才说出他真正的目的：</p><blockquote><p>今者兴动不小，动而无成，何以示后？苟欲班师，无以重之千载！朕世居幽朔，欲南迁中土，苟不南伐，当迁都于此，王公以为如何？欲迁者左，不欲者右！——《资治通鉴》</p></blockquote><p>这里有三个要素：</p><ol><li>我可以在南伐之事上让步</li><li>但我的让步有条件</li><li>不许考虑太久</li></ol><p>最终的结果自然是大家都站到了左边。迁都这件事，就这么“取得”了大家的同意。</p><p><img src="http://5b0988e595225.cdn.sohucs.com/images/20170720/b36a2fde600f4b909885b0a76ada9876.jpeg" alt=""></p><h2 id="抽象提取"><a href="#抽象提取" class="headerlink" title="抽象提取"></a>抽象提取</h2><p>在谈判领域存在一个让步/妥协的谈判技巧。</p><p>对每个人来说，如果对面已有所让步，那么心里将会产生同样让步的压力，趋向于同意对方提出的让步条件。</p><p>这种场景在生活中非常常见，例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">多少钱？</span><br><span class="line">100</span><br><span class="line">30吧</span><br><span class="line">最低90</span><br><span class="line">40</span><br><span class="line">低于85就赔本了</span><br><span class="line">你看我就50块钱</span><br><span class="line">行了80吧，今天好不容易开张</span><br></pre></td></tr></table></figure><p>如果能成交，说明买家和卖家一开始的心理价位就都是80元左右，但买家必须要首先压到30，卖家也要提到100，互相留出这个让步的空间。</p><p>也许你觉得这种技巧太市侩，但它其实有很多变种版本，也许自己已经身堕瓠中而不自知。<br>E.g.<br>房产中介请你看房，首先是一间各方面条件都很差的房间，但却有一个让你惊讶的高额租金。然后带你看了一套各方面比第一间好非常多的房间，租金却和第一间一样，或者略多而已。<br>如此你会觉得租了第二间是占了便宜。但其实中介的目标就是租给你第二间房，第一间就是让你产生这种对比让步的错觉的。</p><p>所以，每当打算提一个艰难的Proposal的时候，我都会效仿这种形式。</p>]]></content>
      
      
      <categories>
          
          <category> history </category>
          
      </categories>
      
      
        <tags>
            
            <tag> history </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ftrace uprobe使用填坑历程</title>
      <link href="/2018/12/04/ftrace-uprobe/"/>
      <url>/2018/12/04/ftrace-uprobe/</url>
      
        <content type="html"><![CDATA[<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>打算用一下<code>ftrace</code>对用户态程序的trace支持。</p><h3 id="测试用程序test-c："><a href="#测试用程序test-c：" class="headerlink" title="测试用程序test.c："></a>测试用程序<code>test.c</code>：</h3><a id="more"></a><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">print_curr_state_one(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is the print current state one function\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">print_curr_state_two(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is the print current state two function\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        print_curr_state_one();</span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">        print_curr_state_two();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="编译："><a href="#编译：" class="headerlink" title="编译："></a>编译：</h3><p><code>gcc -o test test.c</code></p><h3 id="Obtain-Offset："><a href="#Obtain-Offset：" class="headerlink" title="Obtain Offset："></a>Obtain Offset：</h3><p><code>objdump -d test</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">000000000040055d &lt;print_curr_state_one&gt;:</span><br><span class="line">  40055d:55                   push   %rbp</span><br><span class="line">  40055e:48 89 e5             mov    %rsp,%rbp</span><br><span class="line">  400561:bf 30 06 40 00       mov    $0x400630,%edi</span><br><span class="line">  400566:e8 c5 fe ff ff       callq  400430 &lt;puts@plt&gt;</span><br><span class="line">  40056b:5d                   pop    %rbp</span><br><span class="line">  40056c:c3                   retq   </span><br><span class="line"></span><br><span class="line">000000000040056d &lt;print_curr_state_two&gt;:</span><br><span class="line">  40056d:55                   push   %rbp</span><br><span class="line">  40056e:48 89 e5             mov    %rsp,%rbp</span><br><span class="line">  400571:bf 60 06 40 00       mov    $0x400660,%edi</span><br><span class="line">  400576:e8 b5 fe ff ff       callq  400430 &lt;puts@plt&gt;</span><br><span class="line">  40057b:5d                   pop    %rbp</span><br><span class="line">  40057c:c3                   retq</span><br></pre></td></tr></table></figure><p>添加uprobe trace event：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 'p:print_current_state_one /root/test/uprobe/uprobe:0x55d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_events</span><br><span class="line">echo 'p:print_current_state_two /root/test/uprobe/uprobe:0x56d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_events</span><br></pre></td></tr></table></figure><p>有时会出现Invalid argument的错误。用<code>sudo su</code>获取<code>root</code>权限。</p><blockquote><p>这里注意，偏移的大小只写0x55d，不能写0x40055d</p></blockquote><h2 id="开启trace"><a href="#开启trace" class="headerlink" title="开启trace"></a>开启trace</h2><p>先启动<code>test</code>程序：<code>./test</code></p><p><code>echo 1 &gt; /sys/kernel/debug/tracing/event/enable</code></p><p>如果此时<code>cat /sys/kernel/debug/tracing/event/enable</code>显示为<code>X</code></p><p><code>echo 1 &gt; /sys/kernel/debug/tracing/event/uprobes/enable</code></p><p>最后<code>cat /sys/kernel/debug/tracing/trace</code>应该就能看到了</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> ftrace </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ftrace trace-cmd kernelshark资料汇总</title>
      <link href="/2018/11/30/ftrace/"/>
      <url>/2018/11/30/ftrace/</url>
      
        <content type="html"><![CDATA[<p>一些关于这一类技术的资料和文档汇总。<br>文章中可以找到比较详细的工具使用方法。如果想了解更多内容可以阅读<code>linux/Documentation/trace</code>下的文档以及源码。</p><p>以及<code>git log ./kernel/trace</code> :)<br><a id="more"></a></p><h2 id="ftrace"><a href="#ftrace" class="headerlink" title="ftrace"></a>ftrace</h2><ul><li><a href="https://lwn.net/Articles/365835/" target="_blank" rel="noopener">Debugging the kernel using Ftrace - part 1</a></li><li><a href="https://lwn.net/Articles/366796/" target="_blank" rel="noopener">Debugging the kernel using ftrace - part 2</a></li><li><a href="https://www.kernel.org/doc/Documentation/trace/ftrace.txt" target="_blank" rel="noopener">Kernel Documents: ftrace</a></li><li><a href="https://lwn.net/Articles/370423/" target="_blank" rel="noopener">Secrets of the Ftrace function tracer</a></li><li><a href="https://people.canonical.com/~acelan/coscup-2010/Debugging%20Linux%20Kernel%20by%20Ftrace.pdf" target="_blank" rel="noopener">PDF:Debugging Linux Kernel by ftrace</a></li><li><a href="https://opensourceforu.com/2010/11/kernel-tracing-with-ftrace-part-1/" target="_blank" rel="noopener">Kernel Tracing with ftrace, Part 1</a></li><li><a href="http://opensourceforu.com/2010/12/kernel-tracing-with-ftrace-part-2/" target="_blank" rel="noopener">Kernel Tracing with ftrace, Part 2</a></li><li><a href="https://jvns.ca/blog/2017/03/19/getting-started-with-ftrace/" target="_blank" rel="noopener">ftrace: trace your kernel functions!</a></li><li><a href="https://movaxbx.ru/2018/10/12/hooking-linux-kernel-functions-how-to-hook-functions-with-ftrace/" target="_blank" rel="noopener">Hooking Linux Kernel Functions, how to Hook Functions with Ftrace</a></li><li><a href="https://www.slideshare.net/ennael/kernel-recipes-2017-understanding-the-linux-kernel-via-ftrace-steven-rostedt" target="_blank" rel="noopener">Understanding the Linux kernel via ftrace</a></li></ul><h2 id="trace-cmd"><a href="#trace-cmd" class="headerlink" title="trace-cmd"></a>trace-cmd</h2><ul><li><a href="https://lwn.net/Articles/410200/" target="_blank" rel="noopener">trace-cmd: A front-end for Ftrace</a></li><li><a href="https://github.com/rostedt/trace-cmd" target="_blank" rel="noopener">Code:trace-cmd</a></li></ul><h2 id="kernelshark"><a href="#kernelshark" class="headerlink" title="kernelshark"></a>kernelshark</h2><ul><li><a href="https://lwn.net/Articles/425583/" target="_blank" rel="noopener">Using KernelShark to analyze the real-time scheduler</a></li><li><a href="https://kernel-recipes.org/en/2018/talks/kernelshark-1-0-whats-new-and-whats-coming/" target="_blank" rel="noopener">Video:KERNELSHARK 1.0; WHAT’S NEW AND WHAT’S COMING</a></li><li><a href="https://www.youtube.com/watch?v=RwVnnuGrb_c" target="_blank" rel="noopener">Video:Yordan Karadzhov - What’s Coming in Kernel Shark</a></li><li><a href="https://events.linuxfoundation.org/wp-content/uploads/2017/12/Swimming-with-the-New-KernelShark-Yordan-Karadzhov-VMware.pdf" target="_blank" rel="noopener">PDF:Swimming with the New KernelShark</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> ftrace </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去1：DPDK no-huge模式性能对比测试</title>
      <link href="/2018/11/29/test1-dpdk-no-huge/"/>
      <url>/2018/11/29/test1-dpdk-no-huge/</url>
      
        <content type="html"><![CDATA[<h2 id="no-huge"><a href="#no-huge" class="headerlink" title="no-huge"></a>no-huge</h2><p>DPDK使用大页内存作为性能优化的一个手段。但大页内存在云计算等环境下可能会出现内存资源浪费的情况，作为售卖资源的云服务商，希望能找到更充分的内存资源利用的方法。在此背景下，DPDK引入了no-huge机制，即不使用hugepage，从而解放更多的系统资源。</p><p>那么这种配置下DPDK性能会下降多少呢？还是需要实际定量测试一下。<br><a id="more"></a></p><h2 id="测试平台"><a href="#测试平台" class="headerlink" title="测试平台"></a>测试平台</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                88</span><br><span class="line">On-line CPU(s) list:   0-87</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    22</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 85</span><br><span class="line">Model name:            Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHz</span><br><span class="line">Stepping:              4</span><br><span class="line">CPU MHz:               2100.393</span><br><span class="line">BogoMIPS:              4201.72</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              30976K</span><br><span class="line">NUMA node0 CPU(s):     0-21,44-65</span><br><span class="line">NUMA node1 CPU(s):     22-43,66-87</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep Ether</span><br><span class="line">86:00.0 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.1 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.2 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.3 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br></pre></td></tr></table></figure><p>DPDK Version: <code>18.05.1</code><br>Tester: IXIA<br>Test Plan: RFC2544<br>DPDK APP: <code>./l2fwd -l 22-24 --no-huge  -- -p 0x3 -T 5</code></p><h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p><img src="https://s1.ax1x.com/2018/11/29/FZIYcT.png" alt=""></p><p>在64Byte包长时丢包率达到了50%以上，而使用大页内存时丢包率可以控制在0.05%以内。<br>其他长度丢包和吞吐情况基本相同。<br>根据业务情况，平均包长如果在300Byte以上–no-huge模式不妨一试。<br>后续添加针对更大链路带宽(25Gbps/100Gbps)的网卡以及不同Xeon平台的测试结果。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> dpdk </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>云计算的发展需要向社区街道管理看齐</title>
      <link href="/2018/11/28/thoughts1-cloud-community/"/>
      <url>/2018/11/28/thoughts1-cloud-community/</url>
      
        <content type="html"><![CDATA[<h2 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h2><p>云计算本质上是一种服务。由各种不同的组件为租户提供计算、网络和存储服务。</p><p>用户对这些服务的要求除了功能之外，还有安全性、可用性、性能、成本、迁移难度、SLA等一系列要求。</p><p>与之类比，社区街道作为一个完整的功能单元，各个基层职能部门，也为社区内的居民提供各类生活服务。</p><p>如何做好基层工作，是需要费一番脑筋的。<br><a id="more"></a></p><h2 id="服务网格"><a href="#服务网格" class="headerlink" title="服务网格"></a>服务网格</h2><p>下图是我在北京中关村某社区拍到的当地派出所的“网格团队”成员和工作职责。</p><p><img src="https://s1.ax1x.com/2018/11/28/FV0v3q.jpg" alt=""><br>如果你熟悉云计算，熟悉当前的领先理念，那么<code>service mesh</code>这个词你肯定不陌生，这是当前容器和微服务领域的最新热点，拥有Istio、Envoy等一众明星开源项目，并且有Google、AWS、Alibaba等大佬拥趸。这个词翻译过来就是<code>服务网格</code>。</p><p>而社区街道提出的这个“网格”的概念，明显领先于自诩为科技前沿的云计算。</p><p>如果仔细阅读一下上图中的“工作职责”，就能够轻易地将其内容与时下云计算和企业数字化转型热炒的概念对应起来：</p><ul><li>管理网格单元：Microservice微服务</li><li>落实基信息采集：Digital Twin数字孪生</li><li>综合网格力量：Orchestration协同</li><li>加强依法自治：Decouple解耦/Distrubute分布式</li><li>排查隐患：Situational Awareness态势感知/Active Defence主动式防御</li><li>协调解决社会服务管理中存在的问题：Full Stack Management全栈管理</li><li>推进公共服务建设：Aglie敏捷/DevOps</li><li>监督管理网格力量，督促责任落实：Sidecar</li><li>及时上报网格工作数据：Telemetry遥测</li><li>完成街道交办的其他工作：Serverless无服务器</li></ul><p>总结就是这个街道派出所就是Community-Native Microservice &amp; Service Mesh &amp; Serverless &amp; Security的典范，理念领先云计算至少5年。</p><h2 id="好好学习"><a href="#好好学习" class="headerlink" title="好好学习"></a>好好学习</h2><p>为什么街道派出所的理念能领先云计算的发展？道理都是殊途同归的，很多理念（经验）的获得都是靠积攒年头。</p><p>云计算方兴未艾，但毕竟用户还不足够多，问题暴露还不足够全面，或者说，没太多管理经验。而派出所展开基层管理工作的时间至少比在坐的诸位岁数都长。同时基层群众形形色色，就像软件测试时的边界条件，绝对都能满足。</p><p>在此种“得天独厚”的条件下总结出的经验，云计算从业者除了好好消化吸收之外，也可以小小的自鸣得意一下，毕竟你仅仅用了10年就追上了街道派出所。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
            <tag> tech </tag>
            
            <tag> cloud </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚3:什么是False Sharing</title>
      <link href="/2018/11/27/quickwords3-falsesharing/"/>
      <url>/2018/11/27/quickwords3-falsesharing/</url>
      
        <content type="html"><![CDATA[<h2 id="不用图"><a href="#不用图" class="headerlink" title="不用图"></a>不用图</h2><p>以为又要见到那几张网上已经用烂了的图了是不是？这次我们不用图来讲这个事。<br><a id="more"></a></p><p>Cache line是64个Byte，我们经常操作(R/W)的变量是4个或者8个Byte。</p><p>于是一个Cache line里就可以放好几个变量，比如说其中有两个变量A和B。</p><p>当CPU0写入A，CPU1写入B的时候，就发生了False Sharing，就这么简单。</p><p>所谓“假共享”，其实就是你以为你俩自己操作自己的变量是共产国际按需分配互不影响，其实都是假象。</p><p>很多材料上说是因为不同的CPU核共享了相同的Cache Line，其实并不严谨。根本因素是不同的CPU核需要更新的缓存出现了地址上的重叠。</p><p>那么当其中一个核更新了它的变量A之后，CPU并不能识别出是哪4个Byte或8个Byte地址上的数据被更新，而只能认为该变量所在的整条64Byte Cache Line都应该被更新。</p><p>所有有和这64Byte重叠的Cache Line，不管在哪个CPU核上，都需要被更新，这样才能保证大家手头的数据是一致的。</p><p>于是乎，和这64Byte地址存在重叠的变量B所在的CPU1中的缓存也需要被更新，自然就影响到了性能。</p><p>如果只是读，就没有这个问题，因为不需要关心缓存一致这个事。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>这里有一个活生生的代码的例子：</p><p><a href="https://github.com/PanZhangg/x86perf/blob/master/false_sharing_padding.c" target="_blank" rel="noopener">https://github.com/PanZhangg/x86perf/blob/master/false_sharing_padding.c</a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> c1;</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifdef</span> PADDING_64_BYTE</span></span><br><span class="line">    <span class="keyword">uint32_t</span> padding[<span class="number">15</span>];</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">elif</span> PADDING_128_BYTE</span></span><br><span class="line">    <span class="keyword">uint32_t</span> padding[<span class="number">31</span>];</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">uint32_t</span> c2;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>本来是打算用来验证在CPU预取开启的情况下到底是应该Padding 64还是128，但在Haswell和Skylake上验证，这两个长度都没有区别。</p><p>后来查找资料是在Sandy bridge上需要padding到128，但我这里没有这么老的CPU….先这样吧..</p><p>上面的代码注意用<code>-O0</code>编译。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚2:CPU缓存的组织形式</title>
      <link href="/2018/11/25/quickwords2-cacheassociativity/"/>
      <url>/2018/11/25/quickwords2-cacheassociativity/</url>
      
        <content type="html"><![CDATA[<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>缓存和其他存储形式在功能形式上没有太大区别，均是输入一个地址，还你一个数据。但作为一个缓存，要考虑如何在有限的容量下保证较高的命中率以及查找效率(<a href="https://decodezp.github.io/2018/11/20/cachesize/">相关阅读</a>)。这个问题从本质上来说，就是如何建立缓存地址与内存地址的映射关系。</p><a id="more"></a><h2 id="组织形式"><a href="#组织形式" class="headerlink" title="组织形式"></a>组织形式</h2><p>缓存按照一个Cache Line的长度（主流长度为64Byte）为粒度来组织：</p><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140538/481_051.gif" alt=""><br>各种不同的映射形式就是在决定内存中某一个特定地址范围内的数据，具体可以放到哪一个Cacha Line里去。</p><p>能想出来的方式也无外乎三种：</p><ul><li>哪个都可以放</li><li>只能放到第N个（N是内存地址的函数）</li><li>只能放到第N个至第M个（M也是内存地址的函数）</li></ul><blockquote><p>其实基本上这篇文章可以结束了，很多技术都不是什么新鲜的“创想”，只是给朴素的思想内核穿上了一层“术语”的外衣。</p></blockquote><h3 id="Direct-Mapping"><a href="#Direct-Mapping" class="headerlink" title="Direct Mapping"></a>Direct Mapping</h3><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140525/481_061.gif" alt=""><br>这就是上面说的第二种方式，某一个内存地址段的数据，只能放在第N个Cache Line里</p><ul><li>Pros:查找快，一次寻址，有就是有，没有就是没有，不啰嗦（因为只需要验证一个Cache Line中是否存在该地址）</li><li>Cons:命中率低，CPU经常需要相邻地址的数据，而根据规则，同属于第N个Cache Line的数据会互相排斥，不会同时出现在缓存里</li></ul><h3 id="Fully-Associative"><a href="#Fully-Associative" class="headerlink" title="Fully Associative"></a>Fully Associative</h3><p>这就是第一种方式，随便放。</p><ul><li>Pros:命中率高，过去和未来一段时间内需要的数据都可以被放在缓存内，同时不用担心被相邻地址上的数据踢出</li><li>Cons:查找慢，确认一个地址是否在缓存里通常需要遍历整个缓存（Miss的情况）</li></ul><h3 id="n-Way-Set-Associative-Cache"><a href="#n-Way-Set-Associative-Cache" class="headerlink" title="n-Way Set Associative Cache"></a>n-Way Set Associative Cache</h3><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140450/481_081.gif" alt=""><br>这就是第三种方式了，颜色相同的内存地址范围和缓存Cache Line互相对应，不能越界。每一个颜色就是一个Way。</p><p>但如果单独拿出某一个颜色来看，是Fully Associative的方式。</p><p>这么做当然是为了充分发挥前两种方式的优势。既可以存在相邻内存中的数据以提高命中，同时也一定程度上减少了查找范围，提升查找效率。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>XXV710网卡Target Link Speed探秘</title>
      <link href="/2018/11/23/x710-target-link-speed/"/>
      <url>/2018/11/23/x710-target-link-speed/</url>
      
        <content type="html"><![CDATA[<h2 id="发现"><a href="#发现" class="headerlink" title="发现"></a>发现</h2><p>用lspci指令查看PCIe设备，特别是网卡设备经常会查看LnkCap及LnkSta字段，以确保网卡运行在期望的PCIe总线类型/带宽上，从而保证网卡的性能。</p><p>最近拿到一块XXV710-DA2，插上之后简单看了一下状态。LnkCap和LnkSta均显示为Speed 8GT/s，Width x8，没太大问题。这时候无意中瞥见LnkCtl2中Target Link Speed显示为2.5GT/s，引发了兴趣。<br><a id="more"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</span><br><span class="line">DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not Supported</span><br><span class="line">DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled</span><br><span class="line">LnkCtl2: Target Link Speed: 2.5GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB</span><br></pre></td></tr></table></figure><h2 id="Target-Link-Speed"><a href="#Target-Link-Speed" class="headerlink" title="Target Link Speed"></a>Target Link Speed</h2><p>关于Target Link Speed是什么，查找到了Intel Skylake Processor External Design Specification(EDS)中的定义：</p><blockquote><p>For Downstream Ports, this field sets an upper limit on Link operational speed by restricting the values advertised by the Upstream component in its training sequences.</p></blockquote><p>基本上LnkCap表示支持的速度，LnkCtl2设置你需要的速度，LnkSta显示实际Training好的速度，如果想要修改的话，都是改LnkCtl2的值。</p><p>现在的问题就是LnkSta和LnkCtl2矛盾。那么我们现在这块网卡的速度到底是多少？只能实际测试一下。</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>起个<code>pktgen</code>打个性能，是能直接到线速的，也就是说Target Link Speed没有实际起到限制速度的作用。</p><p>又查询了一些资料，从这里看到一个帖子：<a href="https://communities.intel.com/thread/106568" target="_blank" rel="noopener">https://communities.intel.com/thread/106568</a></p><p>最终Intel的官方回复是，这个寄存器的值确实和实际速度没有关系。</p><p>规范也是你们写的，帖子也是你们回的，现在正话反话都让你说了，搞什么鬼。</p><p>最后查到了该寄存器的位置(D0h)，暴力修改一下：</p><p><code>setpci -s 0000:18:00.0 d0.B=3</code></p><p>然后就乖乖地显示为8GT/s了，真是个毫无脾气的寄存器，你让别的遵守规范的设备如何自处。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</span><br><span class="line">DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not Supported</span><br><span class="line">DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled</span><br><span class="line">LnkCtl2: Target Link Speed: 8GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序员和工厂劳工有何不同</title>
      <link href="/2018/11/22/programmer-worker/"/>
      <url>/2018/11/22/programmer-worker/</url>
      
        <content type="html"><![CDATA[<p>如今流行的一个说法是，现在的程序员与工业时期的工厂工人并无二致。<br>均是富集于人口密集的城市、均是超时劳动、均是遭受资本家的盘剥、均是一架大机器上的螺丝钉，在超过“劳动年龄”之后被弃如敝屣。<br>基于这些相似点，有些人得出结论，程序员不过是这个时代的“无产阶级”，和以前的流水线工人，纺织厂女工属于同一社会分工和定位。<br>是否当真如此，这个问题值得仔细推敲一下。<br><a id="more"></a></p><h2 id="生产资料"><a href="#生产资料" class="headerlink" title="生产资料"></a>生产资料</h2><p>个人所处的社会阶层，取决于他能让属于他的生产资料产生的价值。传统的生产资料包括实体的机器、厂房、地皮、原材料、资本和人等等。<br>而作为信息时代的标志，人人都可以通过网络获取一项虚拟的生产资料——信息。诚然，信息壁垒依然存在，但普通人能接触到的信息总量和质量与信息革命之前的时代相比已不可同日而语。<br>程序员是与电子计算设备打交道的人，此类设备本质上是信息的产生、加工和分发工具。一台电脑加一条网线，程序员就可以以极其低廉的方式获得他所需要的生产资料。而拥有生产资料的人，就不能再称之为“无产阶级”。<br>我们已经听过了太多程序员在车库创业的故事，也许这些故事仍然可以称之为“个例”，毕竟，哪个时代没有一些白手起家的人。<br>但如果某个行业能在全社会掀起创业的热潮，那么就不能再以孤例的眼光看待。只有在该行业的生产资料极大丰富，且对再加工之后的产品有持续需求的情况下才有可能出现这类情况。<br>是否能以足够廉价的方式获取生产资料，是程序员与工厂工人的第一个区别。<br><img src="http://www.xinhuanet.com/politics/2015-05/05/127763760_14307851178281n.jpg" alt=""></p><h2 id="对生产资料的再分工"><a href="#对生产资料的再分工" class="headerlink" title="对生产资料的再分工"></a>对生产资料的再分工</h2><p>注意这里强调的是再“分”工，而不是再加工。<br>程序员能够开发出各种程序满足人们的需求，工人也能生产出各种生活必需品，所以在生产资料再加工这一点上，两者没有本质区别。<br>专业细分是社会生产率提高的根本因素。每个人只负责整条产业链中的一环，愈发细致的分工与合作是现代生产活动的组织方式。<br>程序员和工人均为某一细分领域的专家，但二者所处的分工链条深度不同。<br>工人是分工链条的末端，他所能做的就是尽自己所能做好手头的事情。<br>而程序员虽然仍然要听老板的，但他手下仍有电子设备作为分工的最后一环。<br>程序员可以通过编码为这些电子设备“分工”，从而令其为程序员服务。<br>从某种意义上说，程序员就是这些电子设备的“老板”。同时随着设备的计算能力越来越强，这些设备就能逐渐胜任更加精细的分工任务。<br>随着分工的深入，一方面带动社会整体劳动生产率的提升，一方面更加高效地产生价值。<br>一个大型工厂的老板最多能令数万工人为其服务，而所有能跑代码的设备都可能为程序员服务。<br>在分工链所处的位置和对生产资料的再分工能力，是程序员与工厂工人的第二个区别。<br><img src="http://s2.51cto.com/oss/201811/05/d0c5758831b1df8bcac6728d848e014a.jpg-wh_651x-s_1764483471.jpg" alt=""></p><h2 id="程序员如何度过”中年危机”"><a href="#程序员如何度过”中年危机”" class="headerlink" title="程序员如何度过”中年危机”"></a>程序员如何度过”中年危机”</h2><p>其实程序员是新时代的工厂工人这种论调，只不过是之前“青春饭”、“过了30岁不能再编程“等论调的新瓶装旧酒而已。<br>但程序员面对的现实压力确实是不容忽视的问题。很多人学了很多技术，掉了很多头发，但最后仍被公司扫地出门，问题就在于做了无用的努力。<br>解决之道其实就蕴含在前文论述的两点之内：</p><ul><li>尽可能占有(处理)更多的生产资料——信息</li><li>为尽可能多的电子设备”分工”</li></ul><p>实际执行的术便是一定要有自己的“产品”。<br>这当然是一个程序，可以是公司的产品，也可以是个人作品。但需要关注两个关键点：</p><ul><li>我的程序是否位于信息交叉的节点或能协助信息的获取、处理及分发</li><li>运行我的程序的设备是否在增长</li></ul><p>可以看看这些久盛不衰的“产品”：操作系统、数据库、浏览器、服务器软件、办公处理、图像应用处理等等甚或编程语言本身，都是这两个关键点的很好的体现。<br>当你拥有这样的产品时，操心的就不是公司会不会要你了，而是如何高效地指挥你自己这支被你分工的生产队，实践一些大胆的想法。<br>最后附上我最喜欢的历史名人名言作为结尾：</p><blockquote><p>臣但恐富贵来逼臣，臣无心图富贵。</p></blockquote><p>——杨素</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚1:为什么CPU L1缓存容量始终很小</title>
      <link href="/2018/11/20/cachesize/"/>
      <url>/2018/11/20/cachesize/</url>
      
        <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>CPU缓存是影响软件性能的关键因素之一。在做性能调优时，经常关注的一个指标就是缓存的命中率(hit rate)。<br>缓存之所以不会达到100%的命中率，是因为缓存容量有限，不能将内存中的全部数据都同时放入其中。只能将当前最热，相邻最近的数据存入，同时还受多核CPU中缓存同步机制的影响。<br>奇怪的是，CPU的制程、晶体管数量、核心数量一直都在增加，但L1缓存的容量始终维持在一个相当低的水平。为什么不加大L1缓存呢？<br><a id="more"></a></p><p><img src="https://cenalulu.github.io/images/linux/cache_line/latency.png" alt=""></p><h2 id="缓存组织形式"><a href="#缓存组织形式" class="headerlink" title="缓存组织形式"></a>缓存组织形式</h2><p>当然要考虑到成本和功耗，以及边界效益的问题，但这些不是本文讨论的重点。<br>缓存存在的意义是当CPU需要某些数据时，能够以最快的速度给它。<br>这个速度是以CPU时钟周期为计量单位的。在这一个周期内，CPU能处理的数据量并不大。<br>作为L1缓存，首先需要做的就是把这几个周期内的数据保存好，这个确实缓存容量越大，可以做得越好。<br>但把数据喂给CPU，还需要另外一步工作——缓存的查找。<br>种种不同的缓存组织方式和对应的查找机制，其实是在命中率以及查找效率中寻找平衡。</p><p><img src="https://cs.nyu.edu/~gottlieb/courses/2000s/2007-08-fall/arch/lectures/diagrams/cache-set-assoc.png" alt=""></p><ul><li>直接映射(Direct Mapping)查找效率高，但命中率很低</li><li>全关联映射(Fully Associative Mapping)命中率会提高，但查找效率非常低，与缓存容量成反比</li><li>N路组相联映射(N-ways Set-Associative Mapping)折衷方案，平衡命中率和查找效率，也是缓存采用的组织方式</li></ul><h2 id="L1"><a href="#L1" class="headerlink" title="L1$"></a>L1$</h2><p>对L1缓存来说，任务很艰巨，既要追求命中率，同时也要保证查找效率，那么解决方法就是缩小体积。既享受N-ways Set-Associative Mapping带来的命中率，同时因为每个Set的尺寸不大，仍然会有很高的查找效率。<br>如果将缓存的容量增大，不仅仅是成本和功耗上得不偿失，也将会让缓存的查找效率降低而使缓存丧失意义。</p><p>“大曰逝，逝曰远，远曰反”，以退为进，以曲为直的道理在缓存中有了很好的体现。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>top命令使用方法补遗</title>
      <link href="/2018/11/19/topcmd/"/>
      <url>/2018/11/19/topcmd/</url>
      
        <content type="html"><![CDATA[<h2 id="更改界面刷新频率"><a href="#更改界面刷新频率" class="headerlink" title="更改界面刷新频率"></a>更改界面刷新频率</h2><ul><li>自动刷新</li></ul><p><code>top</code><br><code>d</code><br>输入刷新时间（默认3秒，可调至0.5）</p><ul><li>手动刷新<br>空格</li></ul><a id="more"></a><h2 id="屏幕滚动"><a href="#屏幕滚动" class="headerlink" title="屏幕滚动"></a>屏幕滚动</h2><p>一个屏幕显示不完<br><code>C</code><br>使用方向键滚动</p><p>可用在使用<code>c</code>和<code>V</code>开启命令行及Forest view之后</p><h2 id="查看线程top信息"><a href="#查看线程top信息" class="headerlink" title="查看线程top信息"></a>查看线程top信息</h2><p><code>H</code></p><h2 id="查看线程CPU绑定-亲和性状态"><a href="#查看线程CPU绑定-亲和性状态" class="headerlink" title="查看线程CPU绑定/亲和性状态"></a>查看线程CPU绑定/亲和性状态</h2><p><code>F</code><br>移动光标至<code>Last Used Cpu</code><br>空格<br><code>q</code>返回</p><p>与<code>H</code>配合使用<br>可观察各线程是否与对应的CPU核绑定亲和性</p><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p><code>M</code>按驻留内存大小排序<br><code>P</code>按CPU使用率排序<br><code>T</code>按累计时间排序<br><code>x</code>高亮排序的列</p><h2 id="按NUMA查看CPU使用情况"><a href="#按NUMA查看CPU使用情况" class="headerlink" title="按NUMA查看CPU使用情况"></a>按NUMA查看CPU使用情况</h2><p><code>2</code>查看各NUMA节点CPU汇总使用信息<br><code>3</code>输入节点号，查看该节点各CPU使用信息</p><h2 id="按条件过滤"><a href="#按条件过滤" class="headerlink" title="按条件过滤"></a>按条件过滤</h2><p>‘O’<br>输入过滤条件，如:<br><code>!COMMAND=top</code> COMMAND栏中不包含top<br><code>%CPU&gt;3.0</code> CPU占用率大于3%<br>清除全部过滤条件 <code>=</code></p><h2 id="保存当前命令配置"><a href="#保存当前命令配置" class="headerlink" title="保存当前命令配置"></a>保存当前命令配置</h2><p><code>W</code><br>下次再启动时恢复当前配置形式</p><h2 id="其他信息"><a href="#其他信息" class="headerlink" title="其他信息"></a>其他信息</h2><p><code>man top</code></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>刚日读经，柔日读史</title>
      <link href="/2018/11/18/gangrirouri/"/>
      <url>/2018/11/18/gangrirouri/</url>
      
        <content type="html"><![CDATA[<p>在不知道什么时候，我们似乎被灌输了一种互补好，什么都是互补好的认知。<br>资源要互补，团队要互补，思想要互补，连看个书也得掐着日子互补。</p><a id="more"></a><p>刚日读经，柔日读史，“刚日”就是阳数的日子，“柔日”就是阴数的日子。因为阴阳要互补，所以刚日要读致虚守弱恒常静笃的经；柔日便要读变动不居周行不殆的史。<br>为此还有各位理论导师的笺注，比如南怀瑾：</p><blockquote><p>亢阳激扬，刚也；卑幽忧昧，柔也。经主常，史主变。故刚日读经，理气养生也；柔日读史，生情造意也。有生有息，合乎天理，何乐而不为哉！</p></blockquote><p>感觉并不如我总结得那般言简意赅提要钩玄。<br>如果说这种“互补”确实在指导我们的行为，那也无可厚非。而实际上我们日常行事，却和这种思想观念有很大出入。<br>饮食上要以形补形，想要强要壮，自然是找来更强更壮的，绝对不会找短小“互补”的食材。<br>婚嫁上要强强联合，至少至少也要找个“门当户对”的。至于相互互补的情节，不是出现在少儿童话故事里，就是出现在成人童话故事里。<br>嘴里说的是阴阳互补，做的却是采阴补阳的勾当。<br>而最重要的是，没有人觉得有问题。我们妄自接受了这些观念，很少去问这些到底是什么。只是在需要的场合，程式化地提出这一观念。<br>什么是互补，什么是阴，什么是阳，什么是刚，什么是柔。如果我脑中只是一些不明来源，未经考究过的观念，那么什么是我自己。<br>更诡吊的是，人与人之间最大的仇恨与惨剧，都滥觞于这种我们根本自己也没搞清楚的观念。<br>不要说“互补”，即便是稍有不同，那便是异端邪说、是外族、是异教徒、是政治犯；那便会有党争、门户、正宗、政治清洗和宗教审判。<br>信不知凭何而信，恨不知因何而恨。被左右的观念所左右，被迷惑的语言所迷惑，操纵感官输出的表象又被表象所操纵。<br>无论刚日柔日，翻开经史，里面都是这样的故事。只要稍微读几页就会发现，与先前想的正好相反，教给你变化的其实是经，而教给你不变的是史。<br>所以这句话并不是要教给你刚柔相济之道，而是提醒你认清人心之妄作，行为之颠倒，以及，追求真实的难能可贵。<br>谨录于上，念念不忘。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>如何在偷偷搜索关键字后避免令人尴尬的广告</title>
      <link href="/2018/11/17/duckduckgo/"/>
      <url>/2018/11/17/duckduckgo/</url>
      
        <content type="html"><![CDATA[<blockquote><p>转载自<a href="https://cloudwonders.info" target="_blank" rel="noopener">cloudwonders.info</a></p></blockquote><p>当你在任意一个搜索引擎输入一个关键词之后，你就成了全网全平台追逐的流量热点。</p><p>平时大打口水战的各大平台在共享你的隐私数据方面异常团结，在B系网站搜索，在A系T系的应用APP上都会看到为你“量身定制”的推送和广告，延迟不超过一分钟。</p><a id="more"></a><p>这一点即便是业界道德楷模G老师都未能免俗，毕竟它也要靠着广告收入维持其智能推荐算法引擎的研发投入。</p><p>最可气的是，推送些边栏广告也就算了，竟然连自己看的新闻和短视频内容也都要和搜索记录沾边，在聚会上随便刷下手机就暴露了自己到底是个什么货色。</p><p>网络对你的监视是全方位的，除了你主动输入的那些关键字，你平时的谈话、你的地理位置，你周围的环境照片都会被偷偷记录上传，用以支撑靠勤劳质朴的城镇劳动人民手动打标签的“人工”智能工程师们的高薪。</p><p>当个人隐私在巨头面前节节败退，当生而为人的尊严在利益机器面前粉碎，当你不能说的秘密被拿来公开叫卖和嘲弄，当互联网利用你心底的弱点反过来操控你之时，难道就没有一款可以放心解放双手，安全地释放自己的求知欲，满足人类最原始的好奇的搜索引擎吗？当然不是这样的鸭——</p><p><img src="http://ww1.sinaimg.cn/large/73403117ly1fhsqrvtg20j223w1kwq8e.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt=""></p><p>这个创立于2008年的搜索引擎，十年来一直在巨头的夹击下惨淡经营。如果没有愈演愈烈的互联网隐私泄露事件、没棱镜门、没有小扎的听证会，恐怕Duckduckgo也不会有近来的长足发展。</p><p><img src="https://i.loli.net/2018/11/05/5be057be3a57f.jpg" alt=""></p><p>Duckduckgo从创立之初秉承的理念就是不对用户的搜索做任何追踪与记录，不把用户的隐私和数据当作公司的资产，做好一个搜索引擎的本分。自2018年之初，该搜索引擎已每日接受多于两千万次的匿名搜索。</p><p>Duckduckgo的使用方式与其他搜索引擎没有区别，唯一的不同就是搜索之后在其他任何平台没有相关的广告推送。至于搜索本身的质量和水平，笔者简单做了个对比：</p><p><img src="https://i.loli.net/2018/11/05/5be057fe2c0e7.png" alt=""></p><p>应当说完全可以满足日常应用，不说超越G老师，超越B老师应该是问题不大。同时不用担心在互联网大机器下无所遁形。已经有越来越多的朋友和公司将Duckduckgo设置为了默认搜索引擎。</p><p>如果说互联网早已是赢家通吃的寡头时代，用隐私交换在线服务已如缴纳“人头税“一般自然，而在这万马齐喑的时刻，Duckduckgo代表的是一豆星星点点的亮光，为所有在歌舞升平中“心怀鬼胎“的人们擎举起惊奇与愤怒的能力。可以放心大胆地搜索不可描述内容的传送门：<a href="https://www.duckduckgo.com" target="_blank" rel="noopener">https://www.duckduckgo.com</a></p>]]></content>
      
      
      <categories>
          
          <category> wonder </category>
          
      </categories>
      
      
        <tags>
            
            <tag> resources </tag>
            
            <tag> wonder </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
