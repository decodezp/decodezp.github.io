<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>几句话说清楚7：DPDK不同CPU平台交叉编译指令不支持的问题</title>
      <link href="/2018/12/24/quickwords7-dpdk-cross-compile/"/>
      <url>/2018/12/24/quickwords7-dpdk-cross-compile/</url>
      
        <content type="html"><![CDATA[<h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>在比较高级的CPU平台(比如skylake)编译DPDK，会在编译的目标文件中加入一些高级指令集中的指令，比如AVX512。</p><p>如果运行最终可执行文件的机器的CPU架构(比如broadwell)不支持编译机器中的指令，则会在执行时报类似这种错误：<br><a id="more"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">174146:Dec 21 10:56:30 n10-023-013 kernel: [57619.700220] traps: obj-name[861199] trap invalid opcode ip:501c31 sp:7fff9782d090 error:0</span><br></pre></td></tr></table></figure><p>其实就是在0x501c31(ip是instruction pointer)这个位置上的指令不支持(invalid)。</p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>那么如何查看具体是哪条指令呢? </p><p>用<code>objdump -D obj-name</code>查看一下目标文件的汇编代码，找到该位置上的指令。</p><p>我这里的例子中，这个指令是<code>vmovdqa64</code>，简单搜索一下可以知道这是个<code>AVX512f</code>的指令。</p><blockquote><p>其他详细内容可以查看Intel SDM(Software Development Manual)<a href="https://software.intel.com/en-us/articles/intel-sdm" target="_blank" rel="noopener">下载链接</a></p></blockquote><p>而这个指令在<code>skylake</code>上支持，<code>broadwell</code>上不支持。</p><p>可以通过在两个机器上执行<code>cat /proc/cpuinfo | grep flags</code>查看支持的指令集。或者执行<code>gcc -march=native -Q --help=target</code>查看。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>在编译机器(skylake)DPDK的/mk/machine/native/rte.vars.mk中，设置<code>MACHINE_CFLAGS= -march=native</code>为<code>-march=broadwell</code>就可以了。</p><p>当然还有一些详细的交叉编译方法，可以参考这篇<a href="http://syswift.com/355.html" target="_blank" rel="noopener">文章</a>。</p><p>另外还有一点要提醒的是，如果你是在编译某些基于DPDK的应用，比如DPVS，要一并修改应用中的编译配置，例如DPVS就是在<code>./src/dpdk.mk</code>中，需要修改<code>CFLAGS += -march=broadwell</code>。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> dpdk </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>5分钟经典英文技术演讲2：软件设计真正的精髓-Scott Meyer</title>
      <link href="/2018/12/21/eng-talk2-things-matter/"/>
      <url>/2018/12/21/eng-talk2-things-matter/</url>
      
        <content type="html"><![CDATA[<blockquote><p>一个人的能力上限很大程度上取决于他获取信息的能力。</p><p>而能力增长的速度与获取信息的_质量_正相关。</p><p>不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。</p><p>最新内容将发布于<a href="https://decodezp.github.io">DecodeZ</a>: <a href="https://decodezp.github.io">https://decodezp.github.io</a></p><p><a href="https://decodezp.github.io/2018/12/12/eng-talk1-fast-learn/">往期回顾：如何快速掌握新技术</a></p></blockquote><h1 id="DConf2017：软件设计真正的精髓"><a href="#DConf2017：软件设计真正的精髓" class="headerlink" title="DConf2017：软件设计真正的精髓"></a>DConf2017：软件设计真正的精髓</h1><p><a href="https://www.youtube.com/watch?v=RT46MpK39rQ" target="_blank" rel="noopener">原视频</a></p><p><a href="http://dconf.org/2017/talks/meyers.pptx" target="_blank" rel="noopener">PPT/Slides下载</a></p><p>演讲者：Scott Meyer</p><p>上一张演讲者的照片，硬撸过C++的应该都很熟悉他:</p><p><img src="https://s1.ax1x.com/2018/12/21/FsMA2R.jpg" alt="Scott Meyer"></p><blockquote><p>摘要：成功的软件产品都有其共性。在Scott Meyer看来，这些共性由几个要素组成。在你的作品中考虑这些要素，将帮助你掌握软件设计真正的精髓。<br><a id="more"></a></p></blockquote><h2 id="效率-速度-Efficiency-Speed"><a href="#效率-速度-Efficiency-Speed" class="headerlink" title="效率/速度(Efficiency/Speed)"></a>效率/速度(Efficiency/Speed)</h2><p>效率高(所需要执行的指令数少)的软件在大多数情况下等于速度快性能高的软件。</p><p>在硬件性能普遍过剩的2C和移动市场，对软件效率的追求也可以带来更广泛的平台配适性和更好的功耗表现。</p><p>而在每增加100毫秒延时，年收入就掉几个百分点的电商、在线广告和高频交易领域，对服务器软件效率的追求没有止境。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsM5W9.jpg" alt=""></p><p>追求软件的高性能肯定没错，但大家一定都熟悉一句话：</p><blockquote><p>“过早优化是万恶之源”(Pre-mature optimization is the root of all evil)。</p></blockquote><p>很多人将这句话作为“先不忙优化，最后再说”的理由。但有多少人知道这句话的出处和上下文?</p><p>这句话出自Donald Knuth的一篇叫做”Structured Programming with go to Statements”的论文。而这句话的前面一句话和它连起来是：</p><blockquote><p>如果你不能确定在哪里可以优化，就先不要优化。过早优化是万恶之源。</p></blockquote><p>而在这篇总长度41页的论文的同一页，Donald写道：</p><blockquote><p>可以简单获得(easily obtained)的性能提升，并非无足轻重。</p></blockquote><p><img src="https://s1.ax1x.com/2018/12/21/FsMhi4.jpg" alt=""></p><p>当软件已届完成时再考虑性能优化，将是艰难甚至不可能的任务，例如单线程程序改为多线程，有锁替换为无锁结构等等。</p><p>所谓”过早优化“(我还是更喜欢将其直译为”不成熟的优化“)，并不是指“从软件的设计阶段就考虑性能”，而是指你还并不知道哪里能优化就一通乱搞的时候。</p><p>而能看出系统性能的瓶颈，可以给出“成熟的优化”方案，是需要长期的学习和实践积累的。</p><blockquote><p>Side Note: 对软件性能优化，特别是结合CPU内存等硬件特性感兴趣的读者可以自行搜索一下笔者在青涩时期挖了还没填上的大坑: <a href="https://www.baidu.com/s?wd=x86%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B%E7%AC%BA%E6%B3%A8&amp;rsv_spt=1&amp;rsv_iqid=0xe6a969f800013a74&amp;issp=1&amp;f=8&amp;rsv_bp=0&amp;rsv_idx=2&amp;ie=utf-8&amp;tn=baiduhome_pg&amp;rsv_enter=1&amp;rsv_sug3=34&amp;rsv_sug1=2&amp;rsv_sug7=100&amp;rsv_sug2=0&amp;inputT=6753&amp;rsv_sug4=6958" target="_blank" rel="noopener">x86高性能编程笺注</a></p></blockquote><h2 id="可移植性-Portability"><a href="#可移植性-Portability" class="headerlink" title="可移植性(Portability)"></a>可移植性(Portability)</h2><p>可移植性的出发点，是市场和客户。</p><p>Scott举出了一个他供职过的公司的例子：有自己的硬件平台、编译器、和操作系统。他们的产品跑在自己高度定制化的平台上，各方面的优化已臻完美，一切都很美好。</p><p>相形之下，那些跑在“拼凑”出来的平台上的竞品，就像一个拙劣的玩笑。</p><p>这一切都随着“通用硬件”性价比突飞猛进而结束，竞品提出的策略是：提供该公司80%的产品性能，但只需要20%的价格。</p><p>而这样的故事，在Scott二十余年的从业经历中重复发生着。</p><p>当你真的认真在考虑一个严肃的软件产品时，请通过可移植性给予它更多的市场适应能力，而不至于因为产品之外的因素影响产品本身的生命周期。</p><p>同时可移植性也可以帮助你在推出了一款成功的产品并在当前平台下达到市场饱和之后，开拓出更多的市场增长空间。有增长才有后续的融资嘛 :)</p><p>而做好产品的可移植性设计，其难度不亚于上一节提到的性能优化。有太多硬件的和软件的细节需要考虑，不但要做好不同平台之间的抽象，还要考虑如何充分利用不同平台的独有特性。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsMWoF.jpg" alt=""></p><p>而这一切都将是你不断学习的内容。</p><h2 id="修补性-Toolability"><a href="#修补性-Toolability" class="headerlink" title="修补性(Toolability)"></a>修补性(Toolability)</h2><p>字典中出给的翻译是“修补性”，但我觉得这是一个不贴切的翻译。<code>Toolability</code>在这里的意思是，当你创造出某种产品的时候，需要考虑能够简单地让别人围绕它开发出工具(Tool-able)。</p><p>我个人的理解就是，预留出构建生态的能力。</p><p>如果把编程语言看作是一种产品，那么某种语言的重构工具就是它整个生态中重要的一环。</p><p>重构工具的一项基本功能，就是在一个项目工程中替换某一个函数的名字。在Java中我们有Intellij，有Eclipse，在对C++来说，我们还没有一个特别好使的重构工具。</p><p>因为在C++中，一个简单的<code>f(x)</code>可能是：</p><ul><li>一个函数</li><li>一个函数指针</li><li>一个重载操作符</li><li>一个模板</li><li>一个宏</li><li>等等等等</li></ul><p>这样的复杂度，让实现C++的重构工具变得几乎不可能。<code>Comments: 现在确实出现了一些C++的重构工具，但相比于其他语言，晚了十余年。</code></p><p>但我们想强调的并不是C++如何重构，而是当没有这些工具，没有产品生态的时候，你的产品能发挥出多大作用，完全受限于使用者本身的能力。而如果他人能够迅速构建出一套工具，将会帮助你提升产品能力的下限。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsM4JJ.jpg" alt=""></p><p>简单来说就是，只靠产品一个人打天下不行，需要有组件团队的能力。同时当别人想加入你的团队时，最好不要有太多障碍。</p><h2 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性(Consistency)"></a>一致性(Consistency)</h2><p>一致性是用户体验提升的核心，这里的用户既包括产品最终的消费者，同时也包括开发者。</p><p>所谓用户体验，是能够轻易的与以往的经验做类比。保持一致并不是处女座强迫症作祟，而是在软件设计领域有重要意义——带来有效的抽象和类比。一致性本质上是在为我们的大脑创造一种”模式“，既然是模式，就需要有保持一致的东西。</p><p>看一个iOS10上的例子：<br><img src="https://s1.ax1x.com/2018/12/21/FsMRdU.jpg" alt=""></p><p>删除按钮的图标都是一致的，但位置和颜色并没有保持一致。</p><p>试想，如果一系列相关的函数调用，它的相同类型的参数位置都不一样，如下面这个C语言的例子：<br><img src="https://s1.ax1x.com/2018/12/21/FsMTQ1.jpg" alt=""></p><p>即便是编写了数十年C程序的程序员，每次也都需要查表才能确定自己把参数放对了位置。</p><p>又如Java中求得某个数据类型的长度的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array.length</span><br><span class="line">string.length()</span><br><span class="line">List.size()</span><br></pre></td></tr></table></figure><p>这种体验需要开发者针对每种不同的数据类型分别记忆不同的方法，而不能构建一个一致性的抽象。</p><p>现在当然有智能化的IDE可以帮助我们摆放好参数或者使用正确的方法，但我们想探究的正是，为什么IDE会加入这个功能——因为不一致的参数位置和方法名实在太恼人了。</p><p>而用户体验的核心，并非是扁平化设计，而是追求一致：产品本身性能一致，稳定性一致；用起来的时候，能把我以前的经验带到这里来，并且我一看就知道，这个产品如何操作。</p><h2 id="接口-Interfaces"><a href="#接口-Interfaces" class="headerlink" title="接口(Interfaces)"></a>接口(Interfaces)</h2><p>设计接口，既要考虑如何容易用对，同时也考虑如何很难用得不对。</p><p>而上一节提到的一致性，就是一个很好的指导原则。</p><p>毕竟会调用你接口的人，都是聪明人，都是有软件经验的人，同时他们也希望你实现的接口能够帮助他们自己，所以也愿意去读一点文档。</p><p>如果即便如此他们还是不能正确使用你的接口，那一定是你自己的问题。</p><p>而真正优秀的接口，是调用者凭借你提供的一致性，凭直觉就能使用的接口——“我也不知道为什么，但这个接口就是工作了”。</p><p>而一个设计不靠谱接口的开发人员的典型口头禅就是：他们会搞明白的。</p><p><img src="https://s1.ax1x.com/2018/12/21/FsMIzR.jpg" alt=""></p><p>这可能正是你的产品变得混乱不堪的开始。</p><p>以上就是Scott Meyer想要在本次演讲中传达给我们的内容。</p>]]></content>
      
      
      <categories>
          
          <category> ENG_talk </category>
          
      </categories>
      
      
        <tags>
            
            <tag> English </tag>
            
            <tag> Presentation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚6：什么是DDP(Dynamic Device Personalization)</title>
      <link href="/2018/12/18/quickwords6-ddp/"/>
      <url>/2018/12/18/quickwords6-ddp/</url>
      
        <content type="html"><![CDATA[<h2 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h2><p>通过网卡的多队列和RSS将网包根据一些关键字段散列(hash)到不同的队列已成为一种主流的在x86平台开发信通以及云计算领域产品的方式。</p><p>在整体产品架构规划中，不同的网卡队列(Rx/Tx Queues)往往对应/绑定着不同的CPU核(Worker)，以利用资源隔离的方式提高性能。</p><p>传统的RSS，往往是依据header的五元组来做散列。通常，网卡可以识别出的报文类型包括<code>ipv4-tcp|ipv4-udp|ipv4-other|ipv6-tcp|l2-payload</code>等等，然后根据能识别出的类型进行关键字段的提取。</p><p>但现在如此简单的识别能力已经不能满足业务的需求。在复杂的协议和隧道通讯场景下，往往还需要识别隧道内层header甚至私有字段才能实现业务能力的最优化。<br><a id="more"></a></p><p>所以对RSS/Fdir来说，首先需要能“识别”出特定的协议报文，才能找到关键的字段进行散列操作。</p><p>在网卡出厂的时候，是可以预置一些协议类型的，但还是最好能有自定义的动态调整的能力。</p><h2 id="DDP-Dynamic-Device-Personalization"><a href="#DDP-Dynamic-Device-Personalization" class="headerlink" title="DDP(Dynamic Device Personalization)"></a>DDP(Dynamic Device Personalization)</h2><p>名字起得很“大”，不过就是上面说的定制化的技能——动态地赋予网卡识别新协议的能力。</p><p>具有这种能力之后，就可以把任意协议的网包按用户意愿提取出关键字段(Key)，然后散列到网卡各个Rx队列里。比如VxLAN协议中的内层DIP等等。</p><p>下图是一个赋予网卡<code>GTP-U</code>协议(好吧，我并不知道这是什么…)识别能力，并可以依据<code>TEID</code>字段的值进行RSS计算的示例：</p><p><img src="https://s1.ax1x.com/2018/12/18/FBJ5q0.png" alt="绿色的可以被用来RSS的字段增多"></p><p>现在已经能被识别出的包括L2TPv3\QUIC\PPPOE\SRv6\RoE\MQTT-SNoUDP等等，还有一些大客户做了自己私有协议的定制。</p><p>总得来说就是，可以把这部分classification的活儿offload到硬件上，减轻后续CPU处理/分发时的压力，同时均衡一下负载，提升整体性能。</p><h2 id="DDP的需求："><a href="#DDP的需求：" class="headerlink" title="DDP的需求："></a>DDP的需求：</h2><ul><li>Intel 700系列网卡以上</li><li>固件版本6.01以上</li><li>一个由Intel官方出品的特定协议识别的binary package file(需要到官网下载)</li><li>DPDK提供的配置接口</li></ul><p>具体在DPDK上怎么搞后续会有文章说明。</p><h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><blockquote><p>Q:如何自己制作binary package file?<br>A:目前不支持自己制作，只能由Intel提供。</p><p>Q:一张网卡最多支持载入多少个binary package file(profile)?<br>A:最多支持16个，但不推荐这么做，推荐同时只载入一个。</p><p>Q:载入之前需要首先关闭网卡设备吗？<br>A:不需要，支持运行时直接载入，但会引起一些丢包</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>谁不是在像CPU一样活着</title>
      <link href="/2018/12/16/cpulized-life/"/>
      <url>/2018/12/16/cpulized-life/</url>
      
        <content type="html"><![CDATA[<p>上一次兴奋到浑身发热，还是把赛扬300A超频到450兆赫的时候。身体如摩尔定律般长高，觉得距离1GHz只差一罐液氮，心里装着只有一心一意才能装下的事情。</p><p>记得那时看到一篇报道，英特尔说“到2011年的时候，我们都能用上10GHz的电脑”。十几岁的你笑这家美国公司野心不大，现在你说出这件事，只是想给大家讲个笑话。<br><a id="more"></a></p><p>2018年，没等来10GHz的电脑，也再也没有一心一意的机会。学会了MMX、SSE、AVX，TSX和AEX等十八般武艺，领导说你是“业务中坚”，其实你知道你只是个挣扎着适应环境的执行人员。</p><p>好在熟稔让你变得老练，打点好前端后端的各种关系，再低的IPC也可以不动声色。毫无指摘地把锅甩给温吞的硬盘，你想你可能明白了什么是sophisticated，就是心里只寻思自己那点14nm的柴米。</p><p>但越是老练越让你厌恶风险，你给自己加了iCache、dCache、iTLB、dTLB，IOTLB等各种保险，但每次分支预测失败还是要彻底打乱你的流水线。即便凭借经验已能做到99%的正确，却能又让你掉入Spectre的窠臼。</p><p>真是怕什么来什么，左右为难的时候，自己的窘样又让心里有一点点好笑，能用一罐液氮解决的事情，偏要搞这么复杂。</p><p>突然有些怀念那个为450兆赫兴奋的自己，当时你只想完成这一件事。但此刻你心里不再只住着你自己，每个人都同时在跑好几个角色，你号称你是3GHz还能hyperthread，其实你知道你早已没了章法，所有的事情都不过是水来土掩的乱序执行。</p><p>但好在还有一块L3缓存，和你那些sophisticated的L1缓存相比，这里虽然慢，慢得就像曾经的赛扬300A，但却有一心一意的完整。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚5：影响服务器内存性能的硬件知识</title>
      <link href="/2018/12/13/quickwords5-server-memory/"/>
      <url>/2018/12/13/quickwords5-server-memory/</url>
      
        <content type="html"><![CDATA[<h2 id="发挥内存条理财的最大收益率"><a href="#发挥内存条理财的最大收益率" class="headerlink" title="发挥内存条理财的最大收益率"></a>发挥内存条理财的最大收益率</h2><p>内存条作为年度最佳理财产品除了能躺着赚钱之外，使用得好还可以一条当两条用。</p><p>在计算机系统中，内存的价值就体现在快速提供数据给CPU处理。当CPU需要的数据没有在缓存里时，CPU内部的<code>Memory Controller</code>就需要去内存中读取内容。<br><a id="more"></a></p><p>而<code>Memory Controller</code>为了尽快完成CPU交代的任务，用了<code>多通道</code>的方式增大内存存取带宽。</p><p><code>多通道</code>这个概念很好理解，和多条车道是一个意思。比如CPU需要1MB大小的数据，单通道的话数据就只能在一条通道上老老实实排队；双通道就可以并行两个512KB的读取；四通道就是并行四个256KB的读取。</p><p>我知道你要问什么，这1MB大小的数据已经被<code>Memory Controller</code>通过一种叫做<code>Interleave(交织)</code>的技术“打散”在了两个通道或者四个通道对应的物理内存上。<code>Interleave</code>由硬件实现，细节不在这里深究，我们想说明的是发挥这些硬件组件的最大能力需要外界条件配合。</p><p>内存在硬件方面的性能优化，就围绕这个主题。</p><h2 id="内存相关概念"><a href="#内存相关概念" class="headerlink" title="内存相关概念"></a>内存相关概念</h2><p>现在主流Intel E5 CPU的配置是一颗CPU上两个<code>Memory Controller</code>，每个Controller有两个通道，每个通道对应主板上三个内存插槽(DIMM)。</p><p><img src="http://1.bp.blogspot.com/-Iaf9qQgC-zM/VdDIBPzscoI/AAAAAAAAABs/AU-vcOrCSck/s1600/6101_48_supermicro_x9dr7_tf_intel_c602j_server_motherboard_review.jpg" alt="内存插槽"></p><p><code>Interleave</code>首先发生在通道层面，进而发生在通道的DIMM层面（使用的DIMM越多，交织得越充分）</p><p>同时每根内存条还有一个<code>Rank</code>的概念。这个概念可以理解为更进一步的<code>Interleave</code>，多<code>Rank</code>的内存条可以再进行一次<code>Interleave</code>。</p><p><img src="https://cdn3.bigcommerce.com/s-3jjekk/product_images/uploaded_images/memory-rank.png?t=1518214379&amp;_ga=2.27767868.1254827790.1518192896-72491761.1493653618" alt="看序列号读取内存信息"></p><h2 id="充分平衡"><a href="#充分平衡" class="headerlink" title="充分平衡"></a>充分平衡</h2><p>满足最优的内存配置就是四个字：充分平衡。</p><p>-充分：并不是要你插满所有插槽，而是充分利用每个<code>Memory Controller</code>和每条通道<br>-平衡：每个<code>Memory Controller</code>和通道上的内存配置(Size, Rank和频率)都相同。</p><p>在实际应用中，首先绘制一个内存拓扑，如下图：<br><img src="https://s1.ax1x.com/2018/12/13/FNdSBT.png" alt="充分平衡"></p><blockquote><p>如何检查是否充分？看一下每个<code>Memory Controller</code>中的每个通道是否都有内存条<br>如何检查是否平衡？将拓扑图从中垂线对折一次，检查图像是否能重合；再从水平中位线对折一次，检查是否能重合。如果两次回答都是yes，就平衡了。</p></blockquote><h3 id="实例1"><a href="#实例1" class="headerlink" title="实例1"></a>实例1</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNwPqf.png" alt="平衡不充分"></p><h3 id="实例2"><a href="#实例2" class="headerlink" title="实例2"></a>实例2</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNazuV.png" alt="充分不平衡"></p><h3 id="实例3"><a href="#实例3" class="headerlink" title="实例3"></a>实例3</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNajcq.png" alt="不充分不平衡"></p><h3 id="实例4"><a href="#实例4" class="headerlink" title="实例4"></a>实例4</h3><p><img src="https://s1.ax1x.com/2018/12/13/FNavj0.png" alt="充分平衡"></p><h2 id="软件检查工具"><a href="#软件检查工具" class="headerlink" title="软件检查工具"></a>软件检查工具</h2><p>为了不让每次内存检测都需要打开机箱…有一个开源工具可以通过读取<code>dmidecode</code>的信息自动化做检验：<a href="https://github.com/PanZhangg/DPDKick" target="_blank" rel="noopener">DPDKick</a></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> performance </tag>
            
            <tag> memory </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>5分钟经典英文技术演讲1：如何快速掌握新技术 - Kathy Sierra</title>
      <link href="/2018/12/12/eng-talk1-fast-learn/"/>
      <url>/2018/12/12/eng-talk1-fast-learn/</url>
      
        <content type="html"><![CDATA[<blockquote><p>一个人的能力上限很大程度上取决于他获取信息的能力。</p><p>而能力增长的速度与获取信息的质量正相关。</p><p>不可否认，大量优质的技术内容都基于英文。“5分钟经典英文技术演讲”专门撷取国外最有价值的纯英文技术演讲，以最精炼的形式将信息传达给国内的技术同侪，绕过网络政策和语言的障碍，实现中西方技术世界无壁垒的信息同步。</p><p>最新内容将发布于DecodeZ: decodezp.github.io</p></blockquote><h2 id="Fluent-如何快速掌握新技术"><a href="#Fluent-如何快速掌握新技术" class="headerlink" title="Fluent: 如何快速掌握新技术"></a>Fluent: 如何快速掌握新技术</h2><p><a href="https://www.youtube.com/watch?v=FKTxC9pl-WM" target="_blank" rel="noopener">原视频</a><br>演讲者: Kathy Sierra</p><blockquote><p>摘要：无论是谁，以有限的精力来面对层出不穷的新技术挑战都是不够的。你需要学会一套方法论来帮助你快速习得新的技能。而快速学习的秘诀却还不止这些…<br><a id="more"></a></p></blockquote><h2 id="每个程序员都面临的挑战"><a href="#每个程序员都面临的挑战" class="headerlink" title="每个程序员都面临的挑战"></a>每个程序员都面临的挑战</h2><p>为了成为一名“合格”的程序员，你认为你需要掌握哪些技术？</p><p>这将是一个长长长长长的名单，更可怕的是，每个人列出的内容都将各不相同。</p><p>所以这么提问并没有太大意义，更好的问题是：</p><p>我如何快速掌握新的技术？</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0sqf.jpg" alt=""></p><h2 id="认知资源"><a href="#认知资源" class="headerlink" title="认知资源"></a>认知资源</h2><p>我们习得新的技能，需要依赖我们自己的认知资源（Cognitive resources）。</p><p>但作为一个正常的“人类”，我们的认知资源易耗且稀缺。</p><p>到底有多容易消耗？Kathy提到了一个大学里的实验：实验人员要求一半实验参与者记忆一个两位的数字，而另外一半参与者记忆一个七位的数字。</p><p>等确保每个人都记住了自己的数字之后，实验人员随即宣布实验结束，并邀请所有参与者去取用一些零食——蛋糕，或水果。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0rsP.jpg" alt=""></p><p>而实验结果也能猜到，仅仅是5位数字的差别，就让记忆七位数的实验者选取蛋糕的比例比记忆两位数的参与者高出一半。</p><p>你是否有想认真掌握一门新技能，但一拿起各类技术书籍、文档，很快就放弃的经历？你又是否在做一些让别人“选择蛋糕”的事情？比如让别人阅读你自己编写的项目文档。</p><p>当你想要快速掌握一项技能的时候，你需要学会管理自己的认知资源。<br><img src="https://s1.ax1x.com/2018/12/12/Ft0cdS.jpg" alt=""></p><h2 id="学习方法"><a href="#学习方法" class="headerlink" title="学习方法"></a>学习方法</h2><p>将你现在的技能分为三类：</p><ul><li>A还没有掌握，但需要掌握的</li><li>B经过一定努力可以掌握的</li><li>C已经掌握的</li></ul><p><img src="https://s1.ax1x.com/2018/12/12/Ft0DMt.jpg" alt=""></p><p>我们的目标其实是如何将AB的技能快速移动到C。在这个过程中我们会遇到两类典型问题：</p><ul><li>没有进步</li><li>耗时太久</li></ul><h3 id="没有进步"><a href="#没有进步" class="headerlink" title="没有进步"></a>没有进步</h3><p>第一类问题的根本原因在于你的认知资源不足以支撑技能的学习需求。我们不能要求自己有无限的认知资源，在资源极度有限的情况下，仍有两种解决策略：</p><p>第一种，将更多的需要掌握的技能放在A，将精力集中于少量的B类技能。但在日常工作中，需要掌握哪些技能，解决哪些问题，都不是自己可以安排的。对此，我们还有第二种策略。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0gIg.jpg" alt=""><br>第二种策略，就是将B中的技能分解为更小的粒度。这种策略，在有限的认知资源的情况下效果等同于一个需要处理多任务并发的CPU，上面运行的程序都采用了更加细粒度的锁机制，带来了程序性能的提升。<br><img src="https://s1.ax1x.com/2018/12/12/Ft06Z8.jpg" alt=""></p><p>那么如何界定分解之后的技能足够“细”？Kathy给出了一个她的评判标准：</p><blockquote><p>从完全不会到十分熟练，最多经过3次练习，每次45-90分钟。</p></blockquote><p>能满足上面的标准就可以认为分解到了合理的粒度。</p><h3 id="耗时太久"><a href="#耗时太久" class="headerlink" title="耗时太久"></a>耗时太久</h3><p>程序员不但要学习很多技能，还需要快速学习。所以从A开始，我们最好能够绕过B直接到C。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0fRs.jpg" alt=""><br>怎么可能从完全不懂，到突然就明白了？</p><p>Kathy给出了一个“极端”的例子：学习给分辨雏鸡的性别。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0RiQ.jpg" alt=""><br>从视觉上，这是一件不可能的事，但日本却有一些非常擅长分别雏鸡性别的人。</p><p>人们希望这些“性别分辨大师”能够将他们的方法教授给别人，但这些人并不能讲出什么明确的“规则”。</p><p>这就是这件真正神奇的地方，我们的大脑能够在潜意识中处理一些信息，但却讲不出来为什么。</p><p>所以学习雏鸡性别分辨的人最开始只是随机判断雏鸡的性别，而这些“专家”则告诉他们结果是不是正确。</p><p>一段时间以后，这些学习分辨性别的人正确率越来越高，最终达到了专家的水平。</p><p>这些学习的人并没有记忆任何具体的“规则”，却能够不断提升自己的技能水平。这里产生核心影响的是：高质量的例子。</p><blockquote><p>这非常类似机器学习的过程，模型的质量取决于训练这些模型的数据的质量。</p></blockquote><h2 id="关键的缺失——高质量的例子"><a href="#关键的缺失——高质量的例子" class="headerlink" title="关键的缺失——高质量的例子"></a>关键的缺失——高质量的例子</h2><p>当要学习某样特殊技术的时候，你是找官方的、正式的、长而无味的文档，还是去找一个精悍的例子？</p><p>当你能找到一个精确的示例来演示如何使用这样技术的时候，你几乎可以“瞬间”掌握这项技术。</p><p>你需要这些示例来让大脑自动地，潜意识地识别其中的模式。但现在的问题是，所有技术里又臭又长的文档很多，但短小精悍的示例很少。</p><p><img src="https://s1.ax1x.com/2018/12/12/Ft0WGj.jpg" alt=""><br>所以是否可以利用社区的力量，将这些文档转换成一系列高质量的示例库呢？</p><p>以上就是在本次演讲中，Kathy想要传达给我们的内容。</p><h2 id="引申"><a href="#引申" class="headerlink" title="引申"></a>引申</h2><p>《庄子》中有这样一个故事：</p><blockquote><p>桓公读书于堂上，轮扁斫轮于堂下，释椎凿而上，问桓公曰：“敢问：“公之所读者，何言邪？”<br>公曰：“圣人之言也。”<br>曰：“圣人在乎？”<br>公曰：“已死矣。”<br>曰：“然则君之所读者，古人之糟粕已夫！”<br>桓公曰：“寡人读书，轮人安得议乎！有说则可，无说则死！”<br>轮扁曰：“臣也以臣之事观之。斫轮，徐则甘而不固，疾则苦而不入，不徐不疾，得之于手而应于心，口不能言，有数存焉于其间。臣不能以喻臣之子，臣之子亦不能受之于臣，是以行年七十而老斫轮。古之人与其不可传也死矣，然则君之所读者，古人之糟粕已夫。“</p></blockquote><p>真正的精髓，都在手上，而不在文档里。</p>]]></content>
      
      
      <categories>
          
          <category> ENG_talk </category>
          
      </categories>
      
      
        <tags>
            
            <tag> English </tag>
            
            <tag> Presentation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚4：什么是Pointer Aliasing</title>
      <link href="/2018/12/11/quickwords4-pointer-aliasing/"/>
      <url>/2018/12/11/quickwords4-pointer-aliasing/</url>
      
        <content type="html"><![CDATA[<h2 id="指向同一地址的两个相同类型的指针"><a href="#指向同一地址的两个相同类型的指针" class="headerlink" title="指向同一地址的两个相同类型的指针"></a>指向同一地址的两个相同类型的指针</h2><p><code>aliasing</code>本身是一个信号处理方面的概念。是指在信号采样过程中，不同的信号不再能相互区分的现象。</p><p>如下图所示的波纹现象，相对于拍摄的采样频率（横纵像素分辨率），墙砖缝隙变化的频率要大于采样频率。或者换句话说，多条墙砖缝隙需要挤在一个像素里面。<br><img src="https://svi.nl/wikiimg/StFargeaux_kasteel_buiten1_aliased.jpg" alt=""></p><a id="more"></a><p>同样的现象也会出现在程序员穿着“高密度”的格子衬衫接受电视采访时。</p><p>墙砖缝隙出现<code>aliasing</code>后无法再行区分，从字面意义来说，<code>Pointer Aliasing</code>就是不同的指针也无法区分。</p><p>指针无法区分，只有一种情况，就是指针的类型和指向的地址都是相同的，这就是<code>Pointer Aliasing</code>。</p><h2 id="为什么会有性能影响"><a href="#为什么会有性能影响" class="headerlink" title="为什么会有性能影响"></a>为什么会有性能影响</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> *<span class="built_in">array</span>, <span class="keyword">int</span> *size, <span class="keyword">int</span> *value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; *size; ++i) &#123;</span><br><span class="line">        <span class="built_in">array</span>[i] = <span class="number">2</span> * *value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果让我们自己“优化”一下这段代码，我们可能会首先将<code>value</code>指向的值存入一个临时变量里，然后将临时变量在循环中直接赋值给<code>array</code>。</p><p>我们假设个<code>array</code>的初始状态：<code>[0, 1, 2, 3, 4]</code></p><p>如果<code>value</code>指向的值等于3，那么按我们优化的方式，<code>array</code>最终的状态是：<code>[6, 6, 6, 6, 6]</code></p><p>但这里存在一个问题，如果<code>value</code>指向<code>array[3]</code>，那么<code>array</code>最终的状态就是：<code>[6, 6, 6, 12, 24]</code></p><p><code>value</code>和<code>array[3]</code>就是指向相同地址类型相同的指针。</p><p>编译器为了得到最终正确的结果，就不得不取消我们之前提到的”优化”方式。</p><h2 id="预防方法"><a href="#预防方法" class="headerlink" title="预防方法"></a>预防方法</h2><p>使用<code>__restrict</code>关键字：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> * __restrict <span class="built_in">array</span>, <span class="keyword">int</span> *__restrict size, <span class="keyword">int</span> *__restrict value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; *size; ++i) &#123;</span><br><span class="line">        <span class="built_in">array</span>[i] = <span class="number">2</span> * *value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然，前提是自己可以确定代码逻辑中不会引入<code>aliasing</code>。</p><h2 id="怎么使用"><a href="#怎么使用" class="headerlink" title="怎么使用"></a>怎么使用</h2><p>首先明确一点，不是加上了<code>__restrict</code>性能就会提升。</p><blockquote><p><code>Pointer aliasing</code>对性能根本的伤害不是需要每次重新去某个地址取值，而是因为引入了潜在的数据依赖关系，从而关闭了很多编译器优化代码的能力。</p></blockquote><p>上面两段代码，在<code>-O0</code>优化时生成的汇编代码(<code>gcc 4.8.5</code>)完全相同。不同的地方在于，第一段代码在<code>-O2</code>和<code>-O3</code>时生成的汇编代码仍然相同；而第二段做了<code>__restrict</code>处理的代码则会在<code>-O3</code>时加入大量循环展开等优化方式。</p><p>在线查看汇编代码：<a href="https://godbolt.org/z/2nXlNa" target="_blank" rel="noopener">链接</a></p><p>所以<code>__restrict</code>需要在打开较高等级的编译器优化的情况下使用才会有效果。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> CPU </tag>
            
            <tag> performance </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>产品观察1：华为FabricInsight产品简要分析</title>
      <link href="/2018/12/08/product1-huawei-fabricinsight/"/>
      <url>/2018/12/08/product1-huawei-fabricinsight/</url>
      
        <content type="html"><![CDATA[<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">最近机缘巧合之下接触到了华为FabricInsight这款产品，简要谈谈看法。</span><br><span class="line">只针对2018年8月份左右发布的版本。</span><br><span class="line">另外注意，在Google搜索相关资料的时候，记得要把Fabric Insight这两个单词合并在一起搜索，中间不要加空格，别问我怎么知道的。</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="信息采集"><a href="#信息采集" class="headerlink" title="信息采集"></a>信息采集</h3><h4 id="SNMP"><a href="#SNMP" class="headerlink" title="SNMP"></a>SNMP</h4><p>在使用FabricInsight之前需要配置华为设备的SNMP协议，主要作用为获取设备的MIB信息，<br>并进行其他管理操作。</p><h4 id="LLDP"><a href="#LLDP" class="headerlink" title="LLDP"></a>LLDP</h4><p>使能各设备的LLDP功能，以便FabricInsight据此（以及通过SNMP上送的MIB信息）绘制硬<br>件连接拓扑图。</p><h4 id="NetConf"><a href="#NetConf" class="headerlink" title="NetConf"></a>NetConf</h4><p>使能各设备的NetConf配置，以便FabricInsight能通过NetConf协议配置各设备的ERSPAN功<br>能。</p><h4 id="ERSPAN"><a href="#ERSPAN" class="headerlink" title="ERSPAN"></a>ERSPAN</h4><p>配置ERSPAN功能，destination IP配置为FabricInsight collector的地址。底层实现为：通过<br>GRE隧道的方式将远程设备的流量路由/镜像至分析节点，以实现对流量可视化分析。<br>ERSPAN可配置筛选特定的流量，并非全量镜像。从华为对交换机的配置： </p><pre><code class="shell">[~Device] observe-port 1​ destination-ip 10.10.10.20​ source-ip 10.1.1.1 [*Device] traffic-mirroring vxlan tag-format none tcp-flag fin syn rst observe-port 1 inbound [*Device] traffic-mirroring tcp-flag fin syn rst observe-port 1 inbound [*Device] commit</code></pre><p>通过ERSPAN镜像给FabricInsight的流量包括带有FIN/SYN/RST等TCP flag的网包。对应其<br>产品中对TCP事件的可视化能力。<br><em>注*：据此可以看出FabricInsight没有全量流量镜像&amp;分析能力</em><br><em>注*：命令中的vxlan可能是将流量通过vxlan封装，做三层转发，而非镜像全部vxlan流量</em></p><h4 id="Telemetry"><a href="#Telemetry" class="headerlink" title="Telemetry"></a>Telemetry</h4><p>华为的Telemetry指设备主动、以固定周期上报的一些设备信息，包括CPU\MEM\QUEUE等信<br>息。 </p><h4 id="手动录入"><a href="#手动录入" class="headerlink" title="手动录入"></a>手动录入</h4><p>主要为用户业务信息，每一个业务的定义为一组IP和某一固定端口号的集合，需要用户手工录<br>入。</p><p><img src="https://i.ytimg.com/vi/uVcXxn30qqY/maxresdefault.jpg" alt=""></p><h3 id="功能分类"><a href="#功能分类" class="headerlink" title="功能分类"></a>功能分类</h3><h4 id="Underlay拓扑可视化"><a href="#Underlay拓扑可视化" class="headerlink" title="Underlay拓扑可视化"></a>Underlay拓扑可视化</h4><p>依据LLDP生成及SNMP上报的信息，可生成Underlay设备间的拓扑信息。<br>流量事件统计<br>依据ERSPAN镜像的含有SYN\FIN\RST等flag的TCP网包，可统计一条流（五元组）中的事件<br>发生次数、时间及类型。并可据此进行简单的SYN重传、建立连接RTT、建连成功率分析。但<br>缺少对网流完整过程（e.g.流量传输数据总量、pps、整体平均时延等）的统计和分析。 </p><h4 id="设备信息统计"><a href="#设备信息统计" class="headerlink" title="设备信息统计"></a>设备信息统计</h4><p>根据Telemetry信息给出CPU\MEM等设备运行状态统计信息，以及对各网络端口IN/OUT总<br>量、drop、error数量等的统计信息。 </p><h4 id="应用流量分类过滤"><a href="#应用流量分类过滤" class="headerlink" title="应用流量分类过滤"></a>应用流量分类过滤</h4><p>其应用功能，本质为手动设置IP+端口号过滤规则，通过过滤的流量即为一个应用。应用间的<br>流量状态展现，即为在流量事件统计数据库中分别为起止两端的流量配置两个应用的过滤规则<br>，筛选出的流量即可作为应用间的流量状态展示。 </p><h2 id="FabricInsight特点"><a href="#FabricInsight特点" class="headerlink" title="FabricInsight特点"></a>FabricInsight特点</h2><h3 id="强绑定性"><a href="#强绑定性" class="headerlink" title="强绑定性"></a>强绑定性</h3><p>只能用于华为的硬件设备。并且后期会形成双向绑定，如若依赖FabricInsight，扩容时只能继<br>续采购华为设备。 </p><h3 id="基于流量事件"><a href="#基于流量事件" class="headerlink" title="基于流量事件"></a>基于流量事件</h3><p>对于流的分析仅涉及五元组和TCP流量事件。可依据SYN、FIN、RST等TCP流量事件完成<br>TCP SYN重传、RST等事件的侦测，并作为报警依据。 </p><h3 id="无流量全量分析"><a href="#无流量全量分析" class="headerlink" title="无流量全量分析"></a>无流量全量分析</h3><p>当前观察，仅有TCP流量的事件信息，对UDP、ICMP、ARP等网络流量无采集分析能力。仅<br>针对TCP流量，亦无流量全量分析能力，无法获取诸如流量总字节数、总包数、pps、平均时<br>延、最大时延等信息。</p><h3 id="Overlay能力暂无"><a href="#Overlay能力暂无" class="headerlink" title="Overlay能力暂无"></a>Overlay能力暂无</h3><p>当前FabricInsight宣称的可分析虚拟网络是指，手工指定某一虚拟网元（Virtual NE）IP地址<br>，手工指定其角色（e.g. FW\LB\Router）其与外界通讯的流量可以以与Underlay网络相同的<br>方式采集。<br>未发现针对虚拟网络VM间的采集分析能力。从其官方手册中针对ERSPAN的配置来看，可能<br>或未来会具有一定的VXLAN隧道解封装及关联对应能力。但即便如此，在大规模网络流量的<br>情况下，对全部VXLAN流量分析亦将为设备带来压力。<br>另外，主机内的虚拟网络流量，FabricInsight以现在的形式是绝对无法取得的。 </p><h2 id="FabricInsight未来演进趋势推测"><a href="#FabricInsight未来演进趋势推测" class="headerlink" title="FabricInsight未来演进趋势推测"></a>FabricInsight未来演进趋势推测</h2><h3 id="In-band-Telemetry"><a href="#In-band-Telemetry" class="headerlink" title="In-band Telemetry"></a>In-band Telemetry</h3><p>FabricInsight的数据采集能力全部来自于设备提供的能力。在设备/芯片领域的发展趋势是提<br>供更加精细化的In-band Telemetry遥测能力。从Cisco/Barefoot等厂商近期对P4芯片的动态来<br>看，华为跟风也是早晚的事。In-band Telemetry可以提供诸如per packet的全生命周期、匹配<br>的具体转发规则、更加精细的时间戳等能力。但如若采用新的芯片组提供In-band Telemetry<br>，则会仅支持新款产品。<br>除此之外，也将不仅仅将流量分析的范畴局限于TCP流量。 </p><h3 id="虚拟网络"><a href="#虚拟网络" class="headerlink" title="虚拟网络"></a>虚拟网络</h3><p>虚拟网络是行业演进的趋势，但需要考虑华为对FabricInsight这款产品本身的定位。如果添加<br>虚拟网络能力，则其品牌名称、目标人群都将会有较大调整。但华为整体上缺乏虚拟网络可视<br>化的产品和能力，因此推断会先对接华为自己的云平台FusionCloud，计算节点绑定探针。但<br>先期仍会仅采用TCP流量事件的分析模式，不会全量采集和分析。 </p><h3 id="AIops"><a href="#AIops" class="headerlink" title="AIops"></a>AIops</h3><p>AI的概念在当前版本的FabricInsight中已有所体现，但当前仅是一些标准差方差的统计计算。<br>演进的方式将是对网络中断和延迟的诊断以及自调优的赋能。但这种分析首先要求用户能够输<br>入一定的专家经验作为数据训练的标记，同时对分析节点的部署要求较高（支持大数据分布式<br>计算和存储）。 </p><h3 id="安全防御"><a href="#安全防御" class="headerlink" title="安全防御"></a>安全防御</h3><p>这是当前看起来最有实际效能的功能。其本身具有的TCP事件分析能力完全可以用来完成<br>DDoS攻击的侦测和防御。 </p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> product </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>可以预测交通路况的 APP</title>
      <link href="/2018/12/06/life-traffic-prediction/"/>
      <url>/2018/12/06/life-traffic-prediction/</url>
      
        <content type="html"><![CDATA[<blockquote><p>能不能有这样一款应用<br><a id="more"></a></p><p>或者地图 APP 实现这样一个功能</p><p>能通过历史路况大数据分析</p><p>告诉我今天晚上几点出发上路</p><p>东北四环不堵</p><p>把什么机器学习人工智能数字孪生</p><p>能加的都给它加上</p><p>感觉又是一个割 VC 韭菜的杀手应用</p><p>只要有人搭出来这个框架</p><p>我愿意帮忙实现所有的业务代码</p><p>因为只需要一句</p><p><code>return &quot;您期望的时间不存在&quot;</code></p></blockquote><p><em><em>2018.12.6</em></em></p>]]></content>
      
      
      <categories>
          
          <category> life </category>
          
      </categories>
      
      
        <tags>
            
            <tag> life </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去2：CPU缓存读入策略</title>
      <link href="/2018/12/06/test2-cache-line-alignment/"/>
      <url>/2018/12/06/test2-cache-line-alignment/</url>
      
        <content type="html"><![CDATA[<h2 id="到底哪些数据写入了CPU缓存"><a href="#到底哪些数据写入了CPU缓存" class="headerlink" title="到底哪些数据写入了CPU缓存"></a>到底哪些数据写入了CPU缓存</h2><p>我们知道CPU会在要读写某个数据时，先将数据写入缓存。</p><p>我们也知道这个操作一般以Cache Line为操作粒度，并且Cache Line的长度一般为64Byte。<br><a id="more"></a></p><p>那么这个Cache Line包含的数据到底是哪64Byte呢？</p><p>如果要读写的数据的地址正好以64Byte对齐，那么肯定是这个数据和它之后的<code>（64 - sizeof(数据)）</code>Byte存在于这个缓存行里。</p><p>但是如果要读写的这个数据地址不以64Byte对齐，而是在两个64Byte对齐的地址中间的某个位置，CPU写入Cache Line里的数据还是它和它之后的64Byte吗？CPU会“向前”对64取整作为Cache Line中的数据吗？</p><h2 id="用False-Sharing证明"><a href="#用False-Sharing证明" class="headerlink" title="用False Sharing证明"></a>用False Sharing证明</h2><p>根据之前介绍False Sharing的原理<a href="https://decodezp.github.io/2018/11/27/quickwords3-falsesharing/">链接</a>，通过判断是否发生False Sharing可以判断某两个数据是否存在于同一条Cache Line里。</p><p>构造如下结构体：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> front_padding[<span class="number">15</span>];</span><br><span class="line">    <span class="keyword">uint32_t</span> c1;</span><br><span class="line">    <span class="comment">/* 64 bytes */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> c2;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中<code>c1</code>和<code>c2</code>是分别被两个CPU core写入的变量。</p><p>在构造counter_t的实例时，利用<code>GCC attribute</code>确保其起始地址与64Byte对齐：</p><p><code>struct counter_t counter __attribute__((aligned(64)));</code></p><p>在两个CPU核分别开始操作<code>c1</code>和<code>c2</code>之前利用<code>clflush</code>指令清除所有相关缓存：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span></span><br><span class="line">clflush(<span class="keyword">volatile</span> <span class="keyword">void</span> *p)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span> <span class="params">(<span class="string">"clflush (%0)"</span> :: <span class="string">"r"</span>(p))</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>如果发生了False Sharing，则说明这两个变量在一个Cache Line里，则证明CPU是取欲读写变量及其之后64Byte数据写入缓存<br>如果没有发生False Sharing，则说明这两个变量不在一个Cache Line里，则证明CPU是取欲读写变量向前64取整地址上的数据写入缓存</p></blockquote><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>结果当然是没有发生False Sharing。</p><p>不然还搞什么n-way set associative :)</p><p>代码：<a href="https://github.com/PanZhangg/x86perf/blob/master/cache_line_alignment.c" target="_blank" rel="noopener">https://github.com/PanZhangg/x86perf/blob/master/cache_line_alignment.c</a></p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>魏孝文帝教你提proposal</title>
      <link href="/2018/12/05/history-tuobahong/"/>
      <url>/2018/12/05/history-tuobahong/</url>
      
        <content type="html"><![CDATA[<h2 id="艰难的Proposal"><a href="#艰难的Proposal" class="headerlink" title="艰难的Proposal"></a>艰难的Proposal</h2><p>每个人都有独自一人面对全世界的时候，即便你是魏孝文帝拓跋宏。</p><p>北魏太和十七年，承平日久的北魏都城里正在酝酿一件大事——迁都。<br><a id="more"></a></p><p>自天兴元年拓跋圭定都平城起，北魏在此地经营了九十余年。此时的平城，早已是北魏王公贵族富商巨贾的乐土。</p><p>而拓跋宏却不想在这呆了，对这位一心思慕华夏风仪的少数民族首领来说，城狭地偏的平城终究不是久居之地。</p><p>迁都，迁往洛阳，只有住在这座每块城砖上都写满了厚重的城邑的中心，才是北漂买房落户的那一刻。</p><p>但除了拓跋宏，没有人愿意当拆迁户，被连根拔起。拓跋宏自己也知道这一点。晓以大义？没用的，天底下最难的事，就是劝说别人放弃眼前的利益，去追求什么万世之业；</p><p>以皇帝的权威一意孤行？没有问题，但人心不齐，效果打折扣，既损威严，又于事无益。</p><p>那么迁都这个Proposal，到底怎么提呢？</p><h2 id="魏孝文帝的方式"><a href="#魏孝文帝的方式" class="headerlink" title="魏孝文帝的方式"></a>魏孝文帝的方式</h2><p>拓跋宏并没有在一开始就透露自己的意图，而是提出了一个更加”不得人心”的Proposal——亲自带队，攻打南朝。</p><p>如果说迁都不得人心，那么发动战争就更加让改革的主要阻力——深居平城的皇亲贵胄们如坐针毡。</p><p>因为迁都或许还可以讨论讨论，但南下伐齐“一统中国”那是北魏政权不容辩驳的“正统思想”，是政治正确，有拓跋氏列祖列宗的加持，以及冯太后的附魔。</p><p>这一年的八月，拓跋宏亲率三军开拔南下。</p><p>当然，皇帝都出去打仗了，除了太子监国以外，平日里的文武百官哪有在家呆着的道理，一起走吧！</p><p>从山西大同往南，大军在秋雨连绵的泥泞中走了整整一个月，终于到达了宿命的重点——洛阳。</p><p>这个时候所有人都不想再走了。一路的狼狈或可忍受，但后面还有与齐国的恶战。而拓跋宏依然兴致不减，号令即刻开拔，继续南进。</p><p>这下文武百官们可都要“犯颜进谏”了，纷纷叩头不止，甚至不惜死谏以请求拓跋宏停止南征。</p><p>这个时候拓跋宏才说出他真正的目的：</p><blockquote><p>今者兴动不小，动而无成，何以示后？苟欲班师，无以重之千载！朕世居幽朔，欲南迁中土，苟不南伐，当迁都于此，王公以为如何？欲迁者左，不欲者右！——《资治通鉴》</p></blockquote><p>这里有三个要素：</p><ol><li>我可以在南伐之事上让步</li><li>但我的让步有条件</li><li>不许考虑太久</li></ol><p>最终的结果自然是大家都站到了左边。迁都这件事，就这么“取得”了大家的同意。</p><p><img src="http://5b0988e595225.cdn.sohucs.com/images/20170720/b36a2fde600f4b909885b0a76ada9876.jpeg" alt=""></p><h2 id="抽象提取"><a href="#抽象提取" class="headerlink" title="抽象提取"></a>抽象提取</h2><p>在谈判领域存在一个让步/妥协的谈判技巧。</p><p>对每个人来说，如果对面已有所让步，那么心里将会产生同样让步的压力，趋向于同意对方提出的让步条件。</p><p>这种场景在生活中非常常见，例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">多少钱？</span><br><span class="line">100</span><br><span class="line">30吧</span><br><span class="line">最低90</span><br><span class="line">40</span><br><span class="line">低于85就赔本了</span><br><span class="line">你看我就50块钱</span><br><span class="line">行了80吧，今天好不容易开张</span><br></pre></td></tr></table></figure><p>如果能成交，说明买家和卖家一开始的心理价位就都是80元左右，但买家必须要首先压到30，卖家也要提到100，互相留出这个让步的空间。</p><p>也许你觉得这种技巧太市侩，但它其实有很多变种版本，也许自己已经身堕瓠中而不自知。<br>E.g.<br>房产中介请你看房，首先是一间各方面条件都很差的房间，但却有一个让你惊讶的高额租金。然后带你看了一套各方面比第一间好非常多的房间，租金却和第一间一样，或者略多而已。<br>如此你会觉得租了第二间是占了便宜。但其实中介的目标就是租给你第二间房，第一间就是让你产生这种对比让步的错觉的。</p><p>所以，每当打算提一个艰难的Proposal的时候，我都会效仿这种形式。</p>]]></content>
      
      
      <categories>
          
          <category> history </category>
          
      </categories>
      
      
        <tags>
            
            <tag> history </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ftrace uprobe使用填坑历程</title>
      <link href="/2018/12/04/ftrace-uprobe/"/>
      <url>/2018/12/04/ftrace-uprobe/</url>
      
        <content type="html"><![CDATA[<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>打算用一下<code>ftrace</code>对用户态程序的trace支持。</p><h3 id="测试用程序test-c："><a href="#测试用程序test-c：" class="headerlink" title="测试用程序test.c："></a>测试用程序<code>test.c</code>：</h3><a id="more"></a><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">print_curr_state_one(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is the print current state one function\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">print_curr_state_two(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is the print current state two function\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        print_curr_state_one();</span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">        print_curr_state_two();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="编译："><a href="#编译：" class="headerlink" title="编译："></a>编译：</h3><p><code>gcc -o test test.c</code></p><h3 id="Obtain-Offset："><a href="#Obtain-Offset：" class="headerlink" title="Obtain Offset："></a>Obtain Offset：</h3><p><code>objdump -d test</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">000000000040055d &lt;print_curr_state_one&gt;:</span><br><span class="line">  40055d:55                   push   %rbp</span><br><span class="line">  40055e:48 89 e5             mov    %rsp,%rbp</span><br><span class="line">  400561:bf 30 06 40 00       mov    $0x400630,%edi</span><br><span class="line">  400566:e8 c5 fe ff ff       callq  400430 &lt;puts@plt&gt;</span><br><span class="line">  40056b:5d                   pop    %rbp</span><br><span class="line">  40056c:c3                   retq   </span><br><span class="line"></span><br><span class="line">000000000040056d &lt;print_curr_state_two&gt;:</span><br><span class="line">  40056d:55                   push   %rbp</span><br><span class="line">  40056e:48 89 e5             mov    %rsp,%rbp</span><br><span class="line">  400571:bf 60 06 40 00       mov    $0x400660,%edi</span><br><span class="line">  400576:e8 b5 fe ff ff       callq  400430 &lt;puts@plt&gt;</span><br><span class="line">  40057b:5d                   pop    %rbp</span><br><span class="line">  40057c:c3                   retq</span><br></pre></td></tr></table></figure><p>添加uprobe trace event：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 'p:print_current_state_one /root/test/uprobe/uprobe:0x55d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_events</span><br><span class="line">echo 'p:print_current_state_two /root/test/uprobe/uprobe:0x56d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_events</span><br></pre></td></tr></table></figure><p>有时会出现Invalid argument的错误。用<code>sudo su</code>获取<code>root</code>权限。</p><blockquote><p>这里注意，偏移的大小只写0x55d，不能写0x40055d</p></blockquote><h2 id="开启trace"><a href="#开启trace" class="headerlink" title="开启trace"></a>开启trace</h2><p>先启动<code>test</code>程序：<code>./test</code></p><p><code>echo 1 &gt; /sys/kernel/debug/tracing/event/enable</code></p><p>如果此时<code>cat /sys/kernel/debug/tracing/event/enable</code>显示为<code>X</code></p><p><code>echo 1 &gt; /sys/kernel/debug/tracing/event/uprobes/enable</code></p><p>最后<code>cat /sys/kernel/debug/tracing/trace</code>应该就能看到了</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> ftrace </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ftrace trace-cmd kernelshark资料汇总</title>
      <link href="/2018/11/30/ftrace/"/>
      <url>/2018/11/30/ftrace/</url>
      
        <content type="html"><![CDATA[<p>一些关于这一类技术的资料和文档汇总。<br>文章中可以找到比较详细的工具使用方法。如果想了解更多内容可以阅读<code>linux/Documentation/trace</code>下的文档以及源码。</p><p>以及<code>git log ./kernel/trace</code> :)<br><a id="more"></a></p><h2 id="ftrace"><a href="#ftrace" class="headerlink" title="ftrace"></a>ftrace</h2><ul><li><a href="https://lwn.net/Articles/365835/" target="_blank" rel="noopener">Debugging the kernel using Ftrace - part 1</a></li><li><a href="https://lwn.net/Articles/366796/" target="_blank" rel="noopener">Debugging the kernel using ftrace - part 2</a></li><li><a href="https://www.kernel.org/doc/Documentation/trace/ftrace.txt" target="_blank" rel="noopener">Kernel Documents: ftrace</a></li><li><a href="https://lwn.net/Articles/370423/" target="_blank" rel="noopener">Secrets of the Ftrace function tracer</a></li><li><a href="https://people.canonical.com/~acelan/coscup-2010/Debugging%20Linux%20Kernel%20by%20Ftrace.pdf" target="_blank" rel="noopener">PDF:Debugging Linux Kernel by ftrace</a></li><li><a href="https://opensourceforu.com/2010/11/kernel-tracing-with-ftrace-part-1/" target="_blank" rel="noopener">Kernel Tracing with ftrace, Part 1</a></li><li><a href="http://opensourceforu.com/2010/12/kernel-tracing-with-ftrace-part-2/" target="_blank" rel="noopener">Kernel Tracing with ftrace, Part 2</a></li><li><a href="https://jvns.ca/blog/2017/03/19/getting-started-with-ftrace/" target="_blank" rel="noopener">ftrace: trace your kernel functions!</a></li><li><a href="https://movaxbx.ru/2018/10/12/hooking-linux-kernel-functions-how-to-hook-functions-with-ftrace/" target="_blank" rel="noopener">Hooking Linux Kernel Functions, how to Hook Functions with Ftrace</a></li><li><a href="https://www.slideshare.net/ennael/kernel-recipes-2017-understanding-the-linux-kernel-via-ftrace-steven-rostedt" target="_blank" rel="noopener">Understanding the Linux kernel via ftrace</a></li></ul><h2 id="trace-cmd"><a href="#trace-cmd" class="headerlink" title="trace-cmd"></a>trace-cmd</h2><ul><li><a href="https://lwn.net/Articles/410200/" target="_blank" rel="noopener">trace-cmd: A front-end for Ftrace</a></li><li><a href="https://github.com/rostedt/trace-cmd" target="_blank" rel="noopener">Code:trace-cmd</a></li></ul><h2 id="kernelshark"><a href="#kernelshark" class="headerlink" title="kernelshark"></a>kernelshark</h2><ul><li><a href="https://lwn.net/Articles/425583/" target="_blank" rel="noopener">Using KernelShark to analyze the real-time scheduler</a></li><li><a href="https://kernel-recipes.org/en/2018/talks/kernelshark-1-0-whats-new-and-whats-coming/" target="_blank" rel="noopener">Video:KERNELSHARK 1.0; WHAT’S NEW AND WHAT’S COMING</a></li><li><a href="https://www.youtube.com/watch?v=RwVnnuGrb_c" target="_blank" rel="noopener">Video:Yordan Karadzhov - What’s Coming in Kernel Shark</a></li><li><a href="https://events.linuxfoundation.org/wp-content/uploads/2017/12/Swimming-with-the-New-KernelShark-Yordan-Karadzhov-VMware.pdf" target="_blank" rel="noopener">PDF:Swimming with the New KernelShark</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> ftrace </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去1：DPDK no-huge模式性能对比测试</title>
      <link href="/2018/11/29/test1-dpdk-no-huge/"/>
      <url>/2018/11/29/test1-dpdk-no-huge/</url>
      
        <content type="html"><![CDATA[<h2 id="no-huge"><a href="#no-huge" class="headerlink" title="no-huge"></a>no-huge</h2><p>DPDK使用大页内存作为性能优化的一个手段。但大页内存在云计算等环境下可能会出现内存资源浪费的情况，作为售卖资源的云服务商，希望能找到更充分的内存资源利用的方法。在此背景下，DPDK引入了no-huge机制，即不使用hugepage，从而解放更多的系统资源。</p><p>那么这种配置下DPDK性能会下降多少呢？还是需要实际定量测试一下。<br><a id="more"></a></p><h2 id="测试平台"><a href="#测试平台" class="headerlink" title="测试平台"></a>测试平台</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                88</span><br><span class="line">On-line CPU(s) list:   0-87</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    22</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 85</span><br><span class="line">Model name:            Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHz</span><br><span class="line">Stepping:              4</span><br><span class="line">CPU MHz:               2100.393</span><br><span class="line">BogoMIPS:              4201.72</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              30976K</span><br><span class="line">NUMA node0 CPU(s):     0-21,44-65</span><br><span class="line">NUMA node1 CPU(s):     22-43,66-87</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep Ether</span><br><span class="line">86:00.0 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.1 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.2 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.3 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br></pre></td></tr></table></figure><p>DPDK Version: <code>18.05.1</code><br>Tester: IXIA<br>Test Plan: RFC2544<br>DPDK APP: <code>./l2fwd -l 22-24 --no-huge  -- -p 0x3 -T 5</code></p><h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p><img src="https://s1.ax1x.com/2018/11/29/FZIYcT.png" alt=""></p><p>在64Byte包长时丢包率达到了50%以上，而使用大页内存时丢包率可以控制在0.05%以内。<br>其他长度丢包和吞吐情况基本相同。<br>根据业务情况，平均包长如果在300Byte以上–no-huge模式不妨一试。<br>后续添加针对更大链路带宽(25Gbps/100Gbps)的网卡以及不同Xeon平台的测试结果。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> test </tag>
            
            <tag> dpdk </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>云计算的发展需要向社区街道管理看齐</title>
      <link href="/2018/11/28/thoughts1-cloud-community/"/>
      <url>/2018/11/28/thoughts1-cloud-community/</url>
      
        <content type="html"><![CDATA[<h2 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h2><p>云计算本质上是一种服务。由各种不同的组件为租户提供计算、网络和存储服务。</p><p>用户对这些服务的要求除了功能之外，还有安全性、可用性、性能、成本、迁移难度、SLA等一系列要求。</p><p>与之类比，社区街道作为一个完整的功能单元，各个基层职能部门，也为社区内的居民提供各类生活服务。</p><p>如何做好基层工作，是需要费一番脑筋的。<br><a id="more"></a></p><h2 id="服务网格"><a href="#服务网格" class="headerlink" title="服务网格"></a>服务网格</h2><p>下图是我在北京中关村某社区拍到的当地派出所的“网格团队”成员和工作职责。</p><p><img src="https://s1.ax1x.com/2018/11/28/FV0v3q.jpg" alt=""><br>如果你熟悉云计算，熟悉当前的领先理念，那么<code>service mesh</code>这个词你肯定不陌生，这是当前容器和微服务领域的最新热点，拥有Istio、Envoy等一众明星开源项目，并且有Google、AWS、Alibaba等大佬拥趸。这个词翻译过来就是<code>服务网格</code>。</p><p>而社区街道提出的这个“网格”的概念，明显领先于自诩为科技前沿的云计算。</p><p>如果仔细阅读一下上图中的“工作职责”，就能够轻易地将其内容与时下云计算和企业数字化转型热炒的概念对应起来：</p><ul><li>管理网格单元：Microservice微服务</li><li>落实基信息采集：Digital Twin数字孪生</li><li>综合网格力量：Orchestration协同</li><li>加强依法自治：Decouple解耦/Distrubute分布式</li><li>排查隐患：Situational Awareness态势感知/Active Defence主动式防御</li><li>协调解决社会服务管理中存在的问题：Full Stack Management全栈管理</li><li>推进公共服务建设：Aglie敏捷/DevOps</li><li>监督管理网格力量，督促责任落实：Sidecar</li><li>及时上报网格工作数据：Telemetry遥测</li><li>完成街道交办的其他工作：Serverless无服务器</li></ul><p>总结就是这个街道派出所就是Community-Native Microservice &amp; Service Mesh &amp; Serverless &amp; Security的典范，理念领先云计算至少5年。</p><h2 id="好好学习"><a href="#好好学习" class="headerlink" title="好好学习"></a>好好学习</h2><p>为什么街道派出所的理念能领先云计算的发展？道理都是殊途同归的，很多理念（经验）的获得都是靠积攒年头。</p><p>云计算方兴未艾，但毕竟用户还不足够多，问题暴露还不足够全面，或者说，没太多管理经验。而派出所展开基层管理工作的时间至少比在坐的诸位岁数都长。同时基层群众形形色色，就像软件测试时的边界条件，绝对都能满足。</p><p>在此种“得天独厚”的条件下总结出的经验，云计算从业者除了好好消化吸收之外，也可以小小的自鸣得意一下，毕竟你仅仅用了10年就追上了街道派出所。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> thoughts </tag>
            
            <tag> cloud </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚3:什么是False Sharing</title>
      <link href="/2018/11/27/quickwords3-falsesharing/"/>
      <url>/2018/11/27/quickwords3-falsesharing/</url>
      
        <content type="html"><![CDATA[<h2 id="不用图"><a href="#不用图" class="headerlink" title="不用图"></a>不用图</h2><p>以为又要见到那几张网上已经用烂了的图了是不是？这次我们不用图来讲这个事。<br><a id="more"></a></p><p>Cache line是64个Byte，我们经常操作(R/W)的变量是4个或者8个Byte。</p><p>于是一个Cache line里就可以放好几个变量，比如说其中有两个变量A和B。</p><p>当CPU0写入A，CPU1写入B的时候，就发生了False Sharing，就这么简单。</p><p>所谓“假共享”，其实就是你以为你俩自己操作自己的变量是共产国际按需分配互不影响，其实都是假象。</p><p>很多材料上说是因为不同的CPU核共享了相同的Cache Line，其实并不严谨。根本因素是不同的CPU核需要更新的缓存出现了地址上的重叠。</p><p>那么当其中一个核更新了它的变量A之后，CPU并不能识别出是哪4个Byte或8个Byte地址上的数据被更新，而只能认为该变量所在的整条64Byte Cache Line都应该被更新。</p><p>所有有和这64Byte重叠的Cache Line，不管在哪个CPU核上，都需要被更新，这样才能保证大家手头的数据是一致的。</p><p>于是乎，和这64Byte地址存在重叠的变量B所在的CPU1中的缓存也需要被更新，自然就影响到了性能。</p><p>如果只是读，就没有这个问题，因为不需要关心缓存一致这个事。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>这里有一个活生生的代码的例子：</p><p><a href="https://github.com/PanZhangg/x86perf/blob/master/false_sharing_padding.c" target="_blank" rel="noopener">https://github.com/PanZhangg/x86perf/blob/master/false_sharing_padding.c</a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> c1;</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifdef</span> PADDING_64_BYTE</span></span><br><span class="line">    <span class="keyword">uint32_t</span> padding[<span class="number">15</span>];</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">elif</span> PADDING_128_BYTE</span></span><br><span class="line">    <span class="keyword">uint32_t</span> padding[<span class="number">31</span>];</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">uint32_t</span> c2;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>本来是打算用来验证在CPU预取开启的情况下到底是应该Padding 64还是128，但在Haswell和Skylake上验证，这两个长度都没有区别。</p><p>后来查找资料是在Sandy bridge上需要padding到128，但我这里没有这么老的CPU….先这样吧..</p><p>上面的代码注意用<code>-O0</code>编译。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚2:CPU缓存的组织形式</title>
      <link href="/2018/11/25/quickwords2-cacheassociativity/"/>
      <url>/2018/11/25/quickwords2-cacheassociativity/</url>
      
        <content type="html"><![CDATA[<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>缓存和其他存储形式在功能形式上没有太大区别，均是输入一个地址，还你一个数据。但作为一个缓存，要考虑如何在有限的容量下保证较高的命中率以及查找效率(<a href="https://decodezp.github.io/2018/11/20/cachesize/">相关阅读</a>)。这个问题从本质上来说，就是如何建立缓存地址与内存地址的映射关系。</p><a id="more"></a><h2 id="组织形式"><a href="#组织形式" class="headerlink" title="组织形式"></a>组织形式</h2><p>缓存按照一个Cache Line的长度（主流长度为64Byte）为粒度来组织：</p><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140538/481_051.gif" alt=""><br>各种不同的映射形式就是在决定内存中某一个特定地址范围内的数据，具体可以放到哪一个Cacha Line里去。</p><p>能想出来的方式也无外乎三种：</p><ul><li>哪个都可以放</li><li>只能放到第N个（N是内存地址的函数）</li><li>只能放到第N个至第M个（M也是内存地址的函数）</li></ul><blockquote><p>其实基本上这篇文章可以结束了，很多技术都不是什么新鲜的“创想”，只是给朴素的思想内核穿上了一层“术语”的外衣。</p></blockquote><h3 id="Direct-Mapping"><a href="#Direct-Mapping" class="headerlink" title="Direct Mapping"></a>Direct Mapping</h3><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140525/481_061.gif" alt=""><br>这就是上面说的第二种方式，某一个内存地址段的数据，只能放在第N个Cache Line里</p><ul><li>Pros:查找快，一次寻址，有就是有，没有就是没有，不啰嗦（因为只需要验证一个Cache Line中是否存在该地址）</li><li>Cons:命中率低，CPU经常需要相邻地址的数据，而根据规则，同属于第N个Cache Line的数据会互相排斥，不会同时出现在缓存里</li></ul><h3 id="Fully-Associative"><a href="#Fully-Associative" class="headerlink" title="Fully Associative"></a>Fully Associative</h3><p>这就是第一种方式，随便放。</p><ul><li>Pros:命中率高，过去和未来一段时间内需要的数据都可以被放在缓存内，同时不用担心被相邻地址上的数据踢出</li><li>Cons:查找慢，确认一个地址是否在缓存里通常需要遍历整个缓存（Miss的情况）</li></ul><h3 id="n-Way-Set-Associative-Cache"><a href="#n-Way-Set-Associative-Cache" class="headerlink" title="n-Way Set Associative Cache"></a>n-Way Set Associative Cache</h3><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140450/481_081.gif" alt=""><br>这就是第三种方式了，颜色相同的内存地址范围和缓存Cache Line互相对应，不能越界。每一个颜色就是一个Way。</p><p>但如果单独拿出某一个颜色来看，是Fully Associative的方式。</p><p>这么做当然是为了充分发挥前两种方式的优势。既可以存在相邻内存中的数据以提高命中，同时也一定程度上减少了查找范围，提升查找效率。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>XXV710网卡Target Link Speed探秘</title>
      <link href="/2018/11/23/x710-target-link-speed/"/>
      <url>/2018/11/23/x710-target-link-speed/</url>
      
        <content type="html"><![CDATA[<h2 id="发现"><a href="#发现" class="headerlink" title="发现"></a>发现</h2><p>用lspci指令查看PCIe设备，特别是网卡设备经常会查看LnkCap及LnkSta字段，以确保网卡运行在期望的PCIe总线类型/带宽上，从而保证网卡的性能。</p><p>最近拿到一块XXV710-DA2，插上之后简单看了一下状态。LnkCap和LnkSta均显示为Speed 8GT/s，Width x8，没太大问题。这时候无意中瞥见LnkCtl2中Target Link Speed显示为2.5GT/s，引发了兴趣。<br><a id="more"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</span><br><span class="line">DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not Supported</span><br><span class="line">DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled</span><br><span class="line">LnkCtl2: Target Link Speed: 2.5GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB</span><br></pre></td></tr></table></figure><h2 id="Target-Link-Speed"><a href="#Target-Link-Speed" class="headerlink" title="Target Link Speed"></a>Target Link Speed</h2><p>关于Target Link Speed是什么，查找到了Intel Skylake Processor External Design Specification(EDS)中的定义：</p><blockquote><p>For Downstream Ports, this field sets an upper limit on Link operational speed by restricting the values advertised by the Upstream component in its training sequences.</p></blockquote><p>基本上LnkCap表示支持的速度，LnkCtl2设置你需要的速度，LnkSta显示实际Training好的速度，如果想要修改的话，都是改LnkCtl2的值。</p><p>现在的问题就是LnkSta和LnkCtl2矛盾。那么我们现在这块网卡的速度到底是多少？只能实际测试一下。</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>起个<code>pktgen</code>打个性能，是能直接到线速的，也就是说Target Link Speed没有实际起到限制速度的作用。</p><p>又查询了一些资料，从这里看到一个帖子：<a href="https://communities.intel.com/thread/106568" target="_blank" rel="noopener">https://communities.intel.com/thread/106568</a></p><p>最终Intel的官方回复是，这个寄存器的值确实和实际速度没有关系。</p><p>规范也是你们写的，帖子也是你们回的，现在正话反话都让你说了，搞什么鬼。</p><p>最后查到了该寄存器的位置(D0h)，暴力修改一下：</p><p><code>setpci -s 0000:18:00.0 d0.B=3</code></p><p>然后就乖乖地显示为8GT/s了，真是个毫无脾气的寄存器，你让别的遵守规范的设备如何自处。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</span><br><span class="line">DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not Supported</span><br><span class="line">DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled</span><br><span class="line">LnkCtl2: Target Link Speed: 8GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序员和工厂劳工有何不同</title>
      <link href="/2018/11/22/programmer-worker/"/>
      <url>/2018/11/22/programmer-worker/</url>
      
        <content type="html"><![CDATA[<p>如今流行的一个说法是，现在的程序员与工业时期的工厂工人并无二致。<br>均是富集于人口密集的城市、均是超时劳动、均是遭受资本家的盘剥、均是一架大机器上的螺丝钉，在超过“劳动年龄”之后被弃如敝屣。<br>基于这些相似点，有些人得出结论，程序员不过是这个时代的“无产阶级”，和以前的流水线工人，纺织厂女工属于同一社会分工和定位。<br>是否当真如此，这个问题值得仔细推敲一下。<br><a id="more"></a></p><h2 id="生产资料"><a href="#生产资料" class="headerlink" title="生产资料"></a>生产资料</h2><p>个人所处的社会阶层，取决于他能让属于他的生产资料产生的价值。传统的生产资料包括实体的机器、厂房、地皮、原材料、资本和人等等。<br>而作为信息时代的标志，人人都可以通过网络获取一项虚拟的生产资料——信息。诚然，信息壁垒依然存在，但普通人能接触到的信息总量和质量与信息革命之前的时代相比已不可同日而语。<br>程序员是与电子计算设备打交道的人，此类设备本质上是信息的产生、加工和分发工具。一台电脑加一条网线，程序员就可以以极其低廉的方式获得他所需要的生产资料。而拥有生产资料的人，就不能再称之为“无产阶级”。<br>我们已经听过了太多程序员在车库创业的故事，也许这些故事仍然可以称之为“个例”，毕竟，哪个时代没有一些白手起家的人。<br>但如果某个行业能在全社会掀起创业的热潮，那么就不能再以孤例的眼光看待。只有在该行业的生产资料极大丰富，且对再加工之后的产品有持续需求的情况下才有可能出现这类情况。<br>是否能以足够廉价的方式获取生产资料，是程序员与工厂工人的第一个区别。<br><img src="http://www.xinhuanet.com/politics/2015-05/05/127763760_14307851178281n.jpg" alt=""></p><h2 id="对生产资料的再分工"><a href="#对生产资料的再分工" class="headerlink" title="对生产资料的再分工"></a>对生产资料的再分工</h2><p>注意这里强调的是再“分”工，而不是再加工。<br>程序员能够开发出各种程序满足人们的需求，工人也能生产出各种生活必需品，所以在生产资料再加工这一点上，两者没有本质区别。<br>专业细分是社会生产率提高的根本因素。每个人只负责整条产业链中的一环，愈发细致的分工与合作是现代生产活动的组织方式。<br>程序员和工人均为某一细分领域的专家，但二者所处的分工链条深度不同。<br>工人是分工链条的末端，他所能做的就是尽自己所能做好手头的事情。<br>而程序员虽然仍然要听老板的，但他手下仍有电子设备作为分工的最后一环。<br>程序员可以通过编码为这些电子设备“分工”，从而令其为程序员服务。<br>从某种意义上说，程序员就是这些电子设备的“老板”。同时随着设备的计算能力越来越强，这些设备就能逐渐胜任更加精细的分工任务。<br>随着分工的深入，一方面带动社会整体劳动生产率的提升，一方面更加高效地产生价值。<br>一个大型工厂的老板最多能令数万工人为其服务，而所有能跑代码的设备都可能为程序员服务。<br>在分工链所处的位置和对生产资料的再分工能力，是程序员与工厂工人的第二个区别。<br><img src="http://s2.51cto.com/oss/201811/05/d0c5758831b1df8bcac6728d848e014a.jpg-wh_651x-s_1764483471.jpg" alt=""></p><h2 id="程序员如何度过”中年危机”"><a href="#程序员如何度过”中年危机”" class="headerlink" title="程序员如何度过”中年危机”"></a>程序员如何度过”中年危机”</h2><p>其实程序员是新时代的工厂工人这种论调，只不过是之前“青春饭”、“过了30岁不能再编程“等论调的新瓶装旧酒而已。<br>但程序员面对的现实压力确实是不容忽视的问题。很多人学了很多技术，掉了很多头发，但最后仍被公司扫地出门，问题就在于做了无用的努力。<br>解决之道其实就蕴含在前文论述的两点之内：</p><ul><li>尽可能占有(处理)更多的生产资料——信息</li><li>为尽可能多的电子设备”分工”</li></ul><p>实际执行的术便是一定要有自己的“产品”。<br>这当然是一个程序，可以是公司的产品，也可以是个人作品。但需要关注两个关键点：</p><ul><li>我的程序是否位于信息交叉的节点或能协助信息的获取、处理及分发</li><li>运行我的程序的设备是否在增长</li></ul><p>可以看看这些久盛不衰的“产品”：操作系统、数据库、浏览器、服务器软件、办公处理、图像应用处理等等甚或编程语言本身，都是这两个关键点的很好的体现。<br>当你拥有这样的产品时，操心的就不是公司会不会要你了，而是如何高效地指挥你自己这支被你分工的生产队，实践一些大胆的想法。<br>最后附上我最喜欢的历史名人名言作为结尾：</p><blockquote><p>臣但恐富贵来逼臣，臣无心图富贵。</p></blockquote><p>——杨素</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚1:为什么CPU L1缓存容量始终很小</title>
      <link href="/2018/11/20/cachesize/"/>
      <url>/2018/11/20/cachesize/</url>
      
        <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>CPU缓存是影响软件性能的关键因素之一。在做性能调优时，经常关注的一个指标就是缓存的命中率(hit rate)。<br>缓存之所以不会达到100%的命中率，是因为缓存容量有限，不能将内存中的全部数据都同时放入其中。只能将当前最热，相邻最近的数据存入，同时还受多核CPU中缓存同步机制的影响。<br>奇怪的是，CPU的制程、晶体管数量、核心数量一直都在增加，但L1缓存的容量始终维持在一个相当低的水平。为什么不加大L1缓存呢？<br><a id="more"></a></p><p><img src="https://cenalulu.github.io/images/linux/cache_line/latency.png" alt=""></p><h2 id="缓存组织形式"><a href="#缓存组织形式" class="headerlink" title="缓存组织形式"></a>缓存组织形式</h2><p>当然要考虑到成本和功耗，以及边界效益的问题，但这些不是本文讨论的重点。<br>缓存存在的意义是当CPU需要某些数据时，能够以最快的速度给它。<br>这个速度是以CPU时钟周期为计量单位的。在这一个周期内，CPU能处理的数据量并不大。<br>作为L1缓存，首先需要做的就是把这几个周期内的数据保存好，这个确实缓存容量越大，可以做得越好。<br>但把数据喂给CPU，还需要另外一步工作——缓存的查找。<br>种种不同的缓存组织方式和对应的查找机制，其实是在命中率以及查找效率中寻找平衡。</p><p><img src="https://cs.nyu.edu/~gottlieb/courses/2000s/2007-08-fall/arch/lectures/diagrams/cache-set-assoc.png" alt=""></p><ul><li>直接映射(Direct Mapping)查找效率高，但命中率很低</li><li>全关联映射(Fully Associative Mapping)命中率会提高，但查找效率非常低，与缓存容量成反比</li><li>N路组相联映射(N-ways Set-Associative Mapping)折衷方案，平衡命中率和查找效率，也是缓存采用的组织方式</li></ul><h2 id="L1"><a href="#L1" class="headerlink" title="L1$"></a>L1$</h2><p>对L1缓存来说，任务很艰巨，既要追求命中率，同时也要保证查找效率，那么解决方法就是缩小体积。既享受N-ways Set-Associative Mapping带来的命中率，同时因为每个Set的尺寸不大，仍然会有很高的查找效率。<br>如果将缓存的容量增大，不仅仅是成本和功耗上得不偿失，也将会让缓存的查找效率降低而使缓存丧失意义。</p><p>“大曰逝，逝曰远，远曰反”，以退为进，以曲为直的道理在缓存中有了很好的体现。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>top命令使用方法补遗</title>
      <link href="/2018/11/19/topcmd/"/>
      <url>/2018/11/19/topcmd/</url>
      
        <content type="html"><![CDATA[<h2 id="更改界面刷新频率"><a href="#更改界面刷新频率" class="headerlink" title="更改界面刷新频率"></a>更改界面刷新频率</h2><ul><li>自动刷新</li></ul><p><code>top</code><br><code>d</code><br>输入刷新时间（默认3秒，可调至0.5）</p><ul><li>手动刷新<br>空格</li></ul><a id="more"></a><h2 id="屏幕滚动"><a href="#屏幕滚动" class="headerlink" title="屏幕滚动"></a>屏幕滚动</h2><p>一个屏幕显示不完<br><code>C</code><br>使用方向键滚动</p><p>可用在使用<code>c</code>和<code>V</code>开启命令行及Forest view之后</p><h2 id="查看线程top信息"><a href="#查看线程top信息" class="headerlink" title="查看线程top信息"></a>查看线程top信息</h2><p><code>H</code></p><h2 id="查看线程CPU绑定-亲和性状态"><a href="#查看线程CPU绑定-亲和性状态" class="headerlink" title="查看线程CPU绑定/亲和性状态"></a>查看线程CPU绑定/亲和性状态</h2><p><code>F</code><br>移动光标至<code>Last Used Cpu</code><br>空格<br><code>q</code>返回</p><p>与<code>H</code>配合使用<br>可观察各线程是否与对应的CPU核绑定亲和性</p><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p><code>M</code>按驻留内存大小排序<br><code>P</code>按CPU使用率排序<br><code>T</code>按累计时间排序<br><code>x</code>高亮排序的列</p><h2 id="按NUMA查看CPU使用情况"><a href="#按NUMA查看CPU使用情况" class="headerlink" title="按NUMA查看CPU使用情况"></a>按NUMA查看CPU使用情况</h2><p><code>2</code>查看各NUMA节点CPU汇总使用信息<br><code>3</code>输入节点号，查看该节点各CPU使用信息</p><h2 id="按条件过滤"><a href="#按条件过滤" class="headerlink" title="按条件过滤"></a>按条件过滤</h2><p>‘O’<br>输入过滤条件，如:<br><code>!COMMAND=top</code> COMMAND栏中不包含top<br><code>%CPU&gt;3.0</code> CPU占用率大于3%<br>清除全部过滤条件 <code>=</code></p><h2 id="保存当前命令配置"><a href="#保存当前命令配置" class="headerlink" title="保存当前命令配置"></a>保存当前命令配置</h2><p><code>W</code><br>下次再启动时恢复当前配置形式</p><h2 id="其他信息"><a href="#其他信息" class="headerlink" title="其他信息"></a>其他信息</h2><p><code>man top</code></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>刚日读经，柔日读史</title>
      <link href="/2018/11/18/gangrirouri/"/>
      <url>/2018/11/18/gangrirouri/</url>
      
        <content type="html"><![CDATA[<p>在不知道什么时候，我们似乎被灌输了一种互补好，什么都是互补好的认知。<br>资源要互补，团队要互补，思想要互补，连看个书也得掐着日子互补。</p><a id="more"></a><p>刚日读经，柔日读史，“刚日”就是阳数的日子，“柔日”就是阴数的日子。因为阴阳要互补，所以刚日要读致虚守弱恒常静笃的经；柔日便要读变动不居周行不殆的史。<br>为此还有各位理论导师的笺注，比如南怀瑾：</p><blockquote><p>亢阳激扬，刚也；卑幽忧昧，柔也。经主常，史主变。故刚日读经，理气养生也；柔日读史，生情造意也。有生有息，合乎天理，何乐而不为哉！</p></blockquote><p>感觉并不如我总结得那般言简意赅提要钩玄。<br>如果说这种“互补”确实在指导我们的行为，那也无可厚非。而实际上我们日常行事，却和这种思想观念有很大出入。<br>饮食上要以形补形，想要强要壮，自然是找来更强更壮的，绝对不会找短小“互补”的食材。<br>婚嫁上要强强联合，至少至少也要找个“门当户对”的。至于相互互补的情节，不是出现在少儿童话故事里，就是出现在成人童话故事里。<br>嘴里说的是阴阳互补，做的却是采阴补阳的勾当。<br>而最重要的是，没有人觉得有问题。我们妄自接受了这些观念，很少去问这些到底是什么。只是在需要的场合，程式化地提出这一观念。<br>什么是互补，什么是阴，什么是阳，什么是刚，什么是柔。如果我脑中只是一些不明来源，未经考究过的观念，那么什么是我自己。<br>更诡吊的是，人与人之间最大的仇恨与惨剧，都滥觞于这种我们根本自己也没搞清楚的观念。<br>不要说“互补”，即便是稍有不同，那便是异端邪说、是外族、是异教徒、是政治犯；那便会有党争、门户、正宗、政治清洗和宗教审判。<br>信不知凭何而信，恨不知因何而恨。被左右的观念所左右，被迷惑的语言所迷惑，操纵感官输出的表象又被表象所操纵。<br>无论刚日柔日，翻开经史，里面都是这样的故事。只要稍微读几页就会发现，与先前想的正好相反，教给你变化的其实是经，而教给你不变的是史。<br>所以这句话并不是要教给你刚柔相济之道，而是提醒你认清人心之妄作，行为之颠倒，以及，追求真实的难能可贵。<br>谨录于上，念念不忘。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>如何在偷偷搜索关键字后避免令人尴尬的广告</title>
      <link href="/2018/11/17/duckduckgo/"/>
      <url>/2018/11/17/duckduckgo/</url>
      
        <content type="html"><![CDATA[<blockquote><p>转载自<a href="https://cloudwonders.info" target="_blank" rel="noopener">cloudwonders.info</a></p></blockquote><p>当你在任意一个搜索引擎输入一个关键词之后，你就成了全网全平台追逐的流量热点。</p><p>平时大打口水战的各大平台在共享你的隐私数据方面异常团结，在B系网站搜索，在A系T系的应用APP上都会看到为你“量身定制”的推送和广告，延迟不超过一分钟。</p><a id="more"></a><p>这一点即便是业界道德楷模G老师都未能免俗，毕竟它也要靠着广告收入维持其智能推荐算法引擎的研发投入。</p><p>最可气的是，推送些边栏广告也就算了，竟然连自己看的新闻和短视频内容也都要和搜索记录沾边，在聚会上随便刷下手机就暴露了自己到底是个什么货色。</p><p>网络对你的监视是全方位的，除了你主动输入的那些关键字，你平时的谈话、你的地理位置，你周围的环境照片都会被偷偷记录上传，用以支撑靠勤劳质朴的城镇劳动人民手动打标签的“人工”智能工程师们的高薪。</p><p>当个人隐私在巨头面前节节败退，当生而为人的尊严在利益机器面前粉碎，当你不能说的秘密被拿来公开叫卖和嘲弄，当互联网利用你心底的弱点反过来操控你之时，难道就没有一款可以放心解放双手，安全地释放自己的求知欲，满足人类最原始的好奇的搜索引擎吗？当然不是这样的鸭——</p><p><img src="http://ww1.sinaimg.cn/large/73403117ly1fhsqrvtg20j223w1kwq8e.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt=""></p><p>这个创立于2008年的搜索引擎，十年来一直在巨头的夹击下惨淡经营。如果没有愈演愈烈的互联网隐私泄露事件、没棱镜门、没有小扎的听证会，恐怕Duckduckgo也不会有近来的长足发展。</p><p><img src="https://i.loli.net/2018/11/05/5be057be3a57f.jpg" alt=""></p><p>Duckduckgo从创立之初秉承的理念就是不对用户的搜索做任何追踪与记录，不把用户的隐私和数据当作公司的资产，做好一个搜索引擎的本分。自2018年之初，该搜索引擎已每日接受多于两千万次的匿名搜索。</p><p>Duckduckgo的使用方式与其他搜索引擎没有区别，唯一的不同就是搜索之后在其他任何平台没有相关的广告推送。至于搜索本身的质量和水平，笔者简单做了个对比：</p><p><img src="https://i.loli.net/2018/11/05/5be057fe2c0e7.png" alt=""></p><p>应当说完全可以满足日常应用，不说超越G老师，超越B老师应该是问题不大。同时不用担心在互联网大机器下无所遁形。已经有越来越多的朋友和公司将Duckduckgo设置为了默认搜索引擎。</p><p>如果说互联网早已是赢家通吃的寡头时代，用隐私交换在线服务已如缴纳“人头税“一般自然，而在这万马齐喑的时刻，Duckduckgo代表的是一豆星星点点的亮光，为所有在歌舞升平中“心怀鬼胎“的人们擎举起惊奇与愤怒的能力。可以放心大胆地搜索不可描述内容的传送门：<a href="https://www.duckduckgo.com" target="_blank" rel="noopener">https://www.duckduckgo.com</a></p>]]></content>
      
      
      <categories>
          
          <category> wonder </category>
          
      </categories>
      
      
        <tags>
            
            <tag> resources </tag>
            
            <tag> wonder </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
