<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>产品观察1：华为FabricInsight产品简要分析</title>
      <link href="/2018/12/08/product1-huawei-fabricinsight/"/>
      <url>/2018/12/08/product1-huawei-fabricinsight/</url>
      
        <content type="html"><![CDATA[<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">最近机缘巧合之下接触到了华为FabricInsight这款产品，简要谈谈看法。</span><br><span class="line">只针对2018年8月份左右发布的版本。</span><br><span class="line">另外注意，在Google搜索相关资料的时候，记得要把Fabric Insight这两个单词合并在一起搜索，中间不要加空格，别问我怎么知道的。</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="信息采集"><a href="#信息采集" class="headerlink" title="信息采集"></a>信息采集</h3><h4 id="SNMP"><a href="#SNMP" class="headerlink" title="SNMP"></a>SNMP</h4><p>在使用FabricInsight之前需要配置华为设备的SNMP协议，主要作用为获取设备的MIB信息，<br>并进行其他管理操作。</p><h4 id="LLDP"><a href="#LLDP" class="headerlink" title="LLDP"></a>LLDP</h4><p>使能各设备的LLDP功能，以便FabricInsight据此（以及通过SNMP上送的MIB信息）绘制硬<br>件连接拓扑图。</p><h4 id="NetConf"><a href="#NetConf" class="headerlink" title="NetConf"></a>NetConf</h4><p>使能各设备的NetConf配置，以便FabricInsight能通过NetConf协议配置各设备的ERSPAN功<br>能。</p><h4 id="ERSPAN"><a href="#ERSPAN" class="headerlink" title="ERSPAN"></a>ERSPAN</h4><p>配置ERSPAN功能，destination IP配置为FabricInsight collector的地址。底层实现为：通过<br>GRE隧道的方式将远程设备的流量路由/镜像至分析节点，以实现对流量可视化分析。<br>ERSPAN可配置筛选特定的流量，并非全量镜像。从华为对交换机的配置： </p><pre><code class="shell">[~Device] observe-port 1​ destination-ip 10.10.10.20​ source-ip 10.1.1.1 [*Device] traffic-mirroring vxlan tag-format none tcp-flag fin syn rst observe-port 1 inbound [*Device] traffic-mirroring tcp-flag fin syn rst observe-port 1 inbound [*Device] commit</code></pre><p>通过ERSPAN镜像给FabricInsight的流量包括带有FIN/SYN/RST等TCP flag的网包。对应其<br>产品中对TCP事件的可视化能力。<br><em>注*：据此可以看出FabricInsight没有全量流量镜像&amp;分析能力</em><br><em>注*：命令中的vxlan可能是将流量通过vxlan封装，做三层转发，而非镜像全部vxlan流量</em></p><h4 id="Telemetry"><a href="#Telemetry" class="headerlink" title="Telemetry"></a>Telemetry</h4><p>华为的Telemetry指设备主动、以固定周期上报的一些设备信息，包括CPU\MEM\QUEUE等信<br>息。 </p><h4 id="手动录入"><a href="#手动录入" class="headerlink" title="手动录入"></a>手动录入</h4><p>主要为用户业务信息，每一个业务的定义为一组IP和某一固定端口号的集合，需要用户手工录<br>入。</p><p><img src="https://i.ytimg.com/vi/uVcXxn30qqY/maxresdefault.jpg" alt=""></p><h3 id="功能分类"><a href="#功能分类" class="headerlink" title="功能分类"></a>功能分类</h3><h4 id="Underlay拓扑可视化"><a href="#Underlay拓扑可视化" class="headerlink" title="Underlay拓扑可视化"></a>Underlay拓扑可视化</h4><p>依据LLDP生成及SNMP上报的信息，可生成Underlay设备间的拓扑信息。<br>流量事件统计<br>依据ERSPAN镜像的含有SYN\FIN\RST等flag的TCP网包，可统计一条流（五元组）中的事件<br>发生次数、时间及类型。并可据此进行简单的SYN重传、建立连接RTT、建连成功率分析。但<br>缺少对网流完整过程（e.g.流量传输数据总量、pps、整体平均时延等）的统计和分析。 </p><h4 id="设备信息统计"><a href="#设备信息统计" class="headerlink" title="设备信息统计"></a>设备信息统计</h4><p>根据Telemetry信息给出CPU\MEM等设备运行状态统计信息，以及对各网络端口IN/OUT总<br>量、drop、error数量等的统计信息。 </p><h4 id="应用流量分类过滤"><a href="#应用流量分类过滤" class="headerlink" title="应用流量分类过滤"></a>应用流量分类过滤</h4><p>其应用功能，本质为手动设置IP+端口号过滤规则，通过过滤的流量即为一个应用。应用间的<br>流量状态展现，即为在流量事件统计数据库中分别为起止两端的流量配置两个应用的过滤规则<br>，筛选出的流量即可作为应用间的流量状态展示。 </p><h2 id="FabricInsight特点"><a href="#FabricInsight特点" class="headerlink" title="FabricInsight特点"></a>FabricInsight特点</h2><h3 id="强绑定性"><a href="#强绑定性" class="headerlink" title="强绑定性"></a>强绑定性</h3><p>只能用于华为的硬件设备。并且后期会形成双向绑定，如若依赖FabricInsight，扩容时只能继<br>续采购华为设备。 </p><h3 id="基于流量事件"><a href="#基于流量事件" class="headerlink" title="基于流量事件"></a>基于流量事件</h3><p>对于流的分析仅涉及五元组和TCP流量事件。可依据SYN、FIN、RST等TCP流量事件完成<br>TCP SYN重传、RST等事件的侦测，并作为报警依据。 </p><h3 id="无流量全量分析"><a href="#无流量全量分析" class="headerlink" title="无流量全量分析"></a>无流量全量分析</h3><p>当前观察，仅有TCP流量的事件信息，对UDP、ICMP、ARP等网络流量无采集分析能力。仅<br>针对TCP流量，亦无流量全量分析能力，无法获取诸如流量总字节数、总包数、pps、平均时<br>延、最大时延等信息。</p><h3 id="Overlay能力暂无"><a href="#Overlay能力暂无" class="headerlink" title="Overlay能力暂无"></a>Overlay能力暂无</h3><p>当前FabricInsight宣称的可分析虚拟网络是指，手工指定某一虚拟网元（Virtual NE）IP地址<br>，手工指定其角色（e.g. FW\LB\Router）其与外界通讯的流量可以以与Underlay网络相同的<br>方式采集。<br>未发现针对虚拟网络VM间的采集分析能力。从其官方手册中针对ERSPAN的配置来看，可能<br>或未来会具有一定的VXLAN隧道解封装及关联对应能力。但即便如此，在大规模网络流量的<br>情况下，对全部VXLAN流量分析亦将为设备带来压力。<br>另外，主机内的虚拟网络流量，FabricInsight以现在的形式是绝对无法取得的。 </p><h2 id="FabricInsight未来演进趋势推测"><a href="#FabricInsight未来演进趋势推测" class="headerlink" title="FabricInsight未来演进趋势推测"></a>FabricInsight未来演进趋势推测</h2><h3 id="In-band-Telemetry"><a href="#In-band-Telemetry" class="headerlink" title="In-band Telemetry"></a>In-band Telemetry</h3><p>FabricInsight的数据采集能力全部来自于设备提供的能力。在设备/芯片领域的发展趋势是提<br>供更加精细化的In-band Telemetry遥测能力。从Cisco/Barefoot等厂商近期对P4芯片的动态来<br>看，华为跟风也是早晚的事。In-band Telemetry可以提供诸如per packet的全生命周期、匹配<br>的具体转发规则、更加精细的时间戳等能力。但如若采用新的芯片组提供In-band Telemetry<br>，则会仅支持新款产品。<br>除此之外，也将不仅仅将流量分析的范畴局限于TCP流量。 </p><h3 id="虚拟网络"><a href="#虚拟网络" class="headerlink" title="虚拟网络"></a>虚拟网络</h3><p>虚拟网络是行业演进的趋势，但需要考虑华为对FabricInsight这款产品本身的定位。如果添加<br>虚拟网络能力，则其品牌名称、目标人群都将会有较大调整。但华为整体上缺乏虚拟网络可视<br>化的产品和能力，因此推断会先对接华为自己的云平台FusionCloud，计算节点绑定探针。但<br>先期仍会仅采用TCP流量事件的分析模式，不会全量采集和分析。 </p><h3 id="AIops"><a href="#AIops" class="headerlink" title="AIops"></a>AIops</h3><p>AI的概念在当前版本的FabricInsight中已有所体现，但当前仅是一些标准差方差的统计计算。<br>演进的方式将是对网络中断和延迟的诊断以及自调优的赋能。但这种分析首先要求用户能够输<br>入一定的专家经验作为数据训练的标记，同时对分析节点的部署要求较高（支持大数据分布式<br>计算和存储）。 </p><h3 id="安全防御"><a href="#安全防御" class="headerlink" title="安全防御"></a>安全防御</h3><p>这是当前看起来最有实际效能的功能。其本身具有的TCP事件分析能力完全可以用来完成<br>DDoS攻击的侦测和防御。 </p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> product </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> product </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>可以预测交通路况的 APP</title>
      <link href="/2018/12/06/life-traffic-prediction/"/>
      <url>/2018/12/06/life-traffic-prediction/</url>
      
        <content type="html"><![CDATA[<blockquote><p>能不能有这样一款应用<br><a id="more"></a></p><p>或者地图 APP 实现这样一个功能</p><p>能通过历史路况大数据分析</p><p>告诉我今天晚上几点出发上路</p><p>东北四环不堵</p><p>把什么机器学习人工智能数字孪生</p><p>能加的都给它加上</p><p>感觉又是一个割 VC 韭菜的杀手应用</p><p>只要有人搭出来这个框架</p><p>我愿意帮忙实现所有的业务代码</p><p>因为只需要一句</p><p><code>return &quot;您期望的时间不存在&quot;</code></p></blockquote><p><em><em>2018.12.6</em></em></p>]]></content>
      
      
      <categories>
          
          <category> life </category>
          
      </categories>
      
      
        <tags>
            
            <tag> life </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去2：CPU缓存读入策略</title>
      <link href="/2018/12/06/test2-cache-line-alignment/"/>
      <url>/2018/12/06/test2-cache-line-alignment/</url>
      
        <content type="html"><![CDATA[<h2 id="到底哪些数据写入了CPU缓存"><a href="#到底哪些数据写入了CPU缓存" class="headerlink" title="到底哪些数据写入了CPU缓存"></a>到底哪些数据写入了CPU缓存</h2><p>我们知道CPU会在要读写某个数据时，先将数据写入缓存。</p><p>我们也知道这个操作一般以Cache Line为操作粒度，并且Cache Line的长度一般为64Byte。<br><a id="more"></a></p><p>那么这个Cache Line包含的数据到底是哪64Byte呢？</p><p>如果要读写的数据的地址正好以64Byte对齐，那么肯定是这个数据和它之后的<code>（64 - sizeof(数据)）</code>Byte存在于这个缓存行里。</p><p>但是如果要读写的这个数据地址不以64Byte对齐，而是在两个64Byte对齐的地址中间的某个位置，CPU写入Cache Line里的数据还是它和它之后的64Byte吗？CPU会“向前”对64取整作为Cache Line中的数据吗？</p><h2 id="用False-Sharing证明"><a href="#用False-Sharing证明" class="headerlink" title="用False Sharing证明"></a>用False Sharing证明</h2><p>根据之前介绍False Sharing的原理<a href="https://decodezp.github.io/2018/11/27/quickwords3-falsesharing/">链接</a>，通过判断是否发生False Sharing可以判断某两个数据是否存在于同一条Cache Line里。</p><p>构造如下结构体：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> front_padding[<span class="number">15</span>];</span><br><span class="line">    <span class="keyword">uint32_t</span> c1;</span><br><span class="line">    <span class="comment">/* 64 bytes */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> c2;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中<code>c1</code>和<code>c2</code>是分别被两个CPU core写入的变量。</p><p>在构造counter_t的实例时，利用<code>GCC attribute</code>确保其起始地址与64Byte对齐：</p><p><code>struct counter_t counter __attribute__((aligned(64)));</code></p><p>在两个CPU核分别开始操作<code>c1</code>和<code>c2</code>之前利用<code>clflush</code>指令清除所有相关缓存：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="keyword">void</span></span><br><span class="line">clflush(<span class="keyword">volatile</span> <span class="keyword">void</span> *p)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function"><span class="keyword">asm</span> <span class="title">volatile</span> <span class="params">(<span class="string">"clflush (%0)"</span> :: <span class="string">"r"</span>(p))</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>如果发生了False Sharing，则说明这两个变量在一个Cache Line里，则证明CPU是取欲读写变量及其之后64Byte数据写入缓存<br>如果没有发生False Sharing，则说明这两个变量不在一个Cache Line里，则证明CPU是取欲读写变量向前64取整地址上的数据写入缓存</p></blockquote><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>结果当然是没有发生False Sharing。</p><p>不然还搞什么n-way set associative :)</p><p>代码：<a href="https://github.com/PanZhangg/x86perf/blob/master/cache_line_alignment.c" target="_blank" rel="noopener">https://github.com/PanZhangg/x86perf/blob/master/cache_line_alignment.c</a></p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>魏孝文帝教你提proposal</title>
      <link href="/2018/12/05/history-tuobahong/"/>
      <url>/2018/12/05/history-tuobahong/</url>
      
        <content type="html"><![CDATA[<h2 id="艰难的Proposal"><a href="#艰难的Proposal" class="headerlink" title="艰难的Proposal"></a>艰难的Proposal</h2><p>每个人都有独自一人面对全世界的时候，即便你是魏孝文帝拓跋宏。</p><p>北魏太和十七年，承平日久的北魏都城里正在酝酿一件大事——迁都。<br><a id="more"></a></p><p>自天兴元年拓跋圭定都平城起，北魏在此地经营了九十余年。此时的平城，早已是北魏王公贵族富商巨贾的乐土。</p><p>而拓跋宏却不想在这呆了，对这位一心思慕华夏风仪的少数民族首领来说，城狭地偏的平城终究不是久居之地。</p><p>迁都，迁往洛阳，只有住在这座每块城砖上都写满了厚重的城邑的中心，才是北漂买房落户的那一刻。</p><p>但除了拓跋宏，没有人愿意当拆迁户，被连根拔起。拓跋宏自己也知道这一点。晓以大义？没用的，天底下最难的事，就是劝说别人放弃眼前的利益，去追求什么万世之业；</p><p>以皇帝的权威一意孤行？没有问题，但人心不齐，效果打折扣，既损威严，又于事无益。</p><p>那么迁都这个Proposal，到底怎么提呢？</p><h2 id="魏孝文帝的方式"><a href="#魏孝文帝的方式" class="headerlink" title="魏孝文帝的方式"></a>魏孝文帝的方式</h2><p>拓跋宏并没有在一开始就透露自己的意图，而是提出了一个更加”不得人心”的Proposal——亲自带队，攻打南朝。</p><p>如果说迁都不得人心，那么发动战争就更加让改革的主要阻力——深居平城的皇亲贵胄们如坐针毡。</p><p>因为迁都或许还可以讨论讨论，但南下伐齐“一统中国”那是北魏政权不容辩驳的“正统思想”，是政治正确，有拓跋氏列祖列宗的加持，以及冯太后的附魔。</p><p>这一年的八月，拓跋宏亲率三军开拔南下。</p><p>当然，皇帝都出去打仗了，除了太子监国以外，平日里的文武百官哪有在家呆着的道理，一起走吧！</p><p>从山西大同往南，大军在秋雨连绵的泥泞中走了整整一个月，终于到达了宿命的重点——洛阳。</p><p>这个时候所有人都不想再走了。一路的狼狈或可忍受，但后面还有与齐国的恶战。而拓跋宏依然兴致不减，号令即刻开拔，继续南进。</p><p>这下文武百官们可都要“犯颜进谏”了，纷纷叩头不止，甚至不惜死谏以请求拓跋宏停止南征。</p><p>这个时候拓跋宏才说出他真正的目的：</p><blockquote><p>今者兴动不小，动而无成，何以示后？苟欲班师，无以重之千载！朕世居幽朔，欲南迁中土，苟不南伐，当迁都于此，王公以为如何？欲迁者左，不欲者右！——《资治通鉴》</p></blockquote><p>这里有三个要素：</p><ol><li>我可以在南伐之事上让步</li><li>但我的让步有条件</li><li>不许考虑太久</li></ol><p>最终的结果自然是大家都站到了左边。迁都这件事，就这么“取得”了大家的同意。</p><p><img src="http://5b0988e595225.cdn.sohucs.com/images/20170720/b36a2fde600f4b909885b0a76ada9876.jpeg" alt=""></p><h2 id="抽象提取"><a href="#抽象提取" class="headerlink" title="抽象提取"></a>抽象提取</h2><p>在谈判领域存在一个让步/妥协的谈判技巧。</p><p>对每个人来说，如果对面已有所让步，那么心里将会产生同样让步的压力，趋向于同意对方提出的让步条件。</p><p>这种场景在生活中非常常见，例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">多少钱？</span><br><span class="line">100</span><br><span class="line">30吧</span><br><span class="line">最低90</span><br><span class="line">40</span><br><span class="line">低于85就赔本了</span><br><span class="line">你看我就50块钱</span><br><span class="line">行了80吧，今天好不容易开张</span><br></pre></td></tr></table></figure><p>如果能成交，说明买家和卖家一开始的心理价位就都是80元左右，但买家必须要首先压到30，卖家也要提到100，互相留出这个让步的空间。</p><p>也许你觉得这种技巧太市侩，但它其实有很多变种版本，也许自己已经身堕瓠中而不自知。<br>E.g.<br>房产中介请你看房，首先是一间各方面条件都很差的房间，但却有一个让你惊讶的高额租金。然后带你看了一套各方面比第一间好非常多的房间，租金却和第一间一样，或者略多而已。<br>如此你会觉得租了第二间是占了便宜。但其实中介的目标就是租给你第二间房，第一间就是让你产生这种对比让步的错觉的。</p><p>所以，每当打算提一个艰难的Proposal的时候，我都会效仿这种形式。</p>]]></content>
      
      
      <categories>
          
          <category> history </category>
          
      </categories>
      
      
        <tags>
            
            <tag> history </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ftrace uprobe使用填坑历程</title>
      <link href="/2018/12/04/ftrace-uprobe/"/>
      <url>/2018/12/04/ftrace-uprobe/</url>
      
        <content type="html"><![CDATA[<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>打算用一下<code>ftrace</code>对用户态程序的trace支持。</p><h3 id="测试用程序test-c："><a href="#测试用程序test-c：" class="headerlink" title="测试用程序test.c："></a>测试用程序<code>test.c</code>：</h3><a id="more"></a><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">print_curr_state_one(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is the print current state one function\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">print_curr_state_two(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"This is the print current state two function\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">        print_curr_state_one();</span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">        print_curr_state_two();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="编译："><a href="#编译：" class="headerlink" title="编译："></a>编译：</h3><p><code>gcc -o test test.c</code></p><h3 id="Obtain-Offset："><a href="#Obtain-Offset：" class="headerlink" title="Obtain Offset："></a>Obtain Offset：</h3><p><code>objdump -d test</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">000000000040055d &lt;print_curr_state_one&gt;:</span><br><span class="line">  40055d:55                   push   %rbp</span><br><span class="line">  40055e:48 89 e5             mov    %rsp,%rbp</span><br><span class="line">  400561:bf 30 06 40 00       mov    $0x400630,%edi</span><br><span class="line">  400566:e8 c5 fe ff ff       callq  400430 &lt;puts@plt&gt;</span><br><span class="line">  40056b:5d                   pop    %rbp</span><br><span class="line">  40056c:c3                   retq   </span><br><span class="line"></span><br><span class="line">000000000040056d &lt;print_curr_state_two&gt;:</span><br><span class="line">  40056d:55                   push   %rbp</span><br><span class="line">  40056e:48 89 e5             mov    %rsp,%rbp</span><br><span class="line">  400571:bf 60 06 40 00       mov    $0x400660,%edi</span><br><span class="line">  400576:e8 b5 fe ff ff       callq  400430 &lt;puts@plt&gt;</span><br><span class="line">  40057b:5d                   pop    %rbp</span><br><span class="line">  40057c:c3                   retq</span><br></pre></td></tr></table></figure><p>添加uprobe trace event：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 'p:print_current_state_one /root/test/uprobe/uprobe:0x55d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_events</span><br><span class="line">echo 'p:print_current_state_two /root/test/uprobe/uprobe:0x56d' &gt;&gt; /sys/kernel/debug/tracing/uprobe_events</span><br></pre></td></tr></table></figure><p>有时会出现Invalid argument的错误。用<code>sudo su</code>获取<code>root</code>权限。</p><blockquote><p>这里注意，偏移的大小只写0x55d，不能写0x40055d</p></blockquote><h2 id="开启trace"><a href="#开启trace" class="headerlink" title="开启trace"></a>开启trace</h2><p>先启动<code>test</code>程序：<code>./test</code></p><p><code>echo 1 &gt; /sys/kernel/debug/tracing/event/enable</code></p><p>如果此时<code>cat /sys/kernel/debug/tracing/event/enable</code>显示为<code>X</code></p><p><code>echo 1 &gt; /sys/kernel/debug/tracing/event/uprobes/enable</code></p><p>最后<code>cat /sys/kernel/debug/tracing/trace</code>应该就能看到了</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> ftrace </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ftrace trace-cmd kernelshark资料汇总</title>
      <link href="/2018/11/30/ftrace/"/>
      <url>/2018/11/30/ftrace/</url>
      
        <content type="html"><![CDATA[<p>一些关于这一类技术的资料和文档汇总。<br>文章中可以找到比较详细的工具使用方法。如果想了解更多内容可以阅读<code>linux/Documentation/trace</code>下的文档以及源码。</p><p>以及<code>git log ./kernel/trace</code> :)<br><a id="more"></a></p><h2 id="ftrace"><a href="#ftrace" class="headerlink" title="ftrace"></a>ftrace</h2><ul><li><a href="https://lwn.net/Articles/365835/" target="_blank" rel="noopener">Debugging the kernel using Ftrace - part 1</a></li><li><a href="https://lwn.net/Articles/366796/" target="_blank" rel="noopener">Debugging the kernel using ftrace - part 2</a></li><li><a href="https://www.kernel.org/doc/Documentation/trace/ftrace.txt" target="_blank" rel="noopener">Kernel Documents: ftrace</a></li><li><a href="https://lwn.net/Articles/370423/" target="_blank" rel="noopener">Secrets of the Ftrace function tracer</a></li><li><a href="https://people.canonical.com/~acelan/coscup-2010/Debugging%20Linux%20Kernel%20by%20Ftrace.pdf" target="_blank" rel="noopener">PDF:Debugging Linux Kernel by ftrace</a></li><li><a href="https://opensourceforu.com/2010/11/kernel-tracing-with-ftrace-part-1/" target="_blank" rel="noopener">Kernel Tracing with ftrace, Part 1</a></li><li><a href="http://opensourceforu.com/2010/12/kernel-tracing-with-ftrace-part-2/" target="_blank" rel="noopener">Kernel Tracing with ftrace, Part 2</a></li><li><a href="https://jvns.ca/blog/2017/03/19/getting-started-with-ftrace/" target="_blank" rel="noopener">ftrace: trace your kernel functions!</a></li><li><a href="https://movaxbx.ru/2018/10/12/hooking-linux-kernel-functions-how-to-hook-functions-with-ftrace/" target="_blank" rel="noopener">Hooking Linux Kernel Functions, how to Hook Functions with Ftrace</a></li><li><a href="https://www.slideshare.net/ennael/kernel-recipes-2017-understanding-the-linux-kernel-via-ftrace-steven-rostedt" target="_blank" rel="noopener">Understanding the Linux kernel via ftrace</a></li></ul><h2 id="trace-cmd"><a href="#trace-cmd" class="headerlink" title="trace-cmd"></a>trace-cmd</h2><ul><li><a href="https://lwn.net/Articles/410200/" target="_blank" rel="noopener">trace-cmd: A front-end for Ftrace</a></li><li><a href="https://github.com/rostedt/trace-cmd" target="_blank" rel="noopener">Code:trace-cmd</a></li></ul><h2 id="kernelshark"><a href="#kernelshark" class="headerlink" title="kernelshark"></a>kernelshark</h2><ul><li><a href="https://lwn.net/Articles/425583/" target="_blank" rel="noopener">Using KernelShark to analyze the real-time scheduler</a></li><li><a href="https://kernel-recipes.org/en/2018/talks/kernelshark-1-0-whats-new-and-whats-coming/" target="_blank" rel="noopener">Video:KERNELSHARK 1.0; WHAT’S NEW AND WHAT’S COMING</a></li><li><a href="https://www.youtube.com/watch?v=RwVnnuGrb_c" target="_blank" rel="noopener">Video:Yordan Karadzhov - What’s Coming in Kernel Shark</a></li><li><a href="https://events.linuxfoundation.org/wp-content/uploads/2017/12/Swimming-with-the-New-KernelShark-Yordan-Karadzhov-VMware.pdf" target="_blank" rel="noopener">PDF:Swimming with the New KernelShark</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> ftrace </tag>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>测来测去1：DPDK no-huge模式性能对比测试</title>
      <link href="/2018/11/29/test1-dpdk-no-huge/"/>
      <url>/2018/11/29/test1-dpdk-no-huge/</url>
      
        <content type="html"><![CDATA[<h2 id="no-huge"><a href="#no-huge" class="headerlink" title="no-huge"></a>no-huge</h2><p>DPDK使用大页内存作为性能优化的一个手段。但大页内存在云计算等环境下可能会出现内存资源浪费的情况，作为售卖资源的云服务商，希望能找到更充分的内存资源利用的方法。在此背景下，DPDK引入了no-huge机制，即不使用hugepage，从而解放更多的系统资源。</p><p>那么这种配置下DPDK性能会下降多少呢？还是需要实际定量测试一下。<br><a id="more"></a></p><h2 id="测试平台"><a href="#测试平台" class="headerlink" title="测试平台"></a>测试平台</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">lscpu</span><br><span class="line">Architecture:          x86_64</span><br><span class="line">CPU op-mode(s):        32-bit, 64-bit</span><br><span class="line">Byte Order:            Little Endian</span><br><span class="line">CPU(s):                88</span><br><span class="line">On-line CPU(s) list:   0-87</span><br><span class="line">Thread(s) per core:    2</span><br><span class="line">Core(s) per socket:    22</span><br><span class="line">Socket(s):             2</span><br><span class="line">NUMA node(s):          2</span><br><span class="line">Vendor ID:             GenuineIntel</span><br><span class="line">CPU family:            6</span><br><span class="line">Model:                 85</span><br><span class="line">Model name:            Intel(R) Xeon(R) Gold 6152 CPU @ 2.10GHz</span><br><span class="line">Stepping:              4</span><br><span class="line">CPU MHz:               2100.393</span><br><span class="line">BogoMIPS:              4201.72</span><br><span class="line">Virtualization:        VT-x</span><br><span class="line">L1d cache:             32K</span><br><span class="line">L1i cache:             32K</span><br><span class="line">L2 cache:              1024K</span><br><span class="line">L3 cache:              30976K</span><br><span class="line">NUMA node0 CPU(s):     0-21,44-65</span><br><span class="line">NUMA node1 CPU(s):     22-43,66-87</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep Ether</span><br><span class="line">86:00.0 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.1 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.2 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br><span class="line">86:00.3 Ethernet controller: Intel Corporation Ethernet Controller X710 for 10GbE SFP+ (rev 01)</span><br></pre></td></tr></table></figure><p>DPDK Version: <code>18.05.1</code><br>Tester: IXIA<br>Test Plan: RFC2544<br>DPDK APP: <code>./l2fwd -l 22-24 --no-huge  -- -p 0x3 -T 5</code></p><h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p><img src="https://s1.ax1x.com/2018/11/29/FZIYcT.png" alt=""></p><p>在64Byte包长时丢包率达到了50%以上，而使用大页内存时丢包率可以控制在0.05%以内。<br>其他长度丢包和吞吐情况基本相同。<br>根据业务情况，平均包长如果在300Byte以上–no-huge模式不妨一试。<br>后续添加针对更大链路带宽(25Gbps/100Gbps)的网卡以及不同Xeon平台的测试结果。</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> test </tag>
            
            <tag> dpdk </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>云计算的发展需要向社区街道管理看齐</title>
      <link href="/2018/11/28/thoughts1-cloud-community/"/>
      <url>/2018/11/28/thoughts1-cloud-community/</url>
      
        <content type="html"><![CDATA[<h2 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h2><p>云计算本质上是一种服务。由各种不同的组件为租户提供计算、网络和存储服务。</p><p>用户对这些服务的要求除了功能之外，还有安全性、可用性、性能、成本、迁移难度、SLA等一系列要求。</p><p>与之类比，社区街道作为一个完整的功能单元，各个基层职能部门，也为社区内的居民提供各类生活服务。</p><p>如何做好基层工作，是需要费一番脑筋的。<br><a id="more"></a></p><h2 id="服务网格"><a href="#服务网格" class="headerlink" title="服务网格"></a>服务网格</h2><p>下图是我在北京中关村某社区拍到的当地派出所的“网格团队”成员和工作职责。</p><p><img src="https://s1.ax1x.com/2018/11/28/FV0v3q.jpg" alt=""><br>如果你熟悉云计算，熟悉当前的领先理念，那么<code>service mesh</code>这个词你肯定不陌生，这是当前容器和微服务领域的最新热点，拥有Istio、Envoy等一众明星开源项目，并且有Google、AWS、Alibaba等大佬拥趸。这个词翻译过来就是<code>服务网格</code>。</p><p>而社区街道提出的这个“网格”的概念，明显领先于自诩为科技前沿的云计算。</p><p>如果仔细阅读一下上图中的“工作职责”，就能够轻易地将其内容与时下云计算和企业数字化转型热炒的概念对应起来：</p><ul><li>管理网格单元：Microservice微服务</li><li>落实基信息采集：Digital Twin数字孪生</li><li>综合网格力量：Orchestration协同</li><li>加强依法自治：Decouple解耦/Distrubute分布式</li><li>排查隐患：Situational Awareness态势感知/Active Defence主动式防御</li><li>协调解决社会服务管理中存在的问题：Full Stack Management全栈管理</li><li>推进公共服务建设：Aglie敏捷/DevOps</li><li>监督管理网格力量，督促责任落实：Sidecar</li><li>及时上报网格工作数据：Telemetry遥测</li><li>完成街道交办的其他工作：Serverless无服务器</li></ul><p>总结就是这个街道派出所就是Community-Native Microservice &amp; Service Mesh &amp; Serverless &amp; Security的典范，理念领先云计算至少5年。</p><h2 id="好好学习"><a href="#好好学习" class="headerlink" title="好好学习"></a>好好学习</h2><p>为什么街道派出所的理念能领先云计算的发展？道理都是殊途同归的，很多理念（经验）的获得都是靠积攒年头。</p><p>云计算方兴未艾，但毕竟用户还不足够多，问题暴露还不足够全面，或者说，没太多管理经验。而派出所展开基层管理工作的时间至少比在坐的诸位岁数都长。同时基层群众形形色色，就像软件测试时的边界条件，绝对都能满足。</p><p>在此种“得天独厚”的条件下总结出的经验，云计算从业者除了好好消化吸收之外，也可以小小的自鸣得意一下，毕竟你仅仅用了10年就追上了街道派出所。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> thoughts </tag>
            
            <tag> cloud </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚3:什么是False Sharing</title>
      <link href="/2018/11/27/quickwords3-falsesharing/"/>
      <url>/2018/11/27/quickwords3-falsesharing/</url>
      
        <content type="html"><![CDATA[<h2 id="不用图"><a href="#不用图" class="headerlink" title="不用图"></a>不用图</h2><p>以为又要见到那几张网上已经用烂了的图了是不是？这次我们不用图来讲这个事。<br><a id="more"></a></p><p>Cache line是64个Byte，我们经常操作(R/W)的变量是4个或者8个Byte。</p><p>于是一个Cache line里就可以放好几个变量，比如说其中有两个变量A和B。</p><p>当CPU0写入A，CPU1写入B的时候，就发生了False Sharing，就这么简单。</p><p>所谓“假共享”，其实就是你以为你俩自己操作自己的变量是共产国际按需分配互不影响，其实都是假象。</p><p>很多材料上说是因为不同的CPU核共享了相同的Cache Line，其实并不严谨。根本因素是不同的CPU核需要更新的缓存出现了地址上的重叠。</p><p>那么当其中一个核更新了它的变量A之后，CPU并不能识别出是哪4个Byte或8个Byte地址上的数据被更新，而只能认为该变量所在的整条64Byte Cache Line都应该被更新。</p><p>所有有和这64Byte重叠的Cache Line，不管在哪个CPU核上，都需要被更新，这样才能保证大家手头的数据是一致的。</p><p>于是乎，和这64Byte地址存在重叠的变量B所在的CPU1中的缓存也需要被更新，自然就影响到了性能。</p><p>如果只是读，就没有这个问题，因为不需要关心缓存一致这个事。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>这里有一个活生生的代码的例子：</p><p><a href="https://github.com/PanZhangg/x86perf/blob/master/false_sharing_padding.c" target="_blank" rel="noopener">https://github.com/PanZhangg/x86perf/blob/master/false_sharing_padding.c</a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> c1;</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifdef</span> PADDING_64_BYTE</span></span><br><span class="line">    <span class="keyword">uint32_t</span> padding[<span class="number">15</span>];</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">elif</span> PADDING_128_BYTE</span></span><br><span class="line">    <span class="keyword">uint32_t</span> padding[<span class="number">31</span>];</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">uint32_t</span> c2;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>本来是打算用来验证在CPU预取开启的情况下到底是应该Padding 64还是128，但在Haswell和Skylake上验证，这两个长度都没有区别。</p><p>后来查找资料是在Sandy bridge上需要padding到128，但我这里没有这么老的CPU….先这样吧..</p><p>上面的代码注意用<code>-O0</code>编译。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚2:CPU缓存的组织形式</title>
      <link href="/2018/11/25/quickwords2-cacheassociativity/"/>
      <url>/2018/11/25/quickwords2-cacheassociativity/</url>
      
        <content type="html"><![CDATA[<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>缓存和其他存储形式在功能形式上没有太大区别，均是输入一个地址，还你一个数据。但作为一个缓存，要考虑如何在有限的容量下保证较高的命中率以及查找效率(<a href="https://decodezp.github.io/2018/11/20/cachesize/">相关阅读</a>)。这个问题从本质上来说，就是如何建立缓存地址与内存地址的映射关系。</p><a id="more"></a><h2 id="组织形式"><a href="#组织形式" class="headerlink" title="组织形式"></a>组织形式</h2><p>缓存按照一个Cache Line的长度（主流长度为64Byte）为粒度来组织：</p><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140538/481_051.gif" alt=""><br>各种不同的映射形式就是在决定内存中某一个特定地址范围内的数据，具体可以放到哪一个Cacha Line里去。</p><p>能想出来的方式也无外乎三种：</p><ul><li>哪个都可以放</li><li>只能放到第N个（N是内存地址的函数）</li><li>只能放到第N个至第M个（M也是内存地址的函数）</li></ul><blockquote><p>其实基本上这篇文章可以结束了，很多技术都不是什么新鲜的“创想”，只是给朴素的思想内核穿上了一层“术语”的外衣。</p></blockquote><h3 id="Direct-Mapping"><a href="#Direct-Mapping" class="headerlink" title="Direct Mapping"></a>Direct Mapping</h3><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140525/481_061.gif" alt=""><br>这就是上面说的第二种方式，某一个内存地址段的数据，只能放在第N个Cache Line里</p><ul><li>Pros:查找快，一次寻址，有就是有，没有就是没有，不啰嗦（因为只需要验证一个Cache Line中是否存在该地址）</li><li>Cons:命中率低，CPU经常需要相邻地址的数据，而根据规则，同属于第N个Cache Line的数据会互相排斥，不会同时出现在缓存里</li></ul><h3 id="Fully-Associative"><a href="#Fully-Associative" class="headerlink" title="Fully Associative"></a>Fully Associative</h3><p>这就是第一种方式，随便放。</p><ul><li>Pros:命中率高，过去和未来一段时间内需要的数据都可以被放在缓存内，同时不用担心被相邻地址上的数据踢出</li><li>Cons:查找慢，确认一个地址是否在缓存里通常需要遍历整个缓存（Miss的情况）</li></ul><h3 id="n-Way-Set-Associative-Cache"><a href="#n-Way-Set-Associative-Cache" class="headerlink" title="n-Way Set Associative Cache"></a>n-Way Set Associative Cache</h3><p><img src="https://s3.amazonaws.com/hs-wordpress/wp-content/uploads/2017/12/13140450/481_081.gif" alt=""><br>这就是第三种方式了，颜色相同的内存地址范围和缓存Cache Line互相对应，不能越界。每一个颜色就是一个Way。</p><p>但如果单独拿出某一个颜色来看，是Fully Associative的方式。</p><p>这么做当然是为了充分发挥前两种方式的优势。既可以存在相邻内存中的数据以提高命中，同时也一定程度上减少了查找范围，提升查找效率。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>XXV710网卡Target Link Speed探秘</title>
      <link href="/2018/11/23/x710-target-link-speed/"/>
      <url>/2018/11/23/x710-target-link-speed/</url>
      
        <content type="html"><![CDATA[<h2 id="发现"><a href="#发现" class="headerlink" title="发现"></a>发现</h2><p>用lspci指令查看PCIe设备，特别是网卡设备经常会查看LnkCap及LnkSta字段，以确保网卡运行在期望的PCIe总线类型/带宽上，从而保证网卡的性能。</p><p>最近拿到一块XXV710-DA2，插上之后简单看了一下状态。LnkCap和LnkSta均显示为Speed 8GT/s，Width x8，没太大问题。这时候无意中瞥见LnkCtl2中Target Link Speed显示为2.5GT/s，引发了兴趣。<br><a id="more"></a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</span><br><span class="line">DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not Supported</span><br><span class="line">DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled</span><br><span class="line">LnkCtl2: Target Link Speed: 2.5GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB</span><br></pre></td></tr></table></figure><h2 id="Target-Link-Speed"><a href="#Target-Link-Speed" class="headerlink" title="Target Link Speed"></a>Target Link Speed</h2><p>关于Target Link Speed是什么，查找到了Intel Skylake Processor External Design Specification(EDS)中的定义：</p><blockquote><p>For Downstream Ports, this field sets an upper limit on Link operational speed by restricting the values advertised by the Upstream component in its training sequences.</p></blockquote><p>基本上LnkCap表示支持的速度，LnkCtl2设置你需要的速度，LnkSta显示实际Training好的速度，如果想要修改的话，都是改LnkCtl2的值。</p><p>现在的问题就是LnkSta和LnkCtl2矛盾。那么我们现在这块网卡的速度到底是多少？只能实际测试一下。</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>起个<code>pktgen</code>打个性能，是能直接到线速的，也就是说Target Link Speed没有实际起到限制速度的作用。</p><p>又查询了一些资料，从这里看到一个帖子：<a href="https://communities.intel.com/thread/106568" target="_blank" rel="noopener">https://communities.intel.com/thread/106568</a></p><p>最终Intel的官方回复是，这个寄存器的值确实和实际速度没有关系。</p><p>规范也是你们写的，帖子也是你们回的，现在正话反话都让你说了，搞什么鬼。</p><p>最后查到了该寄存器的位置(D0h)，暴力修改一下：</p><p><code>setpci -s 0000:18:00.0 d0.B=3</code></p><p>然后就乖乖地显示为8GT/s了，真是个毫无脾气的寄存器，你让别的遵守规范的设备如何自处。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LnkSta:Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</span><br><span class="line">DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not Supported</span><br><span class="line">DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled</span><br><span class="line">LnkCtl2: Target Link Speed: 8GT/s, EnterCompliance- SpeedDis-Transmit Margin: Normal Operating Range, EnterModifiedCompliance-ComplianceSOS-Compliance De-emphasis: -6dB</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>程序员和工厂劳工有何不同</title>
      <link href="/2018/11/22/programmer-worker/"/>
      <url>/2018/11/22/programmer-worker/</url>
      
        <content type="html"><![CDATA[<p>如今流行的一个说法是，现在的程序员与工业时期的工厂工人并无二致。<br>均是富集于人口密集的城市、均是超时劳动、均是遭受资本家的盘剥、均是一架大机器上的螺丝钉，在超过“劳动年龄”之后被弃如敝屣。<br>基于这些相似点，有些人得出结论，程序员不过是这个时代的“无产阶级”，和以前的流水线工人，纺织厂女工属于同一社会分工和定位。<br>是否当真如此，这个问题值得仔细推敲一下。<br><a id="more"></a></p><h2 id="生产资料"><a href="#生产资料" class="headerlink" title="生产资料"></a>生产资料</h2><p>个人所处的社会阶层，取决于他能让属于他的生产资料产生的价值。传统的生产资料包括实体的机器、厂房、地皮、原材料、资本和人等等。<br>而作为信息时代的标志，人人都可以通过网络获取一项虚拟的生产资料——信息。诚然，信息壁垒依然存在，但普通人能接触到的信息总量和质量与信息革命之前的时代相比已不可同日而语。<br>程序员是与电子计算设备打交道的人，此类设备本质上是信息的产生、加工和分发工具。一台电脑加一条网线，程序员就可以以极其低廉的方式获得他所需要的生产资料。而拥有生产资料的人，就不能再称之为“无产阶级”。<br>我们已经听过了太多程序员在车库创业的故事，也许这些故事仍然可以称之为“个例”，毕竟，哪个时代没有一些白手起家的人。<br>但如果某个行业能在全社会掀起创业的热潮，那么就不能再以孤例的眼光看待。只有在该行业的生产资料极大丰富，且对再加工之后的产品有持续需求的情况下才有可能出现这类情况。<br>是否能以足够廉价的方式获取生产资料，是程序员与工厂工人的第一个区别。<br><img src="http://www.xinhuanet.com/politics/2015-05/05/127763760_14307851178281n.jpg" alt=""></p><h2 id="对生产资料的再分工"><a href="#对生产资料的再分工" class="headerlink" title="对生产资料的再分工"></a>对生产资料的再分工</h2><p>注意这里强调的是再“分”工，而不是再加工。<br>程序员能够开发出各种程序满足人们的需求，工人也能生产出各种生活必需品，所以在生产资料再加工这一点上，两者没有本质区别。<br>专业细分是社会生产率提高的根本因素。每个人只负责整条产业链中的一环，愈发细致的分工与合作是现代生产活动的组织方式。<br>程序员和工人均为某一细分领域的专家，但二者所处的分工链条深度不同。<br>工人是分工链条的末端，他所能做的就是尽自己所能做好手头的事情。<br>而程序员虽然仍然要听老板的，但他手下仍有电子设备作为分工的最后一环。<br>程序员可以通过编码为这些电子设备“分工”，从而令其为程序员服务。<br>从某种意义上说，程序员就是这些电子设备的“老板”。同时随着设备的计算能力越来越强，这些设备就能逐渐胜任更加精细的分工任务。<br>随着分工的深入，一方面带动社会整体劳动生产率的提升，一方面更加高效地产生价值。<br>一个大型工厂的老板最多能令数万工人为其服务，而所有能跑代码的设备都可能为程序员服务。<br>在分工链所处的位置和对生产资料的再分工能力，是程序员与工厂工人的第二个区别。<br><img src="http://s2.51cto.com/oss/201811/05/d0c5758831b1df8bcac6728d848e014a.jpg-wh_651x-s_1764483471.jpg" alt=""></p><h2 id="程序员如何度过”中年危机”"><a href="#程序员如何度过”中年危机”" class="headerlink" title="程序员如何度过”中年危机”"></a>程序员如何度过”中年危机”</h2><p>其实程序员是新时代的工厂工人这种论调，只不过是之前“青春饭”、“过了30岁不能再编程“等论调的新瓶装旧酒而已。<br>但程序员面对的现实压力确实是不容忽视的问题。很多人学了很多技术，掉了很多头发，但最后仍被公司扫地出门，问题就在于做了无用的努力。<br>解决之道其实就蕴含在前文论述的两点之内：</p><ul><li>尽可能占有(处理)更多的生产资料——信息</li><li>为尽可能多的电子设备”分工”</li></ul><p>实际执行的术便是一定要有自己的“产品”。<br>这当然是一个程序，可以是公司的产品，也可以是个人作品。但需要关注两个关键点：</p><ul><li>我的程序是否位于信息交叉的节点或能协助信息的获取、处理及分发</li><li>运行我的程序的设备是否在增长</li></ul><p>可以看看这些久盛不衰的“产品”：操作系统、数据库、浏览器、服务器软件、办公处理、图像应用处理等等甚或编程语言本身，都是这两个关键点的很好的体现。<br>当你拥有这样的产品时，操心的就不是公司会不会要你了，而是如何高效地指挥你自己这支被你分工的生产队，实践一些大胆的想法。<br>最后附上我最喜欢的历史名人名言作为结尾：</p><blockquote><p>臣但恐富贵来逼臣，臣无心图富贵。</p></blockquote><p>——杨素</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>几句话说清楚1:为什么CPU L1缓存容量始终很小</title>
      <link href="/2018/11/20/cachesize/"/>
      <url>/2018/11/20/cachesize/</url>
      
        <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>CPU缓存是影响软件性能的关键因素之一。在做性能调优时，经常关注的一个指标就是缓存的命中率(hit rate)。<br>缓存之所以不会达到100%的命中率，是因为缓存容量有限，不能将内存中的全部数据都同时放入其中。只能将当前最热，相邻最近的数据存入，同时还受多核CPU中缓存同步机制的影响。<br>奇怪的是，CPU的制程、晶体管数量、核心数量一直都在增加，但L1缓存的容量始终维持在一个相当低的水平。为什么不加大L1缓存呢？<br><a id="more"></a></p><p><img src="https://cenalulu.github.io/images/linux/cache_line/latency.png" alt=""></p><h2 id="缓存组织形式"><a href="#缓存组织形式" class="headerlink" title="缓存组织形式"></a>缓存组织形式</h2><p>当然要考虑到成本和功耗，以及边界效益的问题，但这些不是本文讨论的重点。<br>缓存存在的意义是当CPU需要某些数据时，能够以最快的速度给它。<br>这个速度是以CPU时钟周期为计量单位的。在这一个周期内，CPU能处理的数据量并不大。<br>作为L1缓存，首先需要做的就是把这几个周期内的数据保存好，这个确实缓存容量越大，可以做得越好。<br>但把数据喂给CPU，还需要另外一步工作——缓存的查找。<br>种种不同的缓存组织方式和对应的查找机制，其实是在命中率以及查找效率中寻找平衡。</p><p><img src="https://cs.nyu.edu/~gottlieb/courses/2000s/2007-08-fall/arch/lectures/diagrams/cache-set-assoc.png" alt=""></p><ul><li>直接映射(Direct Mapping)查找效率高，但命中率很低</li><li>全关联映射(Fully Associative Mapping)命中率会提高，但查找效率非常低，与缓存容量成反比</li><li>N路组相联映射(N-ways Set-Associative Mapping)折衷方案，平衡命中率和查找效率，也是缓存采用的组织方式</li></ul><h2 id="L1"><a href="#L1" class="headerlink" title="L1$"></a>L1$</h2><p>对L1缓存来说，任务很艰巨，既要追求命中率，同时也要保证查找效率，那么解决方法就是缩小体积。既享受N-ways Set-Associative Mapping带来的命中率，同时因为每个Set的尺寸不大，仍然会有很高的查找效率。<br>如果将缓存的容量增大，不仅仅是成本和功耗上得不偿失，也将会让缓存的查找效率降低而使缓存丧失意义。</p><p>“大曰逝，逝曰远，远曰反”，以退为进，以曲为直的道理在缓存中有了很好的体现。</p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
          <category> quickwords </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
            <tag> hardware </tag>
            
            <tag> CPU </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>top命令使用方法补遗</title>
      <link href="/2018/11/19/topcmd/"/>
      <url>/2018/11/19/topcmd/</url>
      
        <content type="html"><![CDATA[<h2 id="更改界面刷新频率"><a href="#更改界面刷新频率" class="headerlink" title="更改界面刷新频率"></a>更改界面刷新频率</h2><ul><li>自动刷新</li></ul><p><code>top</code><br><code>d</code><br>输入刷新时间（默认3秒，可调至0.5）</p><ul><li>手动刷新<br>空格</li></ul><a id="more"></a><h2 id="屏幕滚动"><a href="#屏幕滚动" class="headerlink" title="屏幕滚动"></a>屏幕滚动</h2><p>一个屏幕显示不完<br><code>C</code><br>使用方向键滚动</p><p>可用在使用<code>c</code>和<code>V</code>开启命令行及Forest view之后</p><h2 id="查看线程top信息"><a href="#查看线程top信息" class="headerlink" title="查看线程top信息"></a>查看线程top信息</h2><p><code>H</code></p><h2 id="查看线程CPU绑定-亲和性状态"><a href="#查看线程CPU绑定-亲和性状态" class="headerlink" title="查看线程CPU绑定/亲和性状态"></a>查看线程CPU绑定/亲和性状态</h2><p><code>F</code><br>移动光标至<code>Last Used Cpu</code><br>空格<br><code>q</code>返回</p><p>与<code>H</code>配合使用<br>可观察各线程是否与对应的CPU核绑定亲和性</p><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p><code>M</code>按驻留内存大小排序<br><code>P</code>按CPU使用率排序<br><code>T</code>按累计时间排序<br><code>x</code>高亮排序的列</p><h2 id="按NUMA查看CPU使用情况"><a href="#按NUMA查看CPU使用情况" class="headerlink" title="按NUMA查看CPU使用情况"></a>按NUMA查看CPU使用情况</h2><p><code>2</code>查看各NUMA节点CPU汇总使用信息<br><code>3</code>输入节点号，查看该节点各CPU使用信息</p><h2 id="按条件过滤"><a href="#按条件过滤" class="headerlink" title="按条件过滤"></a>按条件过滤</h2><p>‘O’<br>输入过滤条件，如:<br><code>!COMMAND=top</code> COMMAND栏中不包含top<br><code>%CPU&gt;3.0</code> CPU占用率大于3%<br>清除全部过滤条件 <code>=</code></p><h2 id="保存当前命令配置"><a href="#保存当前命令配置" class="headerlink" title="保存当前命令配置"></a>保存当前命令配置</h2><p><code>W</code><br>下次再启动时恢复当前配置形式</p><h2 id="其他信息"><a href="#其他信息" class="headerlink" title="其他信息"></a>其他信息</h2><p><code>man top</code></p>]]></content>
      
      
      <categories>
          
          <category> tech </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tech </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>刚日读经，柔日读史</title>
      <link href="/2018/11/18/gangrirouri/"/>
      <url>/2018/11/18/gangrirouri/</url>
      
        <content type="html"><![CDATA[<p>在不知道什么时候，我们似乎被灌输了一种互补好，什么都是互补好的认知。<br>资源要互补，团队要互补，思想要互补，连看个书也得掐着日子互补。</p><a id="more"></a><p>刚日读经，柔日读史，“刚日”就是阳数的日子，“柔日”就是阴数的日子。因为阴阳要互补，所以刚日要读致虚守弱恒常静笃的经；柔日便要读变动不居周行不殆的史。<br>为此还有各位理论导师的笺注，比如南怀瑾：</p><blockquote><p>亢阳激扬，刚也；卑幽忧昧，柔也。经主常，史主变。故刚日读经，理气养生也；柔日读史，生情造意也。有生有息，合乎天理，何乐而不为哉！</p></blockquote><p>感觉并不如我总结得那般言简意赅提要钩玄。<br>如果说这种“互补”确实在指导我们的行为，那也无可厚非。而实际上我们日常行事，却和这种思想观念有很大出入。<br>饮食上要以形补形，想要强要壮，自然是找来更强更壮的，绝对不会找短小“互补”的食材。<br>婚嫁上要强强联合，至少至少也要找个“门当户对”的。至于相互互补的情节，不是出现在少儿童话故事里，就是出现在成人童话故事里。<br>嘴里说的是阴阳互补，做的却是采阴补阳的勾当。<br>而最重要的是，没有人觉得有问题。我们妄自接受了这些观念，很少去问这些到底是什么。只是在需要的场合，程式化地提出这一观念。<br>什么是互补，什么是阴，什么是阳，什么是刚，什么是柔。如果我脑中只是一些不明来源，未经考究过的观念，那么什么是我自己。<br>更诡吊的是，人与人之间最大的仇恨与惨剧，都滥觞于这种我们根本自己也没搞清楚的观念。<br>不要说“互补”，即便是稍有不同，那便是异端邪说、是外族、是异教徒、是政治犯；那便会有党争、门户、正宗、政治清洗和宗教审判。<br>信不知凭何而信，恨不知因何而恨。被左右的观念所左右，被迷惑的语言所迷惑，操纵感官输出的表象又被表象所操纵。<br>无论刚日柔日，翻开经史，里面都是这样的故事。只要稍微读几页就会发现，与先前想的正好相反，教给你变化的其实是经，而教给你不变的是史。<br>所以这句话并不是要教给你刚柔相济之道，而是提醒你认清人心之妄作，行为之颠倒，以及，追求真实的难能可贵。<br>谨录于上，念念不忘。</p>]]></content>
      
      
      <categories>
          
          <category> thoughts </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thoughts </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>如何在偷偷搜索关键字后避免令人尴尬的广告</title>
      <link href="/2018/11/17/duckduckgo/"/>
      <url>/2018/11/17/duckduckgo/</url>
      
        <content type="html"><![CDATA[<blockquote><p>转载自<a href="https://cloudwonders.info" target="_blank" rel="noopener">cloudwonders.info</a></p></blockquote><p>当你在任意一个搜索引擎输入一个关键词之后，你就成了全网全平台追逐的流量热点。</p><p>平时大打口水战的各大平台在共享你的隐私数据方面异常团结，在B系网站搜索，在A系T系的应用APP上都会看到为你“量身定制”的推送和广告，延迟不超过一分钟。</p><a id="more"></a><p>这一点即便是业界道德楷模G老师都未能免俗，毕竟它也要靠着广告收入维持其智能推荐算法引擎的研发投入。</p><p>最可气的是，推送些边栏广告也就算了，竟然连自己看的新闻和短视频内容也都要和搜索记录沾边，在聚会上随便刷下手机就暴露了自己到底是个什么货色。</p><p>网络对你的监视是全方位的，除了你主动输入的那些关键字，你平时的谈话、你的地理位置，你周围的环境照片都会被偷偷记录上传，用以支撑靠勤劳质朴的城镇劳动人民手动打标签的“人工”智能工程师们的高薪。</p><p>当个人隐私在巨头面前节节败退，当生而为人的尊严在利益机器面前粉碎，当你不能说的秘密被拿来公开叫卖和嘲弄，当互联网利用你心底的弱点反过来操控你之时，难道就没有一款可以放心解放双手，安全地释放自己的求知欲，满足人类最原始的好奇的搜索引擎吗？当然不是这样的鸭——</p><p><img src="http://ww1.sinaimg.cn/large/73403117ly1fhsqrvtg20j223w1kwq8e.jpg?imageView2/2/w/1120/q/90/interlace/1/ignore-error/1" alt=""></p><p>这个创立于2008年的搜索引擎，十年来一直在巨头的夹击下惨淡经营。如果没有愈演愈烈的互联网隐私泄露事件、没棱镜门、没有小扎的听证会，恐怕Duckduckgo也不会有近来的长足发展。</p><p><img src="https://i.loli.net/2018/11/05/5be057be3a57f.jpg" alt=""></p><p>Duckduckgo从创立之初秉承的理念就是不对用户的搜索做任何追踪与记录，不把用户的隐私和数据当作公司的资产，做好一个搜索引擎的本分。自2018年之初，该搜索引擎已每日接受多于两千万次的匿名搜索。</p><p>Duckduckgo的使用方式与其他搜索引擎没有区别，唯一的不同就是搜索之后在其他任何平台没有相关的广告推送。至于搜索本身的质量和水平，笔者简单做了个对比：</p><p><img src="https://i.loli.net/2018/11/05/5be057fe2c0e7.png" alt=""></p><p>应当说完全可以满足日常应用，不说超越G老师，超越B老师应该是问题不大。同时不用担心在互联网大机器下无所遁形。已经有越来越多的朋友和公司将Duckduckgo设置为了默认搜索引擎。</p><p>如果说互联网早已是赢家通吃的寡头时代，用隐私交换在线服务已如缴纳“人头税“一般自然，而在这万马齐喑的时刻，Duckduckgo代表的是一豆星星点点的亮光，为所有在歌舞升平中“心怀鬼胎“的人们擎举起惊奇与愤怒的能力。可以放心大胆地搜索不可描述内容的传送门：<a href="https://www.duckduckgo.com" target="_blank" rel="noopener">https://www.duckduckgo.com</a></p>]]></content>
      
      
      <categories>
          
          <category> wonder </category>
          
      </categories>
      
      
        <tags>
            
            <tag> resources </tag>
            
            <tag> wonder </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
